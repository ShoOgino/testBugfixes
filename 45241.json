{"path":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":null,"sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9c8b12bda3f5864b27e3e04df1be4f6736ec067a","date":1270088127,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.snowball.SnowballFilter\");\n    assertNotNull(\"Expecting the 'SnowballFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.snowball.SnowballFilter\");\n    assertNotNull(\"Expecting the 'SnowballFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.solr.analysis.EnglishPorterFilter\");\n    assertNotNull(\"Expecting the 'EnglishPorterFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3b8d301760a29119d797c1dd47f32bd442c1b562","date":1270142652,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.snowball.SnowballFilter\");\n    assertNotNull(\"Expecting the 'SnowballFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.snowball.SnowballFilter\");\n    assertNotNull(\"Expecting the 'SnowballFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"689f35bd9818b47b8d9fe96cf06518228e949ab6","date":1272894884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"790c3f61c9b891d66d919c5d10db9fa5216eb0f1","date":1274818604,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bd0a7f04b5a49a00149b867e7d51f632fb8a4664","date":1279497978,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0487f900016b7da69f089f740e28192189ef3972","date":1307810819,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, \"1\", null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, \"1\", null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, \"1\", null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, \"1\", null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, \"2\", null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, \"1\", null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, \"1/1\", null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, \"1/1/1\", null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, \"1/1/1/1\", null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, \"1/1/1/1/1\", null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, \"1\", null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, \"2\", null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, \"3\", null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, \"4\", null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, \"5\", null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, \"6\", null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, \"1/1\", null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, \"2/2\", null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, \"3/3\", null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, \"4/4\", null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, \"5/5\", null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, \"6/6\", null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, \"1/1/1\", null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, \"2/2/2\", null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, \"3/3/3\", null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, \"4/4/4\", null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, \"5/5/5\", null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, \"6/6/6\", null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, \"2/2/2/1\", null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, \"3/3/3/2\", null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, \"4/4/4/3\", null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, \"6/6/6/4\", null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, \"2/2/2/1/1\", null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, \"3/3/3/2/2\", null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, \"4/4/4/3/3\", null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, \"6/6/6/4/4\", null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02dba75457528db0b73837ff68f971ecb715ab78","date":1307981000,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, \"1\", null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, \"1\", null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, \"1\", null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, \"1\", null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, \"2\", null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, \"1\", null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, \"1/1\", null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, \"1/1/1\", null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, \"1/1/1/1\", null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, \"1/1/1/1/1\", null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, \"1\", null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, \"2\", null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, \"3\", null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, \"4\", null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, \"5\", null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, \"6\", null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, \"1/1\", null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, \"2/2\", null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, \"3/3\", null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, \"4/4\", null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, \"5/5\", null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, \"6/6\", null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, \"1/1/1\", null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, \"2/2/2\", null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, \"3/3/3\", null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, \"4/4/4\", null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, \"5/5/5\", null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, \"6/6/6\", null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, \"2/2/2/1\", null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, \"3/3/3/2\", null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, \"4/4/4/3\", null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, \"6/6/6/4\", null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, \"2/2/2/1/1\", null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, \"3/3/3/2/2\", null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, \"4/4/4/3/3\", null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, \"6/6/6/4/4\", null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9ed208afa1e7aa98899ddb1dedfddedddf898253","date":1308079587,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","pathOld":"solr/src/test/org/apache/solr/handler/DocumentAnalysisRequestHandlerTest#testHandleAnalysisRequest().mjava","sourceNew":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","sourceOld":"  /**\n   * Tests the {@link DocumentAnalysisRequestHandler#handleAnalysisRequest(org.apache.solr.client.solrj.request.DocumentAnalysisRequest,\n   * org.apache.solr.schema.IndexSchema)}\n   */\n  @Test\n  public void testHandleAnalysisRequest() throws Exception {\n\n    SolrInputDocument document = new SolrInputDocument();\n    document.addField(\"id\", 1);\n    document.addField(\"whitetok\", \"Jumping Jack\");\n    document.addField(\"text\", \"The Fox Jumped Over The Dogs\");\n\n    DocumentAnalysisRequest request = new DocumentAnalysisRequest()\n            .setQuery(\"JUMPING\")\n            .setShowMatch(true)\n            .addDocument(document);\n\n    NamedList<Object> result = handler.handleAnalysisRequest(request, h.getCore().getSchema());\n    assertNotNull(\"result is null and it shouldn't be\", result);\n    NamedList<NamedList<NamedList<Object>>> documentResult = (NamedList<NamedList<NamedList<Object>>>) result.get(\"1\");\n    assertNotNull(\"An analysis for document with key '1' should be returned\", documentResult);\n\n    // the id field\n    NamedList<NamedList<Object>> idResult = documentResult.get(\"id\");\n    assertNotNull(\"an analysis for the 'id' field should be returned\", idResult);\n\n    NamedList<Object> queryResult;\n    List<NamedList> tokenList;\n    NamedList<Object> indexResult;\n    NamedList<List<NamedList>> valueResult;\n\n    /*** Much of this test seems invalid for a numeric \"id\" field\n    NamedList<Object> queryResult = idResult.get(\"query\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, queryResult.size());\n    String name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    List<NamedList> tokenList = (List<NamedList>) queryResult.getVal(0);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    NamedList<Object> indexResult = idResult.get(\"index\");\n\n    assertEquals(\"The id field has only a single value\", 1, indexResult.size());\n    NamedList<List<NamedList>> valueResult = (NamedList<List<NamedList>>) indexResult.get(\"1\");\n    assertEquals(\"Only the default analyzer should be applied\", 1, valueResult.size());\n    name = queryResult.getName(0);\n    assertTrue(\"Only the default analyzer should be applied\", name.matches(\"org.apache.solr.schema.FieldType\\\\$DefaultAnalyzer.*\"));\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"The 'id' field value has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"1\", null, \"word\", 0, 1, 1, new int[]{1}, null, false));\n    ***/\n  \n    // the name field\n    NamedList<NamedList<Object>> whitetokResult = documentResult.get(\"whitetok\");\n    assertNotNull(\"an analysis for the 'whitetok' field should be returned\", whitetokResult);\n    queryResult = whitetokResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.WhitespaceTokenizer\");\n    assertNotNull(\"Expecting the 'WhitespaceTokenizer' to be applied on the query for the 'whitetok' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    indexResult = whitetokResult.get(\"index\");\n    assertEquals(\"The 'whitetok' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"Jumping Jack\");\n    tokenList = valueResult.getVal(0);\n    assertEquals(\"Expecting 2 tokens to be present\", 2, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"Jumping\", null, \"word\", 0, 7, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Jack\", null, \"word\", 8, 12, 2, new int[]{2}, null, false));\n\n    // the text field\n    NamedList<NamedList<Object>> textResult = documentResult.get(\"text\");\n    assertNotNull(\"an analysis for the 'text' field should be returned\", textResult);\n    queryResult = textResult.get(\"query\");\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"JUMPING\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jumping\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1}, null, false));\n    tokenList = (List<NamedList>) queryResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the query for the 'text' field\", tokenList);\n    assertEquals(\"Query has only one token\", 1, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 0, 7, 1, new int[]{1,1,1,1,1}, null, false));\n    indexResult = textResult.get(\"index\");\n    assertEquals(\"The 'text' field has only a single value\", 1, indexResult.size());\n    valueResult = (NamedList<List<NamedList>>) indexResult.get(\"The Fox Jumped Over The Dogs\");\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardTokenizer\");\n    assertNotNull(\"Expecting the 'StandardTokenizer' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.standard.StandardFilter\");\n    assertNotNull(\"Expecting the 'StandardFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"Fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"Jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"Over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"The\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"Dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.LowerCaseFilter\");\n    assertNotNull(\"Expecting the 'LowerCaseFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 6 tokens\", 6, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 0, 3, 1, new int[]{1,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 2, new int[]{2,2,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 3, new int[]{3,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 4, new int[]{4,4,4}, null, false));\n    assertToken(tokenList.get(4), new TokenInfo(\"the\", null, \"<ALPHANUM>\", 20, 23, 5, new int[]{5,5,5}, null, false));\n    assertToken(tokenList.get(5), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 6, new int[]{6,6,6}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.core.StopFilter\");\n    assertNotNull(\"Expecting the 'StopFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens after stop word removal\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jumped\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2}, null, false));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dogs\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4}, null, false));\n    tokenList = valueResult.get(\"org.apache.lucene.analysis.en.PorterStemFilter\");\n    assertNotNull(\"Expecting the 'PorterStemFilter' to be applied on the index for the 'text' field\", tokenList);\n    assertEquals(\"Expecting 4 tokens\", 4, tokenList.size());\n    assertToken(tokenList.get(0), new TokenInfo(\"fox\", null, \"<ALPHANUM>\", 4, 7, 1, new int[]{2,2,2,1,1}, null, false));\n    assertToken(tokenList.get(1), new TokenInfo(\"jump\", null, \"<ALPHANUM>\", 8, 14, 2, new int[]{3,3,3,2,2}, null, true));\n    assertToken(tokenList.get(2), new TokenInfo(\"over\", null, \"<ALPHANUM>\", 15, 19, 3, new int[]{4,4,4,3,3}, null, false));\n    assertToken(tokenList.get(3), new TokenInfo(\"dog\", null, \"<ALPHANUM>\", 24, 28, 4, new int[]{6,6,6,4,4}, null, false));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c26f00b574427b55127e869b935845554afde1fa":["02dba75457528db0b73837ff68f971ecb715ab78","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"0487f900016b7da69f089f740e28192189ef3972":["bd0a7f04b5a49a00149b867e7d51f632fb8a4664"],"5f4e87790277826a2aea119328600dfb07761f32":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1","bd0a7f04b5a49a00149b867e7d51f632fb8a4664"],"9ed208afa1e7aa98899ddb1dedfddedddf898253":["bd0a7f04b5a49a00149b867e7d51f632fb8a4664","02dba75457528db0b73837ff68f971ecb715ab78"],"9c8b12bda3f5864b27e3e04df1be4f6736ec067a":["1da8d55113b689b06716246649de6f62430f15c0"],"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"689f35bd9818b47b8d9fe96cf06518228e949ab6":["3b8d301760a29119d797c1dd47f32bd442c1b562"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["9ed208afa1e7aa98899ddb1dedfddedddf898253"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"02dba75457528db0b73837ff68f971ecb715ab78":["0487f900016b7da69f089f740e28192189ef3972"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["02dba75457528db0b73837ff68f971ecb715ab78"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"],"bd0a7f04b5a49a00149b867e7d51f632fb8a4664":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1"],"790c3f61c9b891d66d919c5d10db9fa5216eb0f1":["689f35bd9818b47b8d9fe96cf06518228e949ab6"],"3b8d301760a29119d797c1dd47f32bd442c1b562":["9c8b12bda3f5864b27e3e04df1be4f6736ec067a"]},"commit2Childs":{"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"0487f900016b7da69f089f740e28192189ef3972":["02dba75457528db0b73837ff68f971ecb715ab78"],"5f4e87790277826a2aea119328600dfb07761f32":[],"9ed208afa1e7aa98899ddb1dedfddedddf898253":["c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"9c8b12bda3f5864b27e3e04df1be4f6736ec067a":["3b8d301760a29119d797c1dd47f32bd442c1b562"],"1da8d55113b689b06716246649de6f62430f15c0":["9c8b12bda3f5864b27e3e04df1be4f6736ec067a"],"689f35bd9818b47b8d9fe96cf06518228e949ab6":["790c3f61c9b891d66d919c5d10db9fa5216eb0f1"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"02dba75457528db0b73837ff68f971ecb715ab78":["c26f00b574427b55127e869b935845554afde1fa","9ed208afa1e7aa98899ddb1dedfddedddf898253","a258fbb26824fd104ed795e5d9033d2d040049ee"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"bd0a7f04b5a49a00149b867e7d51f632fb8a4664":["0487f900016b7da69f089f740e28192189ef3972","5f4e87790277826a2aea119328600dfb07761f32","9ed208afa1e7aa98899ddb1dedfddedddf898253"],"790c3f61c9b891d66d919c5d10db9fa5216eb0f1":["5f4e87790277826a2aea119328600dfb07761f32","bd0a7f04b5a49a00149b867e7d51f632fb8a4664"],"3b8d301760a29119d797c1dd47f32bd442c1b562":["689f35bd9818b47b8d9fe96cf06518228e949ab6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5f4e87790277826a2aea119328600dfb07761f32","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}