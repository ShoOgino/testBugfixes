{"path":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","commits":[{"id":"70f91c8322fbffe3a3a897ef20ea19119cac10cd","date":1386170124,"type":1,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","pathOld":"solr/contrib/solr-mr/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","sourceNew":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.currentTimeMillis();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<Request>(executor);\n      Set<Future<Request>> pending = new HashSet<Future<Request>>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              final HttpSolrServer server = new HttpSolrServer(mergeUrl);\n              try {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                try {\n                  mergeRequest.process(server);\n                  req.success = true;\n                } catch (SolrServerException e) {\n                  req.e = e;\n                  return req;\n                } catch (IOException e) {\n                  req.e = e;\n                  return req;\n                }\n              } finally {\n                server.shutdown();\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          CloudSolrServer server = new CloudSolrServer(options.zkHost);\n          server.setDefaultCollection(options.collection);\n          server.commit();\n          server.shutdown();\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              HttpSolrServer server = new HttpSolrServer(url);\n              server.commit();\n              server.shutdown();\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      shutdownNowAndAwaitTermination(executor);\n      float secs = (System.currentTimeMillis() - start) / 1000.0f;\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","sourceOld":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.currentTimeMillis();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<Request>(executor);\n      Set<Future<Request>> pending = new HashSet<Future<Request>>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              final HttpSolrServer server = new HttpSolrServer(mergeUrl);\n              try {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                try {\n                  mergeRequest.process(server);\n                  req.success = true;\n                } catch (SolrServerException e) {\n                  req.e = e;\n                  return req;\n                } catch (IOException e) {\n                  req.e = e;\n                  return req;\n                }\n              } finally {\n                server.shutdown();\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          CloudSolrServer server = new CloudSolrServer(options.zkHost);\n          server.setDefaultCollection(options.collection);\n          server.commit();\n          server.shutdown();\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              HttpSolrServer server = new HttpSolrServer(url);\n              server.commit();\n              server.shutdown();\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      shutdownNowAndAwaitTermination(executor);\n      float secs = (System.currentTimeMillis() - start) / 1000.0f;\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","pathOld":"/dev/null","sourceNew":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.currentTimeMillis();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<Request>(executor);\n      Set<Future<Request>> pending = new HashSet<Future<Request>>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              final HttpSolrServer server = new HttpSolrServer(mergeUrl);\n              try {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                try {\n                  mergeRequest.process(server);\n                  req.success = true;\n                } catch (SolrServerException e) {\n                  req.e = e;\n                  return req;\n                } catch (IOException e) {\n                  req.e = e;\n                  return req;\n                }\n              } finally {\n                server.shutdown();\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          CloudSolrServer server = new CloudSolrServer(options.zkHost);\n          server.setDefaultCollection(options.collection);\n          server.commit();\n          server.shutdown();\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              HttpSolrServer server = new HttpSolrServer(url);\n              server.commit();\n              server.shutdown();\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      shutdownNowAndAwaitTermination(executor);\n      float secs = (System.currentTimeMillis() - start) / 1000.0f;\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd5bc858b8426d40bbe90b94120ead37c77d7954","date":1393812525,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","sourceNew":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<Request>(executor);\n      Set<Future<Request>> pending = new HashSet<Future<Request>>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              final HttpSolrServer server = new HttpSolrServer(mergeUrl);\n              try {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                try {\n                  mergeRequest.process(server);\n                  req.success = true;\n                } catch (SolrServerException e) {\n                  req.e = e;\n                  return req;\n                } catch (IOException e) {\n                  req.e = e;\n                  return req;\n                }\n              } finally {\n                server.shutdown();\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          CloudSolrServer server = new CloudSolrServer(options.zkHost);\n          server.setDefaultCollection(options.collection);\n          server.commit();\n          server.shutdown();\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              HttpSolrServer server = new HttpSolrServer(url);\n              server.commit();\n              server.shutdown();\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      shutdownNowAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","sourceOld":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.currentTimeMillis();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<Request>(executor);\n      Set<Future<Request>> pending = new HashSet<Future<Request>>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              final HttpSolrServer server = new HttpSolrServer(mergeUrl);\n              try {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                try {\n                  mergeRequest.process(server);\n                  req.success = true;\n                } catch (SolrServerException e) {\n                  req.e = e;\n                  return req;\n                } catch (IOException e) {\n                  req.e = e;\n                  return req;\n                }\n              } finally {\n                server.shutdown();\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          CloudSolrServer server = new CloudSolrServer(options.zkHost);\n          server.setDefaultCollection(options.collection);\n          server.commit();\n          server.shutdown();\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              HttpSolrServer server = new HttpSolrServer(url);\n              server.commit();\n              server.shutdown();\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      shutdownNowAndAwaitTermination(executor);\n      float secs = (System.currentTimeMillis() - start) / 1000.0f;\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","sourceNew":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              final HttpSolrServer server = new HttpSolrServer(mergeUrl);\n              try {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                try {\n                  mergeRequest.process(server);\n                  req.success = true;\n                } catch (SolrServerException e) {\n                  req.e = e;\n                  return req;\n                } catch (IOException e) {\n                  req.e = e;\n                  return req;\n                }\n              } finally {\n                server.shutdown();\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          CloudSolrServer server = new CloudSolrServer(options.zkHost);\n          server.setDefaultCollection(options.collection);\n          server.commit();\n          server.shutdown();\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              HttpSolrServer server = new HttpSolrServer(url);\n              server.commit();\n              server.shutdown();\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      shutdownNowAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","sourceOld":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<Request>(executor);\n      Set<Future<Request>> pending = new HashSet<Future<Request>>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              final HttpSolrServer server = new HttpSolrServer(mergeUrl);\n              try {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                try {\n                  mergeRequest.process(server);\n                  req.success = true;\n                } catch (SolrServerException e) {\n                  req.e = e;\n                  return req;\n                } catch (IOException e) {\n                  req.e = e;\n                  return req;\n                }\n              } finally {\n                server.shutdown();\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          CloudSolrServer server = new CloudSolrServer(options.zkHost);\n          server.setDefaultCollection(options.collection);\n          server.commit();\n          server.shutdown();\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              HttpSolrServer server = new HttpSolrServer(url);\n              server.commit();\n              server.shutdown();\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      shutdownNowAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bafca15d8e408346a67f4282ad1143b88023893b","date":1420034748,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","sourceNew":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              final HttpSolrClient server = new HttpSolrClient(mergeUrl);\n              try {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                try {\n                  mergeRequest.process(server);\n                  req.success = true;\n                } catch (SolrServerException e) {\n                  req.e = e;\n                  return req;\n                } catch (IOException e) {\n                  req.e = e;\n                  return req;\n                }\n              } finally {\n                server.shutdown();\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          CloudSolrClient server = new CloudSolrClient(options.zkHost);\n          server.setDefaultCollection(options.collection);\n          server.commit();\n          server.shutdown();\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              HttpSolrClient server = new HttpSolrClient(url);\n              server.commit();\n              server.shutdown();\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      shutdownNowAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","sourceOld":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              final HttpSolrServer server = new HttpSolrServer(mergeUrl);\n              try {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                try {\n                  mergeRequest.process(server);\n                  req.success = true;\n                } catch (SolrServerException e) {\n                  req.e = e;\n                  return req;\n                } catch (IOException e) {\n                  req.e = e;\n                  return req;\n                }\n              } finally {\n                server.shutdown();\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          CloudSolrServer server = new CloudSolrServer(options.zkHost);\n          server.setDefaultCollection(options.collection);\n          server.commit();\n          server.shutdown();\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              HttpSolrServer server = new HttpSolrServer(url);\n              server.commit();\n              server.shutdown();\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      shutdownNowAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cc3b13b430571c2e169f98fe38e1e7666f88522d","date":1422446157,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","sourceNew":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              try (final HttpSolrClient client = new HttpSolrClient(mergeUrl)) {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                mergeRequest.process(client);\n                req.success = true;\n              } catch (SolrServerException | IOException e) {\n                req.e = e;\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          try (CloudSolrClient server = new CloudSolrClient(options.zkHost)) {\n            server.setDefaultCollection(options.collection);\n            server.commit();\n          }\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              try (HttpSolrClient server = new HttpSolrClient(url)) {\n                server.commit();\n              }\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      shutdownNowAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","sourceOld":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              final HttpSolrClient server = new HttpSolrClient(mergeUrl);\n              try {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                try {\n                  mergeRequest.process(server);\n                  req.success = true;\n                } catch (SolrServerException e) {\n                  req.e = e;\n                  return req;\n                } catch (IOException e) {\n                  req.e = e;\n                  return req;\n                }\n              } finally {\n                server.shutdown();\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          CloudSolrClient server = new CloudSolrClient(options.zkHost);\n          server.setDefaultCollection(options.collection);\n          server.commit();\n          server.shutdown();\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              HttpSolrClient server = new HttpSolrClient(url);\n              server.commit();\n              server.shutdown();\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      shutdownNowAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4a04721f602dc10b140dca8dd0fce9d43079f8f1","date":1428994252,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","sourceNew":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ExecutorUtil.MDCAwareThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              try (final HttpSolrClient client = new HttpSolrClient(mergeUrl)) {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                mergeRequest.process(client);\n                req.success = true;\n              } catch (SolrServerException | IOException e) {\n                req.e = e;\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          try (CloudSolrClient server = new CloudSolrClient(options.zkHost)) {\n            server.setDefaultCollection(options.collection);\n            server.commit();\n          }\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              try (HttpSolrClient server = new HttpSolrClient(url)) {\n                server.commit();\n              }\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      shutdownNowAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","sourceOld":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              try (final HttpSolrClient client = new HttpSolrClient(mergeUrl)) {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                mergeRequest.process(client);\n                req.success = true;\n              } catch (SolrServerException | IOException e) {\n                req.e = e;\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          try (CloudSolrClient server = new CloudSolrClient(options.zkHost)) {\n            server.setDefaultCollection(options.collection);\n            server.commit();\n          }\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              try (HttpSolrClient server = new HttpSolrClient(url)) {\n                server.commit();\n              }\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      shutdownNowAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70d61fdc6a5871f80a74c0e2e55bb8a94e9ac59d","date":1440987729,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","sourceNew":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ExecutorUtil.MDCAwareThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              try (final HttpSolrClient client = new HttpSolrClient(mergeUrl)) {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                mergeRequest.process(client);\n                req.success = true;\n              } catch (SolrServerException | IOException e) {\n                req.e = e;\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          try (CloudSolrClient server = new CloudSolrClient(options.zkHost)) {\n            server.setDefaultCollection(options.collection);\n            server.commit();\n          }\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              try (HttpSolrClient server = new HttpSolrClient(url)) {\n                server.commit();\n              }\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      ExecutorUtil.shutdownAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","sourceOld":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ExecutorUtil.MDCAwareThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              try (final HttpSolrClient client = new HttpSolrClient(mergeUrl)) {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                mergeRequest.process(client);\n                req.success = true;\n              } catch (SolrServerException | IOException e) {\n                req.e = e;\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          try (CloudSolrClient server = new CloudSolrClient(options.zkHost)) {\n            server.setDefaultCollection(options.collection);\n            server.commit();\n          }\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              try (HttpSolrClient server = new HttpSolrClient(url)) {\n                server.commit();\n              }\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      shutdownNowAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"043df2e9a841864922c32756a44c939ed768cb89","date":1459876536,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","sourceNew":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ExecutorUtil.MDCAwareThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = () -> {\n            Request req = new Request();\n            LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n            try (final HttpSolrClient client = new HttpSolrClient(mergeUrl)) {\n              CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n              mergeRequest.setCoreName(name);\n              mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n              mergeRequest.process(client);\n              req.success = true;\n            } catch (SolrServerException | IOException e) {\n              req.e = e;\n            }\n            return req;\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          try (CloudSolrClient server = new CloudSolrClient(options.zkHost)) {\n            server.setDefaultCollection(options.collection);\n            server.commit();\n          }\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              try (HttpSolrClient server = new HttpSolrClient(url)) {\n                server.commit();\n              }\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      ExecutorUtil.shutdownAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","sourceOld":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ExecutorUtil.MDCAwareThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              try (final HttpSolrClient client = new HttpSolrClient(mergeUrl)) {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                mergeRequest.process(client);\n                req.success = true;\n              } catch (SolrServerException | IOException e) {\n                req.e = e;\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          try (CloudSolrClient server = new CloudSolrClient(options.zkHost)) {\n            server.setDefaultCollection(options.collection);\n            server.commit();\n          }\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              try (HttpSolrClient server = new HttpSolrClient(url)) {\n                server.commit();\n              }\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      ExecutorUtil.shutdownAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6284684320a9808c41a5e43de958b2da22f89bd","date":1459977490,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","sourceNew":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ExecutorUtil.MDCAwareThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = () -> {\n            Request req = new Request();\n            LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n            try (final HttpSolrClient client = new HttpSolrClient(mergeUrl)) {\n              CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n              mergeRequest.setCoreName(name);\n              mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n              mergeRequest.process(client);\n              req.success = true;\n            } catch (SolrServerException | IOException e) {\n              req.e = e;\n            }\n            return req;\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          try (CloudSolrClient server = new CloudSolrClient(options.zkHost)) {\n            server.setDefaultCollection(options.collection);\n            server.commit();\n          }\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              try (HttpSolrClient server = new HttpSolrClient(url)) {\n                server.commit();\n              }\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      ExecutorUtil.shutdownAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","sourceOld":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ExecutorUtil.MDCAwareThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = new Callable<Request>() {\n            @Override\n            public Request call() {\n              Request req = new Request();\n              LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n              try (final HttpSolrClient client = new HttpSolrClient(mergeUrl)) {\n                CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n                mergeRequest.setCoreName(name);\n                mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n                mergeRequest.process(client);\n                req.success = true;\n              } catch (SolrServerException | IOException e) {\n                req.e = e;\n              }\n              return req;\n            }\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          try (CloudSolrClient server = new CloudSolrClient(options.zkHost)) {\n            server.setDefaultCollection(options.collection);\n            server.commit();\n          }\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              try (HttpSolrClient server = new HttpSolrClient(url)) {\n                server.commit();\n              }\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      ExecutorUtil.shutdownAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e3c94a8b8bf47db4f968d9ae510ec8bbe1372088","date":1460069869,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","sourceNew":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ExecutorUtil.MDCAwareThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = () -> {\n            Request req = new Request();\n            LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n            try (final HttpSolrClient client = new HttpSolrClient.Builder(mergeUrl).build()) {\n              CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n              mergeRequest.setCoreName(name);\n              mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n              mergeRequest.process(client);\n              req.success = true;\n            } catch (SolrServerException | IOException e) {\n              req.e = e;\n            }\n            return req;\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          try (CloudSolrClient server = new CloudSolrClient.Builder().withZkHost(options.zkHost).build()) {\n            server.setDefaultCollection(options.collection);\n            server.commit();\n          }\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              try (HttpSolrClient server = new HttpSolrClient.Builder(url).build()) {\n                server.commit();\n              }\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      ExecutorUtil.shutdownAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","sourceOld":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ExecutorUtil.MDCAwareThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = () -> {\n            Request req = new Request();\n            LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n            try (final HttpSolrClient client = new HttpSolrClient(mergeUrl)) {\n              CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n              mergeRequest.setCoreName(name);\n              mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n              mergeRequest.process(client);\n              req.success = true;\n            } catch (SolrServerException | IOException e) {\n              req.e = e;\n            }\n            return req;\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          try (CloudSolrClient server = new CloudSolrClient(options.zkHost)) {\n            server.setDefaultCollection(options.collection);\n            server.commit();\n          }\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              try (HttpSolrClient server = new HttpSolrClient(url)) {\n                server.commit();\n              }\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      ExecutorUtil.shutdownAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5bdaf2cee03ff78b0a0cbf23df0095a3590b493b","date":1460110033,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","sourceNew":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ExecutorUtil.MDCAwareThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = () -> {\n            Request req = new Request();\n            LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n            try (final HttpSolrClient client = new HttpSolrClient.Builder(mergeUrl).build()) {\n              CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n              mergeRequest.setCoreName(name);\n              mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n              mergeRequest.process(client);\n              req.success = true;\n            } catch (SolrServerException | IOException e) {\n              req.e = e;\n            }\n            return req;\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          try (CloudSolrClient server = new CloudSolrClient.Builder().withZkHost(options.zkHost).build()) {\n            server.setDefaultCollection(options.collection);\n            server.commit();\n          }\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              try (HttpSolrClient server = new HttpSolrClient.Builder(url).build()) {\n                server.commit();\n              }\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      ExecutorUtil.shutdownAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","sourceOld":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ExecutorUtil.MDCAwareThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = () -> {\n            Request req = new Request();\n            LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n            try (final HttpSolrClient client = new HttpSolrClient(mergeUrl)) {\n              CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n              mergeRequest.setCoreName(name);\n              mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n              mergeRequest.process(client);\n              req.success = true;\n            } catch (SolrServerException | IOException e) {\n              req.e = e;\n            }\n            return req;\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          try (CloudSolrClient server = new CloudSolrClient(options.zkHost)) {\n            server.setDefaultCollection(options.collection);\n            server.commit();\n          }\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              try (HttpSolrClient server = new HttpSolrClient(url)) {\n                server.commit();\n              }\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      ExecutorUtil.shutdownAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"12109b652e9210b8d58fca47f6c4a725d058a58e","date":1490373076,"type":4,"author":"Steve Rowe","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","sourceNew":null,"sourceOld":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ExecutorUtil.MDCAwareThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = () -> {\n            Request req = new Request();\n            LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n            try (final HttpSolrClient client = new HttpSolrClient.Builder(mergeUrl).build()) {\n              CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n              mergeRequest.setCoreName(name);\n              mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n              mergeRequest.process(client);\n              req.success = true;\n            } catch (SolrServerException | IOException e) {\n              req.e = e;\n            }\n            return req;\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          try (CloudSolrClient server = new CloudSolrClient.Builder().withZkHost(options.zkHost).build()) {\n            server.setDefaultCollection(options.collection);\n            server.commit();\n          }\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              try (HttpSolrClient server = new HttpSolrClient.Builder(url).build()) {\n                server.commit();\n              }\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      ExecutorUtil.shutdownAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe1c4aa9af769a38e878f608070f672efbeac27f","date":1490594650,"type":4,"author":"Steve Rowe","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive#goLive(Options,FileStatus[]).mjava","sourceNew":null,"sourceOld":"  // TODO: handle clusters with replicas\n  public boolean goLive(Options options, FileStatus[] outDirs) {\n    LOG.info(\"Live merging of output shards into Solr cluster...\");\n    boolean success = false;\n    long start = System.nanoTime();\n    int concurrentMerges = options.goLiveThreads;\n    ThreadPoolExecutor executor = new ExecutorUtil.MDCAwareThreadPoolExecutor(concurrentMerges,\n        concurrentMerges, 1, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<Runnable>());\n    \n    try {\n      CompletionService<Request> completionService = new ExecutorCompletionService<>(executor);\n      Set<Future<Request>> pending = new HashSet<>();\n      int cnt = -1;\n      for (final FileStatus dir : outDirs) {\n        \n        LOG.debug(\"processing: \" + dir.getPath());\n\n        cnt++;\n        List<String> urls = options.shardUrls.get(cnt);\n        \n        for (String url : urls) {\n          \n          String baseUrl = url;\n          if (baseUrl.endsWith(\"/\")) {\n            baseUrl = baseUrl.substring(0, baseUrl.length() - 1);\n          }\n          \n          int lastPathIndex = baseUrl.lastIndexOf(\"/\");\n          if (lastPathIndex == -1) {\n            LOG.error(\"Found unexpected shardurl, live merge failed: \" + baseUrl);\n            return false;\n          }\n          \n          final String name = baseUrl.substring(lastPathIndex + 1);\n          baseUrl = baseUrl.substring(0, lastPathIndex);\n          final String mergeUrl = baseUrl;\n          \n          Callable<Request> task = () -> {\n            Request req = new Request();\n            LOG.info(\"Live merge \" + dir.getPath() + \" into \" + mergeUrl);\n            try (final HttpSolrClient client = new HttpSolrClient.Builder(mergeUrl).build()) {\n              CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();\n              mergeRequest.setCoreName(name);\n              mergeRequest.setIndexDirs(Arrays.asList(dir.getPath().toString() + \"/data/index\"));\n              mergeRequest.process(client);\n              req.success = true;\n            } catch (SolrServerException | IOException e) {\n              req.e = e;\n            }\n            return req;\n          };\n          pending.add(completionService.submit(task));\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n          Future<Request> future = completionService.take();\n          if (future == null) break;\n          pending.remove(future);\n          \n          try {\n            Request req = future.get();\n            \n            if (!req.success) {\n              // failed\n              LOG.error(\"A live merge command failed\", req.e);\n              return false;\n            }\n            \n          } catch (ExecutionException e) {\n            LOG.error(\"Error sending live merge command\", e);\n            return false;\n          }\n          \n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          LOG.error(\"Live merge process interrupted\", e);\n          return false;\n        }\n      }\n      \n      cnt = -1;\n      \n      \n      try {\n        LOG.info(\"Committing live merge...\");\n        if (options.zkHost != null) {\n          try (CloudSolrClient server = new CloudSolrClient.Builder().withZkHost(options.zkHost).build()) {\n            server.setDefaultCollection(options.collection);\n            server.commit();\n          }\n        } else {\n          for (List<String> urls : options.shardUrls) {\n            for (String url : urls) {\n              // TODO: we should do these concurrently\n              try (HttpSolrClient server = new HttpSolrClient.Builder(url).build()) {\n                server.commit();\n              }\n            }\n          }\n        }\n        LOG.info(\"Done committing live merge\");\n      } catch (Exception e) {\n        LOG.error(\"Error sending commits to live Solr cluster\", e);\n        return false;\n      }\n\n      success = true;\n      return true;\n    } finally {\n      ExecutorUtil.shutdownAndAwaitTermination(executor);\n      float secs = (System.nanoTime() - start) / (float)(10^9);\n      LOG.info(\"Live merging of index shards into Solr cluster took \" + secs + \" secs\");\n      if (success) {\n        LOG.info(\"Live merging completed successfully\");\n      } else {\n        LOG.info(\"Live merging failed\");\n      }\n    }\n    \n    // if an output dir does not exist, we should fail and do no merge?\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["fd5bc858b8426d40bbe90b94120ead37c77d7954"],"043df2e9a841864922c32756a44c939ed768cb89":["70d61fdc6a5871f80a74c0e2e55bb8a94e9ac59d"],"12109b652e9210b8d58fca47f6c4a725d058a58e":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"e3c94a8b8bf47db4f968d9ae510ec8bbe1372088":["b6284684320a9808c41a5e43de958b2da22f89bd"],"bafca15d8e408346a67f4282ad1143b88023893b":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"70d61fdc6a5871f80a74c0e2e55bb8a94e9ac59d":["4a04721f602dc10b140dca8dd0fce9d43079f8f1"],"fe1c4aa9af769a38e878f608070f672efbeac27f":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"fd5bc858b8426d40bbe90b94120ead37c77d7954":["70f91c8322fbffe3a3a897ef20ea19119cac10cd"],"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4a04721f602dc10b140dca8dd0fce9d43079f8f1":["cc3b13b430571c2e169f98fe38e1e7666f88522d"],"b6284684320a9808c41a5e43de958b2da22f89bd":["70d61fdc6a5871f80a74c0e2e55bb8a94e9ac59d","043df2e9a841864922c32756a44c939ed768cb89"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5bdaf2cee03ff78b0a0cbf23df0095a3590b493b":["b6284684320a9808c41a5e43de958b2da22f89bd","e3c94a8b8bf47db4f968d9ae510ec8bbe1372088"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","70f91c8322fbffe3a3a897ef20ea19119cac10cd"],"cc3b13b430571c2e169f98fe38e1e7666f88522d":["bafca15d8e408346a67f4282ad1143b88023893b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["12109b652e9210b8d58fca47f6c4a725d058a58e"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["bafca15d8e408346a67f4282ad1143b88023893b"],"043df2e9a841864922c32756a44c939ed768cb89":["b6284684320a9808c41a5e43de958b2da22f89bd"],"12109b652e9210b8d58fca47f6c4a725d058a58e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e3c94a8b8bf47db4f968d9ae510ec8bbe1372088":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"bafca15d8e408346a67f4282ad1143b88023893b":["cc3b13b430571c2e169f98fe38e1e7666f88522d"],"70d61fdc6a5871f80a74c0e2e55bb8a94e9ac59d":["043df2e9a841864922c32756a44c939ed768cb89","b6284684320a9808c41a5e43de958b2da22f89bd"],"fe1c4aa9af769a38e878f608070f672efbeac27f":[],"fd5bc858b8426d40bbe90b94120ead37c77d7954":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"70f91c8322fbffe3a3a897ef20ea19119cac10cd":["fd5bc858b8426d40bbe90b94120ead37c77d7954","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"4a04721f602dc10b140dca8dd0fce9d43079f8f1":["70d61fdc6a5871f80a74c0e2e55bb8a94e9ac59d"],"b6284684320a9808c41a5e43de958b2da22f89bd":["e3c94a8b8bf47db4f968d9ae510ec8bbe1372088","5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["70f91c8322fbffe3a3a897ef20ea19119cac10cd","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"5bdaf2cee03ff78b0a0cbf23df0095a3590b493b":["12109b652e9210b8d58fca47f6c4a725d058a58e","fe1c4aa9af769a38e878f608070f672efbeac27f"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"cc3b13b430571c2e169f98fe38e1e7666f88522d":["4a04721f602dc10b140dca8dd0fce9d43079f8f1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["fe1c4aa9af769a38e878f608070f672efbeac27f","74f45af4339b0daf7a95c820ab88c1aea74fbce0","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}