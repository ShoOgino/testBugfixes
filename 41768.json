{"path":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","commits":[{"id":"78277631929de308318c889be36ed69ce7a85048","date":1443977344,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, 1, 2, 1);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    \n    printLayout();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    \n    // recoveries will not finish without SOLR-8075\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["9f1bee4bba8988141f8357bda2ccd9405926c4e5","b8d1bb706d514ef68ac7d45c7bb70ffbc8a16efd"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b8d1bb706d514ef68ac7d45c7bb70ffbc8a16efd","date":1447422052,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","sourceNew":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, 1, 3, 1);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // printLayout();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    \n    // recoveries will not finish without SOLR-8075\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","sourceOld":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, 1, 2, 1);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    \n    printLayout();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    \n    // recoveries will not finish without SOLR-8075\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","bugFix":["78277631929de308318c889be36ed69ce7a85048"],"bugIntro":["9f1bee4bba8988141f8357bda2ccd9405926c4e5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9f1bee4bba8988141f8357bda2ccd9405926c4e5","date":1449703835,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","sourceNew":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n\n    // still waiting to be able to properly start with no default collection1,\n    // delete to remove confusion\n    waitForRecoveriesToFinish(false);\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"action\", CollectionAction.DELETE.toString());\n    params.set(\"name\", DEFAULT_COLLECTION);\n    QueryRequest request = new QueryRequest(params);\n    request.setPath(\"/admin/collections\");\n    String baseUrl = ((HttpSolrClient) clients.get(0)).getBaseURL();\n    HttpSolrClient delClient = new HttpSolrClient(baseUrl.substring(0, baseUrl.lastIndexOf(\"/\")));\n    delClient.request(request);\n    delClient.close();\n    \n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, 1, 3, 1);\n    \n    waitForRecoveriesToFinish(testCollectionName, false);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // everyone gets a couple docs so that everyone has tlog entries\n    // and won't become leader simply because they have no tlog versions\n    SolrInputDocument doc = new SolrInputDocument();\n    addFields(doc, \"id\", \"1\");\n    SolrInputDocument doc2 = new SolrInputDocument();\n    addFields(doc2, \"id\", \"2\");\n    cloudClient.add(doc);\n    cloudClient.add(doc2);\n\n    cloudClient.commit();\n    \n    assertEquals(\"We just added 2 docs, we should be able to find them\", 2, cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    \n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    HttpSolrClient client = (HttpSolrClient) clients.get(random().nextInt(clients.size()));\n    client.setBaseURL(client.getBaseURL().substring(0, client.getBaseURL().lastIndexOf(\"/\")) + \"/\" + testCollectionName);\n    params = new ModifiableSolrParams();\n    params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n    \n    try {\n      for (int i = 0; i < 101; i++) {\n        add(client, params, sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n      }\n    } catch (RemoteSolrException e) {\n      // if we got a conflict it's because we tried to send a versioned doc to the leader,\n      // resend without version\n      if (e.getMessage().contains(\"conflict\")) {\n        for (int i = 0; i < 101; i++) {\n          add(client, params, sdoc(\"id\", 3 + i));\n        }\n      }\n    }\n\n    client.commit();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    ChaosMonkey.stop(controlJetty);\n    \n    Thread.sleep(10000);\n    \n    log.info(\"Start back up\");\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    ChaosMonkey.start(controlJetty);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","sourceOld":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n    waitForThingsToLevelOut(30000);\n\n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, 1, 3, 1);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // printLayout();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    \n    // recoveries will not finish without SOLR-8075\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","bugFix":["78277631929de308318c889be36ed69ce7a85048","b8d1bb706d514ef68ac7d45c7bb70ffbc8a16efd"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e3c94a8b8bf47db4f968d9ae510ec8bbe1372088","date":1460069869,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","sourceNew":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n\n    // still waiting to be able to properly start with no default collection1,\n    // delete to remove confusion\n    waitForRecoveriesToFinish(false);\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"action\", CollectionAction.DELETE.toString());\n    params.set(\"name\", DEFAULT_COLLECTION);\n    QueryRequest request = new QueryRequest(params);\n    request.setPath(\"/admin/collections\");\n    String baseUrl = ((HttpSolrClient) clients.get(0)).getBaseURL();\n    HttpSolrClient delClient = getHttpSolrClient(baseUrl.substring(0, baseUrl.lastIndexOf(\"/\")));\n    delClient.request(request);\n    delClient.close();\n    \n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, 1, 3, 1);\n    \n    waitForRecoveriesToFinish(testCollectionName, false);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // everyone gets a couple docs so that everyone has tlog entries\n    // and won't become leader simply because they have no tlog versions\n    SolrInputDocument doc = new SolrInputDocument();\n    addFields(doc, \"id\", \"1\");\n    SolrInputDocument doc2 = new SolrInputDocument();\n    addFields(doc2, \"id\", \"2\");\n    cloudClient.add(doc);\n    cloudClient.add(doc2);\n\n    cloudClient.commit();\n    \n    assertEquals(\"We just added 2 docs, we should be able to find them\", 2, cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    \n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    HttpSolrClient client = (HttpSolrClient) clients.get(random().nextInt(clients.size()));\n    client.setBaseURL(client.getBaseURL().substring(0, client.getBaseURL().lastIndexOf(\"/\")) + \"/\" + testCollectionName);\n    params = new ModifiableSolrParams();\n    params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n    \n    try {\n      for (int i = 0; i < 101; i++) {\n        add(client, params, sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n      }\n    } catch (RemoteSolrException e) {\n      // if we got a conflict it's because we tried to send a versioned doc to the leader,\n      // resend without version\n      if (e.getMessage().contains(\"conflict\")) {\n        for (int i = 0; i < 101; i++) {\n          add(client, params, sdoc(\"id\", 3 + i));\n        }\n      }\n    }\n\n    client.commit();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    ChaosMonkey.stop(controlJetty);\n    \n    Thread.sleep(10000);\n    \n    log.info(\"Start back up\");\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    ChaosMonkey.start(controlJetty);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","sourceOld":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n\n    // still waiting to be able to properly start with no default collection1,\n    // delete to remove confusion\n    waitForRecoveriesToFinish(false);\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"action\", CollectionAction.DELETE.toString());\n    params.set(\"name\", DEFAULT_COLLECTION);\n    QueryRequest request = new QueryRequest(params);\n    request.setPath(\"/admin/collections\");\n    String baseUrl = ((HttpSolrClient) clients.get(0)).getBaseURL();\n    HttpSolrClient delClient = new HttpSolrClient(baseUrl.substring(0, baseUrl.lastIndexOf(\"/\")));\n    delClient.request(request);\n    delClient.close();\n    \n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, 1, 3, 1);\n    \n    waitForRecoveriesToFinish(testCollectionName, false);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // everyone gets a couple docs so that everyone has tlog entries\n    // and won't become leader simply because they have no tlog versions\n    SolrInputDocument doc = new SolrInputDocument();\n    addFields(doc, \"id\", \"1\");\n    SolrInputDocument doc2 = new SolrInputDocument();\n    addFields(doc2, \"id\", \"2\");\n    cloudClient.add(doc);\n    cloudClient.add(doc2);\n\n    cloudClient.commit();\n    \n    assertEquals(\"We just added 2 docs, we should be able to find them\", 2, cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    \n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    HttpSolrClient client = (HttpSolrClient) clients.get(random().nextInt(clients.size()));\n    client.setBaseURL(client.getBaseURL().substring(0, client.getBaseURL().lastIndexOf(\"/\")) + \"/\" + testCollectionName);\n    params = new ModifiableSolrParams();\n    params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n    \n    try {\n      for (int i = 0; i < 101; i++) {\n        add(client, params, sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n      }\n    } catch (RemoteSolrException e) {\n      // if we got a conflict it's because we tried to send a versioned doc to the leader,\n      // resend without version\n      if (e.getMessage().contains(\"conflict\")) {\n        for (int i = 0; i < 101; i++) {\n          add(client, params, sdoc(\"id\", 3 + i));\n        }\n      }\n    }\n\n    client.commit();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    ChaosMonkey.stop(controlJetty);\n    \n    Thread.sleep(10000);\n    \n    log.info(\"Start back up\");\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    ChaosMonkey.start(controlJetty);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5bdaf2cee03ff78b0a0cbf23df0095a3590b493b","date":1460110033,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","sourceNew":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n\n    // still waiting to be able to properly start with no default collection1,\n    // delete to remove confusion\n    waitForRecoveriesToFinish(false);\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"action\", CollectionAction.DELETE.toString());\n    params.set(\"name\", DEFAULT_COLLECTION);\n    QueryRequest request = new QueryRequest(params);\n    request.setPath(\"/admin/collections\");\n    String baseUrl = ((HttpSolrClient) clients.get(0)).getBaseURL();\n    HttpSolrClient delClient = getHttpSolrClient(baseUrl.substring(0, baseUrl.lastIndexOf(\"/\")));\n    delClient.request(request);\n    delClient.close();\n    \n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, 1, 3, 1);\n    \n    waitForRecoveriesToFinish(testCollectionName, false);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // everyone gets a couple docs so that everyone has tlog entries\n    // and won't become leader simply because they have no tlog versions\n    SolrInputDocument doc = new SolrInputDocument();\n    addFields(doc, \"id\", \"1\");\n    SolrInputDocument doc2 = new SolrInputDocument();\n    addFields(doc2, \"id\", \"2\");\n    cloudClient.add(doc);\n    cloudClient.add(doc2);\n\n    cloudClient.commit();\n    \n    assertEquals(\"We just added 2 docs, we should be able to find them\", 2, cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    \n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    HttpSolrClient client = (HttpSolrClient) clients.get(random().nextInt(clients.size()));\n    client.setBaseURL(client.getBaseURL().substring(0, client.getBaseURL().lastIndexOf(\"/\")) + \"/\" + testCollectionName);\n    params = new ModifiableSolrParams();\n    params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n    \n    try {\n      for (int i = 0; i < 101; i++) {\n        add(client, params, sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n      }\n    } catch (RemoteSolrException e) {\n      // if we got a conflict it's because we tried to send a versioned doc to the leader,\n      // resend without version\n      if (e.getMessage().contains(\"conflict\")) {\n        for (int i = 0; i < 101; i++) {\n          add(client, params, sdoc(\"id\", 3 + i));\n        }\n      }\n    }\n\n    client.commit();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    ChaosMonkey.stop(controlJetty);\n    \n    Thread.sleep(10000);\n    \n    log.info(\"Start back up\");\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    ChaosMonkey.start(controlJetty);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","sourceOld":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n\n    // still waiting to be able to properly start with no default collection1,\n    // delete to remove confusion\n    waitForRecoveriesToFinish(false);\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"action\", CollectionAction.DELETE.toString());\n    params.set(\"name\", DEFAULT_COLLECTION);\n    QueryRequest request = new QueryRequest(params);\n    request.setPath(\"/admin/collections\");\n    String baseUrl = ((HttpSolrClient) clients.get(0)).getBaseURL();\n    HttpSolrClient delClient = new HttpSolrClient(baseUrl.substring(0, baseUrl.lastIndexOf(\"/\")));\n    delClient.request(request);\n    delClient.close();\n    \n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, 1, 3, 1);\n    \n    waitForRecoveriesToFinish(testCollectionName, false);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // everyone gets a couple docs so that everyone has tlog entries\n    // and won't become leader simply because they have no tlog versions\n    SolrInputDocument doc = new SolrInputDocument();\n    addFields(doc, \"id\", \"1\");\n    SolrInputDocument doc2 = new SolrInputDocument();\n    addFields(doc2, \"id\", \"2\");\n    cloudClient.add(doc);\n    cloudClient.add(doc2);\n\n    cloudClient.commit();\n    \n    assertEquals(\"We just added 2 docs, we should be able to find them\", 2, cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    \n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    HttpSolrClient client = (HttpSolrClient) clients.get(random().nextInt(clients.size()));\n    client.setBaseURL(client.getBaseURL().substring(0, client.getBaseURL().lastIndexOf(\"/\")) + \"/\" + testCollectionName);\n    params = new ModifiableSolrParams();\n    params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n    \n    try {\n      for (int i = 0; i < 101; i++) {\n        add(client, params, sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n      }\n    } catch (RemoteSolrException e) {\n      // if we got a conflict it's because we tried to send a versioned doc to the leader,\n      // resend without version\n      if (e.getMessage().contains(\"conflict\")) {\n        for (int i = 0; i < 101; i++) {\n          add(client, params, sdoc(\"id\", 3 + i));\n        }\n      }\n    }\n\n    client.commit();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    ChaosMonkey.stop(controlJetty);\n    \n    Thread.sleep(10000);\n    \n    log.info(\"Start back up\");\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    ChaosMonkey.start(controlJetty);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"197bbedf08450ade98a11f4a0001448059666bec","date":1498534625,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","sourceNew":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n\n    // still waiting to be able to properly start with no default collection1,\n    // delete to remove confusion\n    waitForRecoveriesToFinish(false);\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"action\", CollectionAction.DELETE.toString());\n    params.set(\"name\", DEFAULT_COLLECTION);\n    QueryRequest request = new QueryRequest(params);\n    request.setPath(\"/admin/collections\");\n    String baseUrl = ((HttpSolrClient) clients.get(0)).getBaseURL();\n    HttpSolrClient delClient = getHttpSolrClient(baseUrl.substring(0, baseUrl.lastIndexOf(\"/\")));\n    delClient.request(request);\n    delClient.close();\n    \n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, \"conf1\", 1, 3, 1);\n    \n    waitForRecoveriesToFinish(testCollectionName, false);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // everyone gets a couple docs so that everyone has tlog entries\n    // and won't become leader simply because they have no tlog versions\n    SolrInputDocument doc = new SolrInputDocument();\n    addFields(doc, \"id\", \"1\");\n    SolrInputDocument doc2 = new SolrInputDocument();\n    addFields(doc2, \"id\", \"2\");\n    cloudClient.add(doc);\n    cloudClient.add(doc2);\n\n    cloudClient.commit();\n    \n    assertEquals(\"We just added 2 docs, we should be able to find them\", 2, cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    \n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    HttpSolrClient client = (HttpSolrClient) clients.get(random().nextInt(clients.size()));\n    client.setBaseURL(client.getBaseURL().substring(0, client.getBaseURL().lastIndexOf(\"/\")) + \"/\" + testCollectionName);\n    params = new ModifiableSolrParams();\n    params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n    \n    try {\n      for (int i = 0; i < 101; i++) {\n        add(client, params, sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n      }\n    } catch (RemoteSolrException e) {\n      // if we got a conflict it's because we tried to send a versioned doc to the leader,\n      // resend without version\n      if (e.getMessage().contains(\"conflict\")) {\n        for (int i = 0; i < 101; i++) {\n          add(client, params, sdoc(\"id\", 3 + i));\n        }\n      }\n    }\n\n    client.commit();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    ChaosMonkey.stop(controlJetty);\n    \n    Thread.sleep(10000);\n    \n    log.info(\"Start back up\");\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    ChaosMonkey.start(controlJetty);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","sourceOld":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n\n    // still waiting to be able to properly start with no default collection1,\n    // delete to remove confusion\n    waitForRecoveriesToFinish(false);\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"action\", CollectionAction.DELETE.toString());\n    params.set(\"name\", DEFAULT_COLLECTION);\n    QueryRequest request = new QueryRequest(params);\n    request.setPath(\"/admin/collections\");\n    String baseUrl = ((HttpSolrClient) clients.get(0)).getBaseURL();\n    HttpSolrClient delClient = getHttpSolrClient(baseUrl.substring(0, baseUrl.lastIndexOf(\"/\")));\n    delClient.request(request);\n    delClient.close();\n    \n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, 1, 3, 1);\n    \n    waitForRecoveriesToFinish(testCollectionName, false);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // everyone gets a couple docs so that everyone has tlog entries\n    // and won't become leader simply because they have no tlog versions\n    SolrInputDocument doc = new SolrInputDocument();\n    addFields(doc, \"id\", \"1\");\n    SolrInputDocument doc2 = new SolrInputDocument();\n    addFields(doc2, \"id\", \"2\");\n    cloudClient.add(doc);\n    cloudClient.add(doc2);\n\n    cloudClient.commit();\n    \n    assertEquals(\"We just added 2 docs, we should be able to find them\", 2, cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    \n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    HttpSolrClient client = (HttpSolrClient) clients.get(random().nextInt(clients.size()));\n    client.setBaseURL(client.getBaseURL().substring(0, client.getBaseURL().lastIndexOf(\"/\")) + \"/\" + testCollectionName);\n    params = new ModifiableSolrParams();\n    params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n    \n    try {\n      for (int i = 0; i < 101; i++) {\n        add(client, params, sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n      }\n    } catch (RemoteSolrException e) {\n      // if we got a conflict it's because we tried to send a versioned doc to the leader,\n      // resend without version\n      if (e.getMessage().contains(\"conflict\")) {\n        for (int i = 0; i < 101; i++) {\n          add(client, params, sdoc(\"id\", 3 + i));\n        }\n      }\n    }\n\n    client.commit();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    ChaosMonkey.stop(controlJetty);\n    \n    Thread.sleep(10000);\n    \n    log.info(\"Start back up\");\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    ChaosMonkey.start(controlJetty);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","date":1498540685,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","sourceNew":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n\n    // still waiting to be able to properly start with no default collection1,\n    // delete to remove confusion\n    waitForRecoveriesToFinish(false);\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"action\", CollectionAction.DELETE.toString());\n    params.set(\"name\", DEFAULT_COLLECTION);\n    QueryRequest request = new QueryRequest(params);\n    request.setPath(\"/admin/collections\");\n    String baseUrl = ((HttpSolrClient) clients.get(0)).getBaseURL();\n    HttpSolrClient delClient = getHttpSolrClient(baseUrl.substring(0, baseUrl.lastIndexOf(\"/\")));\n    delClient.request(request);\n    delClient.close();\n    \n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, \"conf1\", 1, 3, 1);\n    \n    waitForRecoveriesToFinish(testCollectionName, false);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // everyone gets a couple docs so that everyone has tlog entries\n    // and won't become leader simply because they have no tlog versions\n    SolrInputDocument doc = new SolrInputDocument();\n    addFields(doc, \"id\", \"1\");\n    SolrInputDocument doc2 = new SolrInputDocument();\n    addFields(doc2, \"id\", \"2\");\n    cloudClient.add(doc);\n    cloudClient.add(doc2);\n\n    cloudClient.commit();\n    \n    assertEquals(\"We just added 2 docs, we should be able to find them\", 2, cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    \n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    HttpSolrClient client = (HttpSolrClient) clients.get(random().nextInt(clients.size()));\n    client.setBaseURL(client.getBaseURL().substring(0, client.getBaseURL().lastIndexOf(\"/\")) + \"/\" + testCollectionName);\n    params = new ModifiableSolrParams();\n    params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n    \n    try {\n      for (int i = 0; i < 101; i++) {\n        add(client, params, sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n      }\n    } catch (RemoteSolrException e) {\n      // if we got a conflict it's because we tried to send a versioned doc to the leader,\n      // resend without version\n      if (e.getMessage().contains(\"conflict\")) {\n        for (int i = 0; i < 101; i++) {\n          add(client, params, sdoc(\"id\", 3 + i));\n        }\n      }\n    }\n\n    client.commit();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    ChaosMonkey.stop(controlJetty);\n    \n    Thread.sleep(10000);\n    \n    log.info(\"Start back up\");\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    ChaosMonkey.start(controlJetty);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","sourceOld":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n\n    // still waiting to be able to properly start with no default collection1,\n    // delete to remove confusion\n    waitForRecoveriesToFinish(false);\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"action\", CollectionAction.DELETE.toString());\n    params.set(\"name\", DEFAULT_COLLECTION);\n    QueryRequest request = new QueryRequest(params);\n    request.setPath(\"/admin/collections\");\n    String baseUrl = ((HttpSolrClient) clients.get(0)).getBaseURL();\n    HttpSolrClient delClient = getHttpSolrClient(baseUrl.substring(0, baseUrl.lastIndexOf(\"/\")));\n    delClient.request(request);\n    delClient.close();\n    \n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, 1, 3, 1);\n    \n    waitForRecoveriesToFinish(testCollectionName, false);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // everyone gets a couple docs so that everyone has tlog entries\n    // and won't become leader simply because they have no tlog versions\n    SolrInputDocument doc = new SolrInputDocument();\n    addFields(doc, \"id\", \"1\");\n    SolrInputDocument doc2 = new SolrInputDocument();\n    addFields(doc2, \"id\", \"2\");\n    cloudClient.add(doc);\n    cloudClient.add(doc2);\n\n    cloudClient.commit();\n    \n    assertEquals(\"We just added 2 docs, we should be able to find them\", 2, cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    \n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    HttpSolrClient client = (HttpSolrClient) clients.get(random().nextInt(clients.size()));\n    client.setBaseURL(client.getBaseURL().substring(0, client.getBaseURL().lastIndexOf(\"/\")) + \"/\" + testCollectionName);\n    params = new ModifiableSolrParams();\n    params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n    \n    try {\n      for (int i = 0; i < 101; i++) {\n        add(client, params, sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n      }\n    } catch (RemoteSolrException e) {\n      // if we got a conflict it's because we tried to send a versioned doc to the leader,\n      // resend without version\n      if (e.getMessage().contains(\"conflict\")) {\n        for (int i = 0; i < 101; i++) {\n          add(client, params, sdoc(\"id\", 3 + i));\n        }\n      }\n    }\n\n    client.commit();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    ChaosMonkey.stop(controlJetty);\n    \n    Thread.sleep(10000);\n    \n    log.info(\"Start back up\");\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    ChaosMonkey.start(controlJetty);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","sourceNew":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n\n    // still waiting to be able to properly start with no default collection1,\n    // delete to remove confusion\n    waitForRecoveriesToFinish(false);\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"action\", CollectionAction.DELETE.toString());\n    params.set(\"name\", DEFAULT_COLLECTION);\n    QueryRequest request = new QueryRequest(params);\n    request.setPath(\"/admin/collections\");\n    String baseUrl = ((HttpSolrClient) clients.get(0)).getBaseURL();\n    HttpSolrClient delClient = getHttpSolrClient(baseUrl.substring(0, baseUrl.lastIndexOf(\"/\")));\n    delClient.request(request);\n    delClient.close();\n    \n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, \"conf1\", 1, 3, 1);\n    \n    waitForRecoveriesToFinish(testCollectionName, false);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // everyone gets a couple docs so that everyone has tlog entries\n    // and won't become leader simply because they have no tlog versions\n    SolrInputDocument doc = new SolrInputDocument();\n    addFields(doc, \"id\", \"1\");\n    SolrInputDocument doc2 = new SolrInputDocument();\n    addFields(doc2, \"id\", \"2\");\n    cloudClient.add(doc);\n    cloudClient.add(doc2);\n\n    cloudClient.commit();\n    \n    assertEquals(\"We just added 2 docs, we should be able to find them\", 2, cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    \n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    HttpSolrClient client = (HttpSolrClient) clients.get(random().nextInt(clients.size()));\n    client.setBaseURL(client.getBaseURL().substring(0, client.getBaseURL().lastIndexOf(\"/\")) + \"/\" + testCollectionName);\n    params = new ModifiableSolrParams();\n    params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n    \n    try {\n      for (int i = 0; i < 101; i++) {\n        add(client, params, sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n      }\n    } catch (RemoteSolrException e) {\n      // if we got a conflict it's because we tried to send a versioned doc to the leader,\n      // resend without version\n      if (e.getMessage().contains(\"conflict\")) {\n        for (int i = 0; i < 101; i++) {\n          add(client, params, sdoc(\"id\", 3 + i));\n        }\n      }\n    }\n\n    client.commit();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    ChaosMonkey.stop(controlJetty);\n    \n    Thread.sleep(10000);\n    \n    log.info(\"Start back up\");\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    ChaosMonkey.start(controlJetty);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","sourceOld":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n\n    // still waiting to be able to properly start with no default collection1,\n    // delete to remove confusion\n    waitForRecoveriesToFinish(false);\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"action\", CollectionAction.DELETE.toString());\n    params.set(\"name\", DEFAULT_COLLECTION);\n    QueryRequest request = new QueryRequest(params);\n    request.setPath(\"/admin/collections\");\n    String baseUrl = ((HttpSolrClient) clients.get(0)).getBaseURL();\n    HttpSolrClient delClient = getHttpSolrClient(baseUrl.substring(0, baseUrl.lastIndexOf(\"/\")));\n    delClient.request(request);\n    delClient.close();\n    \n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, 1, 3, 1);\n    \n    waitForRecoveriesToFinish(testCollectionName, false);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // everyone gets a couple docs so that everyone has tlog entries\n    // and won't become leader simply because they have no tlog versions\n    SolrInputDocument doc = new SolrInputDocument();\n    addFields(doc, \"id\", \"1\");\n    SolrInputDocument doc2 = new SolrInputDocument();\n    addFields(doc2, \"id\", \"2\");\n    cloudClient.add(doc);\n    cloudClient.add(doc2);\n\n    cloudClient.commit();\n    \n    assertEquals(\"We just added 2 docs, we should be able to find them\", 2, cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    \n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    HttpSolrClient client = (HttpSolrClient) clients.get(random().nextInt(clients.size()));\n    client.setBaseURL(client.getBaseURL().substring(0, client.getBaseURL().lastIndexOf(\"/\")) + \"/\" + testCollectionName);\n    params = new ModifiableSolrParams();\n    params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n    \n    try {\n      for (int i = 0; i < 101; i++) {\n        add(client, params, sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n      }\n    } catch (RemoteSolrException e) {\n      // if we got a conflict it's because we tried to send a versioned doc to the leader,\n      // resend without version\n      if (e.getMessage().contains(\"conflict\")) {\n        for (int i = 0; i < 101; i++) {\n          add(client, params, sdoc(\"id\", 3 + i));\n        }\n      }\n    }\n\n    client.commit();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    ChaosMonkey.stop(controlJetty);\n    \n    Thread.sleep(10000);\n    \n    log.info(\"Start back up\");\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    ChaosMonkey.start(controlJetty);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84f20f331d8001864545c7021812d8c6509c7593","date":1517216128,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","sourceNew":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n\n    // still waiting to be able to properly start with no default collection1,\n    // delete to remove confusion\n    waitForRecoveriesToFinish(false);\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"action\", CollectionAction.DELETE.toString());\n    params.set(\"name\", DEFAULT_COLLECTION);\n    QueryRequest request = new QueryRequest(params);\n    request.setPath(\"/admin/collections\");\n    String baseUrl = ((HttpSolrClient) clients.get(0)).getBaseURL();\n    HttpSolrClient delClient = getHttpSolrClient(baseUrl.substring(0, baseUrl.lastIndexOf(\"/\")));\n    delClient.request(request);\n    delClient.close();\n    \n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    CollectionAdminRequest.createCollection(testCollectionName, \"conf1\", 1, 3)\n        .setCreateNodeSet(\"\")\n        .process(cloudClient);\n    Properties oldLir = new Properties();\n    oldLir.setProperty(\"lirVersion\", \"old\");\n    for (int i = 0; i < 3; i++) {\n      CollectionAdminRequest.addReplicaToShard(testCollectionName, \"shard1\").setProperties(oldLir).process(cloudClient);\n    }\n    \n    waitForRecoveriesToFinish(testCollectionName, false);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // everyone gets a couple docs so that everyone has tlog entries\n    // and won't become leader simply because they have no tlog versions\n    SolrInputDocument doc = new SolrInputDocument();\n    addFields(doc, \"id\", \"1\");\n    SolrInputDocument doc2 = new SolrInputDocument();\n    addFields(doc2, \"id\", \"2\");\n    cloudClient.add(doc);\n    cloudClient.add(doc2);\n\n    cloudClient.commit();\n    \n    assertEquals(\"We just added 2 docs, we should be able to find them\", 2, cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    \n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    HttpSolrClient client = (HttpSolrClient) clients.get(random().nextInt(clients.size()));\n    client.setBaseURL(client.getBaseURL().substring(0, client.getBaseURL().lastIndexOf(\"/\")) + \"/\" + testCollectionName);\n    params = new ModifiableSolrParams();\n    params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n    \n    try {\n      for (int i = 0; i < 101; i++) {\n        add(client, params, sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n      }\n    } catch (RemoteSolrException e) {\n      // if we got a conflict it's because we tried to send a versioned doc to the leader,\n      // resend without version\n      if (e.getMessage().contains(\"conflict\")) {\n        for (int i = 0; i < 101; i++) {\n          add(client, params, sdoc(\"id\", 3 + i));\n        }\n      }\n    }\n\n    client.commit();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    ChaosMonkey.stop(controlJetty);\n    \n    Thread.sleep(10000);\n    \n    log.info(\"Start back up\");\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    ChaosMonkey.start(controlJetty);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","sourceOld":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n\n    // still waiting to be able to properly start with no default collection1,\n    // delete to remove confusion\n    waitForRecoveriesToFinish(false);\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"action\", CollectionAction.DELETE.toString());\n    params.set(\"name\", DEFAULT_COLLECTION);\n    QueryRequest request = new QueryRequest(params);\n    request.setPath(\"/admin/collections\");\n    String baseUrl = ((HttpSolrClient) clients.get(0)).getBaseURL();\n    HttpSolrClient delClient = getHttpSolrClient(baseUrl.substring(0, baseUrl.lastIndexOf(\"/\")));\n    delClient.request(request);\n    delClient.close();\n    \n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    createCollection(testCollectionName, \"conf1\", 1, 3, 1);\n    \n    waitForRecoveriesToFinish(testCollectionName, false);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // everyone gets a couple docs so that everyone has tlog entries\n    // and won't become leader simply because they have no tlog versions\n    SolrInputDocument doc = new SolrInputDocument();\n    addFields(doc, \"id\", \"1\");\n    SolrInputDocument doc2 = new SolrInputDocument();\n    addFields(doc2, \"id\", \"2\");\n    cloudClient.add(doc);\n    cloudClient.add(doc2);\n\n    cloudClient.commit();\n    \n    assertEquals(\"We just added 2 docs, we should be able to find them\", 2, cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    \n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    HttpSolrClient client = (HttpSolrClient) clients.get(random().nextInt(clients.size()));\n    client.setBaseURL(client.getBaseURL().substring(0, client.getBaseURL().lastIndexOf(\"/\")) + \"/\" + testCollectionName);\n    params = new ModifiableSolrParams();\n    params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n    \n    try {\n      for (int i = 0; i < 101; i++) {\n        add(client, params, sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n      }\n    } catch (RemoteSolrException e) {\n      // if we got a conflict it's because we tried to send a versioned doc to the leader,\n      // resend without version\n      if (e.getMessage().contains(\"conflict\")) {\n        for (int i = 0; i < 101; i++) {\n          add(client, params, sdoc(\"id\", 3 + i));\n        }\n      }\n    }\n\n    client.commit();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    ChaosMonkey.stop(controlJetty);\n    \n    Thread.sleep(10000);\n    \n    log.info(\"Start back up\");\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    ChaosMonkey.start(controlJetty);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9339df295b9162e4c81adbb4da44b5939d27c1ef","date":1520594349,"type":4,"author":"Cao Manh Dat","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnShardRestartTest#testRestartWithAllInLIR().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testRestartWithAllInLIR() throws Exception {\n\n    // still waiting to be able to properly start with no default collection1,\n    // delete to remove confusion\n    waitForRecoveriesToFinish(false);\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(\"action\", CollectionAction.DELETE.toString());\n    params.set(\"name\", DEFAULT_COLLECTION);\n    QueryRequest request = new QueryRequest(params);\n    request.setPath(\"/admin/collections\");\n    String baseUrl = ((HttpSolrClient) clients.get(0)).getBaseURL();\n    HttpSolrClient delClient = getHttpSolrClient(baseUrl.substring(0, baseUrl.lastIndexOf(\"/\")));\n    delClient.request(request);\n    delClient.close();\n    \n    String testCollectionName = \"all_in_lir\";\n    String shardId = \"shard1\";\n    CollectionAdminRequest.createCollection(testCollectionName, \"conf1\", 1, 3)\n        .setCreateNodeSet(\"\")\n        .process(cloudClient);\n    Properties oldLir = new Properties();\n    oldLir.setProperty(\"lirVersion\", \"old\");\n    for (int i = 0; i < 3; i++) {\n      CollectionAdminRequest.addReplicaToShard(testCollectionName, \"shard1\").setProperties(oldLir).process(cloudClient);\n    }\n    \n    waitForRecoveriesToFinish(testCollectionName, false);\n\n    cloudClient.setDefaultCollection(testCollectionName);\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    \n    byte[] znodeData = Utils.toJSON(stateObj);\n    \n    SolrZkClient zkClient = cloudClient.getZkStateReader().getZkClient();\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    \n    // everyone gets a couple docs so that everyone has tlog entries\n    // and won't become leader simply because they have no tlog versions\n    SolrInputDocument doc = new SolrInputDocument();\n    addFields(doc, \"id\", \"1\");\n    SolrInputDocument doc2 = new SolrInputDocument();\n    addFields(doc2, \"id\", \"2\");\n    cloudClient.add(doc);\n    cloudClient.add(doc2);\n\n    cloudClient.commit();\n    \n    assertEquals(\"We just added 2 docs, we should be able to find them\", 2, cloudClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    \n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    HttpSolrClient client = (HttpSolrClient) clients.get(random().nextInt(clients.size()));\n    client.setBaseURL(client.getBaseURL().substring(0, client.getBaseURL().lastIndexOf(\"/\")) + \"/\" + testCollectionName);\n    params = new ModifiableSolrParams();\n    params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistribPhase.FROMLEADER.toString());\n    \n    try {\n      for (int i = 0; i < 101; i++) {\n        add(client, params, sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n      }\n    } catch (RemoteSolrException e) {\n      // if we got a conflict it's because we tried to send a versioned doc to the leader,\n      // resend without version\n      if (e.getMessage().contains(\"conflict\")) {\n        for (int i = 0; i < 101; i++) {\n          add(client, params, sdoc(\"id\", 3 + i));\n        }\n      }\n    }\n\n    client.commit();\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.stop(jetty);\n    }\n    ChaosMonkey.stop(controlJetty);\n    \n    Thread.sleep(10000);\n    \n    log.info(\"Start back up\");\n    \n    for (JettySolrRunner jetty : jettys) {\n      ChaosMonkey.start(jetty);\n    }\n    ChaosMonkey.start(controlJetty);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n    \n    // now expire each node\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node1\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node2\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    try {\n      zkClient.makePath(\"/collections/\" + testCollectionName + \"/leader_initiated_recovery/\" + shardId + \"/core_node3\", znodeData, true);\n    } catch (NodeExistsException e) {\n    \n    }\n    \n    for (JettySolrRunner jetty : jettys) {\n      chaosMonkey.expireSession(jetty);\n    }\n    \n    Thread.sleep(2000);\n    \n    // recoveries will not finish without SOLR-8075 and SOLR-8367\n    waitForRecoveriesToFinish(testCollectionName, true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"78277631929de308318c889be36ed69ce7a85048":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"197bbedf08450ade98a11f4a0001448059666bec":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"9f1bee4bba8988141f8357bda2ccd9405926c4e5":["b8d1bb706d514ef68ac7d45c7bb70ffbc8a16efd"],"e3c94a8b8bf47db4f968d9ae510ec8bbe1372088":["9f1bee4bba8988141f8357bda2ccd9405926c4e5"],"9339df295b9162e4c81adbb4da44b5939d27c1ef":["84f20f331d8001864545c7021812d8c6509c7593"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b","197bbedf08450ade98a11f4a0001448059666bec"],"5bdaf2cee03ff78b0a0cbf23df0095a3590b493b":["9f1bee4bba8988141f8357bda2ccd9405926c4e5","e3c94a8b8bf47db4f968d9ae510ec8bbe1372088"],"84f20f331d8001864545c7021812d8c6509c7593":["28288370235ed02234a64753cdbf0c6ec096304a"],"b8d1bb706d514ef68ac7d45c7bb70ffbc8a16efd":["78277631929de308318c889be36ed69ce7a85048"],"28288370235ed02234a64753cdbf0c6ec096304a":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b","197bbedf08450ade98a11f4a0001448059666bec"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9339df295b9162e4c81adbb4da44b5939d27c1ef"]},"commit2Childs":{"78277631929de308318c889be36ed69ce7a85048":["b8d1bb706d514ef68ac7d45c7bb70ffbc8a16efd"],"197bbedf08450ade98a11f4a0001448059666bec":["fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","28288370235ed02234a64753cdbf0c6ec096304a"],"9f1bee4bba8988141f8357bda2ccd9405926c4e5":["e3c94a8b8bf47db4f968d9ae510ec8bbe1372088","5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"e3c94a8b8bf47db4f968d9ae510ec8bbe1372088":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["78277631929de308318c889be36ed69ce7a85048"],"9339df295b9162e4c81adbb4da44b5939d27c1ef":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4":[],"5bdaf2cee03ff78b0a0cbf23df0095a3590b493b":["197bbedf08450ade98a11f4a0001448059666bec","fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","28288370235ed02234a64753cdbf0c6ec096304a"],"84f20f331d8001864545c7021812d8c6509c7593":["9339df295b9162e4c81adbb4da44b5939d27c1ef"],"b8d1bb706d514ef68ac7d45c7bb70ffbc8a16efd":["9f1bee4bba8988141f8357bda2ccd9405926c4e5"],"28288370235ed02234a64753cdbf0c6ec096304a":["84f20f331d8001864545c7021812d8c6509c7593"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}