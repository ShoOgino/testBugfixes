{"path":"solr/core/src/java/org/apache/solr/analysis/BaseTokenStreamFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","commits":[{"id":"a6042fc86aab3ca254c90a18f082f9569bdd89c5","date":1328470436,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/analysis/BaseTokenStreamFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = StrUtils.splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(luceneMatchVersion, \n          files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = IOUtils.CHARSET_UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["623b5245fbd9d5af9f458826ba9ed3d6212db24d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"687e86054415a85f912c6eaa38f995038e5c1cd8","date":1336447427,"type":5,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/analysis/BaseTokenStreamFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","sourceNew":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(luceneMatchVersion,\n          files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = IOUtils.CHARSET_UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","sourceOld":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = StrUtils.splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(luceneMatchVersion, \n          files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = IOUtils.CHARSET_UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"687e86054415a85f912c6eaa38f995038e5c1cd8":["a6042fc86aab3ca254c90a18f082f9569bdd89c5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a6042fc86aab3ca254c90a18f082f9569bdd89c5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["687e86054415a85f912c6eaa38f995038e5c1cd8"]},"commit2Childs":{"687e86054415a85f912c6eaa38f995038e5c1cd8":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a6042fc86aab3ca254c90a18f082f9569bdd89c5"],"a6042fc86aab3ca254c90a18f082f9569bdd89c5":["687e86054415a85f912c6eaa38f995038e5c1cd8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}