{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"),\n                                                                false);\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"),\n                                                                false);\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"),\n                                                                false);\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"),\n                                                                false);\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = DirectoryReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"),\n                                                                false);\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = IndexReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"),\n                                                                false);\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c5f000280bc18391509bbb40c4a2a2c7515d54d3","date":1339339354,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    try {\n      w.addDocument(doc);\n      fail(\"did not hit expected exception\");\n    } catch (IllegalArgumentException iea) {\n      // expected\n    }\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    w.addDocument(doc);\n    w.commit();\n\n    IndexReader r = DirectoryReader.open(dir);\n    IndexSearcher s = new IndexSearcher(r);\n    PhraseQuery pq = new PhraseQuery();\n    pq.add(new Term(\"field\", \"a\"));\n    pq.add(new Term(\"field\", \"b\"));\n    pq.add(new Term(\"field\", \"c\"));\n    ScoreDoc[] hits = s.search(pq, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    Query q = new SpanTermQuery(new Term(\"field\", \"a\"));\n    hits = s.search(q, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n\n    DocsAndPositionsEnum tps = MultiFields.getTermPositionsEnum(s.getIndexReader(),\n                                                                MultiFields.getLiveDocs(s.getIndexReader()),\n                                                                \"field\",\n                                                                new BytesRef(\"a\"),\n                                                                false);\n\n    assertTrue(tps.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(1, tps.freq());\n    assertEquals(0, tps.nextPosition());\n    w.close();\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["05fe562aa248790944d43cdd478f512572835ba0"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    try {\n      w.addDocument(doc);\n      fail(\"did not hit expected exception\");\n    } catch (IllegalArgumentException iea) {\n      // expected\n    }\n    w.shutdown();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    try {\n      w.addDocument(doc);\n      fail(\"did not hit expected exception\");\n    } catch (IllegalArgumentException iea) {\n      // expected\n    }\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    try {\n      w.addDocument(doc);\n      fail(\"did not hit expected exception\");\n    } catch (IllegalArgumentException iea) {\n      // expected\n    }\n    w.shutdown();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    try {\n      w.addDocument(doc);\n      fail(\"did not hit expected exception\");\n    } catch (IllegalArgumentException iea) {\n      // expected\n    }\n    w.shutdown();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    try {\n      w.addDocument(doc);\n      fail(\"did not hit expected exception\");\n    } catch (IllegalArgumentException iea) {\n      // expected\n    }\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    try {\n      w.addDocument(doc);\n      fail(\"did not hit expected exception\");\n    } catch (IllegalArgumentException iea) {\n      // expected\n    }\n    w.shutdown();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"05fe562aa248790944d43cdd478f512572835ba0","date":1455901667,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testNegativePositions().mjava","sourceNew":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    expectThrows(IllegalArgumentException.class, () -> {\n      w.addDocument(doc);\n    });\n\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1255\n  public void testNegativePositions() throws Throwable {\n    final TokenStream tokens = new TokenStream() {\n      final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);\n\n      final Iterator<String> terms = Arrays.asList(\"a\",\"b\",\"c\").iterator();\n      boolean first = true;\n\n      @Override\n      public boolean incrementToken() {\n        if (!terms.hasNext()) return false;\n        clearAttributes();\n        termAtt.append(terms.next());\n        posIncrAtt.setPositionIncrement(first ? 0 : 1);\n        first = false;\n        return true;\n      }\n    };\n\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    Document doc = new Document();\n    doc.add(new TextField(\"field\", tokens));\n    try {\n      w.addDocument(doc);\n      fail(\"did not hit expected exception\");\n    } catch (IllegalArgumentException iea) {\n      // expected\n    }\n    w.close();\n    dir.close();\n  }\n\n","bugFix":["c5f000280bc18391509bbb40c4a2a2c7515d54d3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"c5f000280bc18391509bbb40c4a2a2c7515d54d3":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"05fe562aa248790944d43cdd478f512572835ba0":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["c5f000280bc18391509bbb40c4a2a2c7515d54d3"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["05fe562aa248790944d43cdd478f512572835ba0"]},"commit2Childs":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["c5f000280bc18391509bbb40c4a2a2c7515d54d3"],"c5f000280bc18391509bbb40c4a2a2c7515d54d3":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"05fe562aa248790944d43cdd478f512572835ba0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["05fe562aa248790944d43cdd478f512572835ba0"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}