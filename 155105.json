{"path":"src/java/org/apache/lucene/index/SegmentReader.CoreReaders#openDocStores(SegmentInfo).mjava","commits":[{"id":"66f3dadb253a44f4cccc81c8a21b685b18b201fb","date":1247245699,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentReader.CoreReaders#openDocStores(SegmentInfo).mjava","pathOld":"/dev/null","sourceNew":"    synchronized void openDocStores(SegmentInfo si) throws IOException {\n\n      assert si.name.equals(segment);\n\n      if (fieldsReaderOrig == null) {\n        final Directory storeDir;\n        if (si.getDocStoreOffset() != -1) {\n          if (si.getDocStoreIsCompoundFile()) {\n            assert storeCFSReader == null;\n            storeCFSReader = new CompoundFileReader(dir,\n                                                    si.getDocStoreSegment() + \".\" + IndexFileNames.COMPOUND_FILE_STORE_EXTENSION,\n                                                    readBufferSize);\n            storeDir = storeCFSReader;\n            assert storeDir != null;\n          } else {\n            storeDir = dir;\n            assert storeDir != null;\n          }\n        } else if (si.getUseCompoundFile()) {\n          // In some cases, we were originally opened when CFS\n          // was not used, but then we are asked to open doc\n          // stores after the segment has switched to CFS\n          if (cfsReader == null) {\n            cfsReader = new CompoundFileReader(dir, segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION, readBufferSize);\n          }\n          storeDir = cfsReader;\n          assert storeDir != null;\n        } else {\n          storeDir = dir;\n          assert storeDir != null;\n        }\n\n        final String storesSegment;\n        if (si.getDocStoreOffset() != -1) {\n          storesSegment = si.getDocStoreSegment();\n        } else {\n          storesSegment = segment;\n        }\n\n        fieldsReaderOrig = new FieldsReader(storeDir, storesSegment, fieldInfos, readBufferSize,\n                                            si.getDocStoreOffset(), si.docCount);\n\n        // Verify two sources of \"maxDoc\" agree:\n        if (si.getDocStoreOffset() == -1 && fieldsReaderOrig.size() != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + fieldsReaderOrig.size() + \" but segmentInfo shows \" + si.docCount);\n        }\n\n        if (fieldInfos.hasVectors()) { // open term vector files only as needed\n          termVectorsReaderOrig = new TermVectorsReader(storeDir, storesSegment, fieldInfos, readBufferSize, si.getDocStoreOffset(), si.docCount);\n        }\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"775efee7f959e0dd3df7960b93767d9e00b78751","date":1267203159,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentReader.CoreReaders#openDocStores(SegmentInfo).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentReader.CoreReaders#openDocStores(SegmentInfo).mjava","sourceNew":"    synchronized void openDocStores(SegmentInfo si) throws IOException {\n\n      assert si.name.equals(segment);\n\n      if (fieldsReaderOrig == null) {\n        final Directory storeDir;\n        if (si.getDocStoreOffset() != -1) {\n          if (si.getDocStoreIsCompoundFile()) {\n            assert storeCFSReader == null;\n            storeCFSReader = new CompoundFileReader(dir,\n                IndexFileNames.segmentFileName(si.getDocStoreSegment(), IndexFileNames.COMPOUND_FILE_STORE_EXTENSION),\n                                                    readBufferSize);\n            storeDir = storeCFSReader;\n            assert storeDir != null;\n          } else {\n            storeDir = dir;\n            assert storeDir != null;\n          }\n        } else if (si.getUseCompoundFile()) {\n          // In some cases, we were originally opened when CFS\n          // was not used, but then we are asked to open doc\n          // stores after the segment has switched to CFS\n          if (cfsReader == null) {\n            cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n          }\n          storeDir = cfsReader;\n          assert storeDir != null;\n        } else {\n          storeDir = dir;\n          assert storeDir != null;\n        }\n\n        final String storesSegment;\n        if (si.getDocStoreOffset() != -1) {\n          storesSegment = si.getDocStoreSegment();\n        } else {\n          storesSegment = segment;\n        }\n\n        fieldsReaderOrig = new FieldsReader(storeDir, storesSegment, fieldInfos, readBufferSize,\n                                            si.getDocStoreOffset(), si.docCount);\n\n        // Verify two sources of \"maxDoc\" agree:\n        if (si.getDocStoreOffset() == -1 && fieldsReaderOrig.size() != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + fieldsReaderOrig.size() + \" but segmentInfo shows \" + si.docCount);\n        }\n\n        if (fieldInfos.hasVectors()) { // open term vector files only as needed\n          termVectorsReaderOrig = new TermVectorsReader(storeDir, storesSegment, fieldInfos, readBufferSize, si.getDocStoreOffset(), si.docCount);\n        }\n      }\n    }\n\n","sourceOld":"    synchronized void openDocStores(SegmentInfo si) throws IOException {\n\n      assert si.name.equals(segment);\n\n      if (fieldsReaderOrig == null) {\n        final Directory storeDir;\n        if (si.getDocStoreOffset() != -1) {\n          if (si.getDocStoreIsCompoundFile()) {\n            assert storeCFSReader == null;\n            storeCFSReader = new CompoundFileReader(dir,\n                                                    si.getDocStoreSegment() + \".\" + IndexFileNames.COMPOUND_FILE_STORE_EXTENSION,\n                                                    readBufferSize);\n            storeDir = storeCFSReader;\n            assert storeDir != null;\n          } else {\n            storeDir = dir;\n            assert storeDir != null;\n          }\n        } else if (si.getUseCompoundFile()) {\n          // In some cases, we were originally opened when CFS\n          // was not used, but then we are asked to open doc\n          // stores after the segment has switched to CFS\n          if (cfsReader == null) {\n            cfsReader = new CompoundFileReader(dir, segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION, readBufferSize);\n          }\n          storeDir = cfsReader;\n          assert storeDir != null;\n        } else {\n          storeDir = dir;\n          assert storeDir != null;\n        }\n\n        final String storesSegment;\n        if (si.getDocStoreOffset() != -1) {\n          storesSegment = si.getDocStoreSegment();\n        } else {\n          storesSegment = segment;\n        }\n\n        fieldsReaderOrig = new FieldsReader(storeDir, storesSegment, fieldInfos, readBufferSize,\n                                            si.getDocStoreOffset(), si.docCount);\n\n        // Verify two sources of \"maxDoc\" agree:\n        if (si.getDocStoreOffset() == -1 && fieldsReaderOrig.size() != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + fieldsReaderOrig.size() + \" but segmentInfo shows \" + si.docCount);\n        }\n\n        if (fieldInfos.hasVectors()) { // open term vector files only as needed\n          termVectorsReaderOrig = new TermVectorsReader(storeDir, storesSegment, fieldInfos, readBufferSize, si.getDocStoreOffset(), si.docCount);\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentReader.CoreReaders#openDocStores(SegmentInfo).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentReader.CoreReaders#openDocStores(SegmentInfo).mjava","sourceNew":"    synchronized void openDocStores(SegmentInfo si) throws IOException {\n\n      assert si.name.equals(segment);\n\n      if (fieldsReaderOrig == null) {\n        final Directory storeDir;\n        if (si.getDocStoreOffset() != -1) {\n          if (si.getDocStoreIsCompoundFile()) {\n            assert storeCFSReader == null;\n            storeCFSReader = new CompoundFileReader(dir,\n                IndexFileNames.segmentFileName(si.getDocStoreSegment(), IndexFileNames.COMPOUND_FILE_STORE_EXTENSION),\n                                                    readBufferSize);\n            storeDir = storeCFSReader;\n            assert storeDir != null;\n          } else {\n            storeDir = dir;\n            assert storeDir != null;\n          }\n        } else if (si.getUseCompoundFile()) {\n          // In some cases, we were originally opened when CFS\n          // was not used, but then we are asked to open doc\n          // stores after the segment has switched to CFS\n          if (cfsReader == null) {\n            cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n          }\n          storeDir = cfsReader;\n          assert storeDir != null;\n        } else {\n          storeDir = dir;\n          assert storeDir != null;\n        }\n\n        final String storesSegment;\n        if (si.getDocStoreOffset() != -1) {\n          storesSegment = si.getDocStoreSegment();\n        } else {\n          storesSegment = segment;\n        }\n\n        fieldsReaderOrig = new FieldsReader(storeDir, storesSegment, fieldInfos, readBufferSize,\n                                            si.getDocStoreOffset(), si.docCount);\n\n        // Verify two sources of \"maxDoc\" agree:\n        if (si.getDocStoreOffset() == -1 && fieldsReaderOrig.size() != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + fieldsReaderOrig.size() + \" but segmentInfo shows \" + si.docCount);\n        }\n\n        if (fieldInfos.hasVectors()) { // open term vector files only as needed\n          termVectorsReaderOrig = new TermVectorsReader(storeDir, storesSegment, fieldInfos, readBufferSize, si.getDocStoreOffset(), si.docCount);\n        }\n      }\n    }\n\n","sourceOld":"    synchronized void openDocStores(SegmentInfo si) throws IOException {\n\n      assert si.name.equals(segment);\n\n      if (fieldsReaderOrig == null) {\n        final Directory storeDir;\n        if (si.getDocStoreOffset() != -1) {\n          if (si.getDocStoreIsCompoundFile()) {\n            assert storeCFSReader == null;\n            storeCFSReader = new CompoundFileReader(dir,\n                IndexFileNames.segmentFileName(si.getDocStoreSegment(), IndexFileNames.COMPOUND_FILE_STORE_EXTENSION),\n                                                    readBufferSize);\n            storeDir = storeCFSReader;\n            assert storeDir != null;\n          } else {\n            storeDir = dir;\n            assert storeDir != null;\n          }\n        } else if (si.getUseCompoundFile()) {\n          // In some cases, we were originally opened when CFS\n          // was not used, but then we are asked to open doc\n          // stores after the segment has switched to CFS\n          if (cfsReader == null) {\n            cfsReader = new CompoundFileReader(dir, IndexFileNames.segmentFileName(segment, IndexFileNames.COMPOUND_FILE_EXTENSION), readBufferSize);\n          }\n          storeDir = cfsReader;\n          assert storeDir != null;\n        } else {\n          storeDir = dir;\n          assert storeDir != null;\n        }\n\n        final String storesSegment;\n        if (si.getDocStoreOffset() != -1) {\n          storesSegment = si.getDocStoreSegment();\n        } else {\n          storesSegment = segment;\n        }\n\n        fieldsReaderOrig = new FieldsReader(storeDir, storesSegment, fieldInfos, readBufferSize,\n                                            si.getDocStoreOffset(), si.docCount);\n\n        // Verify two sources of \"maxDoc\" agree:\n        if (si.getDocStoreOffset() == -1 && fieldsReaderOrig.size() != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + fieldsReaderOrig.size() + \" but segmentInfo shows \" + si.docCount);\n        }\n\n        if (fieldInfos.hasVectors()) { // open term vector files only as needed\n          termVectorsReaderOrig = new TermVectorsReader(storeDir, storesSegment, fieldInfos, readBufferSize, si.getDocStoreOffset(), si.docCount);\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"775efee7f959e0dd3df7960b93767d9e00b78751":["66f3dadb253a44f4cccc81c8a21b685b18b201fb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["775efee7f959e0dd3df7960b93767d9e00b78751"],"66f3dadb253a44f4cccc81c8a21b685b18b201fb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"775efee7f959e0dd3df7960b93767d9e00b78751":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["66f3dadb253a44f4cccc81c8a21b685b18b201fb"],"66f3dadb253a44f4cccc81c8a21b685b18b201fb":["775efee7f959e0dd3df7960b93767d9e00b78751"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}