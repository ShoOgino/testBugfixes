{"path":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","commits":[{"id":"d80013b5e260def972025c93a0b08524f9c38f49","date":1170102801,"type":1,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.get(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.get(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = new SolrQueryParser(schema, null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n\n      /* for parsing slopy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* * * Main User Query * * */\n\n      String userQuery = U.partialEscape\n        (U.stripUnbalancedQuotes(params.get(Q))).toString();\n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      String minShouldMatch = params.get(DMP.MM, \"100%\");\n      Query dis = up.parse(userQuery);\n      Query parsedUserQuery = dis;\n\n      if (dis instanceof BooleanQuery) {\n        BooleanQuery t = new BooleanQuery();\n        U.flattenBooleanQuery(t, (BooleanQuery)dis);\n        U.setMinShouldMatch(t, minShouldMatch);                \n        parsedUserQuery = t;\n      } \n      query.add(parsedUserQuery, Occur.MUST);\n\n      /* * * Add on Phrases for the Query * * */\n            \n      /* build up phrase boosting queries */\n\n      /* if the userQuery already has some quotes, stip them out.\n       * we've already done the phrases they asked for in the main\n       * part of the query, this is to boost docs that may not have\n       * matched those phrases but do match looser phrases.\n       */\n      String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n      Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n      if (null != phrase) {\n        query.add(phrase, Occur.SHOULD);\n      }\n            \n      /* * * Boosting Query * * */\n\n      String boostQuery = params.get(DMP.BQ);\n      if (null != boostQuery && !boostQuery.equals(\"\")) {\n        Query tmp = p.parse(boostQuery);\n        /* if the default boost was used, and we've got a BooleanQuery\n         * extract the subqueries out and use them directly\n         */\n        if (1.0f == tmp.getBoost() && tmp instanceof BooleanQuery) {\n          for (BooleanClause c : ((BooleanQuery)tmp).getClauses()) {\n            query.add(c);\n          }\n        } else {\n          query.add(tmp, BooleanClause.Occur.SHOULD);\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String boostFunc = params.get(DMP.BF);\n      if (null != boostFunc && !boostFunc.equals(\"\")) {\n        List<Query> funcs = U.parseFuncs(schema, boostFunc);\n        for (Query f : funcs) {\n          query.add(f, Occur.SHOULD);\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"boostquery\", boostQuery);\n          debug.add(\"boostfunc\", boostFunc);\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            List<String> fqs = new ArrayList<String>(restrictions.size());\n            for (Query fq : restrictions) {\n              fqs.add(QueryParsing.toString(fq, req.getSchema()));\n            }\n            debug.add(\"parsed_filter_queries\",fqs);\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception durring debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req)) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(results.docList, parsedUserQuery, \n                                           req, highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n        \n    try {\n      U.setDefaults(req,defaults,appends,invariants);\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.get(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.get(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = new SolrQueryParser(schema, null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n\n      /* for parsing slopy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* * * Main User Query * * */\n\n      String userQuery = U.partialEscape\n        (U.stripUnbalancedQuotes(params.get(Q))).toString();\n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      String minShouldMatch = params.get(DMP.MM, \"100%\");\n      Query dis = up.parse(userQuery);\n      Query parsedUserQuery = dis;\n\n      if (dis instanceof BooleanQuery) {\n        BooleanQuery t = new BooleanQuery();\n        U.flattenBooleanQuery(t, (BooleanQuery)dis);\n        U.setMinShouldMatch(t, minShouldMatch);                \n        parsedUserQuery = t;\n      } \n      query.add(parsedUserQuery, Occur.MUST);\n\n      /* * * Add on Phrases for the Query * * */\n            \n      /* build up phrase boosting queries */\n\n      /* if the userQuery already has some quotes, stip them out.\n       * we've already done the phrases they asked for in the main\n       * part of the query, this is to boost docs that may not have\n       * matched those phrases but do match looser phrases.\n       */\n      String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n      Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n      if (null != phrase) {\n        query.add(phrase, Occur.SHOULD);\n      }\n            \n      /* * * Boosting Query * * */\n\n      String boostQuery = params.get(DMP.BQ);\n      if (null != boostQuery && !boostQuery.equals(\"\")) {\n        Query tmp = p.parse(boostQuery);\n        /* if the default boost was used, and we've got a BooleanQuery\n         * extract the subqueries out and use them directly\n         */\n        if (1.0f == tmp.getBoost() && tmp instanceof BooleanQuery) {\n          for (BooleanClause c : ((BooleanQuery)tmp).getClauses()) {\n            query.add(c);\n          }\n        } else {\n          query.add(tmp, BooleanClause.Occur.SHOULD);\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String boostFunc = params.get(DMP.BF);\n      if (null != boostFunc && !boostFunc.equals(\"\")) {\n        List<Query> funcs = U.parseFuncs(schema, boostFunc);\n        for (Query f : funcs) {\n          query.add(f, Occur.SHOULD);\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"boostquery\", boostQuery);\n          debug.add(\"boostfunc\", boostFunc);\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            List<String> fqs = new ArrayList<String>(restrictions.size());\n            for (Query fq : restrictions) {\n              fqs.add(QueryParsing.toString(fq, req.getSchema()));\n            }\n            debug.add(\"parsed_filter_queries\",fqs);\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception durring debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req)) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(results.docList, parsedUserQuery, \n                                           req, highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n            \n    } catch (Exception e) {\n      SolrException.log(SolrCore.log,e);\n      rsp.setException(e);\n      numErrors++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"468970e5c98bb1c832c6afa7a4587f03ecf16ba2","date":1172103730,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.get(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.get(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = new SolrQueryParser(schema, null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n\n      /* for parsing slopy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      /* * * Main User Query * * */\n      Query parsedUserQuery = null;\n      String userQuery = params.get( Q );\n      Query altUserQuery = null;\n      if( userQuery == null || userQuery.trim().length() < 1 ) {\n        // If no query is specified, we may have an alternate\n        String altQ = params.get( DMP.ALTQ );\n        if (altQ != null) {\n          altUserQuery = p.parse(altQ);\n          query.add( altUserQuery , Occur.MUST );\n        } else {\n          throw new SolrException( 400, \"missing query string\" );\n        }\n      }\n      else {\n        // There is a valid query string\n        userQuery = U.partialEscape(U.stripUnbalancedQuotes(userQuery)).toString();\n            \n        String minShouldMatch = params.get(DMP.MM, \"100%\");\n        Query dis = up.parse(userQuery);\n        parsedUserQuery = dis;\n  \n        if (dis instanceof BooleanQuery) {\n          BooleanQuery t = new BooleanQuery();\n          U.flattenBooleanQuery(t, (BooleanQuery)dis);\n          U.setMinShouldMatch(t, minShouldMatch);                \n          parsedUserQuery = t;\n        } \n        query.add(parsedUserQuery, Occur.MUST);\n        \n\n        /* * * Add on Phrases for the Query * * */\n              \n        /* build up phrase boosting queries */\n\n        /* if the userQuery already has some quotes, stip them out.\n         * we've already done the phrases they asked for in the main\n         * part of the query, this is to boost docs that may not have\n         * matched those phrases but do match looser phrases.\n         */\n        String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n        Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n        if (null != phrase) {\n          query.add(phrase, Occur.SHOULD);\n        }\n      }\n\n            \n      /* * * Boosting Query * * */\n\n      String boostQuery = params.get(DMP.BQ);\n      if (null != boostQuery && !boostQuery.equals(\"\")) {\n        Query tmp = p.parse(boostQuery);\n        /* if the default boost was used, and we've got a BooleanQuery\n         * extract the subqueries out and use them directly\n         */\n        if (1.0f == tmp.getBoost() && tmp instanceof BooleanQuery) {\n          for (BooleanClause c : ((BooleanQuery)tmp).getClauses()) {\n            query.add(c);\n          }\n        } else {\n          query.add(tmp, BooleanClause.Occur.SHOULD);\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String boostFunc = params.get(DMP.BF);\n      if (null != boostFunc && !boostFunc.equals(\"\")) {\n        List<Query> funcs = U.parseFuncs(schema, boostFunc);\n        for (Query f : funcs) {\n          query.add(f, Occur.SHOULD);\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"altquerystring\", altUserQuery);\n          debug.add(\"boostquery\", boostQuery);\n          debug.add(\"boostfunc\", boostFunc);\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            List<String> fqs = new ArrayList<String>(restrictions.size());\n            for (Query fq : restrictions) {\n              fqs.add(QueryParsing.toString(fq, req.getSchema()));\n            }\n            debug.add(\"parsed_filter_queries\",fqs);\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception durring debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req) && parsedUserQuery != null) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(results.docList, parsedUserQuery, \n                                           req, highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","sourceOld":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.get(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.get(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = new SolrQueryParser(schema, null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n\n      /* for parsing slopy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* * * Main User Query * * */\n\n      String userQuery = U.partialEscape\n        (U.stripUnbalancedQuotes(params.get(Q))).toString();\n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      String minShouldMatch = params.get(DMP.MM, \"100%\");\n      Query dis = up.parse(userQuery);\n      Query parsedUserQuery = dis;\n\n      if (dis instanceof BooleanQuery) {\n        BooleanQuery t = new BooleanQuery();\n        U.flattenBooleanQuery(t, (BooleanQuery)dis);\n        U.setMinShouldMatch(t, minShouldMatch);                \n        parsedUserQuery = t;\n      } \n      query.add(parsedUserQuery, Occur.MUST);\n\n      /* * * Add on Phrases for the Query * * */\n            \n      /* build up phrase boosting queries */\n\n      /* if the userQuery already has some quotes, stip them out.\n       * we've already done the phrases they asked for in the main\n       * part of the query, this is to boost docs that may not have\n       * matched those phrases but do match looser phrases.\n       */\n      String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n      Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n      if (null != phrase) {\n        query.add(phrase, Occur.SHOULD);\n      }\n            \n      /* * * Boosting Query * * */\n\n      String boostQuery = params.get(DMP.BQ);\n      if (null != boostQuery && !boostQuery.equals(\"\")) {\n        Query tmp = p.parse(boostQuery);\n        /* if the default boost was used, and we've got a BooleanQuery\n         * extract the subqueries out and use them directly\n         */\n        if (1.0f == tmp.getBoost() && tmp instanceof BooleanQuery) {\n          for (BooleanClause c : ((BooleanQuery)tmp).getClauses()) {\n            query.add(c);\n          }\n        } else {\n          query.add(tmp, BooleanClause.Occur.SHOULD);\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String boostFunc = params.get(DMP.BF);\n      if (null != boostFunc && !boostFunc.equals(\"\")) {\n        List<Query> funcs = U.parseFuncs(schema, boostFunc);\n        for (Query f : funcs) {\n          query.add(f, Occur.SHOULD);\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"boostquery\", boostQuery);\n          debug.add(\"boostfunc\", boostFunc);\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            List<String> fqs = new ArrayList<String>(restrictions.size());\n            for (Query fq : restrictions) {\n              fqs.add(QueryParsing.toString(fq, req.getSchema()));\n            }\n            debug.add(\"parsed_filter_queries\",fqs);\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception durring debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req)) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(results.docList, parsedUserQuery, \n                                           req, highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85a70962f5680a2c24a7abffb6d37d3ca2bfaaff","date":1172104671,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.get(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.get(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n      int qslop = params.getInt(DMP.QS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = new SolrQueryParser(schema, null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n      up.setPhraseSlop(qslop);\n      \n      /* for parsing slopy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      /* * * Main User Query * * */\n      Query parsedUserQuery = null;\n      String userQuery = params.get( Q );\n      Query altUserQuery = null;\n      if( userQuery == null || userQuery.trim().length() < 1 ) {\n        // If no query is specified, we may have an alternate\n        String altQ = params.get( DMP.ALTQ );\n        if (altQ != null) {\n          altUserQuery = p.parse(altQ);\n          query.add( altUserQuery , Occur.MUST );\n        } else {\n          throw new SolrException( 400, \"missing query string\" );\n        }\n      }\n      else {\n        // There is a valid query string\n        userQuery = U.partialEscape(U.stripUnbalancedQuotes(userQuery)).toString();\n            \n        String minShouldMatch = params.get(DMP.MM, \"100%\");\n        Query dis = up.parse(userQuery);\n        parsedUserQuery = dis;\n  \n        if (dis instanceof BooleanQuery) {\n          BooleanQuery t = new BooleanQuery();\n          U.flattenBooleanQuery(t, (BooleanQuery)dis);\n          U.setMinShouldMatch(t, minShouldMatch);                \n          parsedUserQuery = t;\n        } \n        query.add(parsedUserQuery, Occur.MUST);\n        \n\n        /* * * Add on Phrases for the Query * * */\n              \n        /* build up phrase boosting queries */\n\n        /* if the userQuery already has some quotes, stip them out.\n         * we've already done the phrases they asked for in the main\n         * part of the query, this is to boost docs that may not have\n         * matched those phrases but do match looser phrases.\n         */\n        String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n        Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n        if (null != phrase) {\n          query.add(phrase, Occur.SHOULD);\n        }\n      }\n\n            \n      /* * * Boosting Query * * */\n\n      String boostQuery = params.get(DMP.BQ);\n      if (null != boostQuery && !boostQuery.equals(\"\")) {\n        Query tmp = p.parse(boostQuery);\n        /* if the default boost was used, and we've got a BooleanQuery\n         * extract the subqueries out and use them directly\n         */\n        if (1.0f == tmp.getBoost() && tmp instanceof BooleanQuery) {\n          for (BooleanClause c : ((BooleanQuery)tmp).getClauses()) {\n            query.add(c);\n          }\n        } else {\n          query.add(tmp, BooleanClause.Occur.SHOULD);\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String boostFunc = params.get(DMP.BF);\n      if (null != boostFunc && !boostFunc.equals(\"\")) {\n        List<Query> funcs = U.parseFuncs(schema, boostFunc);\n        for (Query f : funcs) {\n          query.add(f, Occur.SHOULD);\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"altquerystring\", altUserQuery);\n          debug.add(\"boostquery\", boostQuery);\n          debug.add(\"boostfunc\", boostFunc);\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            List<String> fqs = new ArrayList<String>(restrictions.size());\n            for (Query fq : restrictions) {\n              fqs.add(QueryParsing.toString(fq, req.getSchema()));\n            }\n            debug.add(\"parsed_filter_queries\",fqs);\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception durring debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req) && parsedUserQuery != null) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(results.docList, parsedUserQuery, \n                                           req, highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","sourceOld":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.get(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.get(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = new SolrQueryParser(schema, null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n\n      /* for parsing slopy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      /* * * Main User Query * * */\n      Query parsedUserQuery = null;\n      String userQuery = params.get( Q );\n      Query altUserQuery = null;\n      if( userQuery == null || userQuery.trim().length() < 1 ) {\n        // If no query is specified, we may have an alternate\n        String altQ = params.get( DMP.ALTQ );\n        if (altQ != null) {\n          altUserQuery = p.parse(altQ);\n          query.add( altUserQuery , Occur.MUST );\n        } else {\n          throw new SolrException( 400, \"missing query string\" );\n        }\n      }\n      else {\n        // There is a valid query string\n        userQuery = U.partialEscape(U.stripUnbalancedQuotes(userQuery)).toString();\n            \n        String minShouldMatch = params.get(DMP.MM, \"100%\");\n        Query dis = up.parse(userQuery);\n        parsedUserQuery = dis;\n  \n        if (dis instanceof BooleanQuery) {\n          BooleanQuery t = new BooleanQuery();\n          U.flattenBooleanQuery(t, (BooleanQuery)dis);\n          U.setMinShouldMatch(t, minShouldMatch);                \n          parsedUserQuery = t;\n        } \n        query.add(parsedUserQuery, Occur.MUST);\n        \n\n        /* * * Add on Phrases for the Query * * */\n              \n        /* build up phrase boosting queries */\n\n        /* if the userQuery already has some quotes, stip them out.\n         * we've already done the phrases they asked for in the main\n         * part of the query, this is to boost docs that may not have\n         * matched those phrases but do match looser phrases.\n         */\n        String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n        Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n        if (null != phrase) {\n          query.add(phrase, Occur.SHOULD);\n        }\n      }\n\n            \n      /* * * Boosting Query * * */\n\n      String boostQuery = params.get(DMP.BQ);\n      if (null != boostQuery && !boostQuery.equals(\"\")) {\n        Query tmp = p.parse(boostQuery);\n        /* if the default boost was used, and we've got a BooleanQuery\n         * extract the subqueries out and use them directly\n         */\n        if (1.0f == tmp.getBoost() && tmp instanceof BooleanQuery) {\n          for (BooleanClause c : ((BooleanQuery)tmp).getClauses()) {\n            query.add(c);\n          }\n        } else {\n          query.add(tmp, BooleanClause.Occur.SHOULD);\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String boostFunc = params.get(DMP.BF);\n      if (null != boostFunc && !boostFunc.equals(\"\")) {\n        List<Query> funcs = U.parseFuncs(schema, boostFunc);\n        for (Query f : funcs) {\n          query.add(f, Occur.SHOULD);\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"altquerystring\", altUserQuery);\n          debug.add(\"boostquery\", boostQuery);\n          debug.add(\"boostfunc\", boostFunc);\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            List<String> fqs = new ArrayList<String>(restrictions.size());\n            for (Query fq : restrictions) {\n              fqs.add(QueryParsing.toString(fq, req.getSchema()));\n            }\n            debug.add(\"parsed_filter_queries\",fqs);\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception durring debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req) && parsedUserQuery != null) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(results.docList, parsedUserQuery, \n                                           req, highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4d1d1f748be6299a4bb58280fa1697824edc82c6","date":1172182682,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.get(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.get(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n      int qslop = params.getInt(DMP.QS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = schema.getSolrQueryParser(null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n      up.setPhraseSlop(qslop);\n      \n      /* for parsing slopy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      /* * * Main User Query * * */\n      Query parsedUserQuery = null;\n      String userQuery = params.get( Q );\n      Query altUserQuery = null;\n      if( userQuery == null || userQuery.trim().length() < 1 ) {\n        // If no query is specified, we may have an alternate\n        String altQ = params.get( DMP.ALTQ );\n        if (altQ != null) {\n          altUserQuery = p.parse(altQ);\n          query.add( altUserQuery , Occur.MUST );\n        } else {\n          throw new SolrException( 400, \"missing query string\" );\n        }\n      }\n      else {\n        // There is a valid query string\n        userQuery = U.partialEscape(U.stripUnbalancedQuotes(userQuery)).toString();\n            \n        String minShouldMatch = params.get(DMP.MM, \"100%\");\n        Query dis = up.parse(userQuery);\n        parsedUserQuery = dis;\n  \n        if (dis instanceof BooleanQuery) {\n          BooleanQuery t = new BooleanQuery();\n          U.flattenBooleanQuery(t, (BooleanQuery)dis);\n          U.setMinShouldMatch(t, minShouldMatch);                \n          parsedUserQuery = t;\n        } \n        query.add(parsedUserQuery, Occur.MUST);\n        \n\n        /* * * Add on Phrases for the Query * * */\n              \n        /* build up phrase boosting queries */\n\n        /* if the userQuery already has some quotes, stip them out.\n         * we've already done the phrases they asked for in the main\n         * part of the query, this is to boost docs that may not have\n         * matched those phrases but do match looser phrases.\n         */\n        String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n        Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n        if (null != phrase) {\n          query.add(phrase, Occur.SHOULD);\n        }\n      }\n\n            \n      /* * * Boosting Query * * */\n\n      String boostQuery = params.get(DMP.BQ);\n      if (null != boostQuery && !boostQuery.equals(\"\")) {\n        Query tmp = p.parse(boostQuery);\n        /* if the default boost was used, and we've got a BooleanQuery\n         * extract the subqueries out and use them directly\n         */\n        if (1.0f == tmp.getBoost() && tmp instanceof BooleanQuery) {\n          for (BooleanClause c : ((BooleanQuery)tmp).getClauses()) {\n            query.add(c);\n          }\n        } else {\n          query.add(tmp, BooleanClause.Occur.SHOULD);\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String boostFunc = params.get(DMP.BF);\n      if (null != boostFunc && !boostFunc.equals(\"\")) {\n        List<Query> funcs = U.parseFuncs(schema, boostFunc);\n        for (Query f : funcs) {\n          query.add(f, Occur.SHOULD);\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"altquerystring\", altUserQuery);\n          debug.add(\"boostquery\", boostQuery);\n          debug.add(\"boostfunc\", boostFunc);\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            List<String> fqs = new ArrayList<String>(restrictions.size());\n            for (Query fq : restrictions) {\n              fqs.add(QueryParsing.toString(fq, req.getSchema()));\n            }\n            debug.add(\"parsed_filter_queries\",fqs);\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception durring debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req) && parsedUserQuery != null) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(results.docList, parsedUserQuery, \n                                           req, highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","sourceOld":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.get(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.get(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n      int qslop = params.getInt(DMP.QS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = new SolrQueryParser(schema, null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n      up.setPhraseSlop(qslop);\n      \n      /* for parsing slopy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      /* * * Main User Query * * */\n      Query parsedUserQuery = null;\n      String userQuery = params.get( Q );\n      Query altUserQuery = null;\n      if( userQuery == null || userQuery.trim().length() < 1 ) {\n        // If no query is specified, we may have an alternate\n        String altQ = params.get( DMP.ALTQ );\n        if (altQ != null) {\n          altUserQuery = p.parse(altQ);\n          query.add( altUserQuery , Occur.MUST );\n        } else {\n          throw new SolrException( 400, \"missing query string\" );\n        }\n      }\n      else {\n        // There is a valid query string\n        userQuery = U.partialEscape(U.stripUnbalancedQuotes(userQuery)).toString();\n            \n        String minShouldMatch = params.get(DMP.MM, \"100%\");\n        Query dis = up.parse(userQuery);\n        parsedUserQuery = dis;\n  \n        if (dis instanceof BooleanQuery) {\n          BooleanQuery t = new BooleanQuery();\n          U.flattenBooleanQuery(t, (BooleanQuery)dis);\n          U.setMinShouldMatch(t, minShouldMatch);                \n          parsedUserQuery = t;\n        } \n        query.add(parsedUserQuery, Occur.MUST);\n        \n\n        /* * * Add on Phrases for the Query * * */\n              \n        /* build up phrase boosting queries */\n\n        /* if the userQuery already has some quotes, stip them out.\n         * we've already done the phrases they asked for in the main\n         * part of the query, this is to boost docs that may not have\n         * matched those phrases but do match looser phrases.\n         */\n        String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n        Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n        if (null != phrase) {\n          query.add(phrase, Occur.SHOULD);\n        }\n      }\n\n            \n      /* * * Boosting Query * * */\n\n      String boostQuery = params.get(DMP.BQ);\n      if (null != boostQuery && !boostQuery.equals(\"\")) {\n        Query tmp = p.parse(boostQuery);\n        /* if the default boost was used, and we've got a BooleanQuery\n         * extract the subqueries out and use them directly\n         */\n        if (1.0f == tmp.getBoost() && tmp instanceof BooleanQuery) {\n          for (BooleanClause c : ((BooleanQuery)tmp).getClauses()) {\n            query.add(c);\n          }\n        } else {\n          query.add(tmp, BooleanClause.Occur.SHOULD);\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String boostFunc = params.get(DMP.BF);\n      if (null != boostFunc && !boostFunc.equals(\"\")) {\n        List<Query> funcs = U.parseFuncs(schema, boostFunc);\n        for (Query f : funcs) {\n          query.add(f, Occur.SHOULD);\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"altquerystring\", altUserQuery);\n          debug.add(\"boostquery\", boostQuery);\n          debug.add(\"boostfunc\", boostFunc);\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            List<String> fqs = new ArrayList<String>(restrictions.size());\n            for (Query fq : restrictions) {\n              fqs.add(QueryParsing.toString(fq, req.getSchema()));\n            }\n            debug.add(\"parsed_filter_queries\",fqs);\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception durring debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req) && parsedUserQuery != null) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(results.docList, parsedUserQuery, \n                                           req, highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"269c8e9f1563aaf046389326e061a3a2c6a62a73","date":1173126130,"type":3,"author":"Mike Klaas","isMerge":false,"pathNew":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.getParams(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.getParams(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n      int qslop = params.getInt(DMP.QS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = schema.getSolrQueryParser(null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n      up.setPhraseSlop(qslop);\n      \n      /* for parsing slopy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      /* * * Main User Query * * */\n      Query parsedUserQuery = null;\n      String userQuery = params.get( Q );\n      Query altUserQuery = null;\n      if( userQuery == null || userQuery.trim().length() < 1 ) {\n        // If no query is specified, we may have an alternate\n        String altQ = params.get( DMP.ALTQ );\n        if (altQ != null) {\n          altUserQuery = p.parse(altQ);\n          query.add( altUserQuery , Occur.MUST );\n        } else {\n          throw new SolrException( 400, \"missing query string\" );\n        }\n      }\n      else {\n        // There is a valid query string\n        userQuery = U.partialEscape(U.stripUnbalancedQuotes(userQuery)).toString();\n            \n        String minShouldMatch = params.get(DMP.MM, \"100%\");\n        Query dis = up.parse(userQuery);\n        parsedUserQuery = dis;\n  \n        if (dis instanceof BooleanQuery) {\n          BooleanQuery t = new BooleanQuery();\n          U.flattenBooleanQuery(t, (BooleanQuery)dis);\n          U.setMinShouldMatch(t, minShouldMatch);                \n          parsedUserQuery = t;\n        } \n        query.add(parsedUserQuery, Occur.MUST);\n        \n\n        /* * * Add on Phrases for the Query * * */\n              \n        /* build up phrase boosting queries */\n\n        /* if the userQuery already has some quotes, stip them out.\n         * we've already done the phrases they asked for in the main\n         * part of the query, this is to boost docs that may not have\n         * matched those phrases but do match looser phrases.\n         */\n        String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n        Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n        if (null != phrase) {\n          query.add(phrase, Occur.SHOULD);\n        }\n      }\n\n            \n      /* * * Boosting Query * * */\n      String[] boostParams = params.getParams(DMP.BQ);\n      List<Query> boostQueries = U.parseQueryStrings(req, boostParams);\n      if (null != boostQueries) {\n        if(1 == boostQueries.size() && 1 == boostParams.length) {\n          /* legacy logic */\n          Query f = boostQueries.get(0);\n          if (1.0f == f.getBoost() && f instanceof BooleanQuery) {\n            /* if the default boost was used, and we've got a BooleanQuery\n             * extract the subqueries out and use them directly\n             */\n            for (BooleanClause c : ((BooleanQuery)f).getClauses()) {\n              query.add(c);\n            }\n          } else {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        } else {\n          for(Query f : boostQueries) {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String[] boostFuncs = params.getParams(DMP.BF);\n      if (null != boostFuncs && 0 != boostFuncs.length) {\n        for (String boostFunc : boostFuncs) {\n          if(null == boostFunc || \"\".equals(boostFunc)) continue;\n          List<Query> funcs = U.parseFuncs(schema, boostFunc);\n          for (Query f : funcs) {\n            query.add(f, Occur.SHOULD);          \n          }\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"altquerystring\", altUserQuery);\n          if (null != boostQueries) {\n            debug.add(\"boost_queries\", boostParams);\n            debug.add(\"parsed_boost_queries\", \n                      QueryParsing.toString(boostQueries, req.getSchema()));\n          }\n          debug.add(\"boostfuncs\", params.getParams(DMP.BF));\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            debug.add(\"parsed_filter_queries\", \n                      QueryParsing.toString(restrictions, req.getSchema()));\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception during debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req) && parsedUserQuery != null) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(\n\t       results.docList, \n\t       parsedUserQuery.rewrite(req.getSearcher().getReader()), \n\t       req, \n\t       highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","sourceOld":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.get(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.get(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n      int qslop = params.getInt(DMP.QS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = schema.getSolrQueryParser(null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n      up.setPhraseSlop(qslop);\n      \n      /* for parsing slopy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      /* * * Main User Query * * */\n      Query parsedUserQuery = null;\n      String userQuery = params.get( Q );\n      Query altUserQuery = null;\n      if( userQuery == null || userQuery.trim().length() < 1 ) {\n        // If no query is specified, we may have an alternate\n        String altQ = params.get( DMP.ALTQ );\n        if (altQ != null) {\n          altUserQuery = p.parse(altQ);\n          query.add( altUserQuery , Occur.MUST );\n        } else {\n          throw new SolrException( 400, \"missing query string\" );\n        }\n      }\n      else {\n        // There is a valid query string\n        userQuery = U.partialEscape(U.stripUnbalancedQuotes(userQuery)).toString();\n            \n        String minShouldMatch = params.get(DMP.MM, \"100%\");\n        Query dis = up.parse(userQuery);\n        parsedUserQuery = dis;\n  \n        if (dis instanceof BooleanQuery) {\n          BooleanQuery t = new BooleanQuery();\n          U.flattenBooleanQuery(t, (BooleanQuery)dis);\n          U.setMinShouldMatch(t, minShouldMatch);                \n          parsedUserQuery = t;\n        } \n        query.add(parsedUserQuery, Occur.MUST);\n        \n\n        /* * * Add on Phrases for the Query * * */\n              \n        /* build up phrase boosting queries */\n\n        /* if the userQuery already has some quotes, stip them out.\n         * we've already done the phrases they asked for in the main\n         * part of the query, this is to boost docs that may not have\n         * matched those phrases but do match looser phrases.\n         */\n        String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n        Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n        if (null != phrase) {\n          query.add(phrase, Occur.SHOULD);\n        }\n      }\n\n            \n      /* * * Boosting Query * * */\n\n      String boostQuery = params.get(DMP.BQ);\n      if (null != boostQuery && !boostQuery.equals(\"\")) {\n        Query tmp = p.parse(boostQuery);\n        /* if the default boost was used, and we've got a BooleanQuery\n         * extract the subqueries out and use them directly\n         */\n        if (1.0f == tmp.getBoost() && tmp instanceof BooleanQuery) {\n          for (BooleanClause c : ((BooleanQuery)tmp).getClauses()) {\n            query.add(c);\n          }\n        } else {\n          query.add(tmp, BooleanClause.Occur.SHOULD);\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String boostFunc = params.get(DMP.BF);\n      if (null != boostFunc && !boostFunc.equals(\"\")) {\n        List<Query> funcs = U.parseFuncs(schema, boostFunc);\n        for (Query f : funcs) {\n          query.add(f, Occur.SHOULD);\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"altquerystring\", altUserQuery);\n          debug.add(\"boostquery\", boostQuery);\n          debug.add(\"boostfunc\", boostFunc);\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            List<String> fqs = new ArrayList<String>(restrictions.size());\n            for (Query fq : restrictions) {\n              fqs.add(QueryParsing.toString(fq, req.getSchema()));\n            }\n            debug.add(\"parsed_filter_queries\",fqs);\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception durring debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req) && parsedUserQuery != null) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(results.docList, parsedUserQuery, \n                                           req, highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09a5ddec58fdfc5abfb601dea8ca6c83a29e0320","date":1177905482,"type":3,"author":"Erik Hatcher","isMerge":false,"pathNew":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.getParams(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.getParams(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n      int qslop = params.getInt(DMP.QS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = schema.getSolrQueryParser(null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n      up.setPhraseSlop(qslop);\n      \n      /* for parsing sloppy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      /* * * Main User Query * * */\n      Query parsedUserQuery = null;\n      String userQuery = params.get( Q );\n      Query altUserQuery = null;\n      if( userQuery == null || userQuery.trim().length() < 1 ) {\n        // If no query is specified, we may have an alternate\n        String altQ = params.get( DMP.ALTQ );\n        if (altQ != null) {\n          altUserQuery = p.parse(altQ);\n          query.add( altUserQuery , Occur.MUST );\n        } else {\n          throw new SolrException( 400, \"missing query string\" );\n        }\n      }\n      else {\n        // There is a valid query string\n        userQuery = U.partialEscape(U.stripUnbalancedQuotes(userQuery)).toString();\n            \n        String minShouldMatch = params.get(DMP.MM, \"100%\");\n        Query dis = up.parse(userQuery);\n        parsedUserQuery = dis;\n  \n        if (dis instanceof BooleanQuery) {\n          BooleanQuery t = new BooleanQuery();\n          U.flattenBooleanQuery(t, (BooleanQuery)dis);\n          U.setMinShouldMatch(t, minShouldMatch);                \n          parsedUserQuery = t;\n        } \n        query.add(parsedUserQuery, Occur.MUST);\n        \n\n        /* * * Add on Phrases for the Query * * */\n              \n        /* build up phrase boosting queries */\n\n        /* if the userQuery already has some quotes, stip them out.\n         * we've already done the phrases they asked for in the main\n         * part of the query, this is to boost docs that may not have\n         * matched those phrases but do match looser phrases.\n         */\n        String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n        Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n        if (null != phrase) {\n          query.add(phrase, Occur.SHOULD);\n        }\n      }\n\n            \n      /* * * Boosting Query * * */\n      String[] boostParams = params.getParams(DMP.BQ);\n      List<Query> boostQueries = U.parseQueryStrings(req, boostParams);\n      if (null != boostQueries) {\n        if(1 == boostQueries.size() && 1 == boostParams.length) {\n          /* legacy logic */\n          Query f = boostQueries.get(0);\n          if (1.0f == f.getBoost() && f instanceof BooleanQuery) {\n            /* if the default boost was used, and we've got a BooleanQuery\n             * extract the subqueries out and use them directly\n             */\n            for (BooleanClause c : ((BooleanQuery)f).getClauses()) {\n              query.add(c);\n            }\n          } else {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        } else {\n          for(Query f : boostQueries) {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String[] boostFuncs = params.getParams(DMP.BF);\n      if (null != boostFuncs && 0 != boostFuncs.length) {\n        for (String boostFunc : boostFuncs) {\n          if(null == boostFunc || \"\".equals(boostFunc)) continue;\n          List<Query> funcs = U.parseFuncs(schema, boostFunc);\n          for (Query f : funcs) {\n            query.add(f, Occur.SHOULD);          \n          }\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"altquerystring\", altUserQuery);\n          if (null != boostQueries) {\n            debug.add(\"boost_queries\", boostParams);\n            debug.add(\"parsed_boost_queries\", \n                      QueryParsing.toString(boostQueries, req.getSchema()));\n          }\n          debug.add(\"boostfuncs\", params.getParams(DMP.BF));\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            debug.add(\"parsed_filter_queries\", \n                      QueryParsing.toString(restrictions, req.getSchema()));\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception during debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req) && parsedUserQuery != null) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(\n\t       results.docList, \n\t       parsedUserQuery.rewrite(req.getSearcher().getReader()), \n\t       req, \n\t       highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","sourceOld":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.getParams(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.getParams(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n      int qslop = params.getInt(DMP.QS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = schema.getSolrQueryParser(null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n      up.setPhraseSlop(qslop);\n      \n      /* for parsing slopy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      /* * * Main User Query * * */\n      Query parsedUserQuery = null;\n      String userQuery = params.get( Q );\n      Query altUserQuery = null;\n      if( userQuery == null || userQuery.trim().length() < 1 ) {\n        // If no query is specified, we may have an alternate\n        String altQ = params.get( DMP.ALTQ );\n        if (altQ != null) {\n          altUserQuery = p.parse(altQ);\n          query.add( altUserQuery , Occur.MUST );\n        } else {\n          throw new SolrException( 400, \"missing query string\" );\n        }\n      }\n      else {\n        // There is a valid query string\n        userQuery = U.partialEscape(U.stripUnbalancedQuotes(userQuery)).toString();\n            \n        String minShouldMatch = params.get(DMP.MM, \"100%\");\n        Query dis = up.parse(userQuery);\n        parsedUserQuery = dis;\n  \n        if (dis instanceof BooleanQuery) {\n          BooleanQuery t = new BooleanQuery();\n          U.flattenBooleanQuery(t, (BooleanQuery)dis);\n          U.setMinShouldMatch(t, minShouldMatch);                \n          parsedUserQuery = t;\n        } \n        query.add(parsedUserQuery, Occur.MUST);\n        \n\n        /* * * Add on Phrases for the Query * * */\n              \n        /* build up phrase boosting queries */\n\n        /* if the userQuery already has some quotes, stip them out.\n         * we've already done the phrases they asked for in the main\n         * part of the query, this is to boost docs that may not have\n         * matched those phrases but do match looser phrases.\n         */\n        String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n        Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n        if (null != phrase) {\n          query.add(phrase, Occur.SHOULD);\n        }\n      }\n\n            \n      /* * * Boosting Query * * */\n      String[] boostParams = params.getParams(DMP.BQ);\n      List<Query> boostQueries = U.parseQueryStrings(req, boostParams);\n      if (null != boostQueries) {\n        if(1 == boostQueries.size() && 1 == boostParams.length) {\n          /* legacy logic */\n          Query f = boostQueries.get(0);\n          if (1.0f == f.getBoost() && f instanceof BooleanQuery) {\n            /* if the default boost was used, and we've got a BooleanQuery\n             * extract the subqueries out and use them directly\n             */\n            for (BooleanClause c : ((BooleanQuery)f).getClauses()) {\n              query.add(c);\n            }\n          } else {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        } else {\n          for(Query f : boostQueries) {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String[] boostFuncs = params.getParams(DMP.BF);\n      if (null != boostFuncs && 0 != boostFuncs.length) {\n        for (String boostFunc : boostFuncs) {\n          if(null == boostFunc || \"\".equals(boostFunc)) continue;\n          List<Query> funcs = U.parseFuncs(schema, boostFunc);\n          for (Query f : funcs) {\n            query.add(f, Occur.SHOULD);          \n          }\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"altquerystring\", altUserQuery);\n          if (null != boostQueries) {\n            debug.add(\"boost_queries\", boostParams);\n            debug.add(\"parsed_boost_queries\", \n                      QueryParsing.toString(boostQueries, req.getSchema()));\n          }\n          debug.add(\"boostfuncs\", params.getParams(DMP.BF));\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            debug.add(\"parsed_filter_queries\", \n                      QueryParsing.toString(restrictions, req.getSchema()));\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception during debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req) && parsedUserQuery != null) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(\n\t       results.docList, \n\t       parsedUserQuery.rewrite(req.getSearcher().getReader()), \n\t       req, \n\t       highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"27adc06684d74d32d4d07537a81903ffbf816d27","date":1178648148,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.getParams(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.getParams(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n      int qslop = params.getInt(DMP.QS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = schema.getSolrQueryParser(null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n      up.setPhraseSlop(qslop);\n      \n      /* for parsing sloppy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      /* * * Main User Query * * */\n      Query parsedUserQuery = null;\n      String userQuery = params.get( Q );\n      Query altUserQuery = null;\n      if( userQuery == null || userQuery.trim().length() < 1 ) {\n        // If no query is specified, we may have an alternate\n        String altQ = params.get( DMP.ALTQ );\n        if (altQ != null) {\n          altUserQuery = p.parse(altQ);\n          query.add( altUserQuery , Occur.MUST );\n        } else {\n          throw new SolrException( 400, \"missing query string\" );\n        }\n      }\n      else {\n        // There is a valid query string\n        userQuery = U.partialEscape(U.stripUnbalancedQuotes(userQuery)).toString();\n            \n        String minShouldMatch = params.get(DMP.MM, \"100%\");\n        Query dis = up.parse(userQuery);\n        parsedUserQuery = dis;\n  \n        if (dis instanceof BooleanQuery) {\n          BooleanQuery t = new BooleanQuery();\n          U.flattenBooleanQuery(t, (BooleanQuery)dis);\n          U.setMinShouldMatch(t, minShouldMatch);                \n          parsedUserQuery = t;\n        } \n        query.add(parsedUserQuery, Occur.MUST);\n        \n\n        /* * * Add on Phrases for the Query * * */\n              \n        /* build up phrase boosting queries */\n\n        /* if the userQuery already has some quotes, stip them out.\n         * we've already done the phrases they asked for in the main\n         * part of the query, this is to boost docs that may not have\n         * matched those phrases but do match looser phrases.\n         */\n        String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n        Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n        if (null != phrase) {\n          query.add(phrase, Occur.SHOULD);\n        }\n      }\n\n            \n      /* * * Boosting Query * * */\n      String[] boostParams = params.getParams(DMP.BQ);\n      List<Query> boostQueries = U.parseQueryStrings(req, boostParams);\n      if (null != boostQueries) {\n        if(1 == boostQueries.size() && 1 == boostParams.length) {\n          /* legacy logic */\n          Query f = boostQueries.get(0);\n          if (1.0f == f.getBoost() && f instanceof BooleanQuery) {\n            /* if the default boost was used, and we've got a BooleanQuery\n             * extract the subqueries out and use them directly\n             */\n            for (Object c : ((BooleanQuery)f).clauses()) {\n              query.add((BooleanClause)c);\n            }\n          } else {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        } else {\n          for(Query f : boostQueries) {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String[] boostFuncs = params.getParams(DMP.BF);\n      if (null != boostFuncs && 0 != boostFuncs.length) {\n        for (String boostFunc : boostFuncs) {\n          if(null == boostFunc || \"\".equals(boostFunc)) continue;\n          List<Query> funcs = U.parseFuncs(schema, boostFunc);\n          for (Query f : funcs) {\n            query.add(f, Occur.SHOULD);          \n          }\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"altquerystring\", altUserQuery);\n          if (null != boostQueries) {\n            debug.add(\"boost_queries\", boostParams);\n            debug.add(\"parsed_boost_queries\", \n                      QueryParsing.toString(boostQueries, req.getSchema()));\n          }\n          debug.add(\"boostfuncs\", params.getParams(DMP.BF));\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            debug.add(\"parsed_filter_queries\", \n                      QueryParsing.toString(restrictions, req.getSchema()));\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception during debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req) && parsedUserQuery != null) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(\n\t       results.docList, \n\t       parsedUserQuery.rewrite(req.getSearcher().getReader()), \n\t       req, \n\t       highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","sourceOld":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.getParams(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.getParams(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n      int qslop = params.getInt(DMP.QS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = schema.getSolrQueryParser(null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n      up.setPhraseSlop(qslop);\n      \n      /* for parsing sloppy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      /* * * Main User Query * * */\n      Query parsedUserQuery = null;\n      String userQuery = params.get( Q );\n      Query altUserQuery = null;\n      if( userQuery == null || userQuery.trim().length() < 1 ) {\n        // If no query is specified, we may have an alternate\n        String altQ = params.get( DMP.ALTQ );\n        if (altQ != null) {\n          altUserQuery = p.parse(altQ);\n          query.add( altUserQuery , Occur.MUST );\n        } else {\n          throw new SolrException( 400, \"missing query string\" );\n        }\n      }\n      else {\n        // There is a valid query string\n        userQuery = U.partialEscape(U.stripUnbalancedQuotes(userQuery)).toString();\n            \n        String minShouldMatch = params.get(DMP.MM, \"100%\");\n        Query dis = up.parse(userQuery);\n        parsedUserQuery = dis;\n  \n        if (dis instanceof BooleanQuery) {\n          BooleanQuery t = new BooleanQuery();\n          U.flattenBooleanQuery(t, (BooleanQuery)dis);\n          U.setMinShouldMatch(t, minShouldMatch);                \n          parsedUserQuery = t;\n        } \n        query.add(parsedUserQuery, Occur.MUST);\n        \n\n        /* * * Add on Phrases for the Query * * */\n              \n        /* build up phrase boosting queries */\n\n        /* if the userQuery already has some quotes, stip them out.\n         * we've already done the phrases they asked for in the main\n         * part of the query, this is to boost docs that may not have\n         * matched those phrases but do match looser phrases.\n         */\n        String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n        Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n        if (null != phrase) {\n          query.add(phrase, Occur.SHOULD);\n        }\n      }\n\n            \n      /* * * Boosting Query * * */\n      String[] boostParams = params.getParams(DMP.BQ);\n      List<Query> boostQueries = U.parseQueryStrings(req, boostParams);\n      if (null != boostQueries) {\n        if(1 == boostQueries.size() && 1 == boostParams.length) {\n          /* legacy logic */\n          Query f = boostQueries.get(0);\n          if (1.0f == f.getBoost() && f instanceof BooleanQuery) {\n            /* if the default boost was used, and we've got a BooleanQuery\n             * extract the subqueries out and use them directly\n             */\n            for (BooleanClause c : ((BooleanQuery)f).getClauses()) {\n              query.add(c);\n            }\n          } else {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        } else {\n          for(Query f : boostQueries) {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String[] boostFuncs = params.getParams(DMP.BF);\n      if (null != boostFuncs && 0 != boostFuncs.length) {\n        for (String boostFunc : boostFuncs) {\n          if(null == boostFunc || \"\".equals(boostFunc)) continue;\n          List<Query> funcs = U.parseFuncs(schema, boostFunc);\n          for (Query f : funcs) {\n            query.add(f, Occur.SHOULD);          \n          }\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"altquerystring\", altUserQuery);\n          if (null != boostQueries) {\n            debug.add(\"boost_queries\", boostParams);\n            debug.add(\"parsed_boost_queries\", \n                      QueryParsing.toString(boostQueries, req.getSchema()));\n          }\n          debug.add(\"boostfuncs\", params.getParams(DMP.BF));\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            debug.add(\"parsed_filter_queries\", \n                      QueryParsing.toString(restrictions, req.getSchema()));\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception during debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req) && parsedUserQuery != null) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(\n\t       results.docList, \n\t       parsedUserQuery.rewrite(req.getSearcher().getReader()), \n\t       req, \n\t       highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c4abe53aaee39b5f2f41dd9a0b905c1ddf880996","date":1180477701,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.getParams(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.getParams(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n      int qslop = params.getInt(DMP.QS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = schema.getSolrQueryParser(null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n      up.setPhraseSlop(qslop);\n      \n      /* for parsing sloppy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      /* * * Main User Query * * */\n      Query parsedUserQuery = null;\n      String userQuery = params.get( Q );\n      Query altUserQuery = null;\n      if( userQuery == null || userQuery.trim().length() < 1 ) {\n        // If no query is specified, we may have an alternate\n        String altQ = params.get( DMP.ALTQ );\n        if (altQ != null) {\n          altUserQuery = p.parse(altQ);\n          query.add( altUserQuery , Occur.MUST );\n        } else {\n          throw new SolrException( SolrException.ErrorCode.BAD_REQUEST, \"missing query string\" );\n        }\n      }\n      else {\n        // There is a valid query string\n        userQuery = U.partialEscape(U.stripUnbalancedQuotes(userQuery)).toString();\n            \n        String minShouldMatch = params.get(DMP.MM, \"100%\");\n        Query dis = up.parse(userQuery);\n        parsedUserQuery = dis;\n  \n        if (dis instanceof BooleanQuery) {\n          BooleanQuery t = new BooleanQuery();\n          U.flattenBooleanQuery(t, (BooleanQuery)dis);\n          U.setMinShouldMatch(t, minShouldMatch);                \n          parsedUserQuery = t;\n        } \n        query.add(parsedUserQuery, Occur.MUST);\n        \n\n        /* * * Add on Phrases for the Query * * */\n              \n        /* build up phrase boosting queries */\n\n        /* if the userQuery already has some quotes, stip them out.\n         * we've already done the phrases they asked for in the main\n         * part of the query, this is to boost docs that may not have\n         * matched those phrases but do match looser phrases.\n         */\n        String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n        Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n        if (null != phrase) {\n          query.add(phrase, Occur.SHOULD);\n        }\n      }\n\n            \n      /* * * Boosting Query * * */\n      String[] boostParams = params.getParams(DMP.BQ);\n      List<Query> boostQueries = U.parseQueryStrings(req, boostParams);\n      if (null != boostQueries) {\n        if(1 == boostQueries.size() && 1 == boostParams.length) {\n          /* legacy logic */\n          Query f = boostQueries.get(0);\n          if (1.0f == f.getBoost() && f instanceof BooleanQuery) {\n            /* if the default boost was used, and we've got a BooleanQuery\n             * extract the subqueries out and use them directly\n             */\n            for (Object c : ((BooleanQuery)f).clauses()) {\n              query.add((BooleanClause)c);\n            }\n          } else {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        } else {\n          for(Query f : boostQueries) {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String[] boostFuncs = params.getParams(DMP.BF);\n      if (null != boostFuncs && 0 != boostFuncs.length) {\n        for (String boostFunc : boostFuncs) {\n          if(null == boostFunc || \"\".equals(boostFunc)) continue;\n          List<Query> funcs = U.parseFuncs(schema, boostFunc);\n          for (Query f : funcs) {\n            query.add(f, Occur.SHOULD);          \n          }\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"altquerystring\", altUserQuery);\n          if (null != boostQueries) {\n            debug.add(\"boost_queries\", boostParams);\n            debug.add(\"parsed_boost_queries\", \n                      QueryParsing.toString(boostQueries, req.getSchema()));\n          }\n          debug.add(\"boostfuncs\", params.getParams(DMP.BF));\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            debug.add(\"parsed_filter_queries\", \n                      QueryParsing.toString(restrictions, req.getSchema()));\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception during debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req) && parsedUserQuery != null) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(\n\t       results.docList, \n\t       parsedUserQuery.rewrite(req.getSearcher().getReader()), \n\t       req, \n\t       highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","sourceOld":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.getParams(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.getParams(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n      int qslop = params.getInt(DMP.QS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = schema.getSolrQueryParser(null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n      up.setPhraseSlop(qslop);\n      \n      /* for parsing sloppy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      /* * * Main User Query * * */\n      Query parsedUserQuery = null;\n      String userQuery = params.get( Q );\n      Query altUserQuery = null;\n      if( userQuery == null || userQuery.trim().length() < 1 ) {\n        // If no query is specified, we may have an alternate\n        String altQ = params.get( DMP.ALTQ );\n        if (altQ != null) {\n          altUserQuery = p.parse(altQ);\n          query.add( altUserQuery , Occur.MUST );\n        } else {\n          throw new SolrException( 400, \"missing query string\" );\n        }\n      }\n      else {\n        // There is a valid query string\n        userQuery = U.partialEscape(U.stripUnbalancedQuotes(userQuery)).toString();\n            \n        String minShouldMatch = params.get(DMP.MM, \"100%\");\n        Query dis = up.parse(userQuery);\n        parsedUserQuery = dis;\n  \n        if (dis instanceof BooleanQuery) {\n          BooleanQuery t = new BooleanQuery();\n          U.flattenBooleanQuery(t, (BooleanQuery)dis);\n          U.setMinShouldMatch(t, minShouldMatch);                \n          parsedUserQuery = t;\n        } \n        query.add(parsedUserQuery, Occur.MUST);\n        \n\n        /* * * Add on Phrases for the Query * * */\n              \n        /* build up phrase boosting queries */\n\n        /* if the userQuery already has some quotes, stip them out.\n         * we've already done the phrases they asked for in the main\n         * part of the query, this is to boost docs that may not have\n         * matched those phrases but do match looser phrases.\n         */\n        String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n        Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n        if (null != phrase) {\n          query.add(phrase, Occur.SHOULD);\n        }\n      }\n\n            \n      /* * * Boosting Query * * */\n      String[] boostParams = params.getParams(DMP.BQ);\n      List<Query> boostQueries = U.parseQueryStrings(req, boostParams);\n      if (null != boostQueries) {\n        if(1 == boostQueries.size() && 1 == boostParams.length) {\n          /* legacy logic */\n          Query f = boostQueries.get(0);\n          if (1.0f == f.getBoost() && f instanceof BooleanQuery) {\n            /* if the default boost was used, and we've got a BooleanQuery\n             * extract the subqueries out and use them directly\n             */\n            for (Object c : ((BooleanQuery)f).clauses()) {\n              query.add((BooleanClause)c);\n            }\n          } else {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        } else {\n          for(Query f : boostQueries) {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String[] boostFuncs = params.getParams(DMP.BF);\n      if (null != boostFuncs && 0 != boostFuncs.length) {\n        for (String boostFunc : boostFuncs) {\n          if(null == boostFunc || \"\".equals(boostFunc)) continue;\n          List<Query> funcs = U.parseFuncs(schema, boostFunc);\n          for (Query f : funcs) {\n            query.add(f, Occur.SHOULD);          \n          }\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"altquerystring\", altUserQuery);\n          if (null != boostQueries) {\n            debug.add(\"boost_queries\", boostParams);\n            debug.add(\"parsed_boost_queries\", \n                      QueryParsing.toString(boostQueries, req.getSchema()));\n          }\n          debug.add(\"boostfuncs\", params.getParams(DMP.BF));\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            debug.add(\"parsed_filter_queries\", \n                      QueryParsing.toString(restrictions, req.getSchema()));\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception during debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req) && parsedUserQuery != null) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(\n\t       results.docList, \n\t       parsedUserQuery.rewrite(req.getSearcher().getReader()), \n\t       req, \n\t       highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3abdd666f12a1d3197de9c612ea8e83cfbb6e7bb","date":1181791578,"type":5,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/request/DisMaxRequestHandler#handleRequestBody(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.getParams(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.getParams(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n      int qslop = params.getInt(DMP.QS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = schema.getSolrQueryParser(null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n      up.setPhraseSlop(qslop);\n      \n      /* for parsing sloppy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      /* * * Main User Query * * */\n      Query parsedUserQuery = null;\n      String userQuery = params.get( Q );\n      Query altUserQuery = null;\n      if( userQuery == null || userQuery.trim().length() < 1 ) {\n        // If no query is specified, we may have an alternate\n        String altQ = params.get( DMP.ALTQ );\n        if (altQ != null) {\n          altUserQuery = p.parse(altQ);\n          query.add( altUserQuery , Occur.MUST );\n        } else {\n          throw new SolrException( SolrException.ErrorCode.BAD_REQUEST, \"missing query string\" );\n        }\n      }\n      else {\n        // There is a valid query string\n        userQuery = U.partialEscape(U.stripUnbalancedQuotes(userQuery)).toString();\n            \n        String minShouldMatch = params.get(DMP.MM, \"100%\");\n        Query dis = up.parse(userQuery);\n        parsedUserQuery = dis;\n  \n        if (dis instanceof BooleanQuery) {\n          BooleanQuery t = new BooleanQuery();\n          U.flattenBooleanQuery(t, (BooleanQuery)dis);\n          U.setMinShouldMatch(t, minShouldMatch);                \n          parsedUserQuery = t;\n        } \n        query.add(parsedUserQuery, Occur.MUST);\n        \n\n        /* * * Add on Phrases for the Query * * */\n              \n        /* build up phrase boosting queries */\n\n        /* if the userQuery already has some quotes, stip them out.\n         * we've already done the phrases they asked for in the main\n         * part of the query, this is to boost docs that may not have\n         * matched those phrases but do match looser phrases.\n         */\n        String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n        Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n        if (null != phrase) {\n          query.add(phrase, Occur.SHOULD);\n        }\n      }\n\n            \n      /* * * Boosting Query * * */\n      String[] boostParams = params.getParams(DMP.BQ);\n      List<Query> boostQueries = U.parseQueryStrings(req, boostParams);\n      if (null != boostQueries) {\n        if(1 == boostQueries.size() && 1 == boostParams.length) {\n          /* legacy logic */\n          Query f = boostQueries.get(0);\n          if (1.0f == f.getBoost() && f instanceof BooleanQuery) {\n            /* if the default boost was used, and we've got a BooleanQuery\n             * extract the subqueries out and use them directly\n             */\n            for (Object c : ((BooleanQuery)f).clauses()) {\n              query.add((BooleanClause)c);\n            }\n          } else {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        } else {\n          for(Query f : boostQueries) {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String[] boostFuncs = params.getParams(DMP.BF);\n      if (null != boostFuncs && 0 != boostFuncs.length) {\n        for (String boostFunc : boostFuncs) {\n          if(null == boostFunc || \"\".equals(boostFunc)) continue;\n          List<Query> funcs = U.parseFuncs(schema, boostFunc);\n          for (Query f : funcs) {\n            query.add(f, Occur.SHOULD);          \n          }\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"altquerystring\", altUserQuery);\n          if (null != boostQueries) {\n            debug.add(\"boost_queries\", boostParams);\n            debug.add(\"parsed_boost_queries\", \n                      QueryParsing.toString(boostQueries, req.getSchema()));\n          }\n          debug.add(\"boostfuncs\", params.getParams(DMP.BF));\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            debug.add(\"parsed_filter_queries\", \n                      QueryParsing.toString(restrictions, req.getSchema()));\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception during debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req) && parsedUserQuery != null) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(\n\t       results.docList, \n\t       parsedUserQuery.rewrite(req.getSearcher().getReader()), \n\t       req, \n\t       highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","sourceOld":"  public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throws Exception\n  {\n      SolrParams params = req.getParams();\n      \n      int flags = 0;\n      \n      SolrIndexSearcher s = req.getSearcher();\n      IndexSchema schema = req.getSchema();\n            \n      Map<String,Float> queryFields = U.parseFieldBoosts(params.getParams(DMP.QF));\n      Map<String,Float> phraseFields = U.parseFieldBoosts(params.getParams(DMP.PF));\n\n      float tiebreaker = params.getFloat(DMP.TIE, 0.0f);\n            \n      int pslop = params.getInt(DMP.PS, 0);\n      int qslop = params.getInt(DMP.QS, 0);\n\n      /* a generic parser for parsing regular lucene queries */\n      QueryParser p = schema.getSolrQueryParser(null);\n\n      /* a parser for dealing with user input, which will convert\n       * things to DisjunctionMaxQueries\n       */\n      U.DisjunctionMaxQueryParser up =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      up.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, queryFields);\n      up.setPhraseSlop(qslop);\n      \n      /* for parsing sloppy phrases using DisjunctionMaxQueries */\n      U.DisjunctionMaxQueryParser pp =\n        new U.DisjunctionMaxQueryParser(schema, IMPOSSIBLE_FIELD_NAME);\n      pp.addAlias(IMPOSSIBLE_FIELD_NAME,\n                  tiebreaker, phraseFields);\n      pp.setPhraseSlop(pslop);\n            \n            \n      /* the main query we will execute.  we disable the coord because\n       * this query is an artificial construct\n       */\n      BooleanQuery query = new BooleanQuery(true);\n\n      /* * * Main User Query * * */\n      Query parsedUserQuery = null;\n      String userQuery = params.get( Q );\n      Query altUserQuery = null;\n      if( userQuery == null || userQuery.trim().length() < 1 ) {\n        // If no query is specified, we may have an alternate\n        String altQ = params.get( DMP.ALTQ );\n        if (altQ != null) {\n          altUserQuery = p.parse(altQ);\n          query.add( altUserQuery , Occur.MUST );\n        } else {\n          throw new SolrException( SolrException.ErrorCode.BAD_REQUEST, \"missing query string\" );\n        }\n      }\n      else {\n        // There is a valid query string\n        userQuery = U.partialEscape(U.stripUnbalancedQuotes(userQuery)).toString();\n            \n        String minShouldMatch = params.get(DMP.MM, \"100%\");\n        Query dis = up.parse(userQuery);\n        parsedUserQuery = dis;\n  \n        if (dis instanceof BooleanQuery) {\n          BooleanQuery t = new BooleanQuery();\n          U.flattenBooleanQuery(t, (BooleanQuery)dis);\n          U.setMinShouldMatch(t, minShouldMatch);                \n          parsedUserQuery = t;\n        } \n        query.add(parsedUserQuery, Occur.MUST);\n        \n\n        /* * * Add on Phrases for the Query * * */\n              \n        /* build up phrase boosting queries */\n\n        /* if the userQuery already has some quotes, stip them out.\n         * we've already done the phrases they asked for in the main\n         * part of the query, this is to boost docs that may not have\n         * matched those phrases but do match looser phrases.\n         */\n        String userPhraseQuery = userQuery.replace(\"\\\"\",\"\");\n        Query phrase = pp.parse(\"\\\"\" + userPhraseQuery + \"\\\"\");\n        if (null != phrase) {\n          query.add(phrase, Occur.SHOULD);\n        }\n      }\n\n            \n      /* * * Boosting Query * * */\n      String[] boostParams = params.getParams(DMP.BQ);\n      List<Query> boostQueries = U.parseQueryStrings(req, boostParams);\n      if (null != boostQueries) {\n        if(1 == boostQueries.size() && 1 == boostParams.length) {\n          /* legacy logic */\n          Query f = boostQueries.get(0);\n          if (1.0f == f.getBoost() && f instanceof BooleanQuery) {\n            /* if the default boost was used, and we've got a BooleanQuery\n             * extract the subqueries out and use them directly\n             */\n            for (Object c : ((BooleanQuery)f).clauses()) {\n              query.add((BooleanClause)c);\n            }\n          } else {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        } else {\n          for(Query f : boostQueries) {\n            query.add(f, BooleanClause.Occur.SHOULD);\n          }\n        }\n      }\n\n      /* * * Boosting Functions * * */\n\n      String[] boostFuncs = params.getParams(DMP.BF);\n      if (null != boostFuncs && 0 != boostFuncs.length) {\n        for (String boostFunc : boostFuncs) {\n          if(null == boostFunc || \"\".equals(boostFunc)) continue;\n          List<Query> funcs = U.parseFuncs(schema, boostFunc);\n          for (Query f : funcs) {\n            query.add(f, Occur.SHOULD);          \n          }\n        }\n      }\n            \n      /* * * Restrict Results * * */\n\n      List<Query> restrictions = U.parseFilterQueries(req);\n            \n      /* * * Generate Main Results * * */\n\n      flags |= U.setReturnFields(req,rsp);\n      \n      DocListAndSet results = new DocListAndSet();\n      NamedList facetInfo = null;\n      if (params.getBool(FACET,false)) {\n        results = s.getDocListAndSet(query, restrictions,\n                                     SolrPluginUtils.getSort(req),\n                                     req.getStart(), req.getLimit(),\n                                     flags);\n        facetInfo = getFacetInfo(req, rsp, results.docSet);\n      } else {\n        results.docList = s.getDocList(query, restrictions,\n                                       SolrPluginUtils.getSort(req),\n                                       req.getStart(), req.getLimit(),\n                                       flags);\n      }\n      rsp.add(\"response\",results.docList);\n      // pre-fetch returned documents\n      U.optimizePreFetchDocs(results.docList, query, req, rsp);\n\n      \n      if (null != facetInfo) rsp.add(\"facet_counts\", facetInfo);\n\n\n            \n      /* * * Debugging Info * * */\n\n      try {\n        NamedList debug = U.doStandardDebug(req, userQuery, query, results.docList);\n        if (null != debug) {\n          debug.add(\"altquerystring\", altUserQuery);\n          if (null != boostQueries) {\n            debug.add(\"boost_queries\", boostParams);\n            debug.add(\"parsed_boost_queries\", \n                      QueryParsing.toString(boostQueries, req.getSchema()));\n          }\n          debug.add(\"boostfuncs\", params.getParams(DMP.BF));\n          if (null != restrictions) {\n            debug.add(\"filter_queries\", params.getParams(FQ));\n            debug.add(\"parsed_filter_queries\", \n                      QueryParsing.toString(restrictions, req.getSchema()));\n          }\n          rsp.add(\"debug\", debug);\n        }\n\n      } catch (Exception e) {\n        SolrException.logOnce(SolrCore.log,\n                              \"Exception during debug\", e);\n        rsp.add(\"exception_during_debug\", SolrException.toStr(e));\n      }\n\n      /* * * Highlighting/Summarizing  * * */\n      if(HighlightingUtils.isHighlightingEnabled(req) && parsedUserQuery != null) {\n        String[] highFields = queryFields.keySet().toArray(new String[0]);\n        NamedList sumData =\n          HighlightingUtils.doHighlighting(\n\t       results.docList, \n\t       parsedUserQuery.rewrite(req.getSearcher().getReader()), \n\t       req, \n\t       highFields);\n        if(sumData != null)\n          rsp.add(\"highlighting\", sumData);\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3abdd666f12a1d3197de9c612ea8e83cfbb6e7bb":["c4abe53aaee39b5f2f41dd9a0b905c1ddf880996"],"269c8e9f1563aaf046389326e061a3a2c6a62a73":["4d1d1f748be6299a4bb58280fa1697824edc82c6"],"468970e5c98bb1c832c6afa7a4587f03ecf16ba2":["d80013b5e260def972025c93a0b08524f9c38f49"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"85a70962f5680a2c24a7abffb6d37d3ca2bfaaff":["468970e5c98bb1c832c6afa7a4587f03ecf16ba2"],"09a5ddec58fdfc5abfb601dea8ca6c83a29e0320":["269c8e9f1563aaf046389326e061a3a2c6a62a73"],"4d1d1f748be6299a4bb58280fa1697824edc82c6":["85a70962f5680a2c24a7abffb6d37d3ca2bfaaff"],"c4abe53aaee39b5f2f41dd9a0b905c1ddf880996":["27adc06684d74d32d4d07537a81903ffbf816d27"],"27adc06684d74d32d4d07537a81903ffbf816d27":["09a5ddec58fdfc5abfb601dea8ca6c83a29e0320"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d80013b5e260def972025c93a0b08524f9c38f49":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"]},"commit2Childs":{"3abdd666f12a1d3197de9c612ea8e83cfbb6e7bb":[],"269c8e9f1563aaf046389326e061a3a2c6a62a73":["09a5ddec58fdfc5abfb601dea8ca6c83a29e0320"],"468970e5c98bb1c832c6afa7a4587f03ecf16ba2":["85a70962f5680a2c24a7abffb6d37d3ca2bfaaff"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["d80013b5e260def972025c93a0b08524f9c38f49"],"85a70962f5680a2c24a7abffb6d37d3ca2bfaaff":["4d1d1f748be6299a4bb58280fa1697824edc82c6"],"09a5ddec58fdfc5abfb601dea8ca6c83a29e0320":["27adc06684d74d32d4d07537a81903ffbf816d27"],"4d1d1f748be6299a4bb58280fa1697824edc82c6":["269c8e9f1563aaf046389326e061a3a2c6a62a73"],"c4abe53aaee39b5f2f41dd9a0b905c1ddf880996":["3abdd666f12a1d3197de9c612ea8e83cfbb6e7bb"],"27adc06684d74d32d4d07537a81903ffbf816d27":["c4abe53aaee39b5f2f41dd9a0b905c1ddf880996"],"d80013b5e260def972025c93a0b08524f9c38f49":["468970e5c98bb1c832c6afa7a4587f03ecf16ba2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3abdd666f12a1d3197de9c612ea8e83cfbb6e7bb","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}