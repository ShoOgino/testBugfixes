{"path":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","commits":[{"id":"08932c793647a36953d1816b1060121f48820d3f","date":1277386540,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"/dev/null","sourceNew":"  public void testSurrogatesOrder() throws Exception {\n    Directory dir = new MockRAMDirectory();\n\n    Codec codec = new PreFlexCodec();\n\n    Random r = newRandom();\n    FieldInfos fieldInfos = new FieldInfos();\n    List<FieldAndText> fieldTerms = new ArrayList<FieldAndText>();\n    SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    // hack alert!!\n    int uniqueTermCount = si.docCount;\n\n    FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    assertNotNull(fields);\n\n    if (DEBUG) {\n      System.out.println(\"\\nTEST: now enum\");\n    }\n    FieldsEnum fieldsEnum = fields.iterator();\n    String field;\n    UnicodeUtil.UTF16Result utf16 = new UnicodeUtil.UTF16Result();\n\n    int termCount = 0;\n    while((field = fieldsEnum.next()) != null) {\n      TermsEnum termsEnum = fieldsEnum.terms();\n      BytesRef text;\n      BytesRef lastText = null;\n      while((text = termsEnum.next()) != null) {\n        UnicodeUtil.UTF8toUTF16(text.bytes, text.offset, text.length, utf16);\n        if (DEBUG) {\n          System.out.println(\"got term=\" + field + \":\" + UnicodeUtil.toHexString(new String(utf16.result, 0, utf16.length)));\n          System.out.println();\n        }\n        if (lastText == null) {\n          lastText = new BytesRef(text);\n        } else {\n          assertTrue(lastText.compareTo(text) < 0);\n          lastText.copy(text);\n        }\n        assertEquals(fieldTerms.get(termCount).field, field);\n        assertEquals(fieldTerms.get(termCount).text, text);\n        termCount++;\n      }\n      if (DEBUG) {\n        System.out.println(\"  no more terms for field=\" + field);\n      }\n    }\n    assertEquals(uniqueTermCount, termCount);\n\n    fields.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"256366680a61632ef0df879389a7715601d37823","date":1278264334,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = new MockRAMDirectory();\n\n    Codec codec = new PreFlexCodec();\n\n    Random r = newRandom();\n    FieldInfos fieldInfos = new FieldInfos();\n    List<FieldAndText> fieldTerms = new ArrayList<FieldAndText>();\n    SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    // hack alert!!\n    int uniqueTermCount = si.docCount;\n\n    FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    assertNotNull(fields);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: now enum\");\n    }\n    FieldsEnum fieldsEnum = fields.iterator();\n    String field;\n    UnicodeUtil.UTF16Result utf16 = new UnicodeUtil.UTF16Result();\n\n    int termCount = 0;\n    while((field = fieldsEnum.next()) != null) {\n      TermsEnum termsEnum = fieldsEnum.terms();\n      BytesRef text;\n      BytesRef lastText = null;\n      while((text = termsEnum.next()) != null) {\n        UnicodeUtil.UTF8toUTF16(text.bytes, text.offset, text.length, utf16);\n        if (VERBOSE) {\n          System.out.println(\"got term=\" + field + \":\" + UnicodeUtil.toHexString(new String(utf16.result, 0, utf16.length)));\n          System.out.println();\n        }\n        if (lastText == null) {\n          lastText = new BytesRef(text);\n        } else {\n          assertTrue(lastText.compareTo(text) < 0);\n          lastText.copy(text);\n        }\n        assertEquals(fieldTerms.get(termCount).field, field);\n        assertEquals(fieldTerms.get(termCount).text, text);\n        termCount++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  no more terms for field=\" + field);\n      }\n    }\n    assertEquals(uniqueTermCount, termCount);\n\n    fields.close();\n  }\n\n","sourceOld":"  public void testSurrogatesOrder() throws Exception {\n    Directory dir = new MockRAMDirectory();\n\n    Codec codec = new PreFlexCodec();\n\n    Random r = newRandom();\n    FieldInfos fieldInfos = new FieldInfos();\n    List<FieldAndText> fieldTerms = new ArrayList<FieldAndText>();\n    SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    // hack alert!!\n    int uniqueTermCount = si.docCount;\n\n    FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    assertNotNull(fields);\n\n    if (DEBUG) {\n      System.out.println(\"\\nTEST: now enum\");\n    }\n    FieldsEnum fieldsEnum = fields.iterator();\n    String field;\n    UnicodeUtil.UTF16Result utf16 = new UnicodeUtil.UTF16Result();\n\n    int termCount = 0;\n    while((field = fieldsEnum.next()) != null) {\n      TermsEnum termsEnum = fieldsEnum.terms();\n      BytesRef text;\n      BytesRef lastText = null;\n      while((text = termsEnum.next()) != null) {\n        UnicodeUtil.UTF8toUTF16(text.bytes, text.offset, text.length, utf16);\n        if (DEBUG) {\n          System.out.println(\"got term=\" + field + \":\" + UnicodeUtil.toHexString(new String(utf16.result, 0, utf16.length)));\n          System.out.println();\n        }\n        if (lastText == null) {\n          lastText = new BytesRef(text);\n        } else {\n          assertTrue(lastText.compareTo(text) < 0);\n          lastText.copy(text);\n        }\n        assertEquals(fieldTerms.get(termCount).field, field);\n        assertEquals(fieldTerms.get(termCount).text, text);\n        termCount++;\n      }\n      if (DEBUG) {\n        System.out.println(\"  no more terms for field=\" + field);\n      }\n    }\n    assertEquals(uniqueTermCount, termCount);\n\n    fields.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4f29ba80b723649f5feb7e37afe1a558dd2c1304","date":1278318805,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = new MockRAMDirectory();\n\n    Codec codec = new PreFlexCodec();\n\n    Random r = newRandom();\n    FieldInfos fieldInfos = new FieldInfos();\n    List<Term> fieldTerms = new ArrayList<Term>();\n    SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    // hack alert!!\n    int uniqueTermCount = si.docCount;\n\n    FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    assertNotNull(fields);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: now enum\");\n    }\n    FieldsEnum fieldsEnum = fields.iterator();\n    String field;\n    UnicodeUtil.UTF16Result utf16 = new UnicodeUtil.UTF16Result();\n\n    int termCount = 0;\n    while((field = fieldsEnum.next()) != null) {\n      TermsEnum termsEnum = fieldsEnum.terms();\n      BytesRef text;\n      BytesRef lastText = null;\n      while((text = termsEnum.next()) != null) {\n        if (VERBOSE) {\n          UnicodeUtil.UTF8toUTF16(text.bytes, text.offset, text.length, utf16);\n          System.out.println(\"got term=\" + field + \":\" + UnicodeUtil.toHexString(new String(utf16.result, 0, utf16.length)));\n          System.out.println();\n        }\n        if (lastText == null) {\n          lastText = new BytesRef(text);\n        } else {\n          assertTrue(lastText.compareTo(text) < 0);\n          lastText.copy(text);\n        }\n        assertEquals(fieldTerms.get(termCount).field(), field);\n        assertEquals(fieldTerms.get(termCount).bytes(), text);\n        termCount++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  no more terms for field=\" + field);\n      }\n    }\n    assertEquals(uniqueTermCount, termCount);\n\n    fields.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = new MockRAMDirectory();\n\n    Codec codec = new PreFlexCodec();\n\n    Random r = newRandom();\n    FieldInfos fieldInfos = new FieldInfos();\n    List<FieldAndText> fieldTerms = new ArrayList<FieldAndText>();\n    SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    // hack alert!!\n    int uniqueTermCount = si.docCount;\n\n    FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    assertNotNull(fields);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: now enum\");\n    }\n    FieldsEnum fieldsEnum = fields.iterator();\n    String field;\n    UnicodeUtil.UTF16Result utf16 = new UnicodeUtil.UTF16Result();\n\n    int termCount = 0;\n    while((field = fieldsEnum.next()) != null) {\n      TermsEnum termsEnum = fieldsEnum.terms();\n      BytesRef text;\n      BytesRef lastText = null;\n      while((text = termsEnum.next()) != null) {\n        UnicodeUtil.UTF8toUTF16(text.bytes, text.offset, text.length, utf16);\n        if (VERBOSE) {\n          System.out.println(\"got term=\" + field + \":\" + UnicodeUtil.toHexString(new String(utf16.result, 0, utf16.length)));\n          System.out.println();\n        }\n        if (lastText == null) {\n          lastText = new BytesRef(text);\n        } else {\n          assertTrue(lastText.compareTo(text) < 0);\n          lastText.copy(text);\n        }\n        assertEquals(fieldTerms.get(termCount).field, field);\n        assertEquals(fieldTerms.get(termCount).text, text);\n        termCount++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  no more terms for field=\" + field);\n      }\n    }\n    assertEquals(uniqueTermCount, termCount);\n\n    fields.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = new MockRAMDirectory();\n\n    Codec codec = new PreFlexCodec();\n\n    Random r = newRandom();\n    FieldInfos fieldInfos = new FieldInfos();\n    List<Term> fieldTerms = new ArrayList<Term>();\n    SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    // hack alert!!\n    int uniqueTermCount = si.docCount;\n\n    FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    assertNotNull(fields);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: now enum\");\n    }\n    FieldsEnum fieldsEnum = fields.iterator();\n    String field;\n    UnicodeUtil.UTF16Result utf16 = new UnicodeUtil.UTF16Result();\n\n    int termCount = 0;\n    while((field = fieldsEnum.next()) != null) {\n      TermsEnum termsEnum = fieldsEnum.terms();\n      BytesRef text;\n      BytesRef lastText = null;\n      while((text = termsEnum.next()) != null) {\n        if (VERBOSE) {\n          UnicodeUtil.UTF8toUTF16(text.bytes, text.offset, text.length, utf16);\n          System.out.println(\"got term=\" + field + \":\" + UnicodeUtil.toHexString(new String(utf16.result, 0, utf16.length)));\n          System.out.println();\n        }\n        if (lastText == null) {\n          lastText = new BytesRef(text);\n        } else {\n          assertTrue(lastText.compareTo(text) < 0);\n          lastText.copy(text);\n        }\n        assertEquals(fieldTerms.get(termCount).field(), field);\n        assertEquals(fieldTerms.get(termCount).bytes(), text);\n        termCount++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  no more terms for field=\" + field);\n      }\n    }\n    assertEquals(uniqueTermCount, termCount);\n\n    fields.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"163fe85a71d778fd2b7747f65ca27b54829e2e57","date":1279898785,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Random r = newRandom();\n\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(r,\n                                                dir,\n                                                new IndexWriterConfig(TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(r) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(r, fieldTerms, reader);\n    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = new MockRAMDirectory();\n\n    Codec codec = new PreFlexCodec();\n\n    Random r = newRandom();\n    FieldInfos fieldInfos = new FieldInfos();\n    List<Term> fieldTerms = new ArrayList<Term>();\n    SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    // hack alert!!\n    int uniqueTermCount = si.docCount;\n\n    FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    assertNotNull(fields);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: now enum\");\n    }\n    FieldsEnum fieldsEnum = fields.iterator();\n    String field;\n    UnicodeUtil.UTF16Result utf16 = new UnicodeUtil.UTF16Result();\n\n    int termCount = 0;\n    while((field = fieldsEnum.next()) != null) {\n      TermsEnum termsEnum = fieldsEnum.terms();\n      BytesRef text;\n      BytesRef lastText = null;\n      while((text = termsEnum.next()) != null) {\n        if (VERBOSE) {\n          UnicodeUtil.UTF8toUTF16(text.bytes, text.offset, text.length, utf16);\n          System.out.println(\"got term=\" + field + \":\" + UnicodeUtil.toHexString(new String(utf16.result, 0, utf16.length)));\n          System.out.println();\n        }\n        if (lastText == null) {\n          lastText = new BytesRef(text);\n        } else {\n          assertTrue(lastText.compareTo(text) < 0);\n          lastText.copy(text);\n        }\n        assertEquals(fieldTerms.get(termCount).field(), field);\n        assertEquals(fieldTerms.get(termCount).bytes(), text);\n        termCount++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  no more terms for field=\" + field);\n      }\n    }\n    assertEquals(uniqueTermCount, termCount);\n\n    fields.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15bbd254c1506df5299c4df8c148262c7bd6301e","date":1279913113,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Random r = newRandom();\n\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(r,\n                                                dir,\n                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(r) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(r, fieldTerms, reader);\n    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Random r = newRandom();\n\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(r,\n                                                dir,\n                                                new IndexWriterConfig(TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(r) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(r, fieldTerms, reader);\n    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"24b91b08ba3110a0904b8ba9803276bf9a9b5f6d","date":1279972526,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Random r = newRandom();\n\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(r,\n                                                dir,\n                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec(null))));\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(r) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(r, fieldTerms, reader);\n    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Random r = newRandom();\n\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(r,\n                                                dir,\n                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      Term protoTerm = new Term(field);\n\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(r) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(r, fieldTerms, reader);\n    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"399a364d374f2132b6d9ff9fd7f997a9f2ef734f","date":1279978822,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Random r = newRandom();\n\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(r,\n                                                dir,\n                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(r) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(r, fieldTerms, reader);\n    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Random r = newRandom();\n\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(r,\n                                                dir,\n                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec(null))));\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(r) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(r, fieldTerms, reader);\n    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b103252dee6afa1b6d7a622c773d178788eb85a","date":1280180143,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Random r = newRandom();\n\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(r,\n                                                dir,\n                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(r) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(r, fieldTerms, reader);\n    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = new MockRAMDirectory();\n\n    Codec codec = new PreFlexCodec();\n\n    Random r = newRandom();\n    FieldInfos fieldInfos = new FieldInfos();\n    List<Term> fieldTerms = new ArrayList<Term>();\n    SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    // hack alert!!\n    int uniqueTermCount = si.docCount;\n\n    FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    assertNotNull(fields);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: now enum\");\n    }\n    FieldsEnum fieldsEnum = fields.iterator();\n    String field;\n    UnicodeUtil.UTF16Result utf16 = new UnicodeUtil.UTF16Result();\n\n    int termCount = 0;\n    while((field = fieldsEnum.next()) != null) {\n      TermsEnum termsEnum = fieldsEnum.terms();\n      BytesRef text;\n      BytesRef lastText = null;\n      while((text = termsEnum.next()) != null) {\n        if (VERBOSE) {\n          UnicodeUtil.UTF8toUTF16(text.bytes, text.offset, text.length, utf16);\n          System.out.println(\"got term=\" + field + \":\" + UnicodeUtil.toHexString(new String(utf16.result, 0, utf16.length)));\n          System.out.println();\n        }\n        if (lastText == null) {\n          lastText = new BytesRef(text);\n        } else {\n          assertTrue(lastText.compareTo(text) < 0);\n          lastText.copy(text);\n        }\n        assertEquals(fieldTerms.get(termCount).field(), field);\n        assertEquals(fieldTerms.get(termCount).bytes(), text);\n        termCount++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  no more terms for field=\" + field);\n      }\n    }\n    assertEquals(uniqueTermCount, termCount);\n\n    fields.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0e45742e10e8e3b98e854babe6dbb07a4197b71","date":1280230285,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Random r = newRandom();\n\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(r,\n                                                dir,\n                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(r) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(r, fieldTerms, reader);\n    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Random r = newRandom();\n\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(r,\n                                                dir,\n                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000*_TestUtil.getRandomMultiplier();\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(r) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(r, fieldTerms, reader);\n    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3242a09f703274d3b9283f2064a1a33064b53a1b","date":1280263474,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Random r = newRandom();\n\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(r,\n                                                dir,\n                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(r) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(r, fieldTerms, reader);\n    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = new MockRAMDirectory();\n\n    Codec codec = new PreFlexCodec();\n\n    Random r = newRandom();\n    FieldInfos fieldInfos = new FieldInfos();\n    List<Term> fieldTerms = new ArrayList<Term>();\n    SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    // hack alert!!\n    int uniqueTermCount = si.docCount;\n\n    FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    assertNotNull(fields);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: now enum\");\n    }\n    FieldsEnum fieldsEnum = fields.iterator();\n    String field;\n    UnicodeUtil.UTF16Result utf16 = new UnicodeUtil.UTF16Result();\n\n    int termCount = 0;\n    while((field = fieldsEnum.next()) != null) {\n      TermsEnum termsEnum = fieldsEnum.terms();\n      BytesRef text;\n      BytesRef lastText = null;\n      while((text = termsEnum.next()) != null) {\n        if (VERBOSE) {\n          UnicodeUtil.UTF8toUTF16(text.bytes, text.offset, text.length, utf16);\n          System.out.println(\"got term=\" + field + \":\" + UnicodeUtil.toHexString(new String(utf16.result, 0, utf16.length)));\n          System.out.println();\n        }\n        if (lastText == null) {\n          lastText = new BytesRef(text);\n        } else {\n          assertTrue(lastText.compareTo(text) < 0);\n          lastText.copy(text);\n        }\n        assertEquals(fieldTerms.get(termCount).field(), field);\n        assertEquals(fieldTerms.get(termCount).bytes(), text);\n        termCount++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  no more terms for field=\" + field);\n      }\n    }\n    assertEquals(uniqueTermCount, termCount);\n\n    fields.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Random r = newRandom();\n\n    Directory dir = newDirectory(r);\n    RandomIndexWriter w = new RandomIndexWriter(r,\n                                                dir,\n                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(r) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(r, fieldTerms, reader);\n    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Random r = newRandom();\n\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(r,\n                                                dir,\n                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(r) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(r, fieldTerms, reader);\n    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Random r = newRandom();\n\n    Directory dir = newDirectory(r);\n    RandomIndexWriter w = new RandomIndexWriter(r,\n                                                dir,\n                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(r) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(r, fieldTerms, reader);\n    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"132903c28af3aa6f67284b78de91c0f0a99488c2","date":1284282129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Random r = newRandom();\n\n    Directory dir = new MockRAMDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(r,\n                                                dir,\n                                                newIndexWriterConfig(r, TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(r, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(r) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(new Field(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(r, fieldTerms, reader);\n    doTestSeekDoesNotExist(r, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff6fd241dc6610f7f81b62e3ba4cedf105939623","date":1307331653,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = (TEST_NIGHTLY ? 10000 : 1000) * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79c2cb24929f2649a8875fb629086171f914d5ce","date":1307332717,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = (TEST_NIGHTLY ? 10000 : 1000) * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f83af14a2a8131b14d7aee6274c740334e0363d3","date":1307579822,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(1000);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = (TEST_NIGHTLY ? 10000 : 1000) * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(1000);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = 10000 * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(1000);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = (TEST_NIGHTLY ? 10000 : 1000) * RANDOM_MULTIPLIER;\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(1000);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, StringField.TYPE_UNSTORED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(1000);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, Field.Store.NO, Field.Index.NOT_ANALYZED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/lucene3x/TestSurrogates#testSurrogatesOrder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/preflex/TestSurrogates#testSurrogatesOrder().mjava","sourceNew":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodec(new PreFlexRWCodec()));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(1000);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, StringField.TYPE_UNSTORED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testSurrogatesOrder() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random,\n                                                dir,\n                                                newIndexWriterConfig( TEST_VERSION_CURRENT,\n                                                                      new MockAnalyzer(random)).setCodecProvider(_TestUtil.alwaysCodec(new PreFlexRWCodec())));\n\n    final int numField = _TestUtil.nextInt(random, 2, 5);\n\n    int uniqueTermCount = 0;\n\n    int tc = 0;\n\n    List<Term> fieldTerms = new ArrayList<Term>();\n\n    for(int f=0;f<numField;f++) {\n      String field = \"f\" + f;\n      final int numTerms = atLeast(1000);\n\n      final Set<String> uniqueTerms = new HashSet<String>();\n\n      for(int i=0;i<numTerms;i++) {\n        String term = getRandomString(random) + \"_ \" + (tc++);\n        uniqueTerms.add(term);\n        fieldTerms.add(new Term(field, term));\n        Document doc = new Document();\n        doc.add(newField(field, term, StringField.TYPE_UNSTORED));\n        w.addDocument(doc);\n      }\n      uniqueTermCount += uniqueTerms.size();\n    }\n\n    IndexReader reader = w.getReader();\n\n    if (VERBOSE) {\n      Collections.sort(fieldTerms, termAsUTF16Comparator);\n\n      System.out.println(\"\\nTEST: UTF16 order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    // sorts in code point order:\n    Collections.sort(fieldTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: codepoint order\");\n      for(Term t: fieldTerms) {\n        System.out.println(\"  \" + toHexString(t));\n      }\n    }\n\n    Term[] fieldTermsArray = fieldTerms.toArray(new Term[fieldTerms.size()]);\n\n    //SegmentInfo si = makePreFlexSegment(r, \"_0\", dir, fieldInfos, codec, fieldTerms);\n\n    //FieldsProducer fields = codec.fieldsProducer(new SegmentReadState(dir, si, fieldInfos, 1024, 1));\n    //assertNotNull(fields);\n\n    doTestStraightEnum(fieldTerms, reader, uniqueTermCount);\n    doTestSeekExists(random, fieldTerms, reader);\n    doTestSeekDoesNotExist(random, numField, fieldTerms, fieldTermsArray, reader);\n\n    reader.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e45742e10e8e3b98e854babe6dbb07a4197b71":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"f83af14a2a8131b14d7aee6274c740334e0363d3":["ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"15bbd254c1506df5299c4df8c148262c7bd6301e":["163fe85a71d778fd2b7747f65ca27b54829e2e57"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["3242a09f703274d3b9283f2064a1a33064b53a1b","132903c28af3aa6f67284b78de91c0f0a99488c2"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"79c2cb24929f2649a8875fb629086171f914d5ce":["a3776dccca01c11e7046323cfad46a3b4a471233","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["f83af14a2a8131b14d7aee6274c740334e0363d3"],"24b91b08ba3110a0904b8ba9803276bf9a9b5f6d":["15bbd254c1506df5299c4df8c148262c7bd6301e"],"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["79c2cb24929f2649a8875fb629086171f914d5ce","f83af14a2a8131b14d7aee6274c740334e0363d3"],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"4f29ba80b723649f5feb7e37afe1a558dd2c1304":["256366680a61632ef0df879389a7715601d37823"],"3242a09f703274d3b9283f2064a1a33064b53a1b":["5f4e87790277826a2aea119328600dfb07761f32","a0e45742e10e8e3b98e854babe6dbb07a4197b71"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["4f29ba80b723649f5feb7e37afe1a558dd2c1304","399a364d374f2132b6d9ff9fd7f997a9f2ef734f"],"163fe85a71d778fd2b7747f65ca27b54829e2e57":["4f29ba80b723649f5feb7e37afe1a558dd2c1304"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["a0e45742e10e8e3b98e854babe6dbb07a4197b71"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["132903c28af3aa6f67284b78de91c0f0a99488c2","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"5f4e87790277826a2aea119328600dfb07761f32":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4f29ba80b723649f5feb7e37afe1a558dd2c1304"],"962d04139994fce5193143ef35615499a9a96d78":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"7b91922b55d15444d554721b352861d028eb8278":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"08932c793647a36953d1816b1060121f48820d3f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a3776dccca01c11e7046323cfad46a3b4a471233":["132903c28af3aa6f67284b78de91c0f0a99488c2","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"399a364d374f2132b6d9ff9fd7f997a9f2ef734f":["24b91b08ba3110a0904b8ba9803276bf9a9b5f6d"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["135621f3a0670a9394eb563224a3b76cc4dddc0f","f83af14a2a8131b14d7aee6274c740334e0363d3"],"256366680a61632ef0df879389a7715601d37823":["08932c793647a36953d1816b1060121f48820d3f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7b91922b55d15444d554721b352861d028eb8278"]},"commit2Childs":{"a0e45742e10e8e3b98e854babe6dbb07a4197b71":["3242a09f703274d3b9283f2064a1a33064b53a1b","ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"f83af14a2a8131b14d7aee6274c740334e0363d3":["1509f151d7692d84fae414b2b799ac06ba60fcb4","a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"15bbd254c1506df5299c4df8c148262c7bd6301e":["24b91b08ba3110a0904b8ba9803276bf9a9b5f6d"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea","135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["962d04139994fce5193143ef35615499a9a96d78"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["ff6fd241dc6610f7f81b62e3ba4cedf105939623","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"79c2cb24929f2649a8875fb629086171f914d5ce":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5f4e87790277826a2aea119328600dfb07761f32","08932c793647a36953d1816b1060121f48820d3f"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["7b91922b55d15444d554721b352861d028eb8278"],"24b91b08ba3110a0904b8ba9803276bf9a9b5f6d":["399a364d374f2132b6d9ff9fd7f997a9f2ef734f"],"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":[],"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["f83af14a2a8131b14d7aee6274c740334e0363d3","79c2cb24929f2649a8875fb629086171f914d5ce"],"3242a09f703274d3b9283f2064a1a33064b53a1b":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"4f29ba80b723649f5feb7e37afe1a558dd2c1304":["4b103252dee6afa1b6d7a622c773d178788eb85a","163fe85a71d778fd2b7747f65ca27b54829e2e57","5f4e87790277826a2aea119328600dfb07761f32"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["a0e45742e10e8e3b98e854babe6dbb07a4197b71"],"163fe85a71d778fd2b7747f65ca27b54829e2e57":["15bbd254c1506df5299c4df8c148262c7bd6301e"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"5f4e87790277826a2aea119328600dfb07761f32":["3242a09f703274d3b9283f2064a1a33064b53a1b"],"962d04139994fce5193143ef35615499a9a96d78":[],"7b91922b55d15444d554721b352861d028eb8278":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"08932c793647a36953d1816b1060121f48820d3f":["256366680a61632ef0df879389a7715601d37823"],"a3776dccca01c11e7046323cfad46a3b4a471233":["79c2cb24929f2649a8875fb629086171f914d5ce"],"399a364d374f2132b6d9ff9fd7f997a9f2ef734f":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"256366680a61632ef0df879389a7715601d37823":["4f29ba80b723649f5feb7e37afe1a558dd2c1304"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","962d04139994fce5193143ef35615499a9a96d78","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}