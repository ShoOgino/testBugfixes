{"path":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(Reader,int,Set).mjava","commits":[{"id":"decc8a7344e9231708f9991fa09db2cafec7a2dd","date":1201187153,"type":0,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(Reader,int,Set).mjava","pathOld":"/dev/null","sourceNew":"  public WikipediaTokenizer(Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(input);\n    this.tokenOutput = tokenOutput;\n    this.scanner = new WikipediaTokenizerImpl(input);\n    this.untokenizedTypes = untokenizedTypes;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d59fc4c8c96a38502968987848162bcd90c3ef0","date":1248016017,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(Reader,int,Set).mjava","pathOld":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(Reader,int,Set).mjava","sourceNew":"  /**\n   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <conde>input</code> to a the newly created JFlex scanner.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(input);\n    this.tokenOutput = tokenOutput;\n    this.scanner = new WikipediaTokenizerImpl(input);\n    this.untokenizedTypes = untokenizedTypes;\n  }\n\n","sourceOld":"  public WikipediaTokenizer(Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(input);\n    this.tokenOutput = tokenOutput;\n    this.scanner = new WikipediaTokenizerImpl(input);\n    this.untokenizedTypes = untokenizedTypes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9b5756469957918cac40a831acec9cf01c8c2bb3","date":1249167152,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(Reader,int,Set).mjava","pathOld":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(Reader,int,Set).mjava","sourceNew":"  /**\n   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <conde>input</code> to a the newly created JFlex scanner.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(input);\n    this.tokenOutput = tokenOutput;\n    this.scanner = new WikipediaTokenizerImpl(input);\n    this.untokenizedTypes = untokenizedTypes;\n    this.offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);\n    this.typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);\n    this.posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);\n    this.termAtt = (TermAttribute) addAttribute(TermAttribute.class);\n    this.flagsAtt = (FlagsAttribute) addAttribute(FlagsAttribute.class);\n  }\n\n","sourceOld":"  /**\n   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <conde>input</code> to a the newly created JFlex scanner.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(input);\n    this.tokenOutput = tokenOutput;\n    this.scanner = new WikipediaTokenizerImpl(input);\n    this.untokenizedTypes = untokenizedTypes;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"047007f30fa7e5c9273d6dc8d292deca18da4c2c","date":1251016462,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(Reader,int,Set).mjava","pathOld":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(Reader,int,Set).mjava","sourceNew":"  /**\n   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <conde>input</code> to a the newly created JFlex scanner.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(input);\n    this.scanner = new WikipediaTokenizerImpl(input);\n    init(tokenOutput, untokenizedTypes);\n  }\n\n","sourceOld":"  /**\n   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <conde>input</code> to a the newly created JFlex scanner.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(input);\n    this.tokenOutput = tokenOutput;\n    this.scanner = new WikipediaTokenizerImpl(input);\n    this.untokenizedTypes = untokenizedTypes;\n    this.offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);\n    this.typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);\n    this.posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);\n    this.termAtt = (TermAttribute) addAttribute(TermAttribute.class);\n    this.flagsAtt = (FlagsAttribute) addAttribute(FlagsAttribute.class);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add7d922e63099fbce8f0a1b31216df7ef5067f1","date":1252002701,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(Reader,int,Set).mjava","pathOld":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(Reader,int,Set).mjava","sourceNew":"  /**\n   * Creates a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <code>input</code> to a the newly created JFlex scanner.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(input);\n    this.scanner = new WikipediaTokenizerImpl(input);\n    init(tokenOutput, untokenizedTypes);\n  }\n\n","sourceOld":"  /**\n   * Createa a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <conde>input</code> to a the newly created JFlex scanner.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(input);\n    this.scanner = new WikipediaTokenizerImpl(input);\n    init(tokenOutput, untokenizedTypes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c69d87d34a81230de56333f52f590caeb6d80667","date":1257848306,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(Reader,int,Set[String]).mjava","pathOld":"contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer#WikipediaTokenizer(Reader,int,Set).mjava","sourceNew":"  /**\n   * Creates a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <code>input</code> to a the newly created JFlex scanner.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(Reader input, int tokenOutput, Set<String> untokenizedTypes) {\n    super(input);\n    this.scanner = new WikipediaTokenizerImpl(input);\n    init(tokenOutput, untokenizedTypes);\n  }\n\n","sourceOld":"  /**\n   * Creates a new instance of the {@link org.apache.lucene.wikipedia.analysis.WikipediaTokenizer}.  Attaches the\n   * <code>input</code> to a the newly created JFlex scanner.\n   *\n   * @param input The input\n   * @param tokenOutput One of {@link #TOKENS_ONLY}, {@link #UNTOKENIZED_ONLY}, {@link #BOTH}\n   * @param untokenizedTypes\n   */\n  public WikipediaTokenizer(Reader input, int tokenOutput, Set untokenizedTypes) {\n    super(input);\n    this.scanner = new WikipediaTokenizerImpl(input);\n    init(tokenOutput, untokenizedTypes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c69d87d34a81230de56333f52f590caeb6d80667":["add7d922e63099fbce8f0a1b31216df7ef5067f1"],"decc8a7344e9231708f9991fa09db2cafec7a2dd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5d59fc4c8c96a38502968987848162bcd90c3ef0":["decc8a7344e9231708f9991fa09db2cafec7a2dd"],"047007f30fa7e5c9273d6dc8d292deca18da4c2c":["9b5756469957918cac40a831acec9cf01c8c2bb3"],"add7d922e63099fbce8f0a1b31216df7ef5067f1":["047007f30fa7e5c9273d6dc8d292deca18da4c2c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9b5756469957918cac40a831acec9cf01c8c2bb3":["5d59fc4c8c96a38502968987848162bcd90c3ef0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c69d87d34a81230de56333f52f590caeb6d80667"]},"commit2Childs":{"c69d87d34a81230de56333f52f590caeb6d80667":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"decc8a7344e9231708f9991fa09db2cafec7a2dd":["5d59fc4c8c96a38502968987848162bcd90c3ef0"],"5d59fc4c8c96a38502968987848162bcd90c3ef0":["9b5756469957918cac40a831acec9cf01c8c2bb3"],"047007f30fa7e5c9273d6dc8d292deca18da4c2c":["add7d922e63099fbce8f0a1b31216df7ef5067f1"],"add7d922e63099fbce8f0a1b31216df7ef5067f1":["c69d87d34a81230de56333f52f590caeb6d80667"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["decc8a7344e9231708f9991fa09db2cafec7a2dd"],"9b5756469957918cac40a831acec9cf01c8c2bb3":["047007f30fa7e5c9273d6dc8d292deca18da4c2c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}