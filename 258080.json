{"path":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#next().mjava","commits":[{"id":"9dc3f3d3156ee3e335155b8a8f44f7e926db09ef","date":1063245093,"type":0,"author":"Erik Hatcher","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#next().mjava","pathOld":"/dev/null","sourceNew":"/** Returns the next token in the stream, or null at EOS.\n * <p>The returned token's type is set to an element of {@link\n * StandardTokenizerConstants#tokenImage}.\n */\n  final public org.apache.lucene.analysis.Token next() throws ParseException, IOException {\n  Token token = null;\n    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {\n    case ALPHANUM:\n      token = jj_consume_token(ALPHANUM);\n      break;\n    case APOSTROPHE:\n      token = jj_consume_token(APOSTROPHE);\n      break;\n    case ACRONYM:\n      token = jj_consume_token(ACRONYM);\n      break;\n    case COMPANY:\n      token = jj_consume_token(COMPANY);\n      break;\n    case EMAIL:\n      token = jj_consume_token(EMAIL);\n      break;\n    case HOST:\n      token = jj_consume_token(HOST);\n      break;\n    case NUM:\n      token = jj_consume_token(NUM);\n      break;\n    case 0:\n      token = jj_consume_token(0);\n      break;\n    default:\n      jj_la1[0] = jj_gen;\n      jj_consume_token(-1);\n      throw new ParseException();\n    }\n      if (token.kind == EOF) {\n        {if (true) return null;}\n      } else {\n        {if (true) return\n          new org.apache.lucene.analysis.Token(token.image,\n                                        token.beginColumn,token.endColumn,\n                                        tokenImage[token.kind]);}\n      }\n    throw new Error(\"Missing return statement in function\");\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5782c80b3147b120883d1d92770063bd1056db3a","date":1065026366,"type":3,"author":"Erik Hatcher","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#next().mjava","pathOld":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#next().mjava","sourceNew":"/** Returns the next token in the stream, or null at EOS.\n * <p>The returned token's type is set to an element of {@link\n * StandardTokenizerConstants#tokenImage}.\n */\n  final public org.apache.lucene.analysis.Token next() throws ParseException, IOException {\n  Token token = null;\n    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {\n    case ALPHANUM:\n      token = jj_consume_token(ALPHANUM);\n      break;\n    case APOSTROPHE:\n      token = jj_consume_token(APOSTROPHE);\n      break;\n    case ACRONYM:\n      token = jj_consume_token(ACRONYM);\n      break;\n    case COMPANY:\n      token = jj_consume_token(COMPANY);\n      break;\n    case EMAIL:\n      token = jj_consume_token(EMAIL);\n      break;\n    case HOST:\n      token = jj_consume_token(HOST);\n      break;\n    case NUM:\n      token = jj_consume_token(NUM);\n      break;\n    case SIGRAM:\n      token = jj_consume_token(SIGRAM);\n      break;\n    case 0:\n      token = jj_consume_token(0);\n      break;\n    default:\n      jj_la1[0] = jj_gen;\n      jj_consume_token(-1);\n      throw new ParseException();\n    }\n      if (token.kind == EOF) {\n        {if (true) return null;}\n      } else {\n        {if (true) return\n          new org.apache.lucene.analysis.Token(token.image,\n                                        token.beginColumn,token.endColumn,\n                                        tokenImage[token.kind]);}\n      }\n    throw new Error(\"Missing return statement in function\");\n  }\n\n","sourceOld":"/** Returns the next token in the stream, or null at EOS.\n * <p>The returned token's type is set to an element of {@link\n * StandardTokenizerConstants#tokenImage}.\n */\n  final public org.apache.lucene.analysis.Token next() throws ParseException, IOException {\n  Token token = null;\n    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {\n    case ALPHANUM:\n      token = jj_consume_token(ALPHANUM);\n      break;\n    case APOSTROPHE:\n      token = jj_consume_token(APOSTROPHE);\n      break;\n    case ACRONYM:\n      token = jj_consume_token(ACRONYM);\n      break;\n    case COMPANY:\n      token = jj_consume_token(COMPANY);\n      break;\n    case EMAIL:\n      token = jj_consume_token(EMAIL);\n      break;\n    case HOST:\n      token = jj_consume_token(HOST);\n      break;\n    case NUM:\n      token = jj_consume_token(NUM);\n      break;\n    case 0:\n      token = jj_consume_token(0);\n      break;\n    default:\n      jj_la1[0] = jj_gen;\n      jj_consume_token(-1);\n      throw new ParseException();\n    }\n      if (token.kind == EOF) {\n        {if (true) return null;}\n      } else {\n        {if (true) return\n          new org.apache.lucene.analysis.Token(token.image,\n                                        token.beginColumn,token.endColumn,\n                                        tokenImage[token.kind]);}\n      }\n    throw new Error(\"Missing return statement in function\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1fd7097d0d90763c9ce3e1eb1def624524118259","date":1072131144,"type":3,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#next().mjava","pathOld":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#next().mjava","sourceNew":"/** Returns the next token in the stream, or null at EOS.\n * <p>The returned token's type is set to an element of {@link\n * StandardTokenizerConstants#tokenImage}.\n */\n  final public org.apache.lucene.analysis.Token next() throws ParseException, IOException {\n  Token token = null;\n    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {\n    case ALPHANUM:\n      token = jj_consume_token(ALPHANUM);\n      break;\n    case APOSTROPHE:\n      token = jj_consume_token(APOSTROPHE);\n      break;\n    case ACRONYM:\n      token = jj_consume_token(ACRONYM);\n      break;\n    case COMPANY:\n      token = jj_consume_token(COMPANY);\n      break;\n    case EMAIL:\n      token = jj_consume_token(EMAIL);\n      break;\n    case HOST:\n      token = jj_consume_token(HOST);\n      break;\n    case NUM:\n      token = jj_consume_token(NUM);\n      break;\n    case CJK:\n      token = jj_consume_token(CJK);\n      break;\n    case 0:\n      token = jj_consume_token(0);\n      break;\n    default:\n      jj_la1[0] = jj_gen;\n      jj_consume_token(-1);\n      throw new ParseException();\n    }\n      if (token.kind == EOF) {\n        {if (true) return null;}\n      } else {\n        {if (true) return\n          new org.apache.lucene.analysis.Token(token.image,\n                                        token.beginColumn,token.endColumn,\n                                        tokenImage[token.kind]);}\n      }\n    throw new Error(\"Missing return statement in function\");\n  }\n\n","sourceOld":"/** Returns the next token in the stream, or null at EOS.\n * <p>The returned token's type is set to an element of {@link\n * StandardTokenizerConstants#tokenImage}.\n */\n  final public org.apache.lucene.analysis.Token next() throws ParseException, IOException {\n  Token token = null;\n    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {\n    case ALPHANUM:\n      token = jj_consume_token(ALPHANUM);\n      break;\n    case APOSTROPHE:\n      token = jj_consume_token(APOSTROPHE);\n      break;\n    case ACRONYM:\n      token = jj_consume_token(ACRONYM);\n      break;\n    case COMPANY:\n      token = jj_consume_token(COMPANY);\n      break;\n    case EMAIL:\n      token = jj_consume_token(EMAIL);\n      break;\n    case HOST:\n      token = jj_consume_token(HOST);\n      break;\n    case NUM:\n      token = jj_consume_token(NUM);\n      break;\n    case SIGRAM:\n      token = jj_consume_token(SIGRAM);\n      break;\n    case 0:\n      token = jj_consume_token(0);\n      break;\n    default:\n      jj_la1[0] = jj_gen;\n      jj_consume_token(-1);\n      throw new ParseException();\n    }\n      if (token.kind == EOF) {\n        {if (true) return null;}\n      } else {\n        {if (true) return\n          new org.apache.lucene.analysis.Token(token.image,\n                                        token.beginColumn,token.endColumn,\n                                        tokenImage[token.kind]);}\n      }\n    throw new Error(\"Missing return statement in function\");\n  }\n\n","bugFix":null,"bugIntro":["71440939a99e296b53d3d64630c7355b914f55a2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"71440939a99e296b53d3d64630c7355b914f55a2","date":1131784401,"type":3,"author":"Erik Hatcher","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#next().mjava","pathOld":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#next().mjava","sourceNew":"/** Returns the next token in the stream, or null at EOS.\n * <p>The returned token's type is set to an element of {@link\n * StandardTokenizerConstants#tokenImage}.\n */\n  final public org.apache.lucene.analysis.Token next() throws ParseException, IOException {\n  Token token = null;\n    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {\n    case ALPHANUM:\n      token = jj_consume_token(ALPHANUM);\n      break;\n    case APOSTROPHE:\n      token = jj_consume_token(APOSTROPHE);\n      break;\n    case ACRONYM:\n      token = jj_consume_token(ACRONYM);\n      break;\n    case COMPANY:\n      token = jj_consume_token(COMPANY);\n      break;\n    case EMAIL:\n      token = jj_consume_token(EMAIL);\n      break;\n    case HOST:\n      token = jj_consume_token(HOST);\n      break;\n    case NUM:\n      token = jj_consume_token(NUM);\n      break;\n    case CJ:\n      token = jj_consume_token(CJ);\n      break;\n    case 0:\n      token = jj_consume_token(0);\n      break;\n    default:\n      jj_la1[0] = jj_gen;\n      jj_consume_token(-1);\n      throw new ParseException();\n    }\n      if (token.kind == EOF) {\n        {if (true) return null;}\n      } else {\n        {if (true) return\n          new org.apache.lucene.analysis.Token(token.image,\n                                        token.beginColumn,token.endColumn,\n                                        tokenImage[token.kind]);}\n      }\n    throw new Error(\"Missing return statement in function\");\n  }\n\n","sourceOld":"/** Returns the next token in the stream, or null at EOS.\n * <p>The returned token's type is set to an element of {@link\n * StandardTokenizerConstants#tokenImage}.\n */\n  final public org.apache.lucene.analysis.Token next() throws ParseException, IOException {\n  Token token = null;\n    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {\n    case ALPHANUM:\n      token = jj_consume_token(ALPHANUM);\n      break;\n    case APOSTROPHE:\n      token = jj_consume_token(APOSTROPHE);\n      break;\n    case ACRONYM:\n      token = jj_consume_token(ACRONYM);\n      break;\n    case COMPANY:\n      token = jj_consume_token(COMPANY);\n      break;\n    case EMAIL:\n      token = jj_consume_token(EMAIL);\n      break;\n    case HOST:\n      token = jj_consume_token(HOST);\n      break;\n    case NUM:\n      token = jj_consume_token(NUM);\n      break;\n    case CJK:\n      token = jj_consume_token(CJK);\n      break;\n    case 0:\n      token = jj_consume_token(0);\n      break;\n    default:\n      jj_la1[0] = jj_gen;\n      jj_consume_token(-1);\n      throw new ParseException();\n    }\n      if (token.kind == EOF) {\n        {if (true) return null;}\n      } else {\n        {if (true) return\n          new org.apache.lucene.analysis.Token(token.image,\n                                        token.beginColumn,token.endColumn,\n                                        tokenImage[token.kind]);}\n      }\n    throw new Error(\"Missing return statement in function\");\n  }\n\n","bugFix":["1fd7097d0d90763c9ce3e1eb1def624524118259"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8e191901ff30c9f34f5e72d2e7b6f6c975eb9b4e","date":1186612004,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#next().mjava","pathOld":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#next().mjava","sourceNew":"    /*\n     * (non-Javadoc)\n     *\n     * @see org.apache.lucene.analysis.TokenStream#next()\n     */\n    public Token next() throws IOException {\n\tint tokenType = scanner.getNextToken();\n\n\tif (tokenType == StandardTokenizerImpl.YYEOF) {\n\t    return null;\n\t}\n\n\tint startPosition = scanner.yychar();\n\n\tfinal String tokenImage = scanner.yytext();\n\treturn new Token(tokenImage, startPosition, startPosition\n\t\t+ tokenImage.length(),\n\t\tStandardTokenizerImpl.TOKEN_TYPES[tokenType]);\n    }\n\n","sourceOld":"/** Returns the next token in the stream, or null at EOS.\n * <p>The returned token's type is set to an element of {@link\n * StandardTokenizerConstants#tokenImage}.\n */\n  final public org.apache.lucene.analysis.Token next() throws ParseException, IOException {\n  Token token = null;\n    switch ((jj_ntk==-1)?jj_ntk():jj_ntk) {\n    case ALPHANUM:\n      token = jj_consume_token(ALPHANUM);\n      break;\n    case APOSTROPHE:\n      token = jj_consume_token(APOSTROPHE);\n      break;\n    case ACRONYM:\n      token = jj_consume_token(ACRONYM);\n      break;\n    case COMPANY:\n      token = jj_consume_token(COMPANY);\n      break;\n    case EMAIL:\n      token = jj_consume_token(EMAIL);\n      break;\n    case HOST:\n      token = jj_consume_token(HOST);\n      break;\n    case NUM:\n      token = jj_consume_token(NUM);\n      break;\n    case CJ:\n      token = jj_consume_token(CJ);\n      break;\n    case 0:\n      token = jj_consume_token(0);\n      break;\n    default:\n      jj_la1[0] = jj_gen;\n      jj_consume_token(-1);\n      throw new ParseException();\n    }\n      if (token.kind == EOF) {\n        {if (true) return null;}\n      } else {\n        {if (true) return\n          new org.apache.lucene.analysis.Token(token.image,\n                                        token.beginColumn,token.endColumn,\n                                        tokenImage[token.kind]);}\n      }\n    throw new Error(\"Missing return statement in function\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6864413dbc0c12104c978c05456f3da1d45adb03","date":1186770873,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#next(Token).mjava","pathOld":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#next().mjava","sourceNew":"    /*\n     * (non-Javadoc)\n     *\n     * @see org.apache.lucene.analysis.TokenStream#next()\n     */\n    public Token next(Token result) throws IOException {\n\tint tokenType = scanner.getNextToken();\n\n\tif (tokenType == StandardTokenizerImpl.YYEOF) {\n\t    return null;\n\t}\n\n        scanner.getText(result);\n        final int start = scanner.yychar();\n        result.setStartOffset(start);\n        result.setEndOffset(start+result.termLength());\n        result.setType(StandardTokenizerImpl.TOKEN_TYPES[tokenType]);\n        return result;\n    }\n\n","sourceOld":"    /*\n     * (non-Javadoc)\n     *\n     * @see org.apache.lucene.analysis.TokenStream#next()\n     */\n    public Token next() throws IOException {\n\tint tokenType = scanner.getNextToken();\n\n\tif (tokenType == StandardTokenizerImpl.YYEOF) {\n\t    return null;\n\t}\n\n\tint startPosition = scanner.yychar();\n\n\tfinal String tokenImage = scanner.yytext();\n\treturn new Token(tokenImage, startPosition, startPosition\n\t\t+ tokenImage.length(),\n\t\tStandardTokenizerImpl.TOKEN_TYPES[tokenType]);\n    }\n\n","bugFix":null,"bugIntro":["c79a056cc0ebc0f62e4a01c20808260cc4c70074"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ec8b5a20a12931b8d7e616c79c5248ae06cc5568","date":1248471948,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#next().mjava","pathOld":"/dev/null","sourceNew":"  /** @deprecated Will be removed in Lucene 3.0. This method is final, as it should\n   * not be overridden. Delegates to the backwards compatibility layer. */\n  public final Token next() throws IOException {\n    return super.next();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"439b0fe2f799d1c722151e88e32bdefad8d34ebe","date":1255282509,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/analysis/standard/StandardTokenizer#next().mjava","sourceNew":null,"sourceOld":"  /** @deprecated Will be removed in Lucene 3.0. This method is final, as it should\n   * not be overridden. Delegates to the backwards compatibility layer. */\n  public final Token next() throws IOException {\n    return super.next();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6864413dbc0c12104c978c05456f3da1d45adb03":["8e191901ff30c9f34f5e72d2e7b6f6c975eb9b4e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5782c80b3147b120883d1d92770063bd1056db3a":["9dc3f3d3156ee3e335155b8a8f44f7e926db09ef"],"1fd7097d0d90763c9ce3e1eb1def624524118259":["5782c80b3147b120883d1d92770063bd1056db3a"],"439b0fe2f799d1c722151e88e32bdefad8d34ebe":["ec8b5a20a12931b8d7e616c79c5248ae06cc5568"],"9dc3f3d3156ee3e335155b8a8f44f7e926db09ef":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"8e191901ff30c9f34f5e72d2e7b6f6c975eb9b4e":["71440939a99e296b53d3d64630c7355b914f55a2"],"71440939a99e296b53d3d64630c7355b914f55a2":["1fd7097d0d90763c9ce3e1eb1def624524118259"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["439b0fe2f799d1c722151e88e32bdefad8d34ebe"],"ec8b5a20a12931b8d7e616c79c5248ae06cc5568":["6864413dbc0c12104c978c05456f3da1d45adb03"]},"commit2Childs":{"6864413dbc0c12104c978c05456f3da1d45adb03":["ec8b5a20a12931b8d7e616c79c5248ae06cc5568"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9dc3f3d3156ee3e335155b8a8f44f7e926db09ef"],"5782c80b3147b120883d1d92770063bd1056db3a":["1fd7097d0d90763c9ce3e1eb1def624524118259"],"1fd7097d0d90763c9ce3e1eb1def624524118259":["71440939a99e296b53d3d64630c7355b914f55a2"],"439b0fe2f799d1c722151e88e32bdefad8d34ebe":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9dc3f3d3156ee3e335155b8a8f44f7e926db09ef":["5782c80b3147b120883d1d92770063bd1056db3a"],"8e191901ff30c9f34f5e72d2e7b6f6c975eb9b4e":["6864413dbc0c12104c978c05456f3da1d45adb03"],"71440939a99e296b53d3d64630c7355b914f55a2":["8e191901ff30c9f34f5e72d2e7b6f6c975eb9b4e"],"ec8b5a20a12931b8d7e616c79c5248ae06cc5568":["439b0fe2f799d1c722151e88e32bdefad8d34ebe"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}