{"path":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","commits":[{"id":"f366ce28775e2b8ea4e06355009471328711666d","date":1360551293,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,SortedDocValues[]).mjava","sourceNew":"    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new AppendingLongBuffer();\n      subIndexes = new AppendingLongBuffer();\n      ordDeltas = new AppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new AppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[subIndex] <= segmentOrd) {\n            ordDeltas[subIndex].add(delta);\n            segmentOrds[subIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n    }\n\n","sourceOld":"    OrdinalMap(Object owner, SortedDocValues subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new AppendingLongBuffer();\n      subIndexes = new AppendingLongBuffer();\n      ordDeltas = new AppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new AppendingLongBuffer();\n      }\n      int segmentOrds[] = new int[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(new SortedDocValuesTermsEnum(subs[i]), i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      int globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          int delta = globalOrd - segmentOrds[subIndex];\n          assert delta >= 0;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          ordDeltas[subIndex].add(delta);\n          segmentOrds[subIndex]++;\n        }\n        globalOrd++;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"664a68f28f24ef49a076dd7ecc73ccb202c492d7","date":1360944593,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","sourceNew":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new AppendingLongBuffer();\n      subIndexes = new AppendingLongBuffer();\n      ordDeltas = new AppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new AppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[subIndex] <= segmentOrd) {\n            ordDeltas[subIndex].add(delta);\n            segmentOrds[subIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n    }\n\n","sourceOld":"    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new AppendingLongBuffer();\n      subIndexes = new AppendingLongBuffer();\n      ordDeltas = new AppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new AppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[subIndex] <= segmentOrd) {\n            ordDeltas[subIndex].add(delta);\n            segmentOrds[subIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae3be3418aea9954be27a83315087f67c0c2201e","date":1361023362,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","sourceNew":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new MonotonicAppendingLongBuffer();\n      subIndexes = new AppendingLongBuffer();\n      ordDeltas = new MonotonicAppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new MonotonicAppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[subIndex] <= segmentOrd) {\n            ordDeltas[subIndex].add(delta);\n            segmentOrds[subIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n    }\n\n","sourceOld":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new AppendingLongBuffer();\n      subIndexes = new AppendingLongBuffer();\n      ordDeltas = new AppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new AppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[subIndex] <= segmentOrd) {\n            ordDeltas[subIndex].add(delta);\n            segmentOrds[subIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddbb72a33557d2b5bc22ee95daf3281c43560502","date":1361334582,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,SortedDocValues[]).mjava","sourceNew":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new MonotonicAppendingLongBuffer();\n      subIndexes = new AppendingLongBuffer();\n      ordDeltas = new MonotonicAppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new MonotonicAppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[subIndex] <= segmentOrd) {\n            ordDeltas[subIndex].add(delta);\n            segmentOrds[subIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n    }\n\n","sourceOld":"    OrdinalMap(Object owner, SortedDocValues subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new AppendingLongBuffer();\n      subIndexes = new AppendingLongBuffer();\n      ordDeltas = new AppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new AppendingLongBuffer();\n      }\n      int segmentOrds[] = new int[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(new SortedDocValuesTermsEnum(subs[i]), i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      int globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          int delta = globalOrd - segmentOrds[subIndex];\n          assert delta >= 0;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          ordDeltas[subIndex].add(delta);\n          segmentOrds[subIndex]++;\n        }\n        globalOrd++;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3618e9b99a76b26b0dbb5e7ea75cbb6065433eaa","date":1373959221,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","sourceNew":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new MonotonicAppendingLongBuffer();\n      subIndexes = new AppendingLongBuffer();\n      ordDeltas = new MonotonicAppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new MonotonicAppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[subIndex] <= segmentOrd) {\n            ordDeltas[subIndex].add(delta);\n            segmentOrds[subIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n      subIndexes.freeze();\n      globalOrdDeltas.freeze();\n      for (int i = 0; i < ordDeltas.length; ++i) {\n        ordDeltas[i].freeze();\n      }\n    }\n\n","sourceOld":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new MonotonicAppendingLongBuffer();\n      subIndexes = new AppendingLongBuffer();\n      ordDeltas = new MonotonicAppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new MonotonicAppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[subIndex] <= segmentOrd) {\n            ordDeltas[subIndex].add(delta);\n            segmentOrds[subIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","sourceNew":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new MonotonicAppendingLongBuffer();\n      subIndexes = new AppendingLongBuffer();\n      ordDeltas = new MonotonicAppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new MonotonicAppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[subIndex] <= segmentOrd) {\n            ordDeltas[subIndex].add(delta);\n            segmentOrds[subIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n      subIndexes.freeze();\n      globalOrdDeltas.freeze();\n      for (int i = 0; i < ordDeltas.length; ++i) {\n        ordDeltas[i].freeze();\n      }\n    }\n\n","sourceOld":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new MonotonicAppendingLongBuffer();\n      subIndexes = new AppendingLongBuffer();\n      ordDeltas = new MonotonicAppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new MonotonicAppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[subIndex] <= segmentOrd) {\n            ordDeltas[subIndex].add(delta);\n            segmentOrds[subIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cb240aebd5a347d79f642127ad9255dd9a979f06","date":1375188159,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","sourceNew":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new MonotonicAppendingLongBuffer(PackedInts.COMPACT);\n      subIndexes = new AppendingPackedLongBuffer(PackedInts.COMPACT);\n      ordDeltas = new MonotonicAppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new MonotonicAppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[subIndex] <= segmentOrd) {\n            ordDeltas[subIndex].add(delta);\n            segmentOrds[subIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n      subIndexes.freeze();\n      globalOrdDeltas.freeze();\n      for (int i = 0; i < ordDeltas.length; ++i) {\n        ordDeltas[i].freeze();\n      }\n    }\n\n","sourceOld":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new MonotonicAppendingLongBuffer();\n      subIndexes = new AppendingLongBuffer();\n      ordDeltas = new MonotonicAppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new MonotonicAppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[subIndex] <= segmentOrd) {\n            ordDeltas[subIndex].add(delta);\n            segmentOrds[subIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n      subIndexes.freeze();\n      globalOrdDeltas.freeze();\n      for (int i = 0; i < ordDeltas.length; ++i) {\n        ordDeltas[i].freeze();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","sourceNew":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new MonotonicAppendingLongBuffer(PackedInts.COMPACT);\n      subIndexes = new AppendingPackedLongBuffer(PackedInts.COMPACT);\n      ordDeltas = new MonotonicAppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new MonotonicAppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[subIndex] <= segmentOrd) {\n            ordDeltas[subIndex].add(delta);\n            segmentOrds[subIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n      subIndexes.freeze();\n      globalOrdDeltas.freeze();\n      for (int i = 0; i < ordDeltas.length; ++i) {\n        ordDeltas[i].freeze();\n      }\n    }\n\n","sourceOld":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new MonotonicAppendingLongBuffer();\n      subIndexes = new AppendingLongBuffer();\n      ordDeltas = new MonotonicAppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new MonotonicAppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[subIndex] <= segmentOrd) {\n            ordDeltas[subIndex].add(delta);\n            segmentOrds[subIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n      subIndexes.freeze();\n      globalOrdDeltas.freeze();\n      for (int i = 0; i < ordDeltas.length; ++i) {\n        ordDeltas[i].freeze();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"418e93579786b1123bf5708692d809826ea239c0","date":1383035702,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","sourceNew":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new MonotonicAppendingLongBuffer(PackedInts.COMPACT);\n      firstSegments = new AppendingPackedLongBuffer(PackedInts.COMPACT);\n      ordDeltas = new MonotonicAppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new MonotonicAppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int segmentIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first segment index/delta where it occurs\n          if (i == 0) {\n            firstSegments.add(segmentIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[segmentIndex] <= segmentOrd) {\n            ordDeltas[segmentIndex].add(delta);\n            segmentOrds[segmentIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n      firstSegments.freeze();\n      globalOrdDeltas.freeze();\n      for (int i = 0; i < ordDeltas.length; ++i) {\n        ordDeltas[i].freeze();\n      }\n    }\n\n","sourceOld":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new MonotonicAppendingLongBuffer(PackedInts.COMPACT);\n      subIndexes = new AppendingPackedLongBuffer(PackedInts.COMPACT);\n      ordDeltas = new MonotonicAppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new MonotonicAppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int subIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first subindex/delta where it occurs\n          if (i == 0) {\n            subIndexes.add(subIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[subIndex] <= segmentOrd) {\n            ordDeltas[subIndex].add(delta);\n            segmentOrds[subIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n      subIndexes.freeze();\n      globalOrdDeltas.freeze();\n      for (int i = 0; i < ordDeltas.length; ++i) {\n        ordDeltas[i].freeze();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9b25d26ad3e8f824d95db88ecc5e5d9d71d3c595","date":1402950824,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","sourceNew":"    /** Create an {@link OrdinalMap} with the default overhead ratio.\n     *  @see #OrdinalMap(Object, TermsEnum[], float)  */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      this(owner, subs, PackedInts.DEFAULT);\n    }\n\n","sourceOld":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new MonotonicAppendingLongBuffer(PackedInts.COMPACT);\n      firstSegments = new AppendingPackedLongBuffer(PackedInts.COMPACT);\n      ordDeltas = new MonotonicAppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new MonotonicAppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int segmentIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first segment index/delta where it occurs\n          if (i == 0) {\n            firstSegments.add(segmentIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[segmentIndex] <= segmentOrd) {\n            ordDeltas[segmentIndex].add(delta);\n            segmentOrds[segmentIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n      firstSegments.freeze();\n      globalOrdDeltas.freeze();\n      for (int i = 0; i < ordDeltas.length; ++i) {\n        ordDeltas[i].freeze();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c6a4b03c1f5179579c87e228943315077aa60dd0","date":1402958332,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","sourceNew":"    /** Create an {@link OrdinalMap} with the default overhead ratio. */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      this(owner, subs, PackedInts.DEFAULT);\n    }\n\n","sourceOld":"    /** Create an {@link OrdinalMap} with the default overhead ratio.\n     *  @see #OrdinalMap(Object, TermsEnum[], float)  */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      this(owner, subs, PackedInts.DEFAULT);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6d0aee18c1653f7ee634fa8830abdb001dcfe1b","date":1402998114,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","sourceNew":"    /** Create an {@link OrdinalMap} with the default overhead ratio. */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      this(owner, subs, PackedInts.DEFAULT);\n    }\n\n","sourceOld":"    /** \n     * Creates an ordinal map that allows mapping ords to/from a merged\n     * space from <code>subs</code>.\n     * @param owner a cache key\n     * @param subs TermsEnums that support {@link TermsEnum#ord()}. They need\n     *             not be dense (e.g. can be FilteredTermsEnums}.\n     * @throws IOException if an I/O error occurred.\n     */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      // create the ordinal mappings by pulling a termsenum over each sub's \n      // unique terms, and walking a multitermsenum over those\n      this.owner = owner;\n      globalOrdDeltas = new MonotonicAppendingLongBuffer(PackedInts.COMPACT);\n      firstSegments = new AppendingPackedLongBuffer(PackedInts.COMPACT);\n      ordDeltas = new MonotonicAppendingLongBuffer[subs.length];\n      for (int i = 0; i < ordDeltas.length; i++) {\n        ordDeltas[i] = new MonotonicAppendingLongBuffer();\n      }\n      long segmentOrds[] = new long[subs.length];\n      ReaderSlice slices[] = new ReaderSlice[subs.length];\n      TermsEnumIndex indexes[] = new TermsEnumIndex[slices.length];\n      for (int i = 0; i < slices.length; i++) {\n        slices[i] = new ReaderSlice(0, 0, i);\n        indexes[i] = new TermsEnumIndex(subs[i], i);\n      }\n      MultiTermsEnum mte = new MultiTermsEnum(slices);\n      mte.reset(indexes);\n      long globalOrd = 0;\n      while (mte.next() != null) {        \n        TermsEnumWithSlice matches[] = mte.getMatchArray();\n        for (int i = 0; i < mte.getMatchCount(); i++) {\n          int segmentIndex = matches[i].index;\n          long segmentOrd = matches[i].terms.ord();\n          long delta = globalOrd - segmentOrd;\n          // for each unique term, just mark the first segment index/delta where it occurs\n          if (i == 0) {\n            firstSegments.add(segmentIndex);\n            globalOrdDeltas.add(delta);\n          }\n          // for each per-segment ord, map it back to the global term.\n          while (segmentOrds[segmentIndex] <= segmentOrd) {\n            ordDeltas[segmentIndex].add(delta);\n            segmentOrds[segmentIndex]++;\n          }\n        }\n        globalOrd++;\n      }\n      firstSegments.freeze();\n      globalOrdDeltas.freeze();\n      for (int i = 0; i < ordDeltas.length; ++i) {\n        ordDeltas[i].freeze();\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5bcfd864fb8b916f7d21f2579d2010a31892055d","date":1403359094,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues.OrdinalMap#OrdinalMap(Object,TermsEnum[]).mjava","sourceNew":null,"sourceOld":"    /** Create an {@link OrdinalMap} with the default overhead ratio. */\n    public OrdinalMap(Object owner, TermsEnum subs[]) throws IOException {\n      this(owner, subs, PackedInts.DEFAULT);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3618e9b99a76b26b0dbb5e7ea75cbb6065433eaa":["ddbb72a33557d2b5bc22ee95daf3281c43560502"],"664a68f28f24ef49a076dd7ecc73ccb202c492d7":["f366ce28775e2b8ea4e06355009471328711666d"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["ddbb72a33557d2b5bc22ee95daf3281c43560502","3618e9b99a76b26b0dbb5e7ea75cbb6065433eaa"],"cb240aebd5a347d79f642127ad9255dd9a979f06":["3618e9b99a76b26b0dbb5e7ea75cbb6065433eaa"],"418e93579786b1123bf5708692d809826ea239c0":["cb240aebd5a347d79f642127ad9255dd9a979f06"],"ddbb72a33557d2b5bc22ee95daf3281c43560502":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ae3be3418aea9954be27a83315087f67c0c2201e"],"f6d0aee18c1653f7ee634fa8830abdb001dcfe1b":["418e93579786b1123bf5708692d809826ea239c0","c6a4b03c1f5179579c87e228943315077aa60dd0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["37a0f60745e53927c4c876cfe5b5a58170f0646c"],"f366ce28775e2b8ea4e06355009471328711666d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9b25d26ad3e8f824d95db88ecc5e5d9d71d3c595":["418e93579786b1123bf5708692d809826ea239c0"],"ae3be3418aea9954be27a83315087f67c0c2201e":["664a68f28f24ef49a076dd7ecc73ccb202c492d7"],"c6a4b03c1f5179579c87e228943315077aa60dd0":["9b25d26ad3e8f824d95db88ecc5e5d9d71d3c595"],"5bcfd864fb8b916f7d21f2579d2010a31892055d":["c6a4b03c1f5179579c87e228943315077aa60dd0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5bcfd864fb8b916f7d21f2579d2010a31892055d"]},"commit2Childs":{"3618e9b99a76b26b0dbb5e7ea75cbb6065433eaa":["37a0f60745e53927c4c876cfe5b5a58170f0646c","cb240aebd5a347d79f642127ad9255dd9a979f06"],"664a68f28f24ef49a076dd7ecc73ccb202c492d7":["ae3be3418aea9954be27a83315087f67c0c2201e"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"cb240aebd5a347d79f642127ad9255dd9a979f06":["418e93579786b1123bf5708692d809826ea239c0"],"418e93579786b1123bf5708692d809826ea239c0":["f6d0aee18c1653f7ee634fa8830abdb001dcfe1b","9b25d26ad3e8f824d95db88ecc5e5d9d71d3c595"],"ddbb72a33557d2b5bc22ee95daf3281c43560502":["3618e9b99a76b26b0dbb5e7ea75cbb6065433eaa","37a0f60745e53927c4c876cfe5b5a58170f0646c"],"f6d0aee18c1653f7ee634fa8830abdb001dcfe1b":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ddbb72a33557d2b5bc22ee95daf3281c43560502","f366ce28775e2b8ea4e06355009471328711666d"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"f366ce28775e2b8ea4e06355009471328711666d":["664a68f28f24ef49a076dd7ecc73ccb202c492d7"],"ae3be3418aea9954be27a83315087f67c0c2201e":["ddbb72a33557d2b5bc22ee95daf3281c43560502"],"9b25d26ad3e8f824d95db88ecc5e5d9d71d3c595":["c6a4b03c1f5179579c87e228943315077aa60dd0"],"c6a4b03c1f5179579c87e228943315077aa60dd0":["f6d0aee18c1653f7ee634fa8830abdb001dcfe1b","5bcfd864fb8b916f7d21f2579d2010a31892055d"],"5bcfd864fb8b916f7d21f2579d2010a31892055d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f6d0aee18c1653f7ee634fa8830abdb001dcfe1b","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}