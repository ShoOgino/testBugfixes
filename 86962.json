{"path":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testFloatPointFieldMultiValuedRangeFacet().mjava","commits":[{"id":"744b111b17d15d490a648eb021bfa240e7f11556","date":1487008069,"type":0,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testFloatPointFieldMultiValuedRangeFacet().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testFloatPointFieldMultiValuedRangeFacet() throws Exception {\n    doTestDoublePointFieldMultiValuedRangeFacet(\"number_p_f_mv_dv\", \"number_p_f_mv\");\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"022a4de90e0479b604264ca9c2e134c996454ab3","date":1487118265,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testFloatPointFieldMultiValuedRangeFacet().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testFloatPointFieldMultiValuedRangeFacet() throws Exception {\n    doTestDoublePointFieldMultiValuedRangeFacet(\"number_p_f_mv_dv\", \"number_p_f_mv\");\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b49c0eb9ef7bc25609a89e7986ce7e6eeb9c9d96","date":1487122334,"type":4,"author":"Noble Paul","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testFloatPointFieldMultiValuedRangeFacet().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testFloatPointFieldMultiValuedRangeFacet() throws Exception {\n    doTestDoublePointFieldMultiValuedRangeFacet(\"number_p_f_mv_dv\", \"number_p_f_mv\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"897b06b1364bd1f658a8be7591e43f0851458e7f","date":1487123008,"type":0,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testFloatPointFieldMultiValuedRangeFacet().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testFloatPointFieldMultiValuedRangeFacet() throws Exception {\n    doTestDoublePointFieldMultiValuedRangeFacet(\"number_p_f_mv_dv\", \"number_p_f_mv\");\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e844d4f9ba6804f10747d7e51e83a9a8868c94","date":1500054875,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testFloatPointFieldMultiValuedRangeFacet().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testFloatPointFieldMultiValuedRangeFacet().mjava","sourceNew":"  @Test\n  public void testFloatPointFieldMultiValuedRangeFacet() throws Exception {\n    String docValuesField = \"number_p_f_mv_dv\";\n    SchemaField dvSchemaField = h.getCore().getLatestSchema().getField(docValuesField);\n    assertTrue(dvSchemaField.multiValued());\n    assertTrue(dvSchemaField.hasDocValues());\n    assertTrue(dvSchemaField.getType() instanceof PointField);\n \n    String nonDocValuesField = \"number_p_f_mv\";\n    SchemaField nonDvSchemaField = h.getCore().getLatestSchema().getField(nonDocValuesField);\n    assertTrue(nonDvSchemaField.multiValued());\n    assertFalse(nonDvSchemaField.hasDocValues());\n    assertTrue(nonDvSchemaField.getType() instanceof PointField);\n \n    int numValues = 20 * RANDOM_MULTIPLIER;\n    int numBuckets = numValues / 2;\n    List<Float> values;\n    List<PosVal<Float>> sortedValues;\n    float min, max, gap, buffer;\n    do {\n      values = getRandomFloats(numValues, false);\n      sortedValues = toAscendingPosVals(values, true);\n      min = sortedValues.get(0).val;\n      max = sortedValues.get(sortedValues.size() - 1).val;\n      buffer = (float)(((double)max - (double)min) / (double)numValues / 2.0D);\n      gap = (float)(((double)max + (double)buffer - (double)min + (double)buffer) / (double)numBuckets);\n    } while (max >= Float.MAX_VALUE - buffer || min <= -Float.MAX_VALUE + buffer);\n    // System.err.println(\"min: \" + min + \"   max: \" + max + \"   gap: \" + gap + \"   buffer: \" + buffer);\n    List<Set<Integer>> docIdBucket = new ArrayList<>(numBuckets);\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      docIdBucket.add(new HashSet<>());\n    }\n    int bucketNum = 0;\n    float minBucketVal = min - buffer;\n    // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + minBucketVal);\n    for (PosVal<Float> value : sortedValues) {\n      // System.err.println(\"value.val: \" + value.val);\n      while (value.val - minBucketVal >= gap) {\n        ++bucketNum;\n        minBucketVal += gap;\n        // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + minBucketVal);\n      }\n      docIdBucket.get(bucketNum).add(value.pos / 2); // each doc gets two consecutive values \n    }\n    for (int i = 0 ; i < numValues ; i += 2) {\n      assertU(adoc(\"id\", String.valueOf(i / 2),\n          docValuesField, String.valueOf(values.get(i)),\n          docValuesField, String.valueOf(values.get(i + 1)),\n          nonDocValuesField, String.valueOf(values.get(i)),\n          nonDocValuesField, String.valueOf(values.get(i + 1))));\n    }\n    assertU(commit());\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).getType() instanceof PointField);\n    String[] testStrings = new String[numBuckets + 1];\n    minBucketVal = min - buffer;\n    testStrings[numBuckets] = \"//*[@numFound='\" + (numValues / 2) + \"']\";\n    for (int i = 0 ; i < numBuckets ; minBucketVal += gap, ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + docValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + minBucketVal + \"'][.='\" + docIdBucket.get(i).size() + \"']\";\n    }\n\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField,\n        \"facet.range.start\", String.valueOf(min - buffer), \"facet.range.end\", String.valueOf(max + buffer),\n        \"facet.range.gap\", String.valueOf(gap), \"indent\", \"on\"),\n        testStrings);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField,\n        \"facet.range.start\", String.valueOf(min - buffer), \"facet.range.end\", String.valueOf(max + buffer),\n        \"facet.range.gap\", String.valueOf(gap), \"facet.range.method\", \"dv\", \"indent\", \"on\"),\n        testStrings);\n\n    assertFalse(h.getCore().getLatestSchema().getField(nonDocValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(nonDocValuesField).getType() instanceof PointField);\n    minBucketVal = min - buffer;\n    for (int i = 0 ; i < numBuckets ; minBucketVal += gap, ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + nonDocValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + minBucketVal + \"'][.='\" + docIdBucket.get(i).size() + \"']\";\n    }\n    // Range Faceting with method = filter should work\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField,\n        \"facet.range.start\", String.valueOf(min - buffer), \"facet.range.end\", String.valueOf(max + buffer),\n        \"facet.range.gap\", String.valueOf(gap), \"facet.range.method\", \"filter\", \"indent\", \"on\"),\n        testStrings);\n    // this should actually use filter method instead of dv\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField,\n        \"facet.range.start\", String.valueOf(min - buffer), \"facet.range.end\", String.valueOf(max + buffer),\n        \"facet.range.gap\", String.valueOf(gap), \"facet.range.method\", \"dv\", \"indent\", \"on\"),\n        testStrings);\n  }\n\n","sourceOld":"  @Test\n  public void testFloatPointFieldMultiValuedRangeFacet() throws Exception {\n    doTestDoublePointFieldMultiValuedRangeFacet(\"number_p_f_mv_dv\", \"number_p_f_mv\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aaf90fc29510e72665ac7934f34c3d1c25efad64","date":1500354819,"type":3,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testFloatPointFieldMultiValuedRangeFacet().mjava","pathOld":"solr/core/src/test/org/apache/solr/schema/TestPointFields#testFloatPointFieldMultiValuedRangeFacet().mjava","sourceNew":"  @Test\n  public void testFloatPointFieldMultiValuedRangeFacet() throws Exception {\n    String docValuesField = \"number_p_f_mv_dv\";\n    SchemaField dvSchemaField = h.getCore().getLatestSchema().getField(docValuesField);\n    assertTrue(dvSchemaField.multiValued());\n    assertTrue(dvSchemaField.hasDocValues());\n    assertTrue(dvSchemaField.getType() instanceof PointField);\n \n    String nonDocValuesField = \"number_p_f_mv\";\n    SchemaField nonDvSchemaField = h.getCore().getLatestSchema().getField(nonDocValuesField);\n    assertTrue(nonDvSchemaField.multiValued());\n    assertFalse(nonDvSchemaField.hasDocValues());\n    assertTrue(nonDvSchemaField.getType() instanceof PointField);\n \n    int numValues = 20 * RANDOM_MULTIPLIER;\n    int numBuckets = numValues / 2;\n    List<Float> values;\n    List<PosVal<Float>> sortedValues;\n    float min, max, gap, buffer;\n    do {\n      values = getRandomFloats(numValues, false);\n      sortedValues = toAscendingPosVals(values, true);\n      min = sortedValues.get(0).val;\n      max = sortedValues.get(sortedValues.size() - 1).val;\n      buffer = (float)(((double)max - (double)min) / (double)numValues / 2.0D);\n      gap = (float)(((double)max + (double)buffer - (double)min + (double)buffer) / (double)numBuckets);\n    } while (max >= Float.MAX_VALUE - buffer || min <= -Float.MAX_VALUE + buffer);\n    // System.err.println(\"min: \" + min + \"   max: \" + max + \"   gap: \" + gap + \"   buffer: \" + buffer);\n    List<Set<Integer>> docIdBucket = new ArrayList<>(numBuckets);\n    for (int i = 0 ; i < numBuckets ; ++i) {\n      docIdBucket.add(new HashSet<>());\n    }\n    int bucketNum = 0;\n    float minBucketVal = min - buffer;\n    // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + minBucketVal);\n    for (PosVal<Float> value : sortedValues) {\n      // System.err.println(\"value.val: \" + value.val);\n      while (value.val - minBucketVal >= gap) {\n        ++bucketNum;\n        minBucketVal += gap;\n        // System.err.println(\"bucketNum: \" + bucketNum + \"   minBucketVal: \" + minBucketVal);\n      }\n      docIdBucket.get(bucketNum).add(value.pos / 2); // each doc gets two consecutive values \n    }\n    for (int i = 0 ; i < numValues ; i += 2) {\n      assertU(adoc(\"id\", String.valueOf(i / 2),\n          docValuesField, String.valueOf(values.get(i)),\n          docValuesField, String.valueOf(values.get(i + 1)),\n          nonDocValuesField, String.valueOf(values.get(i)),\n          nonDocValuesField, String.valueOf(values.get(i + 1))));\n    }\n    assertU(commit());\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(docValuesField).getType() instanceof PointField);\n    String[] testStrings = new String[numBuckets + 1];\n    minBucketVal = min - buffer;\n    testStrings[numBuckets] = \"//*[@numFound='\" + (numValues / 2) + \"']\";\n    for (int i = 0 ; i < numBuckets ; minBucketVal += gap, ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + docValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + minBucketVal + \"'][.='\" + docIdBucket.get(i).size() + \"']\";\n    }\n\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField,\n        \"facet.range.start\", String.valueOf(min - buffer), \"facet.range.end\", String.valueOf(max + buffer),\n        \"facet.range.gap\", String.valueOf(gap), \"indent\", \"on\"),\n        testStrings);\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", docValuesField,\n        \"facet.range.start\", String.valueOf(min - buffer), \"facet.range.end\", String.valueOf(max + buffer),\n        \"facet.range.gap\", String.valueOf(gap), \"facet.range.method\", \"dv\", \"indent\", \"on\"),\n        testStrings);\n\n    assertFalse(h.getCore().getLatestSchema().getField(nonDocValuesField).hasDocValues());\n    assertTrue(h.getCore().getLatestSchema().getField(nonDocValuesField).getType() instanceof PointField);\n    minBucketVal = min - buffer;\n    for (int i = 0 ; i < numBuckets ; minBucketVal += gap, ++i) {\n      testStrings[i] = \"//lst[@name='facet_counts']/lst[@name='facet_ranges']/lst[@name='\" + nonDocValuesField\n          + \"']/lst[@name='counts']/int[@name='\" + minBucketVal + \"'][.='\" + docIdBucket.get(i).size() + \"']\";\n    }\n    // Range Faceting with method = filter should work\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField,\n        \"facet.range.start\", String.valueOf(min - buffer), \"facet.range.end\", String.valueOf(max + buffer),\n        \"facet.range.gap\", String.valueOf(gap), \"facet.range.method\", \"filter\", \"indent\", \"on\"),\n        testStrings);\n    // this should actually use filter method instead of dv\n    assertQ(req(\"q\", \"*:*\", \"facet\", \"true\", \"facet.range\", nonDocValuesField,\n        \"facet.range.start\", String.valueOf(min - buffer), \"facet.range.end\", String.valueOf(max + buffer),\n        \"facet.range.gap\", String.valueOf(gap), \"facet.range.method\", \"dv\", \"indent\", \"on\"),\n        testStrings);\n  }\n\n","sourceOld":"  @Test\n  public void testFloatPointFieldMultiValuedRangeFacet() throws Exception {\n    doTestDoublePointFieldMultiValuedRangeFacet(\"number_p_f_mv_dv\", \"number_p_f_mv\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b49c0eb9ef7bc25609a89e7986ce7e6eeb9c9d96":["022a4de90e0479b604264ca9c2e134c996454ab3"],"022a4de90e0479b604264ca9c2e134c996454ab3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","744b111b17d15d490a648eb021bfa240e7f11556"],"897b06b1364bd1f658a8be7591e43f0851458e7f":["b49c0eb9ef7bc25609a89e7986ce7e6eeb9c9d96"],"aaf90fc29510e72665ac7934f34c3d1c25efad64":["897b06b1364bd1f658a8be7591e43f0851458e7f","17e844d4f9ba6804f10747d7e51e83a9a8868c94"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e844d4f9ba6804f10747d7e51e83a9a8868c94":["897b06b1364bd1f658a8be7591e43f0851458e7f"],"744b111b17d15d490a648eb021bfa240e7f11556":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["17e844d4f9ba6804f10747d7e51e83a9a8868c94"]},"commit2Childs":{"b49c0eb9ef7bc25609a89e7986ce7e6eeb9c9d96":["897b06b1364bd1f658a8be7591e43f0851458e7f"],"022a4de90e0479b604264ca9c2e134c996454ab3":["b49c0eb9ef7bc25609a89e7986ce7e6eeb9c9d96"],"897b06b1364bd1f658a8be7591e43f0851458e7f":["aaf90fc29510e72665ac7934f34c3d1c25efad64","17e844d4f9ba6804f10747d7e51e83a9a8868c94"],"aaf90fc29510e72665ac7934f34c3d1c25efad64":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["022a4de90e0479b604264ca9c2e134c996454ab3","744b111b17d15d490a648eb021bfa240e7f11556"],"744b111b17d15d490a648eb021bfa240e7f11556":["022a4de90e0479b604264ca9c2e134c996454ab3"],"17e844d4f9ba6804f10747d7e51e83a9a8868c94":["aaf90fc29510e72665ac7934f34c3d1c25efad64","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["aaf90fc29510e72665ac7934f34c3d1c25efad64","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}