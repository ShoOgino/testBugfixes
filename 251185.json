{"path":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","sourceNew":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n  }\n\n","sourceOld":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","sourceNew":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n  }\n\n","sourceOld":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","sourceNew":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n  }\n\n","sourceOld":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff4227bb146f97aabae888091c19e48c88dbb0db","date":1406758576,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","sourceNew":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer());\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n  }\n\n","sourceOld":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cdab62f058ea765dd33deb05b4f19b7d626c801","date":1406803479,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","sourceNew":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n  }\n\n","sourceOld":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer());\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"379db3ad24c4f0214f30a122265a6d6be003a99d","date":1407537768,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","sourceNew":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer());\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n  }\n\n","sourceOld":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"44c925e22111328c6ab9731af5e3168f62d3fa9b","date":1491500899,"type":3,"author":"jdyer1","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","sourceNew":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer());\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n    \n    String firstKeyword = \"value1\";\n    String secondKeyword = \"value2\";\n    original = \"field-with-parenthesis:(\" + firstKeyword + \" \" + secondKeyword + \")\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 2\", 2, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n    assertTrue(\"first Token is not \" + firstKeyword, new ArrayList<>(tokens).get(0).toString().equals(firstKeyword));\n    assertTrue(\"second Token is not \" + secondKeyword, new ArrayList<>(tokens).get(1).toString().equals(secondKeyword));    \n  }\n\n","sourceOld":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer());\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54ca69905c5d9d1529286f06ab1d12c68f6c13cb","date":1492683554,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","sourceNew":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer());\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n    \n    String firstKeyword = \"value1\";\n    String secondKeyword = \"value2\";\n    original = \"field-with-parenthesis:(\" + firstKeyword + \" \" + secondKeyword + \")\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 2\", 2, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n    assertTrue(\"first Token is not \" + firstKeyword, new ArrayList<>(tokens).get(0).toString().equals(firstKeyword));\n    assertTrue(\"second Token is not \" + secondKeyword, new ArrayList<>(tokens).get(1).toString().equals(secondKeyword));    \n  }\n\n","sourceOld":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer());\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aa2585c33d5d66a1c837c312221eb55ddb3c4300","date":1592493170,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/SpellingQueryConverterTest#testSpecialChars().mjava","sourceNew":"  @Test\n  @SuppressWarnings({\"rawtypes\"})\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer());\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n    \n    String firstKeyword = \"value1\";\n    String secondKeyword = \"value2\";\n    original = \"field-with-parenthesis:(\" + firstKeyword + \" \" + secondKeyword + \")\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 2\", 2, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n    assertTrue(\"first Token is not \" + firstKeyword, new ArrayList<>(tokens).get(0).toString().equals(firstKeyword));\n    assertTrue(\"second Token is not \" + secondKeyword, new ArrayList<>(tokens).get(1).toString().equals(secondKeyword));    \n  }\n\n","sourceOld":"  @Test\n  public void testSpecialChars()  {\n    SpellingQueryConverter converter = new SpellingQueryConverter();\n    converter.init(new NamedList());\n    converter.setAnalyzer(new WhitespaceAnalyzer());\n    String original = \"field_with_underscore:value_with_underscore\";\n    Collection<Token> tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field_with_digits123:value_with_digits123\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"field-with-hyphens:value-with-hyphens\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    // mix 'em up and add some to the value\n//    original = \"field_with-123s:value_,.|with-hyphens\";\n//    tokens = converter.convert(original);\n//    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n//    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n//    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n\n    original = \"foo:bar^5.0\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 1\", 1, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n    \n    String firstKeyword = \"value1\";\n    String secondKeyword = \"value2\";\n    original = \"field-with-parenthesis:(\" + firstKeyword + \" \" + secondKeyword + \")\";\n    tokens = converter.convert(original);\n    assertTrue(\"tokens is null and it shouldn't be\", tokens != null);\n    assertEquals(\"tokens Size: \" + tokens.size() + \" is not 2\", 2, tokens.size());\n    assertTrue(\"Token offsets do not match\", isOffsetCorrect(original, tokens));\n    assertTrue(\"first Token is not \" + firstKeyword, new ArrayList<>(tokens).get(0).toString().equals(firstKeyword));\n    assertTrue(\"second Token is not \" + secondKeyword, new ArrayList<>(tokens).get(1).toString().equals(secondKeyword));    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"ff4227bb146f97aabae888091c19e48c88dbb0db":["c26f00b574427b55127e869b935845554afde1fa"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["44c925e22111328c6ab9731af5e3168f62d3fa9b"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["ff4227bb146f97aabae888091c19e48c88dbb0db"],"44c925e22111328c6ab9731af5e3168f62d3fa9b":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"]},"commit2Childs":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":[],"ff4227bb146f97aabae888091c19e48c88dbb0db":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"c26f00b574427b55127e869b935845554afde1fa":["ff4227bb146f97aabae888091c19e48c88dbb0db"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","44c925e22111328c6ab9731af5e3168f62d3fa9b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c903c3d15906a3da96b8c0c2fb704491005fdbdb","c26f00b574427b55127e869b935845554afde1fa","a258fbb26824fd104ed795e5d9033d2d040049ee"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"44c925e22111328c6ab9731af5e3168f62d3fa9b":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}