{"path":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","commits":[{"id":"42a18cb0bca2c4ac9747f31c7a74fac90c661f39","date":1171363388,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/NewIndexModifier#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws IOException {\n    SegmentInfo newSegmentInfo = buildSingleDocSegment(doc, analyzer);\n    synchronized (this) {\n      bufferDeleteTerm(term);\n      ramSegmentInfos.addElement(newSegmentInfo);\n      maybeFlushRamSegments();\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting all documents containing\n   * <code>term</code> and then adding the new document.\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws IOException {\n    SegmentInfo newSegmentInfo = buildSingleDocSegment(doc, analyzer);\n    synchronized (this) {\n      bufferDeleteTerm(term);\n      ramSegmentInfos.addElement(newSegmentInfo);\n      maybeFlushRamSegments();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1b54a9bc667895a2095a886184bf69a3179e63df","date":1172088096,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    SegmentInfo newSegmentInfo = buildSingleDocSegment(doc, analyzer);\n    synchronized (this) {\n      bufferDeleteTerm(term);\n      ramSegmentInfos.addElement(newSegmentInfo);\n      maybeFlushRamSegments();\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws IOException {\n    SegmentInfo newSegmentInfo = buildSingleDocSegment(doc, analyzer);\n    synchronized (this) {\n      bufferDeleteTerm(term);\n      ramSegmentInfos.addElement(newSegmentInfo);\n      maybeFlushRamSegments();\n    }\n  }\n\n","bugFix":["42a18cb0bca2c4ac9747f31c7a74fac90c661f39"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"328c1568e471f0c6eaa49ec00334ca59e573710f","date":1173897963,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    SegmentInfo newSegmentInfo = buildSingleDocSegment(doc, analyzer);\n    synchronized (this) {\n      bufferDeleteTerm(term);\n      ramSegmentInfos.addElement(newSegmentInfo);\n      maybeFlushRamSegments();\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    SegmentInfo newSegmentInfo = buildSingleDocSegment(doc, analyzer);\n    synchronized (this) {\n      bufferDeleteTerm(term);\n      ramSegmentInfos.addElement(newSegmentInfo);\n      maybeFlushRamSegments();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4350b17bd363cd13a95171b8df1ca62ea4c3e71c","date":1183562198,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    synchronized (this) {\n      bufferDeleteTerm(term);\n    }\n    if (docWriter.addDocument(doc, analyzer))\n      flush(true, false);\n    else\n      maybeFlush();\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    SegmentInfo newSegmentInfo = buildSingleDocSegment(doc, analyzer);\n    synchronized (this) {\n      bufferDeleteTerm(term);\n      ramSegmentInfos.addElement(newSegmentInfo);\n      maybeFlushRamSegments();\n    }\n  }\n\n","bugFix":null,"bugIntro":["fde68de507dbf344495d7b5e8052866fe5f254ab","5d01393ee15c09415a2d4d8610aef0ec780a5e5f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5d01393ee15c09415a2d4d8610aef0ec780a5e5f","date":1184714576,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    synchronized (this) {\n      bufferDeleteTerm(term);\n    }\n    boolean success = false;\n    try {\n      success = docWriter.addDocument(doc, analyzer);\n    } catch (IOException ioe) {\n      deleter.refresh();\n      throw ioe;\n    }\n    if (success)\n      flush(true, false);\n    else\n      maybeFlush();\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    synchronized (this) {\n      bufferDeleteTerm(term);\n    }\n    if (docWriter.addDocument(doc, analyzer))\n      flush(true, false);\n    else\n      maybeFlush();\n  }\n\n","bugFix":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"bugIntro":["fde68de507dbf344495d7b5e8052866fe5f254ab"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fde68de507dbf344495d7b5e8052866fe5f254ab","date":1189434831,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    boolean doFlush = false;\n    try {\n      doFlush = docWriter.updateDocument(term, doc, analyzer);\n    } catch (IOException ioe) {\n      deleter.refresh();\n      throw ioe;\n    }\n    if (doFlush)\n      flush(true, false);\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    synchronized (this) {\n      bufferDeleteTerm(term);\n    }\n    boolean success = false;\n    try {\n      success = docWriter.addDocument(doc, analyzer);\n    } catch (IOException ioe) {\n      deleter.refresh();\n      throw ioe;\n    }\n    if (success)\n      flush(true, false);\n    else\n      maybeFlush();\n  }\n\n","bugFix":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c","5d01393ee15c09415a2d4d8610aef0ec780a5e5f","42a18cb0bca2c4ac9747f31c7a74fac90c661f39"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b1405362241b561f5590ff4a87d5d6e173bcd9cf","date":1190107634,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    boolean doFlush = false;\n    boolean success = false;\n    try {\n      doFlush = docWriter.updateDocument(term, doc, analyzer);\n      success = true;\n    } finally {\n      if (!success) {\n\n        if (infoStream != null)\n          message(\"hit exception updating document\");\n\n        synchronized (this) {\n          // If docWriter has some aborted files that were\n          // never incref'd, then we clean them up here\n          final List files = docWriter.abortedFiles();\n          if (files != null)\n            deleter.deleteNewFiles(files);\n        }\n      }\n    }\n    if (doFlush)\n      flush(true, false);\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    boolean doFlush = false;\n    try {\n      doFlush = docWriter.updateDocument(term, doc, analyzer);\n    } catch (IOException ioe) {\n      deleter.refresh();\n      throw ioe;\n    }\n    if (doFlush)\n      flush(true, false);\n  }\n\n","bugFix":null,"bugIntro":["5ef87af8c7bd0f8429622b83aa74202383f2e757"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"741a5cca05cabe1e7482410a29e563a08379251a","date":1196676550,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    int status = 0;\n    boolean success = false;\n    try {\n      status = docWriter.updateDocument(term, doc, analyzer);\n      success = true;\n    } finally {\n      if (!success) {\n\n        if (infoStream != null)\n          message(\"hit exception updating document\");\n\n        synchronized (this) {\n          // If docWriter has some aborted files that were\n          // never incref'd, then we clean them up here\n          final List files = docWriter.abortedFiles();\n          if (files != null)\n            deleter.deleteNewFiles(files);\n        }\n      }\n    }\n    if ((status & 1) != 0)\n      flush(true, false);\n    checkMaxTermLength(status);\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    boolean doFlush = false;\n    boolean success = false;\n    try {\n      doFlush = docWriter.updateDocument(term, doc, analyzer);\n      success = true;\n    } finally {\n      if (!success) {\n\n        if (infoStream != null)\n          message(\"hit exception updating document\");\n\n        synchronized (this) {\n          // If docWriter has some aborted files that were\n          // never incref'd, then we clean them up here\n          final List files = docWriter.abortedFiles();\n          if (files != null)\n            deleter.deleteNewFiles(files);\n        }\n      }\n    }\n    if (doFlush)\n      flush(true, false);\n  }\n\n","bugFix":null,"bugIntro":["5a251aa47d1808cbae42c0e172d698c377430e60"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5a251aa47d1808cbae42c0e172d698c377430e60","date":1199375390,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    boolean doFlush = false;\n    boolean success = false;\n    try {\n      doFlush = docWriter.updateDocument(term, doc, analyzer);\n      success = true;\n    } finally {\n      if (!success) {\n\n        if (infoStream != null)\n          message(\"hit exception updating document\");\n\n        synchronized (this) {\n          // If docWriter has some aborted files that were\n          // never incref'd, then we clean them up here\n          final List files = docWriter.abortedFiles();\n          if (files != null)\n            deleter.deleteNewFiles(files);\n        }\n      }\n    }\n    if (doFlush)\n      flush(true, false);\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    int status = 0;\n    boolean success = false;\n    try {\n      status = docWriter.updateDocument(term, doc, analyzer);\n      success = true;\n    } finally {\n      if (!success) {\n\n        if (infoStream != null)\n          message(\"hit exception updating document\");\n\n        synchronized (this) {\n          // If docWriter has some aborted files that were\n          // never incref'd, then we clean them up here\n          final List files = docWriter.abortedFiles();\n          if (files != null)\n            deleter.deleteNewFiles(files);\n        }\n      }\n    }\n    if ((status & 1) != 0)\n      flush(true, false);\n    checkMaxTermLength(status);\n  }\n\n","bugFix":["741a5cca05cabe1e7482410a29e563a08379251a"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63","date":1204234542,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final List files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false);\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    boolean doFlush = false;\n    boolean success = false;\n    try {\n      doFlush = docWriter.updateDocument(term, doc, analyzer);\n      success = true;\n    } finally {\n      if (!success) {\n\n        if (infoStream != null)\n          message(\"hit exception updating document\");\n\n        synchronized (this) {\n          // If docWriter has some aborted files that were\n          // never incref'd, then we clean them up here\n          final List files = docWriter.abortedFiles();\n          if (files != null)\n            deleter.deleteNewFiles(files);\n        }\n      }\n    }\n    if (doFlush)\n      flush(true, false);\n  }\n\n","bugFix":null,"bugIntro":["cd488f50316362b01a7f67b11a96796b9652e3e5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be","date":1204801324,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final List files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final List files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false);\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5350389bf83287111f7760b9e3db3af8e3648474","date":1216372812,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final List files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9665d17707cc21b1db995118ff36129723139ab","date":1225384420,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cd488f50316362b01a7f67b11a96796b9652e3e5","date":1241121034,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    }\n  }\n\n","bugFix":["01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ef82ff03e4016c705811b2658e81471a645c0e49","date":1255900293,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#updateDocument(Term,Document,Analyzer).mjava","sourceNew":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","sourceOld":"  /**\n   * Updates a document by first deleting the document(s)\n   * containing <code>term</code> and then adding the new\n   * document.  The delete and then add are atomic as seen\n   * by a reader on the same index (flush may happen only after\n   * the add).\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @param term the term to identify the document(s) to be\n   * deleted\n   * @param doc the document to be added\n   * @param analyzer the analyzer to use when analyzing the document\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  public void updateDocument(Term term, Document doc, Analyzer analyzer)\n      throws CorruptIndexException, IOException {\n    ensureOpen();\n    try {\n      boolean doFlush = false;\n      boolean success = false;\n      try {\n        doFlush = docWriter.updateDocument(term, doc, analyzer);\n        success = true;\n      } finally {\n        if (!success) {\n\n          if (infoStream != null)\n            message(\"hit exception updating document\");\n\n          synchronized (this) {\n            // If docWriter has some aborted files that were\n            // never incref'd, then we clean them up here\n            final Collection<String> files = docWriter.abortedFiles();\n            if (files != null)\n              deleter.deleteNewFiles(files);\n          }\n        }\n      }\n      if (doFlush)\n        flush(true, false, false);\n    } catch (OutOfMemoryError oom) {\n      handleOOM(oom, \"updateDocument\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b1405362241b561f5590ff4a87d5d6e173bcd9cf":["fde68de507dbf344495d7b5e8052866fe5f254ab"],"328c1568e471f0c6eaa49ec00334ca59e573710f":["1b54a9bc667895a2095a886184bf69a3179e63df"],"fde68de507dbf344495d7b5e8052866fe5f254ab":["5d01393ee15c09415a2d4d8610aef0ec780a5e5f"],"1b54a9bc667895a2095a886184bf69a3179e63df":["42a18cb0bca2c4ac9747f31c7a74fac90c661f39"],"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be":["01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63"],"741a5cca05cabe1e7482410a29e563a08379251a":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["328c1568e471f0c6eaa49ec00334ca59e573710f"],"5d01393ee15c09415a2d4d8610aef0ec780a5e5f":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"e9665d17707cc21b1db995118ff36129723139ab":["5350389bf83287111f7760b9e3db3af8e3648474"],"cd488f50316362b01a7f67b11a96796b9652e3e5":["e9665d17707cc21b1db995118ff36129723139ab"],"01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63":["5a251aa47d1808cbae42c0e172d698c377430e60"],"42a18cb0bca2c4ac9747f31c7a74fac90c661f39":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ef82ff03e4016c705811b2658e81471a645c0e49":["cd488f50316362b01a7f67b11a96796b9652e3e5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5a251aa47d1808cbae42c0e172d698c377430e60":["741a5cca05cabe1e7482410a29e563a08379251a"],"5350389bf83287111f7760b9e3db3af8e3648474":["a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["ef82ff03e4016c705811b2658e81471a645c0e49"]},"commit2Childs":{"b1405362241b561f5590ff4a87d5d6e173bcd9cf":["741a5cca05cabe1e7482410a29e563a08379251a"],"328c1568e471f0c6eaa49ec00334ca59e573710f":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"fde68de507dbf344495d7b5e8052866fe5f254ab":["b1405362241b561f5590ff4a87d5d6e173bcd9cf"],"1b54a9bc667895a2095a886184bf69a3179e63df":["328c1568e471f0c6eaa49ec00334ca59e573710f"],"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be":["5350389bf83287111f7760b9e3db3af8e3648474"],"741a5cca05cabe1e7482410a29e563a08379251a":["5a251aa47d1808cbae42c0e172d698c377430e60"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["5d01393ee15c09415a2d4d8610aef0ec780a5e5f"],"5d01393ee15c09415a2d4d8610aef0ec780a5e5f":["fde68de507dbf344495d7b5e8052866fe5f254ab"],"e9665d17707cc21b1db995118ff36129723139ab":["cd488f50316362b01a7f67b11a96796b9652e3e5"],"01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63":["a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be"],"cd488f50316362b01a7f67b11a96796b9652e3e5":["ef82ff03e4016c705811b2658e81471a645c0e49"],"42a18cb0bca2c4ac9747f31c7a74fac90c661f39":["1b54a9bc667895a2095a886184bf69a3179e63df"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["42a18cb0bca2c4ac9747f31c7a74fac90c661f39"],"ef82ff03e4016c705811b2658e81471a645c0e49":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"5a251aa47d1808cbae42c0e172d698c377430e60":["01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63"],"5350389bf83287111f7760b9e3db3af8e3648474":["e9665d17707cc21b1db995118ff36129723139ab"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}