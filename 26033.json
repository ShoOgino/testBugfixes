{"path":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","commits":[{"id":"845e792cacdb2bb8da8fb051c0afc60db568233f","date":1456851727,"type":0,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","pathOld":"/dev/null","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    File configDir = new File(TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir.toPath())\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    assertNotNull(cluster.createCollection(COLLECTION_NAME, NUM_SHARDS, REPLICATION_FACTOR,\n                                           configName, null, null, collectionProperties));\n    \n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    zkStateReader.updateClusterState();\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = new HttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","344b0840364d990b29b97467bfcc766ff8325d11"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cf1a614098b46c9c22afebd7b898ae4d1d2fc273","date":1457088850,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","pathOld":"/dev/null","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    File configDir = new File(TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir.toPath())\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    assertNotNull(cluster.createCollection(COLLECTION_NAME, NUM_SHARDS, REPLICATION_FACTOR,\n                                           configName, null, null, collectionProperties));\n    \n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    zkStateReader.updateClusterState();\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = new HttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f","date":1457343183,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    File configDir = new File(TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir.toPath())\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    assertNotNull(cluster.createCollection(COLLECTION_NAME, NUM_SHARDS, REPLICATION_FACTOR,\n                                           configName, null, null, collectionProperties));\n    \n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = new HttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","sourceOld":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    File configDir = new File(TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir.toPath())\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    assertNotNull(cluster.createCollection(COLLECTION_NAME, NUM_SHARDS, REPLICATION_FACTOR,\n                                           configName, null, null, collectionProperties));\n    \n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    zkStateReader.updateClusterState();\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = new HttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"302d8fdf94f74714767c82c227021c197dee85a3","date":1458395639,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir)\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    assertNotNull(cluster.createCollection(COLLECTION_NAME, NUM_SHARDS, REPLICATION_FACTOR,\n                                           configName, null, null, collectionProperties));\n    \n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = new HttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","sourceOld":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    File configDir = new File(TEST_HOME() + File.separator + \"collection1\" + File.separator + \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir.toPath())\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    assertNotNull(cluster.createCollection(COLLECTION_NAME, NUM_SHARDS, REPLICATION_FACTOR,\n                                           configName, null, null, collectionProperties));\n    \n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = new HttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e3c94a8b8bf47db4f968d9ae510ec8bbe1372088","date":1460069869,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir)\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    assertNotNull(cluster.createCollection(COLLECTION_NAME, NUM_SHARDS, REPLICATION_FACTOR,\n                                           configName, null, null, collectionProperties));\n    \n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = getHttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","sourceOld":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir)\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    assertNotNull(cluster.createCollection(COLLECTION_NAME, NUM_SHARDS, REPLICATION_FACTOR,\n                                           configName, null, null, collectionProperties));\n    \n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = new HttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5bdaf2cee03ff78b0a0cbf23df0095a3590b493b","date":1460110033,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir)\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    assertNotNull(cluster.createCollection(COLLECTION_NAME, NUM_SHARDS, REPLICATION_FACTOR,\n                                           configName, null, null, collectionProperties));\n    \n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = getHttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","sourceOld":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir)\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    assertNotNull(cluster.createCollection(COLLECTION_NAME, NUM_SHARDS, REPLICATION_FACTOR,\n                                           configName, null, null, collectionProperties));\n    \n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = new HttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = new HttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = new HttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e89a32cc825033ebae8bb9e1c6877c2d9d76749e","date":1476790453,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir)\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, NUM_SHARDS, REPLICATION_FACTOR)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = getHttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","sourceOld":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir)\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    assertNotNull(cluster.createCollection(COLLECTION_NAME, NUM_SHARDS, REPLICATION_FACTOR,\n                                           configName, null, null, collectionProperties));\n    \n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = getHttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir)\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, NUM_SHARDS, REPLICATION_FACTOR)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = getHttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","sourceOld":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir)\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    assertNotNull(cluster.createCollection(COLLECTION_NAME, NUM_SHARDS, REPLICATION_FACTOR,\n                                           configName, null, null, collectionProperties));\n    \n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = getHttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"344b0840364d990b29b97467bfcc766ff8325d11","date":1501574100,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir)\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, NUM_SHARDS, REPLICATION_FACTOR)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getCollection(COLLECTION_NAME).getSlices()) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = getHttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","sourceOld":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir)\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, NUM_SHARDS, REPLICATION_FACTOR)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = getHttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","bugFix":["845e792cacdb2bb8da8fb051c0afc60db568233f"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir)\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, NUM_SHARDS, REPLICATION_FACTOR)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getCollection(COLLECTION_NAME).getSlices()) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = getHttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","sourceOld":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir)\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, NUM_SHARDS, REPLICATION_FACTOR)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getSlices(COLLECTION_NAME)) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = getHttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestCloudDeleteByQuery#createMiniSolrCloudCluster().mjava","sourceNew":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir)\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, NUM_SHARDS, REPLICATION_FACTOR)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n    cluster.waitForActiveCollection(COLLECTION_NAME, NUM_SHARDS, REPLICATION_FACTOR * NUM_SHARDS);\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getCollection(COLLECTION_NAME).getSlices()) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = getHttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","sourceOld":"  @BeforeClass\n  private static void createMiniSolrCloudCluster() throws Exception {\n    \n    final String configName = \"solrCloudCollectionConfig\";\n    final Path configDir = Paths.get(TEST_HOME(), \"collection1\", \"conf\");\n    \n    configureCluster(NUM_SERVERS)\n      .addConfig(configName, configDir)\n      .configure();\n    \n    Map<String, String> collectionProperties = new HashMap<>();\n    collectionProperties.put(\"config\", \"solrconfig-tlog.xml\");\n    collectionProperties.put(\"schema\", \"schema15.xml\"); // string id for doc routing prefix\n\n    CollectionAdminRequest.createCollection(COLLECTION_NAME, configName, NUM_SHARDS, REPLICATION_FACTOR)\n        .setProperties(collectionProperties)\n        .process(cluster.getSolrClient());\n\n    CLOUD_CLIENT = cluster.getSolrClient();\n    CLOUD_CLIENT.setDefaultCollection(COLLECTION_NAME);\n    \n    ZkStateReader zkStateReader = CLOUD_CLIENT.getZkStateReader();\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION_NAME, zkStateReader, true, true, 330);\n\n\n    // really hackish way to get a URL for specific nodes based on shard/replica hosting\n    // inspired by TestMiniSolrCloudCluster\n    HashMap<String, String> urlMap = new HashMap<>();\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      URL jettyURL = jetty.getBaseUrl();\n      String nodeKey = jettyURL.getHost() + \":\" + jettyURL.getPort() + jettyURL.getPath().replace(\"/\",\"_\");\n      urlMap.put(nodeKey, jettyURL.toString());\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    for (Slice slice : clusterState.getCollection(COLLECTION_NAME).getSlices()) {\n      String shardName = slice.getName();\n      Replica leader = slice.getLeader();\n      assertNotNull(\"slice has null leader: \" + slice.toString(), leader);\n      assertNotNull(\"slice leader has null node name: \" + slice.toString(), leader.getNodeName());\n      String leaderUrl = urlMap.remove(leader.getNodeName());\n      assertNotNull(\"could not find URL for \" + shardName + \" leader: \" + leader.getNodeName(),\n                    leaderUrl);\n      assertEquals(\"expected two total replicas for: \" + slice.getName(),\n                   2, slice.getReplicas().size());\n      \n      String passiveUrl = null;\n      \n      for (Replica replica : slice.getReplicas()) {\n        if ( ! replica.equals(leader)) {\n          passiveUrl = urlMap.remove(replica.getNodeName());\n          assertNotNull(\"could not find URL for \" + shardName + \" replica: \" + replica.getNodeName(),\n                        passiveUrl);\n        }\n      }\n      assertNotNull(\"could not find URL for \" + shardName + \" replica\", passiveUrl);\n\n      if (shardName.equals(\"shard1\")) {\n        S_ONE_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_ONE_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else if (shardName.equals(\"shard2\")) {\n        S_TWO_LEADER_CLIENT = getHttpSolrClient(leaderUrl + \"/\" + COLLECTION_NAME + \"/\");\n        S_TWO_NON_LEADER_CLIENT = getHttpSolrClient(passiveUrl + \"/\" + COLLECTION_NAME + \"/\");\n      } else {\n        fail(\"unexpected shard: \" + shardName);\n      }\n    }\n    assertEquals(\"Should be exactly one server left (nost hosting either shard)\", 1, urlMap.size());\n    NO_COLLECTION_CLIENT = getHttpSolrClient(urlMap.values().iterator().next() +\n                                              \"/\" + COLLECTION_NAME + \"/\");\n    \n    assertNotNull(S_ONE_LEADER_CLIENT);\n    assertNotNull(S_TWO_LEADER_CLIENT);\n    assertNotNull(S_ONE_NON_LEADER_CLIENT);\n    assertNotNull(S_TWO_NON_LEADER_CLIENT);\n    assertNotNull(NO_COLLECTION_CLIENT);\n\n    // sanity check that our S_ONE_PRE & S_TWO_PRE really do map to shard1 & shard2 with default routing\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_ONE_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard1\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.add(doc(f(\"id\", S_TWO_PRE + random().nextInt()),\n                                         f(\"expected_shard_s\", \"shard2\"))).getStatus());\n    assertEquals(0, CLOUD_CLIENT.commit().getStatus());\n    SolrDocumentList docs = CLOUD_CLIENT.query(params(\"q\", \"*:*\",\n                                                      \"fl\",\"id,expected_shard_s,[shard]\")).getResults();\n    assertEquals(2, docs.getNumFound());\n    assertEquals(2, docs.size());\n    for (SolrDocument doc : docs) {\n      String expected = COLLECTION_NAME + \"_\" + doc.getFirstValue(\"expected_shard_s\") + \"_replica\";\n      String docShard = doc.getFirstValue(\"[shard]\").toString();\n      assertTrue(\"shard routing prefixes don't seem to be aligned anymore, \" +\n                 \"did someone change the default routing rules? \" +\n                 \"and/or the the default core name rules? \" +\n                 \"and/or the numShards used by this test? ... \" +\n                 \"couldn't find \" + expected + \" as substring of [shard] == '\" + docShard +\n                 \"' ... for docId == \" + doc.getFirstValue(\"id\"),\n                 docShard.contains(expected));\n    }\n  }\n\n","bugFix":["845e792cacdb2bb8da8fb051c0afc60db568233f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e89a32cc825033ebae8bb9e1c6877c2d9d76749e":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["344b0840364d990b29b97467bfcc766ff8325d11"],"344b0840364d990b29b97467bfcc766ff8325d11":["e89a32cc825033ebae8bb9e1c6877c2d9d76749e"],"e3c94a8b8bf47db4f968d9ae510ec8bbe1372088":["302d8fdf94f74714767c82c227021c197dee85a3"],"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b","e89a32cc825033ebae8bb9e1c6877c2d9d76749e"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["e89a32cc825033ebae8bb9e1c6877c2d9d76749e","344b0840364d990b29b97467bfcc766ff8325d11"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5bdaf2cee03ff78b0a0cbf23df0095a3590b493b":["302d8fdf94f74714767c82c227021c197dee85a3","e3c94a8b8bf47db4f968d9ae510ec8bbe1372088"],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","845e792cacdb2bb8da8fb051c0afc60db568233f"],"845e792cacdb2bb8da8fb051c0afc60db568233f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"302d8fdf94f74714767c82c227021c197dee85a3":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"]},"commit2Childs":{"e89a32cc825033ebae8bb9e1c6877c2d9d76749e":["344b0840364d990b29b97467bfcc766ff8325d11","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"344b0840364d990b29b97467bfcc766ff8325d11":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"e3c94a8b8bf47db4f968d9ae510ec8bbe1372088":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f":["302d8fdf94f74714767c82c227021c197dee85a3"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273","845e792cacdb2bb8da8fb051c0afc60db568233f"],"5bdaf2cee03ff78b0a0cbf23df0095a3590b493b":["e89a32cc825033ebae8bb9e1c6877c2d9d76749e","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f"],"845e792cacdb2bb8da8fb051c0afc60db568233f":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"302d8fdf94f74714767c82c227021c197dee85a3":["e3c94a8b8bf47db4f968d9ae510ec8bbe1372088","5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}