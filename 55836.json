{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(SegmentReadState).mjava","commits":[{"id":"e6f7d3244902a0689d3acc83eaa8d8a4e8504de1","date":1412165020,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","sourceNew":"  public FixedGapTermsIndexReader(SegmentReadState state) throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n    \n    String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, \n                                                     state.segmentSuffix, \n                                                     FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, state.context);\n    \n    boolean success = false;\n\n    try {\n      \n      CodecUtil.checkSegmentHeader(in, FixedGapTermsIndexWriter.CODEC_NAME,\n                                       FixedGapTermsIndexWriter.VERSION_CURRENT, \n                                       FixedGapTermsIndexWriter.VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      \n      CodecUtil.checksumEntireFile(in);\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval, in);\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields, in);\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms, in);\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms, in);\n        }\n        final FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name, in);\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","sourceOld":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      \n      if (version >= FixedGapTermsIndexWriter.VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval, in);\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields, in);\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms, in);\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms, in);\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name, in);\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","sourceNew":"  public FixedGapTermsIndexReader(SegmentReadState state) throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n    \n    String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, \n                                                     state.segmentSuffix, \n                                                     FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, state.context);\n    \n    boolean success = false;\n\n    try {\n      \n      CodecUtil.checkSegmentHeader(in, FixedGapTermsIndexWriter.CODEC_NAME,\n                                       FixedGapTermsIndexWriter.VERSION_CURRENT, \n                                       FixedGapTermsIndexWriter.VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      \n      CodecUtil.checksumEntireFile(in);\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval, in);\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields, in);\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms, in);\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms, in);\n        }\n        final FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name, in);\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","sourceOld":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      \n      if (version >= FixedGapTermsIndexWriter.VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval, in);\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields, in);\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms, in);\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms, in);\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name, in);\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3384e6013a93e4d11b7d75388693f8d0388602bf","date":1413951663,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(SegmentReadState).mjava","sourceNew":"  public FixedGapTermsIndexReader(SegmentReadState state) throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n    \n    String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, \n                                                     state.segmentSuffix, \n                                                     FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, state.context);\n    \n    boolean success = false;\n\n    try {\n      \n      CodecUtil.checkIndexHeader(in, FixedGapTermsIndexWriter.CODEC_NAME,\n                                       FixedGapTermsIndexWriter.VERSION_CURRENT, \n                                       FixedGapTermsIndexWriter.VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      \n      CodecUtil.checksumEntireFile(in);\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval, in);\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields, in);\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms, in);\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms, in);\n        }\n        final FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name, in);\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","sourceOld":"  public FixedGapTermsIndexReader(SegmentReadState state) throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n    \n    String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, \n                                                     state.segmentSuffix, \n                                                     FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, state.context);\n    \n    boolean success = false;\n\n    try {\n      \n      CodecUtil.checkSegmentHeader(in, FixedGapTermsIndexWriter.CODEC_NAME,\n                                       FixedGapTermsIndexWriter.VERSION_CURRENT, \n                                       FixedGapTermsIndexWriter.VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      \n      CodecUtil.checksumEntireFile(in);\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval, in);\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields, in);\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms, in);\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms, in);\n        }\n        final FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name, in);\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(SegmentReadState).mjava","sourceNew":"  public FixedGapTermsIndexReader(SegmentReadState state) throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n    \n    String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, \n                                                     state.segmentSuffix, \n                                                     FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, state.context);\n    \n    boolean success = false;\n\n    try {\n      \n      CodecUtil.checkIndexHeader(in, FixedGapTermsIndexWriter.CODEC_NAME,\n                                       FixedGapTermsIndexWriter.VERSION_CURRENT, \n                                       FixedGapTermsIndexWriter.VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      \n      CodecUtil.checksumEntireFile(in);\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval, in);\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields, in);\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms, in);\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms, in);\n        }\n        final FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name, in);\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","sourceOld":"  public FixedGapTermsIndexReader(SegmentReadState state) throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n    \n    String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, \n                                                     state.segmentSuffix, \n                                                     FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, state.context);\n    \n    boolean success = false;\n\n    try {\n      \n      CodecUtil.checkSegmentHeader(in, FixedGapTermsIndexWriter.CODEC_NAME,\n                                       FixedGapTermsIndexWriter.VERSION_CURRENT, \n                                       FixedGapTermsIndexWriter.VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      \n      CodecUtil.checksumEntireFile(in);\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval, in);\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields, in);\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms, in);\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms, in);\n        }\n        final FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name, in);\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e6f7d3244902a0689d3acc83eaa8d8a4e8504de1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9bb9a29a5e71a90295f175df8919802993142c9a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e6f7d3244902a0689d3acc83eaa8d8a4e8504de1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3384e6013a93e4d11b7d75388693f8d0388602bf":["e6f7d3244902a0689d3acc83eaa8d8a4e8504de1"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["9bb9a29a5e71a90295f175df8919802993142c9a","3384e6013a93e4d11b7d75388693f8d0388602bf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"]},"commit2Childs":{"e6f7d3244902a0689d3acc83eaa8d8a4e8504de1":["9bb9a29a5e71a90295f175df8919802993142c9a","3384e6013a93e4d11b7d75388693f8d0388602bf"],"9bb9a29a5e71a90295f175df8919802993142c9a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e6f7d3244902a0689d3acc83eaa8d8a4e8504de1","9bb9a29a5e71a90295f175df8919802993142c9a"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}