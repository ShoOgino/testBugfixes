{"path":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#getUnusualAnalyzer().mjava","commits":[{"id":"cc41b743423981e7ec17a024ce7e107096e472fe","date":1349975327,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#getUnusualAnalyzer().mjava","pathOld":"/dev/null","sourceNew":"  private final Analyzer getUnusualAnalyzer() {\n    return new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n        return new TokenStreamComponents(tokenizer) {\n\n          int count;\n\n          @Override\n          public TokenStream getTokenStream() {\n            // 4th time we are called, return tokens a b,\n            // else just a:\n            if (count++ != 3) {\n              return new CannedTokenStream(new Token[] {\n                  token(\"a\", 1, 1),\n                });\n            } else {\n              // After that \"a b\":\n              return new CannedTokenStream(new Token[] {\n                  token(\"a\", 1, 1),\n                  token(\"b\", 1, 1),\n                });\n            }\n          }\n         \n          @Override\n          protected void setReader(final Reader reader) throws IOException {\n          }\n        };\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b","date":1351615637,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#getUnusualAnalyzer().mjava","pathOld":"/dev/null","sourceNew":"  private final Analyzer getUnusualAnalyzer() {\n    return new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n        return new TokenStreamComponents(tokenizer) {\n\n          int count;\n\n          @Override\n          public TokenStream getTokenStream() {\n            // 4th time we are called, return tokens a b,\n            // else just a:\n            if (count++ != 3) {\n              return new CannedTokenStream(new Token[] {\n                  token(\"a\", 1, 1),\n                });\n            } else {\n              // After that \"a b\":\n              return new CannedTokenStream(new Token[] {\n                  token(\"a\", 1, 1),\n                  token(\"b\", 1, 1),\n                });\n            }\n          }\n         \n          @Override\n          protected void setReader(final Reader reader) throws IOException {\n          }\n        };\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#getUnusualAnalyzer().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#getUnusualAnalyzer().mjava","sourceNew":"  private final Analyzer getUnusualAnalyzer() {\n    return new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n        return new TokenStreamComponents(tokenizer) {\n\n          int count;\n\n          @Override\n          public TokenStream getTokenStream() {\n            // 4th time we are called, return tokens a b,\n            // else just a:\n            if (count++ != 3) {\n              return new CannedTokenStream(new Token[] {\n                  token(\"a\", 1, 1),\n                });\n            } else {\n              // After that \"a b\":\n              return new CannedTokenStream(new Token[] {\n                  token(\"a\", 1, 1),\n                  token(\"b\", 1, 1),\n                });\n            }\n          }\n         \n          @Override\n          protected void setReader(final Reader reader) throws IOException {\n          }\n        };\n      }\n    };\n  }\n\n","sourceOld":"  private final Analyzer getUnusualAnalyzer() {\n    return new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n        return new TokenStreamComponents(tokenizer) {\n\n          int count;\n\n          @Override\n          public TokenStream getTokenStream() {\n            // 4th time we are called, return tokens a b,\n            // else just a:\n            if (count++ != 3) {\n              return new CannedTokenStream(new Token[] {\n                  token(\"a\", 1, 1),\n                });\n            } else {\n              // After that \"a b\":\n              return new CannedTokenStream(new Token[] {\n                  token(\"a\", 1, 1),\n                  token(\"b\", 1, 1),\n                });\n            }\n          }\n         \n          @Override\n          protected void setReader(final Reader reader) throws IOException {\n          }\n        };\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e859719dc778fb66d3d21e7be08cd408fc2bde98","date":1446717611,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#getUnusualAnalyzer().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#getUnusualAnalyzer().mjava","sourceNew":"  private final Analyzer getUnusualAnalyzer() {\n    return new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n        return new TokenStreamComponents(tokenizer) {\n\n          int count;\n\n          @Override\n          public TokenStream getTokenStream() {\n            // 4th time we are called, return tokens a b,\n            // else just a:\n            if (count++ != 3) {\n              return new CannedTokenStream(new Token[] {\n                  token(\"a\", 1, 1),\n                });\n            } else {\n              // After that \"a b\":\n              return new CannedTokenStream(new Token[] {\n                  token(\"a\", 1, 1),\n                  token(\"b\", 1, 1),\n                });\n            }\n          }\n         \n          @Override\n          protected void setReader(final Reader reader) {\n          }\n        };\n      }\n    };\n  }\n\n","sourceOld":"  private final Analyzer getUnusualAnalyzer() {\n    return new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n        return new TokenStreamComponents(tokenizer) {\n\n          int count;\n\n          @Override\n          public TokenStream getTokenStream() {\n            // 4th time we are called, return tokens a b,\n            // else just a:\n            if (count++ != 3) {\n              return new CannedTokenStream(new Token[] {\n                  token(\"a\", 1, 1),\n                });\n            } else {\n              // After that \"a b\":\n              return new CannedTokenStream(new Token[] {\n                  token(\"a\", 1, 1),\n                  token(\"b\", 1, 1),\n                });\n            }\n          }\n         \n          @Override\n          protected void setReader(final Reader reader) throws IOException {\n          }\n        };\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fac252ef8e3d0bbff9303ffbf675e824a729dfaf","date":1537347776,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#getUnusualAnalyzer().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/FuzzySuggesterTest#getUnusualAnalyzer().mjava","sourceNew":"  private Analyzer getUnusualAnalyzer() {\n    // First three calls just returns \"a\", then returns [\"a\",\"b\"], then \"a\" again\n    return new AnalyzingSuggesterTest.MultiCannedAnalyzer(\n        new CannedTokenStream(token(\"a\", 1, 1)),\n        new CannedTokenStream(token(\"a\", 1, 1)),\n        new CannedTokenStream(token(\"a\", 1, 1)),\n        new CannedTokenStream(token(\"a\", 1, 1), token(\"b\", 1, 1)),\n        new CannedTokenStream(token(\"a\", 1, 1)),\n        new CannedTokenStream(token(\"a\", 1, 1)));\n  }\n\n","sourceOld":"  private final Analyzer getUnusualAnalyzer() {\n    return new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n        return new TokenStreamComponents(tokenizer) {\n\n          int count;\n\n          @Override\n          public TokenStream getTokenStream() {\n            // 4th time we are called, return tokens a b,\n            // else just a:\n            if (count++ != 3) {\n              return new CannedTokenStream(new Token[] {\n                  token(\"a\", 1, 1),\n                });\n            } else {\n              // After that \"a b\":\n              return new CannedTokenStream(new Token[] {\n                  token(\"a\", 1, 1),\n                  token(\"b\", 1, 1),\n                });\n            }\n          }\n         \n          @Override\n          protected void setReader(final Reader reader) {\n          }\n        };\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","cc41b743423981e7ec17a024ce7e107096e472fe"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b"],"cc41b743423981e7ec17a024ce7e107096e472fe":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fac252ef8e3d0bbff9303ffbf675e824a729dfaf":["e859719dc778fb66d3d21e7be08cd408fc2bde98"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e859719dc778fb66d3d21e7be08cd408fc2bde98":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fac252ef8e3d0bbff9303ffbf675e824a729dfaf"]},"commit2Childs":{"4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"cc41b743423981e7ec17a024ce7e107096e472fe":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["e859719dc778fb66d3d21e7be08cd408fc2bde98"],"fac252ef8e3d0bbff9303ffbf675e824a729dfaf":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4f3db1dca4ec6d06e771211e9f7c4ae5d8e5758b","cc41b743423981e7ec17a024ce7e107096e472fe"],"e859719dc778fb66d3d21e7be08cd408fc2bde98":["fac252ef8e3d0bbff9303ffbf675e824a729dfaf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}