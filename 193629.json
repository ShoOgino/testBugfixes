{"path":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","commits":[{"id":"67f215f0e4d5c92f5d96ab7675170115b0983501","date":1492649385,"type":0,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger\");\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.info(\"Found livenodes: \" + newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.info(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, System.nanoTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeRemoved.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(System.nanoTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeLostEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeLostTrigger firing registered listener\");\n            listener.triggerFired(new NodeLostEvent(this, timeRemoved, nodeName));\n          }\n          trackingKeySet.remove(nodeName);\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a7699e9ae4550ba2a55335a64ae7de9d5d9de39e","date":1493894873,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger: {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.info(\"Found livenodes: \" + newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.info(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, System.nanoTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeRemoved.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(System.nanoTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeLostEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeLostTrigger firing registered listener\");\n            listener.triggerFired(new NodeLostEvent(this, timeRemoved, nodeName));\n          }\n          trackingKeySet.remove(nodeName);\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger\");\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.info(\"Found livenodes: \" + newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.info(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, System.nanoTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeRemoved.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(System.nanoTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeLostEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeLostTrigger firing registered listener\");\n            listener.triggerFired(new NodeLostEvent(this, timeRemoved, nodeName));\n          }\n          trackingKeySet.remove(nodeName);\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"009caa80830ac6369c42e5f6515405d686eabfee","date":1494487120,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger: {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.info(\"Found livenodes: \" + newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.info(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, System.nanoTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeRemoved.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(System.nanoTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeLostEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeLostTrigger firing registered listener\");\n            if (listener.triggerFired(new NodeLostEvent(this, timeRemoved, nodeName)))  {\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger: {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.info(\"Found livenodes: \" + newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.info(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, System.nanoTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeRemoved.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(System.nanoTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeLostEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeLostTrigger firing registered listener\");\n            listener.triggerFired(new NodeLostEvent(this, timeRemoved, nodeName));\n          }\n          trackingKeySet.remove(nodeName);\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"21b2bdbc19fd09c6d3aed15a7ad25bca9cac762d","date":1494838933,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger: {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.info(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, System.nanoTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeRemoved.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(System.nanoTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeLostEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeLostTrigger firing registered listener\");\n            if (listener.triggerFired(new NodeLostEvent(this, timeRemoved, nodeName)))  {\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger: {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.info(\"Found livenodes: \" + newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.info(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, System.nanoTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeRemoved.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(System.nanoTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeLostEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeLostTrigger firing registered listener\");\n            if (listener.triggerFired(new NodeLostEvent(this, timeRemoved, nodeName)))  {\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"464244264804e3f981bf1fb4b732516d8d62dbc2","date":1495736161,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger: {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeRemoved.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(timeSource.getTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeLostTrigger firing registered listener\");\n            if (listener.triggerFired(new NodeLostEvent(getEventType(), getName(), timeRemoved, nodeName)))  {\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger: {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.info(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, System.nanoTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeRemoved.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(System.nanoTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeLostEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeLostTrigger firing registered listener\");\n            if (listener.triggerFired(new NodeLostEvent(this, timeRemoved, nodeName)))  {\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5531f16a602ef350b6c9adfb08ebaa13a60fe3db","date":1495756318,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger: {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeRemoved.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(timeSource.getTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeLostTrigger firing registered listener\");\n            if (listener.triggerFired(new NodeLostEvent(getEventType(), getName(), timeRemoved, nodeName)))  {\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger: {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.info(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, System.nanoTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeRemoved.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(System.nanoTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener<NodeLostEvent> listener = listenerRef.get();\n          if (listener != null) {\n            log.info(\"NodeLostTrigger firing registered listener\");\n            if (listener.triggerFired(new NodeLostEvent(this, timeRemoved, nodeName)))  {\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = newLiveNodes;\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c32a8448145a74a8902798f2e63e322827757ff2","date":1496834422,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger: {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(timeSource.getTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeLostTrigger firing registered listener\");\n            if (listener.triggerFired(new NodeLostEvent(getEventType(), getName(), timeRemoved, nodeName)))  {\n              it.remove();\n              removeNodeLostMarker(nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeLostMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger: {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeRemoved.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(timeSource.getTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeLostTrigger firing registered listener\");\n            if (listener.triggerFired(new NodeLostEvent(getEventType(), getName(), timeRemoved, nodeName)))  {\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"664ff2b928393480d9655010aa700656b0fcade0","date":1496842764,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger: {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(timeSource.getTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeLostTrigger firing registered listener\");\n            if (listener.triggerFired(new NodeLostEvent(getEventType(), getName(), timeRemoved, nodeName)))  {\n              it.remove();\n              removeNodeLostMarker(nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeLostMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger: {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Map.Entry<String, Long> entry : nodeNameVsTimeRemoved.entrySet()) {\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(timeSource.getTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeLostTrigger firing registered listener\");\n            if (listener.triggerFired(new NodeLostEvent(getEventType(), getName(), timeRemoved, nodeName)))  {\n              trackingKeySet.remove(nodeName);\n            }\n          } else  {\n            trackingKeySet.remove(nodeName);\n          }\n        }\n      }\n\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"47b66a5a735f0babac8c50ae98b885dfc6b15100","date":1499312183,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(timeSource.getTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeLostTrigger firing registered listener for lost node: {}\", nodeName);\n            if (listener.triggerFired(new NodeLostEvent(getEventType(), getName(), timeRemoved, nodeName)))  {\n              it.remove();\n              removeNodeLostMarker(nodeName);\n            } else  {\n              log.debug(\"NodeLostTrigger listener for lost node: {} is not ready, will try later\", nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeLostMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n      log.debug(\"Running NodeLostTrigger: {}\", name);\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Found livenodes: {}\", newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(timeSource.getTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeLostTrigger firing registered listener\");\n            if (listener.triggerFired(new NodeLostEvent(getEventType(), getName(), timeRemoved, nodeName)))  {\n              it.remove();\n              removeNodeLostMarker(nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeLostMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c5fd294da67452cd8d116692194908de00eb5209","date":1499704155,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(timeSource.getTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.EventProcessor processor = processorRef.get();\n          if (processor != null) {\n            log.debug(\"NodeLostTrigger firing registered processor for lost node: {}\", nodeName);\n            if (processor.process(new NodeLostEvent(getEventType(), getName(), timeRemoved, nodeName)))  {\n              it.remove();\n              removeNodeLostMarker(nodeName);\n            } else  {\n              log.debug(\"NodeLostTrigger listener for lost node: {} is not ready, will try later\", nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeLostMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(timeSource.getTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerListener listener = listenerRef.get();\n          if (listener != null) {\n            log.debug(\"NodeLostTrigger firing registered listener for lost node: {}\", nodeName);\n            if (listener.triggerFired(new NodeLostEvent(getEventType(), getName(), timeRemoved, nodeName)))  {\n              it.remove();\n              removeNodeLostMarker(nodeName);\n            } else  {\n              log.debug(\"NodeLostTrigger listener for lost node: {} is not ready, will try later\", nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeLostMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25","date":1499961129,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(timeSource.getTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerEventProcessor processor = processorRef.get();\n          if (processor != null) {\n            log.debug(\"NodeLostTrigger firing registered processor for lost node: {}\", nodeName);\n            if (processor.process(new NodeLostEvent(getEventType(), getName(), timeRemoved, nodeName)))  {\n              it.remove();\n              removeNodeLostMarker(nodeName);\n            } else  {\n              log.debug(\"NodeLostTrigger listener for lost node: {} is not ready, will try later\", nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeLostMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(timeSource.getTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.EventProcessor processor = processorRef.get();\n          if (processor != null) {\n            log.debug(\"NodeLostTrigger firing registered processor for lost node: {}\", nodeName);\n            if (processor.process(new NodeLostEvent(getEventType(), getName(), timeRemoved, nodeName)))  {\n              it.remove();\n              removeNodeLostMarker(nodeName);\n            } else  {\n              log.debug(\"NodeLostTrigger listener for lost node: {} is not ready, will try later\", nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeLostMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cc5ed4ca39a59c23d13866a1e110e608d93cbcc1","date":1503489512,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        if (TimeUnit.SECONDS.convert(timeSource.getTime() - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          // fire!\n          AutoScaling.TriggerEventProcessor processor = processorRef.get();\n          if (processor != null) {\n            log.debug(\"NodeLostTrigger firing registered processor for lost node: {}\", nodeName);\n            if (processor.process(new NodeLostEvent(getEventType(), getName(), timeRemoved, nodeName)))  {\n              it.remove();\n              removeNodeLostMarker(nodeName);\n            } else  {\n              log.debug(\"NodeLostTrigger listener for lost node: {} is not ready, will try later\", nodeName);\n            }\n          } else  {\n            it.remove();\n            removeNodeLostMarker(nodeName);\n          }\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac","date":1503580177,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(clusterDataProvider.getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b869898f50ca80263bac2e3ae0949f7700e5c977","date":1503580229,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(clusterDataProvider.getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5b8cffee0b9c10b78bd087c71485b482217fe84f","date":1505950827,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      ZkStateReader reader = zkController.getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      ZkStateReader reader = container.getZkController().getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c304e97e7c1d472bc70e801b35ee78583916c6cd","date":1507105431,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      ZkStateReader reader = zkController.getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"560c18d71dad43d675158783c3840f8c80d6d39c","date":1507105532,"type":0,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      ZkStateReader reader = zkController.getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"85212dad4ed576c7f7e6c165ee19e597b7b4efc8","date":1507997740,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(dataProvider.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      ZkStateReader reader = zkController.getZkStateReader();\n      Set<String> newLiveNodes = reader.getClusterState().getLiveNodes();\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c3f354f2175f861ee625bb3c9572d53b77cd8545","date":1508405819,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(dataProvider.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes.size());\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          throw new RuntimeException(\"Trigger has been closed\");\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes);\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, timeSource.getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = timeSource.getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a4422b331d00607258b0ed3e43934306e67764aa","date":1513943901,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes.size());\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes.size());\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger listener for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4412883c12067d8a4e2a354aa8adc58c32be1d6","date":1521129281,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes.size());\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes.size());\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTime());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTime();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9b87bf1141cacf62ff7b9585470d5bf565b3ccc8","date":1536142210,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes.size());\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames, preferredOp)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes.size());\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.info(\"Running NodeLostTrigger: {} with currently live nodes: {} and last live nodes: {}\", name, newLiveNodes.size(), lastLiveNodes.size());\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.info(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        long te = TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS);\n        if (te >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames, preferredOp)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (AlreadyClosedException e) { \n    \n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {}\", name, newLiveNodes.size());\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        if (TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS) >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames, preferredOp)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":["cc5ed4ca39a59c23d13866a1e110e608d93cbcc1","464244264804e3f981bf1fb4b732516d8d62dbc2","1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"87ac61afc33fec09e3a20ae85b69d01d3346f0d2","date":1544559512,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {} and last live nodes: {}\", name, newLiveNodes.size(), lastLiveNodes.size());\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.info(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        long te = TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS);\n        if (te >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames, preferredOp)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (AlreadyClosedException e) { \n    \n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.info(\"Running NodeLostTrigger: {} with currently live nodes: {} and last live nodes: {}\", name, newLiveNodes.size(), lastLiveNodes.size());\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.info(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        long te = TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS);\n        if (te >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames, preferredOp)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (AlreadyClosedException e) { \n    \n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f7fb1186f5b61e0b74289e6786df8cbecfa471bc","date":1545308188,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {} and last live nodes: {}\", name, newLiveNodes.size(), lastLiveNodes.size());\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        long te = TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS);\n        if (te >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames, preferredOp)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (AlreadyClosedException e) { \n    \n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {} and last live nodes: {}\", name, newLiveNodes.size(), lastLiveNodes.size());\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.info(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        long te = TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS);\n        if (te >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames, preferredOp)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n              removeMarker(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n            removeMarker(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (AlreadyClosedException e) { \n    \n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c031f89d05e49433a4b3b84f0dcb8fc28df8d06","date":1569862833,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {} and last live nodes: {}\", name, newLiveNodes.size(), lastLiveNodes.size());\n      log.trace(\"Current Live Nodes for {}: {}\", name, newLiveNodes);\n      log.trace(\"Last Live Nodes for {}: {}\", name, lastLiveNodes);\n      \n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        long te = TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS);\n        if (te >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames, preferredOp)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          log.debug(\"NodeLostTrigger firing, but no processor - so removing lost nodes: {}\", nodeNames);\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (AlreadyClosedException e) { \n    \n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {} and last live nodes: {}\", name, newLiveNodes.size(), lastLiveNodes.size());\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        long te = TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS);\n        if (te >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames, preferredOp)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (AlreadyClosedException e) { \n    \n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0b597c65628ca9e73913a07e81691f8229bae35","date":1571224353,"type":3,"author":"jimczi","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {} and last live nodes: {}\", name, newLiveNodes.size(), lastLiveNodes.size());\n      log.trace(\"Current Live Nodes for {}: {}\", name, newLiveNodes);\n      log.trace(\"Last Live Nodes for {}: {}\", name, lastLiveNodes);\n      \n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        long te = TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS);\n        if (te >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames, preferredOp)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          log.debug(\"NodeLostTrigger firing, but no processor - so removing lost nodes: {}\", nodeNames);\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (AlreadyClosedException e) { \n    \n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {} and last live nodes: {}\", name, newLiveNodes.size(), lastLiveNodes.size());\n\n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        long te = TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS);\n        if (te >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames, preferredOp)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (AlreadyClosedException e) { \n    \n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e35f2dde06b35aa9904949a3a93fabd090371077","date":1587906921,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      if (log.isDebugEnabled()) {\n        log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {} and last live nodes: {}\", name, newLiveNodes.size(), lastLiveNodes.size());\n      }\n      log.trace(\"Current Live Nodes for {}: {}\", name, newLiveNodes);\n      log.trace(\"Last Live Nodes for {}: {}\", name, lastLiveNodes);\n      \n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        long te = TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS);\n        if (te >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames, preferredOp)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          log.debug(\"NodeLostTrigger firing, but no processor - so removing lost nodes: {}\", nodeNames);\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (AlreadyClosedException e) { \n    \n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {} and last live nodes: {}\", name, newLiveNodes.size(), lastLiveNodes.size());\n      log.trace(\"Current Live Nodes for {}: {}\", name, newLiveNodes);\n      log.trace(\"Last Live Nodes for {}: {}\", name, lastLiveNodes);\n      \n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        long te = TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS);\n        if (te >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames, preferredOp)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          log.debug(\"NodeLostTrigger firing, but no processor - so removing lost nodes: {}\", nodeNames);\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (AlreadyClosedException e) { \n    \n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/NodeLostTrigger#run().mjava","sourceNew":null,"sourceOld":"  @Override\n  public void run() {\n    try {\n      synchronized (this) {\n        if (isClosed) {\n          log.warn(\"NodeLostTrigger ran but was already closed\");\n          return;\n        }\n      }\n\n      Set<String> newLiveNodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());\n      if (log.isDebugEnabled()) {\n        log.debug(\"Running NodeLostTrigger: {} with currently live nodes: {} and last live nodes: {}\", name, newLiveNodes.size(), lastLiveNodes.size());\n      }\n      log.trace(\"Current Live Nodes for {}: {}\", name, newLiveNodes);\n      log.trace(\"Last Live Nodes for {}: {}\", name, lastLiveNodes);\n      \n      // have any nodes that we were tracking been added to the cluster?\n      // if so, remove them from the tracking map\n      Set<String> trackingKeySet = nodeNameVsTimeRemoved.keySet();\n      trackingKeySet.removeAll(newLiveNodes);\n\n      // have any nodes been removed?\n      Set<String> copyOfLastLiveNodes = new HashSet<>(lastLiveNodes);\n      copyOfLastLiveNodes.removeAll(newLiveNodes);\n      copyOfLastLiveNodes.forEach(n -> {\n        log.debug(\"Tracking lost node: {}\", n);\n        nodeNameVsTimeRemoved.put(n, cloudManager.getTimeSource().getTimeNs());\n      });\n\n      // has enough time expired to trigger events for a node?\n      List<String> nodeNames = new ArrayList<>();\n      List<Long> times = new ArrayList<>();\n      for (Iterator<Map.Entry<String, Long>> it = nodeNameVsTimeRemoved.entrySet().iterator(); it.hasNext(); ) {\n        Map.Entry<String, Long> entry = it.next();\n        String nodeName = entry.getKey();\n        Long timeRemoved = entry.getValue();\n        long now = cloudManager.getTimeSource().getTimeNs();\n        long te = TimeUnit.SECONDS.convert(now - timeRemoved, TimeUnit.NANOSECONDS);\n        if (te >= getWaitForSecond()) {\n          nodeNames.add(nodeName);\n          times.add(timeRemoved);\n        }\n      }\n      // fire!\n      AutoScaling.TriggerEventProcessor processor = processorRef.get();\n      if (!nodeNames.isEmpty()) {\n        if (processor != null) {\n          log.debug(\"NodeLostTrigger firing registered processor for lost nodes: {}\", nodeNames);\n          if (processor.process(new NodeLostEvent(getEventType(), getName(), times, nodeNames, preferredOp)))  {\n            // remove from tracking set only if the fire was accepted\n            nodeNames.forEach(n -> {\n              nodeNameVsTimeRemoved.remove(n);\n            });\n          } else  {\n            log.debug(\"NodeLostTrigger processor for lost nodes: {} is not ready, will try later\", nodeNames);\n          }\n        } else  {\n          log.debug(\"NodeLostTrigger firing, but no processor - so removing lost nodes: {}\", nodeNames);\n          nodeNames.forEach(n -> {\n            nodeNameVsTimeRemoved.remove(n);\n          });\n        }\n      }\n      lastLiveNodes = new HashSet<>(newLiveNodes);\n    } catch (AlreadyClosedException e) { \n    \n    } catch (RuntimeException e) {\n      log.error(\"Unexpected exception in NodeLostTrigger\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c304e97e7c1d472bc70e801b35ee78583916c6cd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5b8cffee0b9c10b78bd087c71485b482217fe84f"],"a7699e9ae4550ba2a55335a64ae7de9d5d9de39e":["67f215f0e4d5c92f5d96ab7675170115b0983501"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["9b87bf1141cacf62ff7b9585470d5bf565b3ccc8"],"cc5ed4ca39a59c23d13866a1e110e608d93cbcc1":["219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25"],"219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25":["c5fd294da67452cd8d116692194908de00eb5209"],"87ac61afc33fec09e3a20ae85b69d01d3346f0d2":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"f7fb1186f5b61e0b74289e6786df8cbecfa471bc":["87ac61afc33fec09e3a20ae85b69d01d3346f0d2"],"009caa80830ac6369c42e5f6515405d686eabfee":["a7699e9ae4550ba2a55335a64ae7de9d5d9de39e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d4412883c12067d8a4e2a354aa8adc58c32be1d6":["a4422b331d00607258b0ed3e43934306e67764aa"],"a4422b331d00607258b0ed3e43934306e67764aa":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"2c031f89d05e49433a4b3b84f0dcb8fc28df8d06":["f7fb1186f5b61e0b74289e6786df8cbecfa471bc"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["c3f354f2175f861ee625bb3c9572d53b77cd8545"],"560c18d71dad43d675158783c3840f8c80d6d39c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c304e97e7c1d472bc70e801b35ee78583916c6cd"],"664ff2b928393480d9655010aa700656b0fcade0":["5531f16a602ef350b6c9adfb08ebaa13a60fe3db","c32a8448145a74a8902798f2e63e322827757ff2"],"c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac":["cc5ed4ca39a59c23d13866a1e110e608d93cbcc1"],"3f504512a03d978990cbff30db0522b354e846db":["e35f2dde06b35aa9904949a3a93fabd090371077"],"9b87bf1141cacf62ff7b9585470d5bf565b3ccc8":["d4412883c12067d8a4e2a354aa8adc58c32be1d6"],"85212dad4ed576c7f7e6c165ee19e597b7b4efc8":["560c18d71dad43d675158783c3840f8c80d6d39c"],"b869898f50ca80263bac2e3ae0949f7700e5c977":["c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac"],"47b66a5a735f0babac8c50ae98b885dfc6b15100":["664ff2b928393480d9655010aa700656b0fcade0"],"67f215f0e4d5c92f5d96ab7675170115b0983501":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c3f354f2175f861ee625bb3c9572d53b77cd8545":["85212dad4ed576c7f7e6c165ee19e597b7b4efc8"],"21b2bdbc19fd09c6d3aed15a7ad25bca9cac762d":["009caa80830ac6369c42e5f6515405d686eabfee"],"5531f16a602ef350b6c9adfb08ebaa13a60fe3db":["21b2bdbc19fd09c6d3aed15a7ad25bca9cac762d","464244264804e3f981bf1fb4b732516d8d62dbc2"],"c5fd294da67452cd8d116692194908de00eb5209":["47b66a5a735f0babac8c50ae98b885dfc6b15100"],"5b8cffee0b9c10b78bd087c71485b482217fe84f":["b869898f50ca80263bac2e3ae0949f7700e5c977"],"464244264804e3f981bf1fb4b732516d8d62dbc2":["21b2bdbc19fd09c6d3aed15a7ad25bca9cac762d"],"e35f2dde06b35aa9904949a3a93fabd090371077":["2c031f89d05e49433a4b3b84f0dcb8fc28df8d06"],"c32a8448145a74a8902798f2e63e322827757ff2":["5531f16a602ef350b6c9adfb08ebaa13a60fe3db"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f504512a03d978990cbff30db0522b354e846db"],"b0b597c65628ca9e73913a07e81691f8229bae35":["f7fb1186f5b61e0b74289e6786df8cbecfa471bc","2c031f89d05e49433a4b3b84f0dcb8fc28df8d06"]},"commit2Childs":{"c304e97e7c1d472bc70e801b35ee78583916c6cd":["560c18d71dad43d675158783c3840f8c80d6d39c"],"a7699e9ae4550ba2a55335a64ae7de9d5d9de39e":["009caa80830ac6369c42e5f6515405d686eabfee"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["87ac61afc33fec09e3a20ae85b69d01d3346f0d2"],"cc5ed4ca39a59c23d13866a1e110e608d93cbcc1":["c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac"],"219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25":["cc5ed4ca39a59c23d13866a1e110e608d93cbcc1"],"87ac61afc33fec09e3a20ae85b69d01d3346f0d2":["f7fb1186f5b61e0b74289e6786df8cbecfa471bc"],"f7fb1186f5b61e0b74289e6786df8cbecfa471bc":["2c031f89d05e49433a4b3b84f0dcb8fc28df8d06","b0b597c65628ca9e73913a07e81691f8229bae35"],"009caa80830ac6369c42e5f6515405d686eabfee":["21b2bdbc19fd09c6d3aed15a7ad25bca9cac762d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c304e97e7c1d472bc70e801b35ee78583916c6cd","560c18d71dad43d675158783c3840f8c80d6d39c","67f215f0e4d5c92f5d96ab7675170115b0983501"],"d4412883c12067d8a4e2a354aa8adc58c32be1d6":["9b87bf1141cacf62ff7b9585470d5bf565b3ccc8"],"a4422b331d00607258b0ed3e43934306e67764aa":["d4412883c12067d8a4e2a354aa8adc58c32be1d6"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["a4422b331d00607258b0ed3e43934306e67764aa"],"2c031f89d05e49433a4b3b84f0dcb8fc28df8d06":["e35f2dde06b35aa9904949a3a93fabd090371077","b0b597c65628ca9e73913a07e81691f8229bae35"],"560c18d71dad43d675158783c3840f8c80d6d39c":["85212dad4ed576c7f7e6c165ee19e597b7b4efc8"],"664ff2b928393480d9655010aa700656b0fcade0":["47b66a5a735f0babac8c50ae98b885dfc6b15100"],"c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac":["b869898f50ca80263bac2e3ae0949f7700e5c977"],"3f504512a03d978990cbff30db0522b354e846db":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9b87bf1141cacf62ff7b9585470d5bf565b3ccc8":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"85212dad4ed576c7f7e6c165ee19e597b7b4efc8":["c3f354f2175f861ee625bb3c9572d53b77cd8545"],"67f215f0e4d5c92f5d96ab7675170115b0983501":["a7699e9ae4550ba2a55335a64ae7de9d5d9de39e"],"b869898f50ca80263bac2e3ae0949f7700e5c977":["5b8cffee0b9c10b78bd087c71485b482217fe84f"],"47b66a5a735f0babac8c50ae98b885dfc6b15100":["c5fd294da67452cd8d116692194908de00eb5209"],"c3f354f2175f861ee625bb3c9572d53b77cd8545":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"21b2bdbc19fd09c6d3aed15a7ad25bca9cac762d":["5531f16a602ef350b6c9adfb08ebaa13a60fe3db","464244264804e3f981bf1fb4b732516d8d62dbc2"],"5531f16a602ef350b6c9adfb08ebaa13a60fe3db":["664ff2b928393480d9655010aa700656b0fcade0","c32a8448145a74a8902798f2e63e322827757ff2"],"c5fd294da67452cd8d116692194908de00eb5209":["219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25"],"5b8cffee0b9c10b78bd087c71485b482217fe84f":["c304e97e7c1d472bc70e801b35ee78583916c6cd"],"464244264804e3f981bf1fb4b732516d8d62dbc2":["5531f16a602ef350b6c9adfb08ebaa13a60fe3db"],"c32a8448145a74a8902798f2e63e322827757ff2":["664ff2b928393480d9655010aa700656b0fcade0"],"e35f2dde06b35aa9904949a3a93fabd090371077":["3f504512a03d978990cbff30db0522b354e846db"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"b0b597c65628ca9e73913a07e81691f8229bae35":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","b0b597c65628ca9e73913a07e81691f8229bae35"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}