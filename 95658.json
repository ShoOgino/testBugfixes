{"path":"solr/core/src/test/org/apache/solr/handler/component/PhrasesIdentificationComponentTest#assertBasicSanityChecks(List[Phrase],int,int,int).mjava","commits":[{"id":"0d1411e62d30c460b09c6f3643df82daa10a27cc","date":1536256256,"type":0,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/handler/component/PhrasesIdentificationComponentTest#assertBasicSanityChecks(List[Phrase],int,int,int).mjava","pathOld":"/dev/null","sourceNew":"  /** \n   * Asserts some basic rules that should be enforced about all Phrases \n   * &amp; their linkages to oher phrases \n   */\n  private void assertBasicSanityChecks(final List<Phrase> phrases,\n                                       final int inputPositionLength,\n                                       final int maxIndexedPositionLength,\n                                       final int maxQueryPositionLength) throws Exception {\n    assert 0 < phrases.size() : \"Don't use this method if phrases might be empty\";\n    \n    assertEmptyStream(\"no phrase should be longer then \"+maxQueryPositionLength+\" positions\",\n                      phrases.stream().filter(p -> p.getPositionLength() > maxQueryPositionLength));\n\n    assertEmptyStream(\"no phrase should have a start offset < 0\",\n                      phrases.stream().filter(p -> p.getOffsetStart() < 0));\n    assertEmptyStream(\"no phrase should have a start position < 1\",\n                      phrases.stream().filter(p -> p.getPositionStart() < 1));\n\n    assertEmptyStream(\"If a phrase has a start offset of 0, then it must have position 1\",\n                      phrases.stream().filter(p -> (p.getOffsetStart() == 0)\n                                              && (p.getPositionStart() != 1)));\n    \n    final Phrase first = phrases.get(0);\n    final Phrase last = phrases.get(phrases.size()-1);\n    \n    assertEmptyStream(\"no phrase should have a start offset < first phrase\",\n                      phrases.stream().filter(p -> p.getOffsetStart() < first.getOffsetStart()));\n    assertEmptyStream(\"no phrase should have an end offset > last phrase\",\n                      phrases.stream().filter(p -> last.getOffsetEnd() < p.getOffsetEnd()));\n    \n    assertEmptyStream(\"no phrase should have a start position < first phrase\",\n                      phrases.stream().filter(p -> p.getPositionStart() < first.getPositionStart()));\n    assertEmptyStream(\"no phrase should have an end position > last phrase\",\n                      phrases.stream().filter(p -> last.getPositionEnd() < p.getPositionEnd()));\n                 \n\n    // NOTE: stuff below this point may not be true for all analyzers (ie: stopwords)\n    // but should be valid for the analyzers used in this test...\n    // (if we expand test to cover analyzers w/stopwords, refactor this into a new method)\n        \n    for (int n = 1; n <= maxQueryPositionLength; n++) {\n      final int len = n;\n      final int expected = Math.max(0, 1 + inputPositionLength - n);\n      final List<Phrase> sizeN = phrases.stream().filter(p -> p.getPositionLength() == len\n                                                         ).collect(Collectors.toList());\n      assertEquals(\"Expected # phrases of size \" + n + \": \" + sizeN, expected, sizeN.size());\n    }\n\n    // check the quantities of sub-terms/phrases...\n    assertEmptyStream(\"no phrase should have num indexed terms != pos_len\",\n                      phrases.stream().filter\n                      (p -> last.getPositionLength() != last.getIndividualIndexedTerms().size()));\n    assertEmptyStream(\"no phrase should have num sub-phrases != max(1, 1 + pos_len - \"+maxIndexedPositionLength+\")\",\n                      phrases.stream().filter\n                      (p -> (Math.max(1, 1 + last.getPositionLength() - maxIndexedPositionLength)\n                             != last.getLargestIndexedSubPhrases().size())));\n    // NOTE: indexed super phrases can be of various lengths, and differing quantities near\n    // begining/end of input so don't worry about an exact count, just check their properties (below)\n\n    // check the properties of our sub/super phrases\n    for (Phrase phrase : phrases) {\n      final String debug = phrase.toString();\n      \n      assertEmptyStream(debug + \" should not have any indexed terms where pos_len != 1\",\n                        phrase.getIndividualIndexedTerms().stream().filter\n                        (term -> 1 != term.getPositionLength()));\n      \n      assertEmptyStream(debug + \" should not have any sub-phrases where pos_len > min(pos_len, \"\n                        + maxIndexedPositionLength+\")\",\n                        phrase.getLargestIndexedSubPhrases().stream().filter\n                        (inner -> (Math.min(phrase.getPositionLength(), maxIndexedPositionLength)\n                                   < inner.getPositionLength())));\n      \n      assertEmptyStream(debug + \" should not have any super-phrases where super.len <= phrase.len or \" \n                        + maxIndexedPositionLength + \" < super.len\",\n                        phrase.getIndexedSuperPhrases().stream().filter\n                        (outer -> (outer.getPositionLength() <= phrase.getPositionLength() ||\n                                   maxIndexedPositionLength < outer.getPositionLength())));\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0d1411e62d30c460b09c6f3643df82daa10a27cc":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0d1411e62d30c460b09c6f3643df82daa10a27cc"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0d1411e62d30c460b09c6f3643df82daa10a27cc"],"0d1411e62d30c460b09c6f3643df82daa10a27cc":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}