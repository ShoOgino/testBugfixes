{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testAddIndexes(boolean,boolean).mjava","commits":[{"id":"5e03940e6e9044943de4b7ac08f8581da37a9534","date":1462870173,"type":1,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testAddIndexes(boolean,boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testAddIndexes(boolean).mjava","sourceNew":"  public void testAddIndexes(boolean withDeletes, boolean useReaders) throws Exception {\n    Directory dir = newDirectory();\n    Sort indexSort = new Sort(new SortField(\"foo\", SortField.Type.LONG));\n    IndexWriterConfig iwc1 = newIndexWriterConfig();\n    if (random().nextBoolean()) {\n      iwc1.setIndexSort(indexSort);\n    }\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs = atLeast(100);\n    for (int i = 0; i < numDocs; ++i) {\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", Integer.toString(i), Store.NO));\n      doc.add(new NumericDocValuesField(\"foo\", random().nextInt(20)));\n      w.addDocument(doc);\n    }\n    if (withDeletes) {\n      for (int i = random().nextInt(5); i < numDocs; i += TestUtil.nextInt(random(), 1, 5)) {\n        w.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n      }\n    }\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader reader = w.getReader();\n    w.close();\n\n    Directory dir2 = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setIndexSort(indexSort);\n    IndexWriter w2 = new IndexWriter(dir2, iwc);\n\n    if (useReaders) {\n      CodecReader[] codecReaders = new CodecReader[reader.leaves().size()];\n      for (int i = 0; i < codecReaders.length; ++i) {\n        codecReaders[i] = (CodecReader) reader.leaves().get(i).reader();\n      }\n      w2.addIndexes(codecReaders);\n    } else {\n      w2.addIndexes(dir);\n    }\n    final IndexReader reader2 = w2.getReader();\n    final IndexSearcher searcher = newSearcher(reader);\n    final IndexSearcher searcher2 = newSearcher(reader2);\n    for (int i = 0; i < numDocs; ++i) {\n      Query query = new TermQuery(new Term(\"id\", Integer.toString(i)));\n      final TopDocs topDocs = searcher.search(query, 1);\n      final TopDocs topDocs2 = searcher2.search(query, 1);\n      assertEquals(topDocs.totalHits, topDocs2.totalHits);\n      if (topDocs.totalHits == 1) {\n        assertEquals(\n            MultiDocValues.getNumericValues(reader, \"foo\").get(topDocs.scoreDocs[0].doc),\n            MultiDocValues.getNumericValues(reader2, \"foo\").get(topDocs2.scoreDocs[0].doc));\n      }\n    }\n\n    IOUtils.close(reader, reader2, w2, dir, dir2);\n  }\n\n","sourceOld":"  public void testAddIndexes(boolean withDeletes) throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs = atLeast(100);\n    for (int i = 0; i < numDocs; ++i) {\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", Integer.toString(i), Store.NO));\n      doc.add(new NumericDocValuesField(\"foo\", random().nextInt(20)));\n      w.addDocument(doc);\n    }\n    if (withDeletes) {\n      for (int i = random().nextInt(5); i < numDocs; i += TestUtil.nextInt(random(), 1, 5)) {\n        w.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n      }\n    }\n    final IndexReader reader = w.getReader();\n\n    Directory dir2 = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    Sort indexSort = new Sort(new SortField(\"foo\", SortField.Type.LONG));\n    iwc.setIndexSort(indexSort);\n    IndexWriter w2 = new IndexWriter(dir2, iwc);\n\n    CodecReader[] codecReaders = new CodecReader[reader.leaves().size()];\n    for (int i = 0; i < codecReaders.length; ++i) {\n      codecReaders[i] = (CodecReader) reader.leaves().get(i).reader();\n    }\n    w2.addIndexes(codecReaders);\n    final IndexReader reader2 = w2.getReader();\n    final IndexSearcher searcher = newSearcher(reader);\n    final IndexSearcher searcher2 = newSearcher(reader2);\n    for (int i = 0; i < numDocs; ++i) {\n      Query query = new TermQuery(new Term(\"id\", Integer.toString(i)));\n      final TopDocs topDocs = searcher.search(query, 1);\n      final TopDocs topDocs2 = searcher2.search(query, 1);\n      assertEquals(topDocs.totalHits, topDocs2.totalHits);\n      if (topDocs.totalHits == 1) {\n        assertEquals(\n            MultiDocValues.getNumericValues(reader, \"foo\").get(topDocs.scoreDocs[0].doc),\n            MultiDocValues.getNumericValues(reader2, \"foo\").get(topDocs2.scoreDocs[0].doc));\n      }\n    }\n\n    IOUtils.close(reader, reader2, w, w2, dir, dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3d33e731a93d4b57e662ff094f64f94a745422d4","date":1463128289,"type":0,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testAddIndexes(boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"  public void testAddIndexes(boolean withDeletes, boolean useReaders) throws Exception {\n    Directory dir = newDirectory();\n    Sort indexSort = new Sort(new SortField(\"foo\", SortField.Type.LONG));\n    IndexWriterConfig iwc1 = newIndexWriterConfig();\n    if (random().nextBoolean()) {\n      iwc1.setIndexSort(indexSort);\n    }\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs = atLeast(100);\n    for (int i = 0; i < numDocs; ++i) {\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", Integer.toString(i), Store.NO));\n      doc.add(new NumericDocValuesField(\"foo\", random().nextInt(20)));\n      w.addDocument(doc);\n    }\n    if (withDeletes) {\n      for (int i = random().nextInt(5); i < numDocs; i += TestUtil.nextInt(random(), 1, 5)) {\n        w.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n      }\n    }\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader reader = w.getReader();\n    w.close();\n\n    Directory dir2 = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setIndexSort(indexSort);\n    IndexWriter w2 = new IndexWriter(dir2, iwc);\n\n    if (useReaders) {\n      CodecReader[] codecReaders = new CodecReader[reader.leaves().size()];\n      for (int i = 0; i < codecReaders.length; ++i) {\n        codecReaders[i] = (CodecReader) reader.leaves().get(i).reader();\n      }\n      w2.addIndexes(codecReaders);\n    } else {\n      w2.addIndexes(dir);\n    }\n    final IndexReader reader2 = w2.getReader();\n    final IndexSearcher searcher = newSearcher(reader);\n    final IndexSearcher searcher2 = newSearcher(reader2);\n    for (int i = 0; i < numDocs; ++i) {\n      Query query = new TermQuery(new Term(\"id\", Integer.toString(i)));\n      final TopDocs topDocs = searcher.search(query, 1);\n      final TopDocs topDocs2 = searcher2.search(query, 1);\n      assertEquals(topDocs.totalHits, topDocs2.totalHits);\n      if (topDocs.totalHits == 1) {\n        assertEquals(\n            MultiDocValues.getNumericValues(reader, \"foo\").get(topDocs.scoreDocs[0].doc),\n            MultiDocValues.getNumericValues(reader2, \"foo\").get(topDocs2.scoreDocs[0].doc));\n      }\n    }\n\n    IOUtils.close(reader, reader2, w2, dir, dir2);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0ad30c6a479e764150a3316e57263319775f1df2","date":1463395403,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testAddIndexes(boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"  public void testAddIndexes(boolean withDeletes, boolean useReaders) throws Exception {\n    Directory dir = newDirectory();\n    Sort indexSort = new Sort(new SortField(\"foo\", SortField.Type.LONG));\n    IndexWriterConfig iwc1 = newIndexWriterConfig();\n    if (random().nextBoolean()) {\n      iwc1.setIndexSort(indexSort);\n    }\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs = atLeast(100);\n    for (int i = 0; i < numDocs; ++i) {\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", Integer.toString(i), Store.NO));\n      doc.add(new NumericDocValuesField(\"foo\", random().nextInt(20)));\n      w.addDocument(doc);\n    }\n    if (withDeletes) {\n      for (int i = random().nextInt(5); i < numDocs; i += TestUtil.nextInt(random(), 1, 5)) {\n        w.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n      }\n    }\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader reader = w.getReader();\n    w.close();\n\n    Directory dir2 = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setIndexSort(indexSort);\n    IndexWriter w2 = new IndexWriter(dir2, iwc);\n\n    if (useReaders) {\n      CodecReader[] codecReaders = new CodecReader[reader.leaves().size()];\n      for (int i = 0; i < codecReaders.length; ++i) {\n        codecReaders[i] = (CodecReader) reader.leaves().get(i).reader();\n      }\n      w2.addIndexes(codecReaders);\n    } else {\n      w2.addIndexes(dir);\n    }\n    final IndexReader reader2 = w2.getReader();\n    final IndexSearcher searcher = newSearcher(reader);\n    final IndexSearcher searcher2 = newSearcher(reader2);\n    for (int i = 0; i < numDocs; ++i) {\n      Query query = new TermQuery(new Term(\"id\", Integer.toString(i)));\n      final TopDocs topDocs = searcher.search(query, 1);\n      final TopDocs topDocs2 = searcher2.search(query, 1);\n      assertEquals(topDocs.totalHits, topDocs2.totalHits);\n      if (topDocs.totalHits == 1) {\n        assertEquals(\n            MultiDocValues.getNumericValues(reader, \"foo\").get(topDocs.scoreDocs[0].doc),\n            MultiDocValues.getNumericValues(reader2, \"foo\").get(topDocs2.scoreDocs[0].doc));\n      }\n    }\n\n    IOUtils.close(reader, reader2, w2, dir, dir2);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testAddIndexes(boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"  public void testAddIndexes(boolean withDeletes, boolean useReaders) throws Exception {\n    Directory dir = newDirectory();\n    Sort indexSort = new Sort(new SortField(\"foo\", SortField.Type.LONG));\n    IndexWriterConfig iwc1 = newIndexWriterConfig();\n    if (random().nextBoolean()) {\n      iwc1.setIndexSort(indexSort);\n    }\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs = atLeast(100);\n    for (int i = 0; i < numDocs; ++i) {\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", Integer.toString(i), Store.NO));\n      doc.add(new NumericDocValuesField(\"foo\", random().nextInt(20)));\n      w.addDocument(doc);\n    }\n    if (withDeletes) {\n      for (int i = random().nextInt(5); i < numDocs; i += TestUtil.nextInt(random(), 1, 5)) {\n        w.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n      }\n    }\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader reader = w.getReader();\n    w.close();\n\n    Directory dir2 = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setIndexSort(indexSort);\n    IndexWriter w2 = new IndexWriter(dir2, iwc);\n\n    if (useReaders) {\n      CodecReader[] codecReaders = new CodecReader[reader.leaves().size()];\n      for (int i = 0; i < codecReaders.length; ++i) {\n        codecReaders[i] = (CodecReader) reader.leaves().get(i).reader();\n      }\n      w2.addIndexes(codecReaders);\n    } else {\n      w2.addIndexes(dir);\n    }\n    final IndexReader reader2 = w2.getReader();\n    final IndexSearcher searcher = newSearcher(reader);\n    final IndexSearcher searcher2 = newSearcher(reader2);\n    for (int i = 0; i < numDocs; ++i) {\n      Query query = new TermQuery(new Term(\"id\", Integer.toString(i)));\n      final TopDocs topDocs = searcher.search(query, 1);\n      final TopDocs topDocs2 = searcher2.search(query, 1);\n      assertEquals(topDocs.totalHits, topDocs2.totalHits);\n      if (topDocs.totalHits == 1) {\n        assertEquals(\n            MultiDocValues.getNumericValues(reader, \"foo\").get(topDocs.scoreDocs[0].doc),\n            MultiDocValues.getNumericValues(reader2, \"foo\").get(topDocs2.scoreDocs[0].doc));\n      }\n    }\n\n    IOUtils.close(reader, reader2, w2, dir, dir2);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6652c74b2358a0b13223817a6a793bf1c9d0749d","date":1474465301,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testAddIndexes(boolean,boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testAddIndexes(boolean,boolean).mjava","sourceNew":"  public void testAddIndexes(boolean withDeletes, boolean useReaders) throws Exception {\n    Directory dir = newDirectory();\n    Sort indexSort = new Sort(new SortField(\"foo\", SortField.Type.LONG));\n    IndexWriterConfig iwc1 = newIndexWriterConfig();\n    if (random().nextBoolean()) {\n      iwc1.setIndexSort(indexSort);\n    }\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs = atLeast(100);\n    for (int i = 0; i < numDocs; ++i) {\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", Integer.toString(i), Store.NO));\n      doc.add(new NumericDocValuesField(\"foo\", random().nextInt(20)));\n      w.addDocument(doc);\n    }\n    if (withDeletes) {\n      for (int i = random().nextInt(5); i < numDocs; i += TestUtil.nextInt(random(), 1, 5)) {\n        w.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n      }\n    }\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader reader = w.getReader();\n    w.close();\n\n    Directory dir2 = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setIndexSort(indexSort);\n    IndexWriter w2 = new IndexWriter(dir2, iwc);\n\n    if (useReaders) {\n      CodecReader[] codecReaders = new CodecReader[reader.leaves().size()];\n      for (int i = 0; i < codecReaders.length; ++i) {\n        codecReaders[i] = (CodecReader) reader.leaves().get(i).reader();\n      }\n      w2.addIndexes(codecReaders);\n    } else {\n      w2.addIndexes(dir);\n    }\n    final IndexReader reader2 = w2.getReader();\n    final IndexSearcher searcher = newSearcher(reader);\n    final IndexSearcher searcher2 = newSearcher(reader2);\n    for (int i = 0; i < numDocs; ++i) {\n      Query query = new TermQuery(new Term(\"id\", Integer.toString(i)));\n      final TopDocs topDocs = searcher.search(query, 1);\n      final TopDocs topDocs2 = searcher2.search(query, 1);\n      assertEquals(topDocs.totalHits, topDocs2.totalHits);\n      if (topDocs.totalHits == 1) {\n        NumericDocValues dvs1 = MultiDocValues.getNumericValues(reader, \"foo\");\n        int hitDoc1 = topDocs.scoreDocs[0].doc;\n        assertEquals(hitDoc1, dvs1.advance(hitDoc1));\n        long value1 = dvs1.longValue();\n        NumericDocValues dvs2 = MultiDocValues.getNumericValues(reader2, \"foo\");\n        int hitDoc2 = topDocs2.scoreDocs[0].doc;\n        assertEquals(hitDoc2, dvs2.advance(hitDoc2));\n        long value2 = dvs2.longValue();\n        assertEquals(value1, value2);\n      }\n    }\n\n    IOUtils.close(reader, reader2, w2, dir, dir2);\n  }\n\n","sourceOld":"  public void testAddIndexes(boolean withDeletes, boolean useReaders) throws Exception {\n    Directory dir = newDirectory();\n    Sort indexSort = new Sort(new SortField(\"foo\", SortField.Type.LONG));\n    IndexWriterConfig iwc1 = newIndexWriterConfig();\n    if (random().nextBoolean()) {\n      iwc1.setIndexSort(indexSort);\n    }\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs = atLeast(100);\n    for (int i = 0; i < numDocs; ++i) {\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", Integer.toString(i), Store.NO));\n      doc.add(new NumericDocValuesField(\"foo\", random().nextInt(20)));\n      w.addDocument(doc);\n    }\n    if (withDeletes) {\n      for (int i = random().nextInt(5); i < numDocs; i += TestUtil.nextInt(random(), 1, 5)) {\n        w.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n      }\n    }\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader reader = w.getReader();\n    w.close();\n\n    Directory dir2 = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setIndexSort(indexSort);\n    IndexWriter w2 = new IndexWriter(dir2, iwc);\n\n    if (useReaders) {\n      CodecReader[] codecReaders = new CodecReader[reader.leaves().size()];\n      for (int i = 0; i < codecReaders.length; ++i) {\n        codecReaders[i] = (CodecReader) reader.leaves().get(i).reader();\n      }\n      w2.addIndexes(codecReaders);\n    } else {\n      w2.addIndexes(dir);\n    }\n    final IndexReader reader2 = w2.getReader();\n    final IndexSearcher searcher = newSearcher(reader);\n    final IndexSearcher searcher2 = newSearcher(reader2);\n    for (int i = 0; i < numDocs; ++i) {\n      Query query = new TermQuery(new Term(\"id\", Integer.toString(i)));\n      final TopDocs topDocs = searcher.search(query, 1);\n      final TopDocs topDocs2 = searcher2.search(query, 1);\n      assertEquals(topDocs.totalHits, topDocs2.totalHits);\n      if (topDocs.totalHits == 1) {\n        assertEquals(\n            MultiDocValues.getNumericValues(reader, \"foo\").get(topDocs.scoreDocs[0].doc),\n            MultiDocValues.getNumericValues(reader2, \"foo\").get(topDocs2.scoreDocs[0].doc));\n      }\n    }\n\n    IOUtils.close(reader, reader2, w2, dir, dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testAddIndexes(boolean,boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testAddIndexes(boolean,boolean).mjava","sourceNew":"  public void testAddIndexes(boolean withDeletes, boolean useReaders) throws Exception {\n    Directory dir = newDirectory();\n    Sort indexSort = new Sort(new SortField(\"foo\", SortField.Type.LONG));\n    IndexWriterConfig iwc1 = newIndexWriterConfig();\n    if (random().nextBoolean()) {\n      iwc1.setIndexSort(indexSort);\n    }\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs = atLeast(100);\n    for (int i = 0; i < numDocs; ++i) {\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", Integer.toString(i), Store.NO));\n      doc.add(new NumericDocValuesField(\"foo\", random().nextInt(20)));\n      w.addDocument(doc);\n    }\n    if (withDeletes) {\n      for (int i = random().nextInt(5); i < numDocs; i += TestUtil.nextInt(random(), 1, 5)) {\n        w.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n      }\n    }\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader reader = w.getReader();\n    w.close();\n\n    Directory dir2 = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setIndexSort(indexSort);\n    IndexWriter w2 = new IndexWriter(dir2, iwc);\n\n    if (useReaders) {\n      CodecReader[] codecReaders = new CodecReader[reader.leaves().size()];\n      for (int i = 0; i < codecReaders.length; ++i) {\n        codecReaders[i] = (CodecReader) reader.leaves().get(i).reader();\n      }\n      w2.addIndexes(codecReaders);\n    } else {\n      w2.addIndexes(dir);\n    }\n    final IndexReader reader2 = w2.getReader();\n    final IndexSearcher searcher = newSearcher(reader);\n    final IndexSearcher searcher2 = newSearcher(reader2);\n    for (int i = 0; i < numDocs; ++i) {\n      Query query = new TermQuery(new Term(\"id\", Integer.toString(i)));\n      final TopDocs topDocs = searcher.search(query, 1);\n      final TopDocs topDocs2 = searcher2.search(query, 1);\n      assertEquals(topDocs.totalHits, topDocs2.totalHits);\n      if (topDocs.totalHits == 1) {\n        NumericDocValues dvs1 = MultiDocValues.getNumericValues(reader, \"foo\");\n        int hitDoc1 = topDocs.scoreDocs[0].doc;\n        assertEquals(hitDoc1, dvs1.advance(hitDoc1));\n        long value1 = dvs1.longValue();\n        NumericDocValues dvs2 = MultiDocValues.getNumericValues(reader2, \"foo\");\n        int hitDoc2 = topDocs2.scoreDocs[0].doc;\n        assertEquals(hitDoc2, dvs2.advance(hitDoc2));\n        long value2 = dvs2.longValue();\n        assertEquals(value1, value2);\n      }\n    }\n\n    IOUtils.close(reader, reader2, w2, dir, dir2);\n  }\n\n","sourceOld":"  public void testAddIndexes(boolean withDeletes, boolean useReaders) throws Exception {\n    Directory dir = newDirectory();\n    Sort indexSort = new Sort(new SortField(\"foo\", SortField.Type.LONG));\n    IndexWriterConfig iwc1 = newIndexWriterConfig();\n    if (random().nextBoolean()) {\n      iwc1.setIndexSort(indexSort);\n    }\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs = atLeast(100);\n    for (int i = 0; i < numDocs; ++i) {\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", Integer.toString(i), Store.NO));\n      doc.add(new NumericDocValuesField(\"foo\", random().nextInt(20)));\n      w.addDocument(doc);\n    }\n    if (withDeletes) {\n      for (int i = random().nextInt(5); i < numDocs; i += TestUtil.nextInt(random(), 1, 5)) {\n        w.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n      }\n    }\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader reader = w.getReader();\n    w.close();\n\n    Directory dir2 = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setIndexSort(indexSort);\n    IndexWriter w2 = new IndexWriter(dir2, iwc);\n\n    if (useReaders) {\n      CodecReader[] codecReaders = new CodecReader[reader.leaves().size()];\n      for (int i = 0; i < codecReaders.length; ++i) {\n        codecReaders[i] = (CodecReader) reader.leaves().get(i).reader();\n      }\n      w2.addIndexes(codecReaders);\n    } else {\n      w2.addIndexes(dir);\n    }\n    final IndexReader reader2 = w2.getReader();\n    final IndexSearcher searcher = newSearcher(reader);\n    final IndexSearcher searcher2 = newSearcher(reader2);\n    for (int i = 0; i < numDocs; ++i) {\n      Query query = new TermQuery(new Term(\"id\", Integer.toString(i)));\n      final TopDocs topDocs = searcher.search(query, 1);\n      final TopDocs topDocs2 = searcher2.search(query, 1);\n      assertEquals(topDocs.totalHits, topDocs2.totalHits);\n      if (topDocs.totalHits == 1) {\n        assertEquals(\n            MultiDocValues.getNumericValues(reader, \"foo\").get(topDocs.scoreDocs[0].doc),\n            MultiDocValues.getNumericValues(reader2, \"foo\").get(topDocs2.scoreDocs[0].doc));\n      }\n    }\n\n    IOUtils.close(reader, reader2, w2, dir, dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testAddIndexes(boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"  public void testAddIndexes(boolean withDeletes, boolean useReaders) throws Exception {\n    Directory dir = newDirectory();\n    Sort indexSort = new Sort(new SortField(\"foo\", SortField.Type.LONG));\n    IndexWriterConfig iwc1 = newIndexWriterConfig();\n    if (random().nextBoolean()) {\n      iwc1.setIndexSort(indexSort);\n    }\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs = atLeast(100);\n    for (int i = 0; i < numDocs; ++i) {\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", Integer.toString(i), Store.NO));\n      doc.add(new NumericDocValuesField(\"foo\", random().nextInt(20)));\n      w.addDocument(doc);\n    }\n    if (withDeletes) {\n      for (int i = random().nextInt(5); i < numDocs; i += TestUtil.nextInt(random(), 1, 5)) {\n        w.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n      }\n    }\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader reader = w.getReader();\n    w.close();\n\n    Directory dir2 = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setIndexSort(indexSort);\n    IndexWriter w2 = new IndexWriter(dir2, iwc);\n\n    if (useReaders) {\n      CodecReader[] codecReaders = new CodecReader[reader.leaves().size()];\n      for (int i = 0; i < codecReaders.length; ++i) {\n        codecReaders[i] = (CodecReader) reader.leaves().get(i).reader();\n      }\n      w2.addIndexes(codecReaders);\n    } else {\n      w2.addIndexes(dir);\n    }\n    final IndexReader reader2 = w2.getReader();\n    final IndexSearcher searcher = newSearcher(reader);\n    final IndexSearcher searcher2 = newSearcher(reader2);\n    for (int i = 0; i < numDocs; ++i) {\n      Query query = new TermQuery(new Term(\"id\", Integer.toString(i)));\n      final TopDocs topDocs = searcher.search(query, 1);\n      final TopDocs topDocs2 = searcher2.search(query, 1);\n      assertEquals(topDocs.totalHits, topDocs2.totalHits);\n      if (topDocs.totalHits == 1) {\n        NumericDocValues dvs1 = MultiDocValues.getNumericValues(reader, \"foo\");\n        int hitDoc1 = topDocs.scoreDocs[0].doc;\n        assertEquals(hitDoc1, dvs1.advance(hitDoc1));\n        long value1 = dvs1.longValue();\n        NumericDocValues dvs2 = MultiDocValues.getNumericValues(reader2, \"foo\");\n        int hitDoc2 = topDocs2.scoreDocs[0].doc;\n        assertEquals(hitDoc2, dvs2.advance(hitDoc2));\n        long value2 = dvs2.longValue();\n        assertEquals(value1, value2);\n      }\n    }\n\n    IOUtils.close(reader, reader2, w2, dir, dir2);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testAddIndexes(boolean,boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testAddIndexes(boolean,boolean).mjava","sourceNew":"  public void testAddIndexes(boolean withDeletes, boolean useReaders) throws Exception {\n    Directory dir = newDirectory();\n    Sort indexSort = new Sort(new SortField(\"foo\", SortField.Type.LONG));\n    IndexWriterConfig iwc1 = newIndexWriterConfig();\n    if (random().nextBoolean()) {\n      iwc1.setIndexSort(indexSort);\n    }\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs = atLeast(100);\n    for (int i = 0; i < numDocs; ++i) {\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", Integer.toString(i), Store.NO));\n      doc.add(new NumericDocValuesField(\"foo\", random().nextInt(20)));\n      w.addDocument(doc);\n    }\n    if (withDeletes) {\n      for (int i = random().nextInt(5); i < numDocs; i += TestUtil.nextInt(random(), 1, 5)) {\n        w.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n      }\n    }\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader reader = w.getReader();\n    w.close();\n\n    Directory dir2 = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setIndexSort(indexSort);\n    IndexWriter w2 = new IndexWriter(dir2, iwc);\n\n    if (useReaders) {\n      CodecReader[] codecReaders = new CodecReader[reader.leaves().size()];\n      for (int i = 0; i < codecReaders.length; ++i) {\n        codecReaders[i] = (CodecReader) reader.leaves().get(i).reader();\n      }\n      w2.addIndexes(codecReaders);\n    } else {\n      w2.addIndexes(dir);\n    }\n    final IndexReader reader2 = w2.getReader();\n    final IndexSearcher searcher = newSearcher(reader);\n    final IndexSearcher searcher2 = newSearcher(reader2);\n    for (int i = 0; i < numDocs; ++i) {\n      Query query = new TermQuery(new Term(\"id\", Integer.toString(i)));\n      final TopDocs topDocs = searcher.search(query, 1);\n      final TopDocs topDocs2 = searcher2.search(query, 1);\n      assertEquals(topDocs.totalHits.value, topDocs2.totalHits.value);\n      if (topDocs.totalHits.value == 1) {\n        NumericDocValues dvs1 = MultiDocValues.getNumericValues(reader, \"foo\");\n        int hitDoc1 = topDocs.scoreDocs[0].doc;\n        assertEquals(hitDoc1, dvs1.advance(hitDoc1));\n        long value1 = dvs1.longValue();\n        NumericDocValues dvs2 = MultiDocValues.getNumericValues(reader2, \"foo\");\n        int hitDoc2 = topDocs2.scoreDocs[0].doc;\n        assertEquals(hitDoc2, dvs2.advance(hitDoc2));\n        long value2 = dvs2.longValue();\n        assertEquals(value1, value2);\n      }\n    }\n\n    IOUtils.close(reader, reader2, w2, dir, dir2);\n  }\n\n","sourceOld":"  public void testAddIndexes(boolean withDeletes, boolean useReaders) throws Exception {\n    Directory dir = newDirectory();\n    Sort indexSort = new Sort(new SortField(\"foo\", SortField.Type.LONG));\n    IndexWriterConfig iwc1 = newIndexWriterConfig();\n    if (random().nextBoolean()) {\n      iwc1.setIndexSort(indexSort);\n    }\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs = atLeast(100);\n    for (int i = 0; i < numDocs; ++i) {\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", Integer.toString(i), Store.NO));\n      doc.add(new NumericDocValuesField(\"foo\", random().nextInt(20)));\n      w.addDocument(doc);\n    }\n    if (withDeletes) {\n      for (int i = random().nextInt(5); i < numDocs; i += TestUtil.nextInt(random(), 1, 5)) {\n        w.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n      }\n    }\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader reader = w.getReader();\n    w.close();\n\n    Directory dir2 = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setIndexSort(indexSort);\n    IndexWriter w2 = new IndexWriter(dir2, iwc);\n\n    if (useReaders) {\n      CodecReader[] codecReaders = new CodecReader[reader.leaves().size()];\n      for (int i = 0; i < codecReaders.length; ++i) {\n        codecReaders[i] = (CodecReader) reader.leaves().get(i).reader();\n      }\n      w2.addIndexes(codecReaders);\n    } else {\n      w2.addIndexes(dir);\n    }\n    final IndexReader reader2 = w2.getReader();\n    final IndexSearcher searcher = newSearcher(reader);\n    final IndexSearcher searcher2 = newSearcher(reader2);\n    for (int i = 0; i < numDocs; ++i) {\n      Query query = new TermQuery(new Term(\"id\", Integer.toString(i)));\n      final TopDocs topDocs = searcher.search(query, 1);\n      final TopDocs topDocs2 = searcher2.search(query, 1);\n      assertEquals(topDocs.totalHits, topDocs2.totalHits);\n      if (topDocs.totalHits == 1) {\n        NumericDocValues dvs1 = MultiDocValues.getNumericValues(reader, \"foo\");\n        int hitDoc1 = topDocs.scoreDocs[0].doc;\n        assertEquals(hitDoc1, dvs1.advance(hitDoc1));\n        long value1 = dvs1.longValue();\n        NumericDocValues dvs2 = MultiDocValues.getNumericValues(reader2, \"foo\");\n        int hitDoc2 = topDocs2.scoreDocs[0].doc;\n        assertEquals(hitDoc2, dvs2.advance(hitDoc2));\n        long value2 = dvs2.longValue();\n        assertEquals(value1, value2);\n      }\n    }\n\n    IOUtils.close(reader, reader2, w2, dir, dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6e22133c22c69a013e8c3c14bb986e7848c7296e","date":1537859647,"type":3,"author":"Jim Ferenczi","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testAddIndexes(boolean,boolean).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testAddIndexes(boolean,boolean).mjava","sourceNew":"  public void testAddIndexes(boolean withDeletes, boolean useReaders) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc1 = newIndexWriterConfig();\n    Sort indexSort = new Sort(new SortField(\"foo\", SortField.Type.LONG), new SortField(\"bar\", SortField.Type.LONG));\n    iwc1.setIndexSort(indexSort);\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc1);\n    final int numDocs = atLeast(100);\n    for (int i = 0; i < numDocs; ++i) {\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", Integer.toString(i), Store.NO));\n      doc.add(new NumericDocValuesField(\"foo\", random().nextInt(20)));\n      doc.add(new NumericDocValuesField(\"bar\", random().nextInt(20)));\n      w.addDocument(doc);\n    }\n    if (withDeletes) {\n      for (int i = random().nextInt(5); i < numDocs; i += TestUtil.nextInt(random(), 1, 5)) {\n        w.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n      }\n    }\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader reader = w.getReader();\n    w.close();\n\n    Directory dir2 = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    if (indexSort != null && random().nextBoolean()) {\n      // test congruent index sort\n      iwc.setIndexSort(new Sort(new SortField(\"foo\", SortField.Type.LONG)));\n    } else {\n      iwc.setIndexSort(indexSort);\n    }\n    IndexWriter w2 = new IndexWriter(dir2, iwc);\n\n    if (useReaders) {\n      CodecReader[] codecReaders = new CodecReader[reader.leaves().size()];\n      for (int i = 0; i < codecReaders.length; ++i) {\n        codecReaders[i] = (CodecReader) reader.leaves().get(i).reader();\n      }\n      w2.addIndexes(codecReaders);\n    } else {\n      w2.addIndexes(dir);\n    }\n    final IndexReader reader2 = w2.getReader();\n    final IndexSearcher searcher = newSearcher(reader);\n    final IndexSearcher searcher2 = newSearcher(reader2);\n    for (int i = 0; i < numDocs; ++i) {\n      Query query = new TermQuery(new Term(\"id\", Integer.toString(i)));\n      final TopDocs topDocs = searcher.search(query, 1);\n      final TopDocs topDocs2 = searcher2.search(query, 1);\n      assertEquals(topDocs.totalHits.value, topDocs2.totalHits.value);\n      if (topDocs.totalHits.value == 1) {\n        NumericDocValues dvs1 = MultiDocValues.getNumericValues(reader, \"foo\");\n        int hitDoc1 = topDocs.scoreDocs[0].doc;\n        assertEquals(hitDoc1, dvs1.advance(hitDoc1));\n        long value1 = dvs1.longValue();\n        NumericDocValues dvs2 = MultiDocValues.getNumericValues(reader2, \"foo\");\n        int hitDoc2 = topDocs2.scoreDocs[0].doc;\n        assertEquals(hitDoc2, dvs2.advance(hitDoc2));\n        long value2 = dvs2.longValue();\n        assertEquals(value1, value2);\n      }\n    }\n\n    IOUtils.close(reader, reader2, w2, dir, dir2);\n  }\n\n","sourceOld":"  public void testAddIndexes(boolean withDeletes, boolean useReaders) throws Exception {\n    Directory dir = newDirectory();\n    Sort indexSort = new Sort(new SortField(\"foo\", SortField.Type.LONG));\n    IndexWriterConfig iwc1 = newIndexWriterConfig();\n    if (random().nextBoolean()) {\n      iwc1.setIndexSort(indexSort);\n    }\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir);\n    final int numDocs = atLeast(100);\n    for (int i = 0; i < numDocs; ++i) {\n      Document doc = new Document();\n      doc.add(new StringField(\"id\", Integer.toString(i), Store.NO));\n      doc.add(new NumericDocValuesField(\"foo\", random().nextInt(20)));\n      w.addDocument(doc);\n    }\n    if (withDeletes) {\n      for (int i = random().nextInt(5); i < numDocs; i += TestUtil.nextInt(random(), 1, 5)) {\n        w.deleteDocuments(new Term(\"id\", Integer.toString(i)));\n      }\n    }\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader reader = w.getReader();\n    w.close();\n\n    Directory dir2 = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setIndexSort(indexSort);\n    IndexWriter w2 = new IndexWriter(dir2, iwc);\n\n    if (useReaders) {\n      CodecReader[] codecReaders = new CodecReader[reader.leaves().size()];\n      for (int i = 0; i < codecReaders.length; ++i) {\n        codecReaders[i] = (CodecReader) reader.leaves().get(i).reader();\n      }\n      w2.addIndexes(codecReaders);\n    } else {\n      w2.addIndexes(dir);\n    }\n    final IndexReader reader2 = w2.getReader();\n    final IndexSearcher searcher = newSearcher(reader);\n    final IndexSearcher searcher2 = newSearcher(reader2);\n    for (int i = 0; i < numDocs; ++i) {\n      Query query = new TermQuery(new Term(\"id\", Integer.toString(i)));\n      final TopDocs topDocs = searcher.search(query, 1);\n      final TopDocs topDocs2 = searcher2.search(query, 1);\n      assertEquals(topDocs.totalHits.value, topDocs2.totalHits.value);\n      if (topDocs.totalHits.value == 1) {\n        NumericDocValues dvs1 = MultiDocValues.getNumericValues(reader, \"foo\");\n        int hitDoc1 = topDocs.scoreDocs[0].doc;\n        assertEquals(hitDoc1, dvs1.advance(hitDoc1));\n        long value1 = dvs1.longValue();\n        NumericDocValues dvs2 = MultiDocValues.getNumericValues(reader2, \"foo\");\n        int hitDoc2 = topDocs2.scoreDocs[0].doc;\n        assertEquals(hitDoc2, dvs2.advance(hitDoc2));\n        long value2 = dvs2.longValue();\n        assertEquals(value1, value2);\n      }\n    }\n\n    IOUtils.close(reader, reader2, w2, dir, dir2);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6e22133c22c69a013e8c3c14bb986e7848c7296e":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["d470c8182e92b264680e34081b75e70a9f2b3c89","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"0ad30c6a479e764150a3316e57263319775f1df2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3d33e731a93d4b57e662ff094f64f94a745422d4"],"5e03940e6e9044943de4b7ac08f8581da37a9534":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5e03940e6e9044943de4b7ac08f8581da37a9534"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6e22133c22c69a013e8c3c14bb986e7848c7296e"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0ad30c6a479e764150a3316e57263319775f1df2"]},"commit2Childs":{"6e22133c22c69a013e8c3c14bb986e7848c7296e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0ad30c6a479e764150a3316e57263319775f1df2","5e03940e6e9044943de4b7ac08f8581da37a9534","3d33e731a93d4b57e662ff094f64f94a745422d4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","d470c8182e92b264680e34081b75e70a9f2b3c89"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["83788ad129a5154d5c6562c4e8ce3db48793aada","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"0ad30c6a479e764150a3316e57263319775f1df2":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"5e03940e6e9044943de4b7ac08f8581da37a9534":["3d33e731a93d4b57e662ff094f64f94a745422d4"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["6e22133c22c69a013e8c3c14bb986e7848c7296e"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["0ad30c6a479e764150a3316e57263319775f1df2"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"d470c8182e92b264680e34081b75e70a9f2b3c89":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}