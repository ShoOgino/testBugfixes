{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","sourceNew":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newField(\"f\" + i, utf8Data[2*i], TextField.TYPE_STORED));\n    w.addDocument(doc);\n    w.close();\n\n    IndexReader ir = IndexReader.open(dir);\n    Document doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newField(\"f\" + i, utf8Data[2*i], TextField.TYPE_STORED));\n    w.addDocument(doc);\n    w.close();\n\n    IndexReader ir = IndexReader.open(dir);\n    Document doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","sourceNew":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newField(\"f\" + i, utf8Data[2*i], TextField.TYPE_STORED));\n    w.addDocument(doc);\n    w.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    Document doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newField(\"f\" + i, utf8Data[2*i], TextField.TYPE_STORED));\n    w.addDocument(doc);\n    w.close();\n\n    IndexReader ir = IndexReader.open(dir);\n    Document doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","sourceNew":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newTextField(\"f\" + i, utf8Data[2*i], Field.Store.YES));\n    w.addDocument(doc);\n    w.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    Document doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newField(\"f\" + i, utf8Data[2*i], TextField.TYPE_STORED));\n    w.addDocument(doc);\n    w.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    Document doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4","date":1341839195,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","sourceNew":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newTextField(\"f\" + i, utf8Data[2*i], Field.Store.YES));\n    w.addDocument(doc);\n    w.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    StoredDocument doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newTextField(\"f\" + i, utf8Data[2*i], Field.Store.YES));\n    w.addDocument(doc);\n    w.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    Document doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","sourceNew":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newTextField(\"f\" + i, utf8Data[2*i], Field.Store.YES));\n    w.addDocument(doc);\n    w.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    StoredDocument doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newTextField(\"f\" + i, utf8Data[2*i], Field.Store.YES));\n    w.addDocument(doc);\n    w.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    Document doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","sourceNew":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newTextField(\"f\" + i, utf8Data[2*i], Field.Store.YES));\n    w.addDocument(doc);\n    w.shutdown();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    StoredDocument doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newTextField(\"f\" + i, utf8Data[2*i], Field.Store.YES));\n    w.addDocument(doc);\n    w.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    StoredDocument doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","sourceNew":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newTextField(\"f\" + i, utf8Data[2*i], Field.Store.YES));\n    w.addDocument(doc);\n    w.shutdown();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    StoredDocument doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newTextField(\"f\" + i, utf8Data[2*i], Field.Store.YES));\n    w.addDocument(doc);\n    w.shutdown();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    StoredDocument doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","sourceNew":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newTextField(\"f\" + i, utf8Data[2*i], Field.Store.YES));\n    w.addDocument(doc);\n    w.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    StoredDocument doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newTextField(\"f\" + i, utf8Data[2*i], Field.Store.YES));\n    w.addDocument(doc);\n    w.shutdown();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    StoredDocument doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterUnicode#testInvalidUTF16().mjava","sourceNew":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newTextField(\"f\" + i, utf8Data[2*i], Field.Store.YES));\n    w.addDocument(doc);\n    w.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    Document doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-510\n  public void testInvalidUTF16() throws Throwable {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new TestIndexWriter.StringSplitAnalyzer()));\n    Document doc = new Document();\n\n    final int count = utf8Data.length/2;\n    for(int i=0;i<count;i++)\n      doc.add(newTextField(\"f\" + i, utf8Data[2*i], Field.Store.YES));\n    w.addDocument(doc);\n    w.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    StoredDocument doc2 = ir.document(0);\n    for(int i=0;i<count;i++) {\n      assertEquals(\"field \" + i + \" was not indexed correctly\", 1, ir.docFreq(new Term(\"f\"+i, utf8Data[2*i+1])));\n      assertEquals(\"field \" + i + \" is incorrect\", utf8Data[2*i+1], doc2.getField(\"f\"+i).stringValue());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"1d028314cced5858683a1bb4741423d0f934257b":["04f07771a2a7dd3a395700665ed839c3dae2def2","8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["1d028314cced5858683a1bb4741423d0f934257b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["d0ef034a4f10871667ae75181537775ddcf8ade4"]},"commit2Childs":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4","1d028314cced5858683a1bb4741423d0f934257b"],"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4":["1d028314cced5858683a1bb4741423d0f934257b"],"1d028314cced5858683a1bb4741423d0f934257b":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}