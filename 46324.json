{"path":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","commits":[{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, Lucene40NormsWriter.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, Lucene40NormsWriter.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6e3376a314fcc2b31bc46d399c2ff23552b78d6","date":1325780477,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40NormsReader#Lucene40NormsReader(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene40NormsReader(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = Lucene40NormsWriter.NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.isIndexed && !fi.omitNorms) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, Lucene40NormsWriter.NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = Lucene40NormsWriter.NORMS_HEADER.length;\n            }\n          }\n\n          Norm norm = new Norm();\n          norm.file = normInput;\n          norm.offset = normSeek;\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length();\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f6e3376a314fcc2b31bc46d399c2ff23552b78d6":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f6e3376a314fcc2b31bc46d399c2ff23552b78d6"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"f6e3376a314fcc2b31bc46d399c2ff23552b78d6":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["f6e3376a314fcc2b31bc46d399c2ff23552b78d6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}