{"path":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","commits":[{"id":"14d5815ecbef89580f5c48990bcd433f04f8563a","date":1399564106,"type":0,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","pathOld":"/dev/null","sourceNew":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 2 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, 3, 10);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + cloudClient.getZkStateReader().getClusterState(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, 20); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+testCollectionName, leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, 20);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 30000);\n        \n    assertNotNull(\"No new leader was elected after 30 seconds\", newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        cloudClient.getZkStateReader().getClusterState(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    Thread.sleep(10000L);\n    \n    cloudClient.getZkStateReader().updateClusterState(true);\n    \n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+activeReps.size()+\"; \"+activeReps, activeReps.size() == 2);\n        \n    sendDoc(6);\n    \n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }  \n\n","sourceOld":null,"bugFix":null,"bugIntro":["67d524cb1b29233f0dfbd6e9cba60e5aa0341dd9"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"aea1d78da2c058b98e64569bcd37981c733b52a8","date":1400551646,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","sourceNew":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 2 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + cloudClient.getZkStateReader().getClusterState(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+testCollectionName, leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds\", newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        cloudClient.getZkStateReader().getClusterState(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    Thread.sleep(10000L);\n    \n    cloudClient.getZkStateReader().updateClusterState(true);\n    \n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+activeReps.size()+\"; \"+activeReps, activeReps.size() == 2);\n        \n    sendDoc(6);\n    \n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }  \n\n","sourceOld":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 2 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, 3, 10);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + cloudClient.getZkStateReader().getClusterState(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, 20); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+testCollectionName, leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, 20);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 30000);\n        \n    assertNotNull(\"No new leader was elected after 30 seconds\", newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        cloudClient.getZkStateReader().getClusterState(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    Thread.sleep(10000L);\n    \n    cloudClient.getZkStateReader().updateClusterState(true);\n    \n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+activeReps.size()+\"; \"+activeReps, activeReps.size() == 2);\n        \n    sendDoc(6);\n    \n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }  \n\n","bugFix":null,"bugIntro":["67d524cb1b29233f0dfbd6e9cba60e5aa0341dd9"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"67d524cb1b29233f0dfbd6e9cba60e5aa0341dd9","date":1400695553,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","sourceNew":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 2 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + printClusterStateInfo(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n      testCollectionName+\"; clusterState: \"+printClusterStateInfo(), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(10000); // give chance for new leader to be elected.\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds; clusterState: \"+\n      printClusterStateInfo(),newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        printClusterStateInfo(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    Thread.sleep(10000L);\n    \n    cloudClient.getZkStateReader().updateClusterState(true);\n    \n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+\n      activeReps.size()+\"; \"+activeReps+\"; clusterState: \"+printClusterStateInfo(), \n      activeReps.size() == 2);\n        \n    sendDoc(6);\n    \n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }\n\n","sourceOld":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 2 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + cloudClient.getZkStateReader().getClusterState(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+testCollectionName, leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds\", newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        cloudClient.getZkStateReader().getClusterState(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    Thread.sleep(10000L);\n    \n    cloudClient.getZkStateReader().updateClusterState(true);\n    \n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+activeReps.size()+\"; \"+activeReps, activeReps.size() == 2);\n        \n    sendDoc(6);\n    \n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }  \n\n","bugFix":["14d5815ecbef89580f5c48990bcd433f04f8563a","aea1d78da2c058b98e64569bcd37981c733b52a8"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7605579001505896d48b07160075a5c8b8e128e","date":1400758727,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","sourceNew":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 2 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + printClusterStateInfo(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n      testCollectionName+\"; clusterState: \"+printClusterStateInfo(), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(10000); // give chance for new leader to be elected.\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds; clusterState: \"+\n      printClusterStateInfo(),newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        printClusterStateInfo(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    Thread.sleep(10000L);\n    \n    cloudClient.getZkStateReader().updateClusterState(true);\n    \n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+\n      activeReps.size()+\"; \"+activeReps+\"; clusterState: \"+printClusterStateInfo(), \n      activeReps.size() == 2);\n        \n    sendDoc(6);\n    \n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }\n\n","sourceOld":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 2 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, 3, 10);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + cloudClient.getZkStateReader().getClusterState(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, 20); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+testCollectionName, leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, 20);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 30000);\n        \n    assertNotNull(\"No new leader was elected after 30 seconds\", newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        cloudClient.getZkStateReader().getClusterState(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    Thread.sleep(10000L);\n    \n    cloudClient.getZkStateReader().updateClusterState(true);\n    \n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+activeReps.size()+\"; \"+activeReps, activeReps.size() == 2);\n        \n    sendDoc(6);\n    \n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"42f13057f5e2d2c456afb5cc5acdeae10489ad71","date":1402587908,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","sourceNew":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 3 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + printClusterStateInfo(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n      testCollectionName+\"; clusterState: \"+printClusterStateInfo(), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(10000); // give chance for new leader to be elected.\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds; clusterState: \"+\n      printClusterStateInfo(),newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        printClusterStateInfo(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    Thread.sleep(10000L);\n    \n    cloudClient.getZkStateReader().updateClusterState(true);\n    \n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+\n      activeReps.size()+\"; \"+activeReps+\"; clusterState: \"+printClusterStateInfo(), \n      activeReps.size() == 2);\n        \n    sendDoc(6);\n    \n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }\n\n","sourceOld":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 2 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + printClusterStateInfo(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n      testCollectionName+\"; clusterState: \"+printClusterStateInfo(), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(10000); // give chance for new leader to be elected.\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds; clusterState: \"+\n      printClusterStateInfo(),newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        printClusterStateInfo(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    Thread.sleep(10000L);\n    \n    cloudClient.getZkStateReader().updateClusterState(true);\n    \n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+\n      activeReps.size()+\"; \"+activeReps+\"; clusterState: \"+printClusterStateInfo(), \n      activeReps.size() == 2);\n        \n    sendDoc(6);\n    \n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c6f080a2ab37c464dd98db173f6cbf10dc74f211","date":1402946779,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","sourceNew":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 3 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + printClusterStateInfo(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n      testCollectionName+\"; clusterState: \"+printClusterStateInfo(), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(10000); // give chance for new leader to be elected.\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds; clusterState: \"+\n      printClusterStateInfo(),newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        printClusterStateInfo(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    Thread.sleep(10000L);\n    \n    cloudClient.getZkStateReader().updateClusterState(true);\n    \n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+\n      activeReps.size()+\"; \"+activeReps+\"; clusterState: \"+printClusterStateInfo(), \n      activeReps.size() == 2);\n        \n    sendDoc(6);\n    \n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }\n\n","sourceOld":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 2 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + printClusterStateInfo(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n      testCollectionName+\"; clusterState: \"+printClusterStateInfo(), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(10000); // give chance for new leader to be elected.\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds; clusterState: \"+\n      printClusterStateInfo(),newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        printClusterStateInfo(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    Thread.sleep(10000L);\n    \n    cloudClient.getZkStateReader().updateClusterState(true);\n    \n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+\n      activeReps.size()+\"; \"+activeReps+\"; clusterState: \"+printClusterStateInfo(), \n      activeReps.size() == 2);\n        \n    sendDoc(6);\n    \n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f9043cd220362869f58e50f635c13c362f8377da","date":1404227796,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","sourceNew":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 3 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + printClusterStateInfo(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n      testCollectionName+\"; clusterState: \"+printClusterStateInfo(), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(10000); // give chance for new leader to be elected.\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds; clusterState: \"+\n      printClusterStateInfo(),newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        printClusterStateInfo(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    Thread.sleep(10000L);\n    \n    cloudClient.getZkStateReader().updateClusterState(true);\n    \n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+\n      activeReps.size()+\"; \"+activeReps+\"; clusterState: \"+printClusterStateInfo(), \n      activeReps.size() == 2);\n        \n    sendDoc(6);\n    \n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }\n\n","sourceOld":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 3 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + printClusterStateInfo(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n      testCollectionName+\"; clusterState: \"+printClusterStateInfo(), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(10000); // give chance for new leader to be elected.\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds; clusterState: \"+\n      printClusterStateInfo(),newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        printClusterStateInfo(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    Thread.sleep(10000L);\n    \n    cloudClient.getZkStateReader().updateClusterState(true);\n    \n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+\n      activeReps.size()+\"; \"+activeReps+\"; clusterState: \"+printClusterStateInfo(), \n      activeReps.size() == 2);\n        \n    sendDoc(6);\n    \n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b3f5be45b5f54f240a9e1485e92e33a094299659","date":1405328334,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","sourceNew":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 3 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + printClusterStateInfo(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n      testCollectionName+\"; clusterState: \"+printClusterStateInfo(), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(10000); // give chance for new leader to be elected.\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds; clusterState: \"+\n      printClusterStateInfo(),newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        printClusterStateInfo(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      cloudClient.getZkStateReader().updateClusterState(true);\n\n      List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n      if (activeReps.size() == 2) break;\n      Thread.sleep(1000);\n    }\n\n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+\n            activeReps.size()+\"; \"+activeReps+\"; clusterState: \"+printClusterStateInfo(),\n        activeReps.size() == 2);\n\n    sendDoc(6);\n\n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }\n\n","sourceOld":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 3 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + printClusterStateInfo(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n      testCollectionName+\"; clusterState: \"+printClusterStateInfo(), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(10000); // give chance for new leader to be elected.\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds; clusterState: \"+\n      printClusterStateInfo(),newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        printClusterStateInfo(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    Thread.sleep(10000L);\n    \n    cloudClient.getZkStateReader().updateClusterState(true);\n    \n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+\n      activeReps.size()+\"; \"+activeReps+\"; clusterState: \"+printClusterStateInfo(), \n      activeReps.size() == 2);\n        \n    sendDoc(6);\n    \n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0cd90adb2be0ad7d69e4f6e26f0fab7675176721","date":1409252598,"type":3,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","sourceNew":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 3 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + printClusterStateInfo(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n      testCollectionName+\"; clusterState: \"+printClusterStateInfo(), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n\n    assertDocExists(getHttpSolrServer(leader, testCollectionName), testCollectionName, \"5\");\n    assertDocExists(getHttpSolrServer(notLeaders.get(1), testCollectionName), testCollectionName, \"5\");\n\n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(10000); // give chance for new leader to be elected.\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds; clusterState: \"+\n      printClusterStateInfo(),newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        printClusterStateInfo(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      cloudClient.getZkStateReader().updateClusterState(true);\n\n      List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n      if (activeReps.size() == 2) break;\n      Thread.sleep(1000);\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+\n            participatingReplicas.size()+\"; \"+participatingReplicas+\"; clusterState: \"+printClusterStateInfo(),\n        participatingReplicas.size() == 2);\n\n    sendDoc(6);\n\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 6);\n  }\n\n","sourceOld":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 3 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + printClusterStateInfo(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n      testCollectionName+\"; clusterState: \"+printClusterStateInfo(), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(10000); // give chance for new leader to be elected.\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds; clusterState: \"+\n      printClusterStateInfo(),newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        printClusterStateInfo(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      cloudClient.getZkStateReader().updateClusterState(true);\n\n      List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n      if (activeReps.size() == 2) break;\n      Thread.sleep(1000);\n    }\n\n    List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+\n            activeReps.size()+\"; \"+activeReps+\"; clusterState: \"+printClusterStateInfo(),\n        activeReps.size() == 2);\n\n    sendDoc(6);\n\n    assertDocsExistInAllReplicas(activeReps, testCollectionName, 1, 6);\n  }\n\n","bugFix":null,"bugIntro":["6784d0cc613dc1ee97030eaaa5e0754edc22d164"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6e36353d7461af8d2329a78a71457cf8e3c1e88f","date":1411572107,"type":5,"author":"Timothy Potter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LeaderFailoverAfterPartitionTest#testRf3WithLeaderFailover().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest#testRf3WithLeaderFailover().mjava","sourceNew":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 3 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + printClusterStateInfo(testCollectionName),\n        notLeaders.size() == 2);\n        \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n      testCollectionName+\"; clusterState: \"+printClusterStateInfo(testCollectionName), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n\n    assertDocExists(getHttpSolrServer(leader, testCollectionName), testCollectionName, \"5\");\n    assertDocExists(getHttpSolrServer(notLeaders.get(1), testCollectionName), testCollectionName, \"5\");\n\n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    //chaosMonkey.expireSession(leaderJetty);\n    // kill the leader\n    leaderJetty.stop();\n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(10000); // give chance for new leader to be elected.\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds; clusterState: \"+\n      printClusterStateInfo(testCollectionName),newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        printClusterStateInfo(testCollectionName),\n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      cloudClient.getZkStateReader().updateClusterState(true);\n\n      List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n      if (activeReps.size() >= 2) break;\n      Thread.sleep(1000);\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+\n            participatingReplicas.size()+\"; \"+participatingReplicas+\"; clusterState: \"+\n            printClusterStateInfo(testCollectionName),\n        participatingReplicas.size() >= 2);\n\n    sendDoc(6);\n\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 6);\n\n    // try to clean up\n    try {\n      CollectionAdminRequest req = new CollectionAdminRequest.Delete();\n      req.setCollectionName(testCollectionName);\n      req.process(cloudClient);\n    } catch (Exception e) {\n      // don't fail the test\n      log.warn(\"Could not delete collection {} after test completed\", testCollectionName);\n    }\n  }\n\n","sourceOld":"  protected void testRf3WithLeaderFailover() throws Exception {\n    // now let's create a partition in one of the replicas and outright\n    // kill the leader ... see what happens\n    // create a collection that has 1 shard but 3 replicas\n    String testCollectionName = \"c8n_1x3_lf\"; // _lf is leader fails\n    createCollection(testCollectionName, 1, 3, 1);\n    cloudClient.setDefaultCollection(testCollectionName);\n    \n    sendDoc(1);\n    \n    List<Replica> notLeaders = \n        ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive);\n    assertTrue(\"Expected 2 replicas for collection \" + testCollectionName\n        + \" but found \" + notLeaders.size() + \"; clusterState: \"\n        + printClusterStateInfo(),\n        notLeaders.size() == 2);\n        \n    sendDoc(1);\n    \n    // ok, now introduce a network partition between the leader and the replica\n    SocketProxy proxy0 = null;\n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    \n    proxy0.close();\n    \n    // indexing during a partition\n    sendDoc(2);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    proxy0.reopen();\n    \n    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));\n    \n    proxy1.close();\n    \n    sendDoc(3);\n    \n    Thread.sleep(sleepMsBeforeHealPartition);\n    proxy1.reopen();\n    \n    // sent 4 docs in so far, verify they are on the leader and replica\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive); \n    \n    sendDoc(4);\n    \n    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 4);    \n        \n    Replica leader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\");\n    String leaderNode = leader.getNodeName();\n    assertNotNull(\"Could not find leader for shard1 of \"+\n      testCollectionName+\"; clusterState: \"+printClusterStateInfo(), leader);\n    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));\n    \n    // since maxShardsPerNode is 1, we're safe to kill the leader\n    notLeaders = ensureAllReplicasAreActive(testCollectionName, \"shard1\", 1, 3, maxWaitSecsToSeeAllActive);    \n    proxy0 = getProxyForReplica(notLeaders.get(0));\n    proxy0.close();\n        \n    // indexing during a partition\n    // doc should be on leader and 1 replica\n    sendDoc(5);\n\n    assertDocExists(getHttpSolrServer(leader, testCollectionName), testCollectionName, \"5\");\n    assertDocExists(getHttpSolrServer(notLeaders.get(1), testCollectionName), testCollectionName, \"5\");\n\n    Thread.sleep(sleepMsBeforeHealPartition);\n    \n    String shouldNotBeNewLeaderNode = notLeaders.get(0).getNodeName();\n\n    // kill the leader\n    leaderJetty.stop();\n    \n    if (leaderJetty.isRunning())\n      fail(\"Failed to stop the leader on \"+leaderNode);\n        \n    SocketProxy oldLeaderProxy = getProxyForReplica(leader);\n    if (oldLeaderProxy != null) {\n      oldLeaderProxy.close();      \n    } else {\n      log.warn(\"No SocketProxy found for old leader node \"+leaderNode);      \n    }\n\n    Thread.sleep(10000); // give chance for new leader to be elected.\n    \n    Replica newLeader = \n        cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, \"shard1\", 60000);\n        \n    assertNotNull(\"No new leader was elected after 60 seconds; clusterState: \"+\n      printClusterStateInfo(),newLeader);\n        \n    assertTrue(\"Expected node \"+shouldNotBeNewLeaderNode+\n        \" to NOT be the new leader b/c it was out-of-sync with the old leader! ClusterState: \"+\n        printClusterStateInfo(), \n        !shouldNotBeNewLeaderNode.equals(newLeader.getNodeName()));\n    \n    proxy0.reopen();\n    \n    long timeout = System.nanoTime() + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    while (System.nanoTime() < timeout) {\n      cloudClient.getZkStateReader().updateClusterState(true);\n\n      List<Replica> activeReps = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n      if (activeReps.size() == 2) break;\n      Thread.sleep(1000);\n    }\n\n    List<Replica> participatingReplicas = getActiveOrRecoveringReplicas(testCollectionName, \"shard1\");\n    assertTrue(\"Expected 2 of 3 replicas to be active but only found \"+\n            participatingReplicas.size()+\"; \"+participatingReplicas+\"; clusterState: \"+printClusterStateInfo(),\n        participatingReplicas.size() == 2);\n\n    sendDoc(6);\n\n    Set<String> replicasToCheck = new HashSet<>();\n    for (Replica stillUp : participatingReplicas)\n      replicasToCheck.add(stillUp.getName());\n    waitToSeeReplicasActive(testCollectionName, \"shard1\", replicasToCheck, 20);\n    assertDocsExistInAllReplicas(participatingReplicas, testCollectionName, 1, 6);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"42f13057f5e2d2c456afb5cc5acdeae10489ad71":["67d524cb1b29233f0dfbd6e9cba60e5aa0341dd9"],"0cd90adb2be0ad7d69e4f6e26f0fab7675176721":["b3f5be45b5f54f240a9e1485e92e33a094299659"],"b3f5be45b5f54f240a9e1485e92e33a094299659":["f9043cd220362869f58e50f635c13c362f8377da"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"14d5815ecbef89580f5c48990bcd433f04f8563a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"aea1d78da2c058b98e64569bcd37981c733b52a8":["14d5815ecbef89580f5c48990bcd433f04f8563a"],"b7605579001505896d48b07160075a5c8b8e128e":["14d5815ecbef89580f5c48990bcd433f04f8563a","67d524cb1b29233f0dfbd6e9cba60e5aa0341dd9"],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":["67d524cb1b29233f0dfbd6e9cba60e5aa0341dd9","42f13057f5e2d2c456afb5cc5acdeae10489ad71"],"f9043cd220362869f58e50f635c13c362f8377da":["42f13057f5e2d2c456afb5cc5acdeae10489ad71"],"6e36353d7461af8d2329a78a71457cf8e3c1e88f":["0cd90adb2be0ad7d69e4f6e26f0fab7675176721"],"67d524cb1b29233f0dfbd6e9cba60e5aa0341dd9":["aea1d78da2c058b98e64569bcd37981c733b52a8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6e36353d7461af8d2329a78a71457cf8e3c1e88f"]},"commit2Childs":{"42f13057f5e2d2c456afb5cc5acdeae10489ad71":["c6f080a2ab37c464dd98db173f6cbf10dc74f211","f9043cd220362869f58e50f635c13c362f8377da"],"0cd90adb2be0ad7d69e4f6e26f0fab7675176721":["6e36353d7461af8d2329a78a71457cf8e3c1e88f"],"b3f5be45b5f54f240a9e1485e92e33a094299659":["0cd90adb2be0ad7d69e4f6e26f0fab7675176721"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["14d5815ecbef89580f5c48990bcd433f04f8563a"],"14d5815ecbef89580f5c48990bcd433f04f8563a":["aea1d78da2c058b98e64569bcd37981c733b52a8","b7605579001505896d48b07160075a5c8b8e128e"],"aea1d78da2c058b98e64569bcd37981c733b52a8":["67d524cb1b29233f0dfbd6e9cba60e5aa0341dd9"],"b7605579001505896d48b07160075a5c8b8e128e":[],"c6f080a2ab37c464dd98db173f6cbf10dc74f211":[],"f9043cd220362869f58e50f635c13c362f8377da":["b3f5be45b5f54f240a9e1485e92e33a094299659"],"67d524cb1b29233f0dfbd6e9cba60e5aa0341dd9":["42f13057f5e2d2c456afb5cc5acdeae10489ad71","b7605579001505896d48b07160075a5c8b8e128e","c6f080a2ab37c464dd98db173f6cbf10dc74f211"],"6e36353d7461af8d2329a78a71457cf8e3c1e88f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b7605579001505896d48b07160075a5c8b8e128e","c6f080a2ab37c464dd98db173f6cbf10dc74f211","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}