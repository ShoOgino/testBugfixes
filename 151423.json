{"path":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","commits":[{"id":"61c45e99cf6676da48f19d7511c73712ad39402b","date":1495508331,"type":0,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":0,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"73a4df49bbf08e66754aaad0861f9627c0276cc2","date":1496792409,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f344bb33ca91f48e99c061980115b46fa84fc8f5","date":1496903283,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","date":1498028748,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e16ac84f9e5d560008fe1554462ff8b853b3d3c","date":1520142134,"type":3,"author":"Erick","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7a7544ad4b63d1b5f556c3da8f9c63d332aa034e","date":1529622176,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  //2018-06-18 (commented) @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  //2018-06-18 (commented) @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  //2018-06-18 (commented) @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  //2018-06-18 (commented) @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run(false);\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":"  @Test\n  //2018-06-18 (commented) @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run();\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","bugFix":["61c45e99cf6676da48f19d7511c73712ad39402b"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add1e7dd742ea533ff4318cea83ca0a1f669f662","date":1585262285,"type":3,"author":"Mike Drob","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  //2018-06-18 (commented) @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(3, TimeUnit.MINUTES);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(3, TimeUnit.MINUTES);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run(false);\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":"  @Test\n  //2018-06-18 (commented) @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(180000);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(180000);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run(false);\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  //2018-06-18 (commented) @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(3, TimeUnit.MINUTES);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(3, TimeUnit.MINUTES);\n\n    if (log.isInfoEnabled()) {\n      log.info(\"control docs:{}\\n\\n\", controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n      log.info(\"collection state: {}\", printClusterStateInfo(DEFAULT_COLLECTION)); // logOk\n    }\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run(false);\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":"  @Test\n  //2018-06-18 (commented) @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(3, TimeUnit.MINUTES);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(3, TimeUnit.MINUTES);\n    \n    log.info(\"control docs:\" + controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound() + \"\\n\\n\");\n    \n    log.info(\"collection state: \" + printClusterStateInfo(DEFAULT_COLLECTION));\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run(false);\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  //2018-06-18 (commented) @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(3, TimeUnit.MINUTES);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(3, TimeUnit.MINUTES);\n\n    if (log.isInfoEnabled()) {\n      log.info(\"control docs:{}\\n\\n\", controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n      log.info(\"collection state: {}\", printClusterStateInfo(DEFAULT_COLLECTION)); // logOk\n    }\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run(false);\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":"  @Test\n  //2018-06-18 (commented) @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(3, TimeUnit.MINUTES);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(3, TimeUnit.MINUTES);\n\n    if (log.isInfoEnabled()) {\n      log.info(\"control docs:{}\\n\\n\", controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n      log.info(\"collection state: {}\", printClusterStateInfo(DEFAULT_COLLECTION)); // logOk\n    }\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run(false);\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, 100, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b2d19164145b2a65acf62a657c75f4a249b649c0","date":1601732857,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest#test().mjava","sourceNew":"  @Test\n  //2018-06-18 (commented) @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(3, TimeUnit.MINUTES);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(3, TimeUnit.MINUTES);\n\n    if (log.isInfoEnabled()) {\n      log.info(\"control docs:{}\\n\\n\", controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n      log.info(\"collection state: {}\", printClusterStateInfo(DEFAULT_COLLECTION)); // nowarn\n    }\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run(false);\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","sourceOld":"  @Test\n  //2018-06-18 (commented) @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void test() throws Exception {\n    DocCollection docCollection = cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION);\n    assertEquals(this.sliceCount, docCollection.getSlices().size());\n    Slice s = docCollection.getSlice(\"shard1\");\n    assertNotNull(s);\n    assertEquals(\"Unexpected number of replicas. Collection: \" + docCollection, numRealtimeOrTlogReplicas + numPullReplicas, s.getReplicas().size());\n    assertEquals(\"Unexpected number of pull replicas. Collection: \" + docCollection, numPullReplicas, s.getReplicas(EnumSet.of(Replica.Type.PULL)).size());\n    assertEquals(useTlogReplicas()?0:numRealtimeOrTlogReplicas, s.getReplicas(EnumSet.of(Replica.Type.NRT)).size());\n    assertEquals(useTlogReplicas()?numRealtimeOrTlogReplicas:0, s.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // randomly turn on 1 seconds 'soft' commit\n    randomlyEnableAutoSoftCommit();\n\n    tryDelete();\n    \n    List<StoppableThread> threads = new ArrayList<>();\n    int threadCount = 2;\n    int batchSize = 1;\n    if (random().nextBoolean()) {\n      batchSize = random().nextInt(98) + 2;\n    }\n    \n    boolean pauseBetweenUpdates = TEST_NIGHTLY ? random().nextBoolean() : true;\n    int maxUpdates = -1;\n    if (!pauseBetweenUpdates) {\n      maxUpdates = 1000 + random().nextInt(1000);\n    } else {\n      maxUpdates = 15000;\n    }\n    \n    for (int i = 0; i < threadCount; i++) {\n      StoppableIndexingThread indexThread = new StoppableIndexingThread(controlClient, cloudClient, Integer.toString(i), true, maxUpdates, batchSize, pauseBetweenUpdates); // random().nextInt(999) + 1\n      threads.add(indexThread);\n      indexThread.start();\n    }\n    \n    StoppableCommitThread commitThread = new StoppableCommitThread(cloudClient, 1000, false);\n    threads.add(commitThread);\n    commitThread.start();\n    \n    chaosMonkey.startTheMonkey(false, 500);\n    try {\n      long runLength;\n      if (RUN_LENGTH != -1) {\n        runLength = RUN_LENGTH;\n      } else {\n        int[] runTimes;\n        if (TEST_NIGHTLY) {\n          runTimes = new int[] {5000, 6000, 10000, 15000, 25000, 30000,\n              30000, 45000, 90000, 120000};\n        } else {\n          runTimes = new int[] {5000, 7000, 15000};\n        }\n        runLength = runTimes[random().nextInt(runTimes.length - 1)];\n      }\n      \n      ChaosMonkey.wait(runLength, DEFAULT_COLLECTION, cloudClient.getZkStateReader());\n    } finally {\n      chaosMonkey.stopTheMonkey();\n    }\n    \n    for (StoppableThread thread : threads) {\n      thread.safeStop();\n    }\n    \n    // wait for stop...\n    for (StoppableThread thread : threads) {\n      thread.join();\n    }\n    \n    for (StoppableThread thread : threads) {\n      if (thread instanceof StoppableIndexingThread) {\n        assertEquals(0, ((StoppableIndexingThread)thread).getFailCount());\n      }\n    }\n    \n    // try and wait for any replications and what not to finish...\n\n    Thread.sleep(2000);\n\n    waitForThingsToLevelOut(3, TimeUnit.MINUTES);\n    \n    // even if things were leveled out, a jetty may have just been stopped or something\n    // we wait again and wait to level out again to make sure the system is not still in flux\n    \n    Thread.sleep(3000);\n\n    waitForThingsToLevelOut(3, TimeUnit.MINUTES);\n\n    if (log.isInfoEnabled()) {\n      log.info(\"control docs:{}\\n\\n\", controlClient.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n      log.info(\"collection state: {}\", printClusterStateInfo(DEFAULT_COLLECTION)); // logOk\n    }\n    \n    waitForReplicationFromReplicas(DEFAULT_COLLECTION, cloudClient.getZkStateReader(), new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME));\n//    waitForAllWarmingSearchers();\n\n    checkShardConsistency(batchSize == 1, true);\n    \n    // try and make a collection to make sure the overseer has survived the expiration and session loss\n\n    // sometimes we restart zookeeper as well\n    if (random().nextBoolean()) {\n      zkServer.shutdown();\n      zkServer = new ZkTestServer(zkServer.getZkDir(), zkServer.getPort());\n      zkServer.run(false);\n    }\n\n    try (CloudSolrClient client = createCloudClient(\"collection1\")) {\n        createCollection(null, \"testcollection\", 1, 1, client, null, \"conf1\");\n\n    }\n    List<Integer> numShardsNumReplicas = new ArrayList<>(2);\n    numShardsNumReplicas.add(1);\n    numShardsNumReplicas.add(1 + getPullReplicaCount());\n    checkForCollection(\"testcollection\",numShardsNumReplicas, null);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e16ac84f9e5d560008fe1554462ff8b853b3d3c":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"61c45e99cf6676da48f19d7511c73712ad39402b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["7a7544ad4b63d1b5f556c3da8f9c63d332aa034e"],"f344bb33ca91f48e99c061980115b46fa84fc8f5":["61c45e99cf6676da48f19d7511c73712ad39402b","73a4df49bbf08e66754aaad0861f9627c0276cc2"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"28288370235ed02234a64753cdbf0c6ec096304a":["61c45e99cf6676da48f19d7511c73712ad39402b","f344bb33ca91f48e99c061980115b46fa84fc8f5"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","61c45e99cf6676da48f19d7511c73712ad39402b"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["7e16ac84f9e5d560008fe1554462ff8b853b3d3c","7a7544ad4b63d1b5f556c3da8f9c63d332aa034e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"b2d19164145b2a65acf62a657c75f4a249b649c0":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"7a7544ad4b63d1b5f556c3da8f9c63d332aa034e":["7e16ac84f9e5d560008fe1554462ff8b853b3d3c"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["28288370235ed02234a64753cdbf0c6ec096304a"],"73a4df49bbf08e66754aaad0861f9627c0276cc2":["61c45e99cf6676da48f19d7511c73712ad39402b"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["e9017cf144952056066919f1ebc7897ff9bd71b1","f344bb33ca91f48e99c061980115b46fa84fc8f5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b2d19164145b2a65acf62a657c75f4a249b649c0"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["7e16ac84f9e5d560008fe1554462ff8b853b3d3c","7a7544ad4b63d1b5f556c3da8f9c63d332aa034e"]},"commit2Childs":{"7e16ac84f9e5d560008fe1554462ff8b853b3d3c":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7a7544ad4b63d1b5f556c3da8f9c63d332aa034e","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"61c45e99cf6676da48f19d7511c73712ad39402b":["f344bb33ca91f48e99c061980115b46fa84fc8f5","28288370235ed02234a64753cdbf0c6ec096304a","e9017cf144952056066919f1ebc7897ff9bd71b1","73a4df49bbf08e66754aaad0861f9627c0276cc2"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"f344bb33ca91f48e99c061980115b46fa84fc8f5":["28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["b2d19164145b2a65acf62a657c75f4a249b649c0"],"28288370235ed02234a64753cdbf0c6ec096304a":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["61c45e99cf6676da48f19d7511c73712ad39402b","e9017cf144952056066919f1ebc7897ff9bd71b1"],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"b2d19164145b2a65acf62a657c75f4a249b649c0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["7e16ac84f9e5d560008fe1554462ff8b853b3d3c"],"7a7544ad4b63d1b5f556c3da8f9c63d332aa034e":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"73a4df49bbf08e66754aaad0861f9627c0276cc2":["f344bb33ca91f48e99c061980115b46fa84fc8f5"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}