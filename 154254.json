{"path":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationHandlerTest#doTestPartialReplicationAfterPeerSync().mjava","commits":[{"id":"86290366cefc1b9d4eced13b430858c4a4c0421d","date":1432321109,"type":0,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationHandlerTest#doTestPartialReplicationAfterPeerSync().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Test the scenario where the slave first recovered with a PeerSync strategy, then with a Replication strategy.\n   * The PeerSync strategy will generate a single tlog file for all the missing updates on the slave node.\n   * If a Replication strategy occurs at a later stage, it should remove this tlog file generated by PeerSync\n   * and fetch the corresponding tlog files from the leader.\n   */\n  public void doTestPartialReplicationAfterPeerSync() throws Exception {\n    this.clearSourceCollection();\n\n    for (int i = 0; i < 5; i++) {\n      List<SolrInputDocument> docs = new ArrayList<>();\n      for (int j = i * 10; j < (i * 10) + 10; j++) {\n        docs.add(getDoc(id, Integer.toString(j)));\n      }\n      index(SOURCE_COLLECTION, docs);\n    }\n\n    List<CloudJettyRunner> slaves = this.getShardToSlaveJetty(SOURCE_COLLECTION, SHARD1);\n    ChaosMonkey.stop(slaves.get(0).jetty);\n\n    for (int i = 5; i < 10; i++) {\n      List<SolrInputDocument> docs = new ArrayList<>();\n      for (int j = i * 10; j < (i * 10) + 10; j++) {\n        docs.add(getDoc(id, Integer.toString(j)));\n      }\n      index(SOURCE_COLLECTION, docs);\n    }\n\n    assertEquals(100, getNumDocs(SOURCE_COLLECTION));\n\n    // Restart the slave node to trigger PeerSync recovery\n    // (the update windows between leader and slave is small enough)\n    this.restartServer(slaves.get(0));\n\n    ChaosMonkey.stop(slaves.get(0).jetty);\n\n    for (int i = 10; i < 15; i++) {\n      List<SolrInputDocument> docs = new ArrayList<>();\n      for (int j = i * 20; j < (i * 20) + 20; j++) {\n        docs.add(getDoc(id, Integer.toString(j)));\n      }\n      index(SOURCE_COLLECTION, docs);\n    }\n\n    // restart the slave node to trigger Replication recovery\n    this.restartServer(slaves.get(0));\n\n    // at this stage, the slave should have replicated the 5 missing tlog files\n    this.assertUpdateLogs(SOURCE_COLLECTION, 15);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4dcd1fe49b76116e7d358993339fe8adbb030638","date":1437151093,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationHandlerTest#doTestPartialReplicationAfterPeerSync().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationHandlerTest#doTestPartialReplicationAfterPeerSync().mjava","sourceNew":"  /**\n   * Test the scenario where the slave first recovered with a PeerSync strategy, then with a Replication strategy.\n   * The PeerSync strategy will generate a single tlog file for all the missing updates on the slave node.\n   * If a Replication strategy occurs at a later stage, it should remove this tlog file generated by PeerSync\n   * and fetch the corresponding tlog files from the leader.\n   */\n  public void doTestPartialReplicationAfterPeerSync() throws Exception {\n    this.clearSourceCollection();\n    for (int i = 0; i < 5; i++) {\n      List<SolrInputDocument> docs = new ArrayList<>();\n      for (int j = i * 10; j < (i * 10) + 10; j++) {\n        docs.add(getDoc(id, Integer.toString(j)));\n      }\n      index(SOURCE_COLLECTION, docs);\n    }\n\n    List<CloudJettyRunner> slaves = this.getShardToSlaveJetty(SOURCE_COLLECTION, SHARD1);\n    ChaosMonkey.stop(slaves.get(0).jetty);\n\n    for (int i = 5; i < 10; i++) {\n      List<SolrInputDocument> docs = new ArrayList<>();\n      for (int j = i * 10; j < (i * 10) + 10; j++) {\n        docs.add(getDoc(id, Integer.toString(j)));\n      }\n      index(SOURCE_COLLECTION, docs);\n    }\n\n    assertEquals(100, getNumDocs(SOURCE_COLLECTION));\n\n    // Restart the slave node to trigger PeerSync recovery\n    // (the update windows between leader and slave is small enough)\n    this.restartServer(slaves.get(0));\n\n    ChaosMonkey.stop(slaves.get(0).jetty);\n\n    for (int i = 10; i < 15; i++) {\n      List<SolrInputDocument> docs = new ArrayList<>();\n      for (int j = i * 20; j < (i * 20) + 20; j++) {\n        docs.add(getDoc(id, Integer.toString(j)));\n      }\n      index(SOURCE_COLLECTION, docs);\n    }\n\n    // restart the slave node to trigger Replication recovery\n    this.restartServer(slaves.get(0));\n\n    // at this stage, the slave should have replicated the 5 missing tlog files\n    this.assertUpdateLogsEquals(SOURCE_COLLECTION, 15);\n  }\n\n","sourceOld":"  /**\n   * Test the scenario where the slave first recovered with a PeerSync strategy, then with a Replication strategy.\n   * The PeerSync strategy will generate a single tlog file for all the missing updates on the slave node.\n   * If a Replication strategy occurs at a later stage, it should remove this tlog file generated by PeerSync\n   * and fetch the corresponding tlog files from the leader.\n   */\n  public void doTestPartialReplicationAfterPeerSync() throws Exception {\n    this.clearSourceCollection();\n\n    for (int i = 0; i < 5; i++) {\n      List<SolrInputDocument> docs = new ArrayList<>();\n      for (int j = i * 10; j < (i * 10) + 10; j++) {\n        docs.add(getDoc(id, Integer.toString(j)));\n      }\n      index(SOURCE_COLLECTION, docs);\n    }\n\n    List<CloudJettyRunner> slaves = this.getShardToSlaveJetty(SOURCE_COLLECTION, SHARD1);\n    ChaosMonkey.stop(slaves.get(0).jetty);\n\n    for (int i = 5; i < 10; i++) {\n      List<SolrInputDocument> docs = new ArrayList<>();\n      for (int j = i * 10; j < (i * 10) + 10; j++) {\n        docs.add(getDoc(id, Integer.toString(j)));\n      }\n      index(SOURCE_COLLECTION, docs);\n    }\n\n    assertEquals(100, getNumDocs(SOURCE_COLLECTION));\n\n    // Restart the slave node to trigger PeerSync recovery\n    // (the update windows between leader and slave is small enough)\n    this.restartServer(slaves.get(0));\n\n    ChaosMonkey.stop(slaves.get(0).jetty);\n\n    for (int i = 10; i < 15; i++) {\n      List<SolrInputDocument> docs = new ArrayList<>();\n      for (int j = i * 20; j < (i * 20) + 20; j++) {\n        docs.add(getDoc(id, Integer.toString(j)));\n      }\n      index(SOURCE_COLLECTION, docs);\n    }\n\n    // restart the slave node to trigger Replication recovery\n    this.restartServer(slaves.get(0));\n\n    // at this stage, the slave should have replicated the 5 missing tlog files\n    this.assertUpdateLogs(SOURCE_COLLECTION, 15);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e586ff50ac71d5ef3a27ced78f69deb41ab35ad5","date":1446841099,"type":5,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationHandlerTest#testPartialReplicationAfterPeerSync().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/CdcrReplicationHandlerTest#doTestPartialReplicationAfterPeerSync().mjava","sourceNew":"  /**\n   * Test the scenario where the slave first recovered with a PeerSync strategy, then with a Replication strategy.\n   * The PeerSync strategy will generate a single tlog file for all the missing updates on the slave node.\n   * If a Replication strategy occurs at a later stage, it should remove this tlog file generated by PeerSync\n   * and fetch the corresponding tlog files from the leader.\n   */\n  @Test\n  @ShardsFixed(num = 2)\n  public void testPartialReplicationAfterPeerSync() throws Exception {\n    for (int i = 0; i < 5; i++) {\n      List<SolrInputDocument> docs = new ArrayList<>();\n      for (int j = i * 10; j < (i * 10) + 10; j++) {\n        docs.add(getDoc(id, Integer.toString(j)));\n      }\n      index(SOURCE_COLLECTION, docs);\n    }\n\n    List<CloudJettyRunner> slaves = this.getShardToSlaveJetty(SOURCE_COLLECTION, SHARD1);\n    ChaosMonkey.stop(slaves.get(0).jetty);\n\n    for (int i = 5; i < 10; i++) {\n      List<SolrInputDocument> docs = new ArrayList<>();\n      for (int j = i * 10; j < (i * 10) + 10; j++) {\n        docs.add(getDoc(id, Integer.toString(j)));\n      }\n      index(SOURCE_COLLECTION, docs);\n    }\n\n    assertNumDocs(100, SOURCE_COLLECTION);\n\n    // Restart the slave node to trigger PeerSync recovery\n    // (the update windows between leader and slave is small enough)\n    this.restartServer(slaves.get(0));\n\n    ChaosMonkey.stop(slaves.get(0).jetty);\n\n    for (int i = 10; i < 15; i++) {\n      List<SolrInputDocument> docs = new ArrayList<>();\n      for (int j = i * 20; j < (i * 20) + 20; j++) {\n        docs.add(getDoc(id, Integer.toString(j)));\n      }\n      index(SOURCE_COLLECTION, docs);\n    }\n\n    // restart the slave node to trigger Replication recovery\n    this.restartServer(slaves.get(0));\n\n    // at this stage, the slave should have replicated the 5 missing tlog files\n    this.assertUpdateLogsEquals(SOURCE_COLLECTION, 15);\n  }\n\n","sourceOld":"  /**\n   * Test the scenario where the slave first recovered with a PeerSync strategy, then with a Replication strategy.\n   * The PeerSync strategy will generate a single tlog file for all the missing updates on the slave node.\n   * If a Replication strategy occurs at a later stage, it should remove this tlog file generated by PeerSync\n   * and fetch the corresponding tlog files from the leader.\n   */\n  public void doTestPartialReplicationAfterPeerSync() throws Exception {\n    this.clearSourceCollection();\n    for (int i = 0; i < 5; i++) {\n      List<SolrInputDocument> docs = new ArrayList<>();\n      for (int j = i * 10; j < (i * 10) + 10; j++) {\n        docs.add(getDoc(id, Integer.toString(j)));\n      }\n      index(SOURCE_COLLECTION, docs);\n    }\n\n    List<CloudJettyRunner> slaves = this.getShardToSlaveJetty(SOURCE_COLLECTION, SHARD1);\n    ChaosMonkey.stop(slaves.get(0).jetty);\n\n    for (int i = 5; i < 10; i++) {\n      List<SolrInputDocument> docs = new ArrayList<>();\n      for (int j = i * 10; j < (i * 10) + 10; j++) {\n        docs.add(getDoc(id, Integer.toString(j)));\n      }\n      index(SOURCE_COLLECTION, docs);\n    }\n\n    assertEquals(100, getNumDocs(SOURCE_COLLECTION));\n\n    // Restart the slave node to trigger PeerSync recovery\n    // (the update windows between leader and slave is small enough)\n    this.restartServer(slaves.get(0));\n\n    ChaosMonkey.stop(slaves.get(0).jetty);\n\n    for (int i = 10; i < 15; i++) {\n      List<SolrInputDocument> docs = new ArrayList<>();\n      for (int j = i * 20; j < (i * 20) + 20; j++) {\n        docs.add(getDoc(id, Integer.toString(j)));\n      }\n      index(SOURCE_COLLECTION, docs);\n    }\n\n    // restart the slave node to trigger Replication recovery\n    this.restartServer(slaves.get(0));\n\n    // at this stage, the slave should have replicated the 5 missing tlog files\n    this.assertUpdateLogsEquals(SOURCE_COLLECTION, 15);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"86290366cefc1b9d4eced13b430858c4a4c0421d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e586ff50ac71d5ef3a27ced78f69deb41ab35ad5":["4dcd1fe49b76116e7d358993339fe8adbb030638"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4dcd1fe49b76116e7d358993339fe8adbb030638":["86290366cefc1b9d4eced13b430858c4a4c0421d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e586ff50ac71d5ef3a27ced78f69deb41ab35ad5"]},"commit2Childs":{"86290366cefc1b9d4eced13b430858c4a4c0421d":["4dcd1fe49b76116e7d358993339fe8adbb030638"],"e586ff50ac71d5ef3a27ced78f69deb41ab35ad5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["86290366cefc1b9d4eced13b430858c4a4c0421d"],"4dcd1fe49b76116e7d358993339fe8adbb030638":["e586ff50ac71d5ef3a27ced78f69deb41ab35ad5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}