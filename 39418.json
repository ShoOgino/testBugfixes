{"path":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    Directory directory = new RAMDirectory();\n    IndexWriter iw = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    iw.close();\n    searcher = new IndexSearcher(directory, true);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    Directory directory = new RAMDirectory();\n    IndexWriter iw = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    iw.close();\n    searcher = new IndexSearcher(directory, true);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d572389229127c297dd1fa5ce4758e1cec41e799","date":1273610938,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    Directory directory = new RAMDirectory();\n    IndexWriter iw = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    iw.close();\n    searcher = new IndexSearcher(directory, true);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    Directory directory = new RAMDirectory();\n    IndexWriter iw = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    iw.close();\n    searcher = new IndexSearcher(directory, true);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new WhitespaceAnalyzer(TEST_VERSION_CURRENT));\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c084e47df29de3330311d69dabf515ceaa989512","date":1279030906,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = new RAMDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(newRandom(), directory, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    Directory directory = new RAMDirectory();\n    IndexWriter iw = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    iw.close();\n    searcher = new IndexSearcher(directory, true);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = new RAMDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(newRandom(), directory, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    Directory directory = new RAMDirectory();\n    IndexWriter iw = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    iw.close();\n    searcher = new IndexSearcher(directory, true);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15bbd254c1506df5299c4df8c148262c7bd6301e","date":1279913113,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = new RAMDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(newRandom(), directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = new RAMDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(newRandom(), directory, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4b103252dee6afa1b6d7a622c773d178788eb85a","date":1280180143,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = new RAMDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(newRandom(), directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = new RAMDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(newRandom(), directory, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3242a09f703274d3b9283f2064a1a33064b53a1b","date":1280263474,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = new RAMDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(newRandom(), directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = new RAMDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(newRandom(), directory, \n        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c","date":1281477834,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = new MockRAMDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(newRandom(), directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = new RAMDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(newRandom(), directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    Random random = newRandom();\n    directory = newDirectory(random);\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = new MockRAMDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(newRandom(), directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    Random random = newRandom();\n    directory = newDirectory(random);\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"43b04c27924fe393e38e9f0986e32c634f261859","date":1284399440,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  protected void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = new RAMDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(newRandom(), directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790e1fde4caa765b3faaad3fbcd25c6973450336","date":1296689245,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = new IndexSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(random));\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(random));\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(random));\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e6e8066baaf2570275b21bf2358ff7983dd1471a","date":1304720731,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(random));\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(random));\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(random));\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(random));\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(random));\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory);\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer());\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"112629f1dfd1451722c6047bcf593e6efc96f5f4","date":1309910887,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(random));\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(random));\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    String qtxt = \"one\";\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      qtxt += ' ' + docText[i]; // large query so that search will be longer\n    }\n    QueryParser queryParser = new QueryParser(TEST_VERSION_CURRENT, FIELD_NAME, new MockAnalyzer(random));\n    query = queryParser.parse(qtxt);\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"23550189554f52bad1625fceab84a71d20a4df3f","date":1321064526,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n\n  }\n\n","bugFix":["64714133cf5ec732e3bbceee63351bb9af0117dc"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["23550189554f52bad1625fceab84a71d20a4df3f"],"15bbd254c1506df5299c4df8c148262c7bd6301e":["c084e47df29de3330311d69dabf515ceaa989512"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["3242a09f703274d3b9283f2064a1a33064b53a1b","43b04c27924fe393e38e9f0986e32c634f261859"],"43b04c27924fe393e38e9f0986e32c634f261859":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"c084e47df29de3330311d69dabf515ceaa989512":["d572389229127c297dd1fa5ce4758e1cec41e799"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["790e1fde4caa765b3faaad3fbcd25c6973450336"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["43b04c27924fe393e38e9f0986e32c634f261859","790e1fde4caa765b3faaad3fbcd25c6973450336"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["135621f3a0670a9394eb563224a3b76cc4dddc0f","e6e8066baaf2570275b21bf2358ff7983dd1471a"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","790e1fde4caa765b3faaad3fbcd25c6973450336"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3242a09f703274d3b9283f2064a1a33064b53a1b":["5f4e87790277826a2aea119328600dfb07761f32","4b103252dee6afa1b6d7a622c773d178788eb85a"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["c084e47df29de3330311d69dabf515ceaa989512","15bbd254c1506df5299c4df8c148262c7bd6301e"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"e6e8066baaf2570275b21bf2358ff7983dd1471a":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"d572389229127c297dd1fa5ce4758e1cec41e799":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"5f4e87790277826a2aea119328600dfb07761f32":["d572389229127c297dd1fa5ce4758e1cec41e799","c084e47df29de3330311d69dabf515ceaa989512"],"962d04139994fce5193143ef35615499a9a96d78":["bde51b089eb7f86171eb3406e38a274743f9b7ac","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["e6e8066baaf2570275b21bf2358ff7983dd1471a","112629f1dfd1451722c6047bcf593e6efc96f5f4"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["a3776dccca01c11e7046323cfad46a3b4a471233","112629f1dfd1451722c6047bcf593e6efc96f5f4"],"790e1fde4caa765b3faaad3fbcd25c6973450336":["43b04c27924fe393e38e9f0986e32c634f261859"],"a3776dccca01c11e7046323cfad46a3b4a471233":["790e1fde4caa765b3faaad3fbcd25c6973450336","e6e8066baaf2570275b21bf2358ff7983dd1471a"],"23550189554f52bad1625fceab84a71d20a4df3f":["112629f1dfd1451722c6047bcf593e6efc96f5f4"],"112629f1dfd1451722c6047bcf593e6efc96f5f4":["e6e8066baaf2570275b21bf2358ff7983dd1471a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"15bbd254c1506df5299c4df8c148262c7bd6301e":["4b103252dee6afa1b6d7a622c773d178788eb85a"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"43b04c27924fe393e38e9f0986e32c634f261859":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","29ef99d61cda9641b6250bf9567329a6e65f901d","790e1fde4caa765b3faaad3fbcd25c6973450336"],"c084e47df29de3330311d69dabf515ceaa989512":["15bbd254c1506df5299c4df8c148262c7bd6301e","4b103252dee6afa1b6d7a622c773d178788eb85a","5f4e87790277826a2aea119328600dfb07761f32"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["135621f3a0670a9394eb563224a3b76cc4dddc0f","e6e8066baaf2570275b21bf2358ff7983dd1471a","962d04139994fce5193143ef35615499a9a96d78"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["43b04c27924fe393e38e9f0986e32c634f261859"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":[],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["962d04139994fce5193143ef35615499a9a96d78"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["d572389229127c297dd1fa5ce4758e1cec41e799"],"3242a09f703274d3b9283f2064a1a33064b53a1b":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"4b103252dee6afa1b6d7a622c773d178788eb85a":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c","3242a09f703274d3b9283f2064a1a33064b53a1b"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"e6e8066baaf2570275b21bf2358ff7983dd1471a":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb","d083e83f225b11e5fdd900e83d26ddb385b6955c","a3776dccca01c11e7046323cfad46a3b4a471233","112629f1dfd1451722c6047bcf593e6efc96f5f4"],"d572389229127c297dd1fa5ce4758e1cec41e799":["c084e47df29de3330311d69dabf515ceaa989512","5f4e87790277826a2aea119328600dfb07761f32"],"5f4e87790277826a2aea119328600dfb07761f32":["3242a09f703274d3b9283f2064a1a33064b53a1b"],"962d04139994fce5193143ef35615499a9a96d78":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"790e1fde4caa765b3faaad3fbcd25c6973450336":["f2c5f0cb44df114db4228c8f77861714b5cabaea","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","a3776dccca01c11e7046323cfad46a3b4a471233"],"a3776dccca01c11e7046323cfad46a3b4a471233":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"23550189554f52bad1625fceab84a71d20a4df3f":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"112629f1dfd1451722c6047bcf593e6efc96f5f4":["d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","23550189554f52bad1625fceab84a71d20a4df3f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb","962d04139994fce5193143ef35615499a9a96d78","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}