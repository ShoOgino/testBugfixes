{"path":"src/test/org/apache/solr/analysis/BaseTokenTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","commits":[{"id":"2fd023a662cc25ae7e0ad0f33d71c476a16d0579","date":1261403630,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/test/org/apache/solr/analysis/BaseTokenTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","pathOld":"/dev/null","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output,\n      int startOffsets[], int endOffsets[], String types[], int posIncrements[])\n      throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = (TermAttribute) ts\n        .getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts\n          .hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = (PositionIncrementAttribute) ts\n          .getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also\n      // assign bogus values\n      ts.clearAttributes();\n      termAtt.setTermBuffer(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724, 24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      assertTrue(\"token \" + i + \" exists\", ts.incrementToken());\n      assertEquals(\"term \" + i, output[i], termAtt.term());\n      if (startOffsets != null) assertEquals(\"startOffset \" + i,\n          startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null) assertEquals(\"endOffset \" + i, endOffsets[i],\n          offsetAtt.endOffset());\n      if (types != null) assertEquals(\"type \" + i, types[i], typeAtt.type());\n      if (posIncrements != null) assertEquals(\"posIncrement \" + i,\n          posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/analysis/BaseTokenTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","pathOld":"src/test/org/apache/solr/analysis/BaseTokenTestCase#assertTokenStreamContents(TokenStream,String[],int[],int[],String[],int[]).mjava","sourceNew":"  public static void assertTokenStreamContents(TokenStream ts, String[] output,\n      int startOffsets[], int endOffsets[], String types[], int posIncrements[])\n      throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = (TermAttribute) ts\n        .getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts\n          .hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = (PositionIncrementAttribute) ts\n          .getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also\n      // assign bogus values\n      ts.clearAttributes();\n      termAtt.setTermBuffer(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724, 24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      assertTrue(\"token \" + i + \" exists\", ts.incrementToken());\n      assertEquals(\"term \" + i, output[i], termAtt.term());\n      if (startOffsets != null) assertEquals(\"startOffset \" + i,\n          startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null) assertEquals(\"endOffset \" + i, endOffsets[i],\n          offsetAtt.endOffset());\n      if (types != null) assertEquals(\"type \" + i, types[i], typeAtt.type());\n      if (posIncrements != null) assertEquals(\"posIncrement \" + i,\n          posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","sourceOld":"  public static void assertTokenStreamContents(TokenStream ts, String[] output,\n      int startOffsets[], int endOffsets[], String types[], int posIncrements[])\n      throws IOException {\n    assertNotNull(output);\n    assertTrue(\"has TermAttribute\", ts.hasAttribute(TermAttribute.class));\n    TermAttribute termAtt = (TermAttribute) ts\n        .getAttribute(TermAttribute.class);\n    \n    OffsetAttribute offsetAtt = null;\n    if (startOffsets != null || endOffsets != null) {\n      assertTrue(\"has OffsetAttribute\", ts.hasAttribute(OffsetAttribute.class));\n      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);\n    }\n    \n    TypeAttribute typeAtt = null;\n    if (types != null) {\n      assertTrue(\"has TypeAttribute\", ts.hasAttribute(TypeAttribute.class));\n      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);\n    }\n    \n    PositionIncrementAttribute posIncrAtt = null;\n    if (posIncrements != null) {\n      assertTrue(\"has PositionIncrementAttribute\", ts\n          .hasAttribute(PositionIncrementAttribute.class));\n      posIncrAtt = (PositionIncrementAttribute) ts\n          .getAttribute(PositionIncrementAttribute.class);\n    }\n    \n    ts.reset();\n    for (int i = 0; i < output.length; i++) {\n      // extra safety to enforce, that the state is not preserved and also\n      // assign bogus values\n      ts.clearAttributes();\n      termAtt.setTermBuffer(\"bogusTerm\");\n      if (offsetAtt != null) offsetAtt.setOffset(14584724, 24683243);\n      if (typeAtt != null) typeAtt.setType(\"bogusType\");\n      if (posIncrAtt != null) posIncrAtt.setPositionIncrement(45987657);\n      \n      assertTrue(\"token \" + i + \" exists\", ts.incrementToken());\n      assertEquals(\"term \" + i, output[i], termAtt.term());\n      if (startOffsets != null) assertEquals(\"startOffset \" + i,\n          startOffsets[i], offsetAtt.startOffset());\n      if (endOffsets != null) assertEquals(\"endOffset \" + i, endOffsets[i],\n          offsetAtt.endOffset());\n      if (types != null) assertEquals(\"type \" + i, types[i], typeAtt.type());\n      if (posIncrements != null) assertEquals(\"posIncrement \" + i,\n          posIncrements[i], posIncrAtt.getPositionIncrement());\n    }\n    assertFalse(\"end of stream\", ts.incrementToken());\n    ts.end();\n    ts.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"ad94625fb8d088209f46650c8097196fec67f00c":["2fd023a662cc25ae7e0ad0f33d71c476a16d0579"],"2fd023a662cc25ae7e0ad0f33d71c476a16d0579":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["2fd023a662cc25ae7e0ad0f33d71c476a16d0579"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"2fd023a662cc25ae7e0ad0f33d71c476a16d0579":["ad94625fb8d088209f46650c8097196fec67f00c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}