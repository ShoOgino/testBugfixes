{"path":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testInOrderWithStopWords().mjava","commits":[{"id":"bbc553081eea52ac8a9c5e1af5ca003289216561","date":1442116486,"type":0,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testInOrderWithStopWords().mjava","pathOld":"/dev/null","sourceNew":"  //shows the need to require inOrder if getSlop() == 0, not if final slop == 0 \n  //in WeightedSpanTermExtractor\n  public void testInOrderWithStopWords() throws IOException, InvalidTokenOffsetsException {\n    MockAnalyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, true,\n        MockTokenFilter.ENGLISH_STOPSET);        \n    final String TEXT = \"the cd the ab the the the the the the the ab the cd the\";\n    final Directory directory = newDirectory();\n    try (IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(stopAnalyzer))) {\n      final Document document = new Document();\n      document.add(newTextField(FIELD, TEXT, Store.YES));\n      indexWriter.addDocument(document);\n    }\n    try (IndexReader indexReader = DirectoryReader.open(directory)) {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      //equivalent of \"ab the cd\"\n      final PhraseQuery phraseQuery = new PhraseQuery.Builder()\n          .add(new Term(FIELD, \"ab\"), 0)\n          .add(new Term(FIELD, \"cd\"), 2).build();\n\n      TopDocs hits = indexSearcher.search(phraseQuery, 100);\n      assertEquals(1, hits.totalHits);\n\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      String[] frags = highlighter.getBestFragments(stopAnalyzer, FIELD, TEXT, 10);\n      assertEquals(1, frags.length);\n      assertTrue(\"contains <B>ab</B> the <B>cd</B>\",\n          (frags[0].contains(\"<B>ab</B> the <B>cd</B>\")));\n      assertTrue(\"does not contain <B>cd</B> the <B>ab</B>\",\n          (!frags[0].contains(\"<B>cd</B> the <B>ab</B>\")));\n    } finally {\n      directory.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testInOrderWithStopWords().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterPhraseTest#testInOrderWithStopWords().mjava","sourceNew":"  //shows the need to require inOrder if getSlop() == 0, not if final slop == 0 \n  //in WeightedSpanTermExtractor\n  public void testInOrderWithStopWords() throws IOException, InvalidTokenOffsetsException {\n    MockAnalyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, true,\n        MockTokenFilter.ENGLISH_STOPSET);        \n    final String TEXT = \"the cd the ab the the the the the the the ab the cd the\";\n    final Directory directory = newDirectory();\n    try (IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(stopAnalyzer))) {\n      final Document document = new Document();\n      document.add(newTextField(FIELD, TEXT, Store.YES));\n      indexWriter.addDocument(document);\n    }\n    try (IndexReader indexReader = DirectoryReader.open(directory)) {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      //equivalent of \"ab the cd\"\n      final PhraseQuery phraseQuery = new PhraseQuery.Builder()\n          .add(new Term(FIELD, \"ab\"), 0)\n          .add(new Term(FIELD, \"cd\"), 2).build();\n\n      TopDocs hits = indexSearcher.search(phraseQuery, 100);\n      assertEquals(1, hits.totalHits.value);\n\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      String[] frags = highlighter.getBestFragments(stopAnalyzer, FIELD, TEXT, 10);\n      assertEquals(1, frags.length);\n      assertTrue(\"contains <B>ab</B> the <B>cd</B>\",\n          (frags[0].contains(\"<B>ab</B> the <B>cd</B>\")));\n      assertTrue(\"does not contain <B>cd</B> the <B>ab</B>\",\n          (!frags[0].contains(\"<B>cd</B> the <B>ab</B>\")));\n    } finally {\n      directory.close();\n    }\n  }\n\n","sourceOld":"  //shows the need to require inOrder if getSlop() == 0, not if final slop == 0 \n  //in WeightedSpanTermExtractor\n  public void testInOrderWithStopWords() throws IOException, InvalidTokenOffsetsException {\n    MockAnalyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, true,\n        MockTokenFilter.ENGLISH_STOPSET);        \n    final String TEXT = \"the cd the ab the the the the the the the ab the cd the\";\n    final Directory directory = newDirectory();\n    try (IndexWriter indexWriter = new IndexWriter(directory,\n        newIndexWriterConfig(stopAnalyzer))) {\n      final Document document = new Document();\n      document.add(newTextField(FIELD, TEXT, Store.YES));\n      indexWriter.addDocument(document);\n    }\n    try (IndexReader indexReader = DirectoryReader.open(directory)) {\n      assertEquals(1, indexReader.numDocs());\n      final IndexSearcher indexSearcher = newSearcher(indexReader);\n      //equivalent of \"ab the cd\"\n      final PhraseQuery phraseQuery = new PhraseQuery.Builder()\n          .add(new Term(FIELD, \"ab\"), 0)\n          .add(new Term(FIELD, \"cd\"), 2).build();\n\n      TopDocs hits = indexSearcher.search(phraseQuery, 100);\n      assertEquals(1, hits.totalHits);\n\n      final Highlighter highlighter = new Highlighter(\n          new SimpleHTMLFormatter(), new SimpleHTMLEncoder(),\n          new QueryScorer(phraseQuery));\n      String[] frags = highlighter.getBestFragments(stopAnalyzer, FIELD, TEXT, 10);\n      assertEquals(1, frags.length);\n      assertTrue(\"contains <B>ab</B> the <B>cd</B>\",\n          (frags[0].contains(\"<B>ab</B> the <B>cd</B>\")));\n      assertTrue(\"does not contain <B>cd</B> the <B>ab</B>\",\n          (!frags[0].contains(\"<B>cd</B> the <B>ab</B>\")));\n    } finally {\n      directory.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"bbc553081eea52ac8a9c5e1af5ca003289216561":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"83788ad129a5154d5c6562c4e8ce3db48793aada":["bbc553081eea52ac8a9c5e1af5ca003289216561"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["83788ad129a5154d5c6562c4e8ce3db48793aada"]},"commit2Childs":{"bbc553081eea52ac8a9c5e1af5ca003289216561":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["bbc553081eea52ac8a9c5e1af5ca003289216561"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}