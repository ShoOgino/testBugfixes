{"path":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testHandlingSharedIndexFiles().mjava","commits":[{"id":"91e2345fb81b6c1c7faefa550ee5eaafadc54486","date":1469730189,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testHandlingSharedIndexFiles().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testHandlingSharedIndexFiles() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"SolrCoreSnapshots_IndexFileSharing\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(cluster.getSolrClient(), collectionName, docsSeed);\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n    String location = createTempDir().toFile().getAbsolutePath();\n\n    try (\n        SolrClient adminClient = getHttpSolrClient(cluster.getJettySolrRunners().get(0).getBaseUrl().toString());\n        SolrClient masterClient = getHttpSolrClient(replica.getCoreUrl())) {\n\n      int numTests = TestUtil.nextInt(random(), 2, 5);\n      List<SnapshotMetaData> snapshots = new ArrayList<>(numTests);\n\n      // Create multiple commits and create a snapshot per commit.\n      // This should result in Lucene reusing some of the segments for later index commits.\n      for (int attempt=0; attempt<numTests; attempt++) {\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(\"id:\" + i);\n          }\n        }\n\n        // Add a few more\n        int moreAdds = TestUtil.nextInt(random(), 1, 100);\n        for (int i = 0; i < moreAdds; i++) {\n          SolrInputDocument doc = new SolrInputDocument();\n          doc.addField(\"id\", i + nDocs);\n          doc.addField(\"name\", \"name = \" + (i + nDocs));\n          masterClient.add(doc);\n        }\n        masterClient.commit();\n\n        // Create a snapshot\n        snapshots.add(createSnapshot(adminClient, coreName, \"snapshot_\" + attempt));\n      }\n\n      // Backup the earlier created snapshot.\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(\"commitName\", snapshots.get(0).getName());\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      // Restore the backup. The purpose of the restore operation is to change the *current* index directory.\n      // This is required since we delegate the file deletion to underlying IndexDeletionPolicy in case of\n      // *current* index directory. Hence for the purpose of this test, we want to ensure that the created\n      // snapshots are NOT in the *current* index directory.\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", \"snapshot.\" + backupName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n      }\n\n      {\n        SnapshotMetaData snapshotMetaData = snapshots.get(0);\n\n        List<IndexCommit> commits = listCommits(snapshotMetaData.getIndexDirPath());\n        // Check if number of index commits are > 0 to ensure index file sharing.\n        assertTrue(commits.size() > 0);\n        Map<String,Integer> refCounts = SolrSnapshotManager.buildRefCounts(snapshots, commits);\n\n        Optional<IndexCommit> ic = commits.stream()\n            .filter(entry -> entry.getGeneration() == snapshotMetaData.getGenerationNumber())\n            .findFirst();\n        assertTrue(ic.isPresent());\n        Collection<String> nonSharedFiles = new ArrayList<>();\n        Collection<String> sharedFiles = new ArrayList<>();\n        for (String fileName : ic.get().getFileNames()) {\n          if (refCounts.getOrDefault(fileName, 0) > 1) {\n            sharedFiles.add(fileName);\n          } else {\n            nonSharedFiles.add(fileName);\n          }\n        }\n\n        // Delete snapshot\n        deleteSnapshot(adminClient, coreName, snapshotMetaData.getName());\n\n        // Verify that the shared files are not deleted.\n        for (String fileName : sharedFiles) {\n          Path path = Paths.get(snapshotMetaData.getIndexDirPath(), fileName);\n          assertTrue(path + \" should exist.\", Files.exists(path));\n        }\n\n        // Verify that the non-shared files are deleted.\n        for (String fileName : nonSharedFiles) {\n          Path path = Paths.get(snapshotMetaData.getIndexDirPath(), fileName);\n          assertFalse(path + \" should not exist.\", Files.exists(path));\n        }\n        }\n      }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testHandlingSharedIndexFiles().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testHandlingSharedIndexFiles() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"SolrCoreSnapshots_IndexFileSharing\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(cluster.getSolrClient(), collectionName, docsSeed);\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n    String location = createTempDir().toFile().getAbsolutePath();\n\n    try (\n        SolrClient adminClient = getHttpSolrClient(cluster.getJettySolrRunners().get(0).getBaseUrl().toString());\n        SolrClient masterClient = getHttpSolrClient(replica.getCoreUrl())) {\n\n      int numTests = TestUtil.nextInt(random(), 2, 5);\n      List<SnapshotMetaData> snapshots = new ArrayList<>(numTests);\n\n      // Create multiple commits and create a snapshot per commit.\n      // This should result in Lucene reusing some of the segments for later index commits.\n      for (int attempt=0; attempt<numTests; attempt++) {\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(\"id:\" + i);\n          }\n        }\n\n        // Add a few more\n        int moreAdds = TestUtil.nextInt(random(), 1, 100);\n        for (int i = 0; i < moreAdds; i++) {\n          SolrInputDocument doc = new SolrInputDocument();\n          doc.addField(\"id\", i + nDocs);\n          doc.addField(\"name\", \"name = \" + (i + nDocs));\n          masterClient.add(doc);\n        }\n        masterClient.commit();\n\n        // Create a snapshot\n        snapshots.add(createSnapshot(adminClient, coreName, \"snapshot_\" + attempt));\n      }\n\n      // Backup the earlier created snapshot.\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(\"commitName\", snapshots.get(0).getName());\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      // Restore the backup. The purpose of the restore operation is to change the *current* index directory.\n      // This is required since we delegate the file deletion to underlying IndexDeletionPolicy in case of\n      // *current* index directory. Hence for the purpose of this test, we want to ensure that the created\n      // snapshots are NOT in the *current* index directory.\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", \"snapshot.\" + backupName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n      }\n\n      {\n        SnapshotMetaData snapshotMetaData = snapshots.get(0);\n\n        List<IndexCommit> commits = listCommits(snapshotMetaData.getIndexDirPath());\n        // Check if number of index commits are > 0 to ensure index file sharing.\n        assertTrue(commits.size() > 0);\n        Map<String,Integer> refCounts = SolrSnapshotManager.buildRefCounts(snapshots, commits);\n\n        Optional<IndexCommit> ic = commits.stream()\n            .filter(entry -> entry.getGeneration() == snapshotMetaData.getGenerationNumber())\n            .findFirst();\n        assertTrue(ic.isPresent());\n        Collection<String> nonSharedFiles = new ArrayList<>();\n        Collection<String> sharedFiles = new ArrayList<>();\n        for (String fileName : ic.get().getFileNames()) {\n          if (refCounts.getOrDefault(fileName, 0) > 1) {\n            sharedFiles.add(fileName);\n          } else {\n            nonSharedFiles.add(fileName);\n          }\n        }\n\n        // Delete snapshot\n        deleteSnapshot(adminClient, coreName, snapshotMetaData.getName());\n\n        // Verify that the shared files are not deleted.\n        for (String fileName : sharedFiles) {\n          Path path = Paths.get(snapshotMetaData.getIndexDirPath(), fileName);\n          assertTrue(path + \" should exist.\", Files.exists(path));\n        }\n\n        // Verify that the non-shared files are deleted.\n        for (String fileName : nonSharedFiles) {\n          Path path = Paths.get(snapshotMetaData.getIndexDirPath(), fileName);\n          assertFalse(path + \" should not exist.\", Files.exists(path));\n        }\n        }\n      }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e13696c44d3e2405098726359ab81dab178e7bc","date":1476726926,"type":4,"author":"Hrishikesh Gadre","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testHandlingSharedIndexFiles().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testHandlingSharedIndexFiles() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"SolrCoreSnapshots_IndexFileSharing\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(cluster.getSolrClient(), collectionName, docsSeed);\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n    String location = createTempDir().toFile().getAbsolutePath();\n\n    try (\n        SolrClient adminClient = getHttpSolrClient(cluster.getJettySolrRunners().get(0).getBaseUrl().toString());\n        SolrClient masterClient = getHttpSolrClient(replica.getCoreUrl())) {\n\n      int numTests = TestUtil.nextInt(random(), 2, 5);\n      List<SnapshotMetaData> snapshots = new ArrayList<>(numTests);\n\n      // Create multiple commits and create a snapshot per commit.\n      // This should result in Lucene reusing some of the segments for later index commits.\n      for (int attempt=0; attempt<numTests; attempt++) {\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(\"id:\" + i);\n          }\n        }\n\n        // Add a few more\n        int moreAdds = TestUtil.nextInt(random(), 1, 100);\n        for (int i = 0; i < moreAdds; i++) {\n          SolrInputDocument doc = new SolrInputDocument();\n          doc.addField(\"id\", i + nDocs);\n          doc.addField(\"name\", \"name = \" + (i + nDocs));\n          masterClient.add(doc);\n        }\n        masterClient.commit();\n\n        // Create a snapshot\n        snapshots.add(createSnapshot(adminClient, coreName, \"snapshot_\" + attempt));\n      }\n\n      // Backup the earlier created snapshot.\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(\"commitName\", snapshots.get(0).getName());\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      // Restore the backup. The purpose of the restore operation is to change the *current* index directory.\n      // This is required since we delegate the file deletion to underlying IndexDeletionPolicy in case of\n      // *current* index directory. Hence for the purpose of this test, we want to ensure that the created\n      // snapshots are NOT in the *current* index directory.\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", \"snapshot.\" + backupName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n      }\n\n      {\n        SnapshotMetaData snapshotMetaData = snapshots.get(0);\n\n        List<IndexCommit> commits = listCommits(snapshotMetaData.getIndexDirPath());\n        // Check if number of index commits are > 0 to ensure index file sharing.\n        assertTrue(commits.size() > 0);\n        Map<String,Integer> refCounts = SolrSnapshotManager.buildRefCounts(snapshots, commits);\n\n        Optional<IndexCommit> ic = commits.stream()\n            .filter(entry -> entry.getGeneration() == snapshotMetaData.getGenerationNumber())\n            .findFirst();\n        assertTrue(ic.isPresent());\n        Collection<String> nonSharedFiles = new ArrayList<>();\n        Collection<String> sharedFiles = new ArrayList<>();\n        for (String fileName : ic.get().getFileNames()) {\n          if (refCounts.getOrDefault(fileName, 0) > 1) {\n            sharedFiles.add(fileName);\n          } else {\n            nonSharedFiles.add(fileName);\n          }\n        }\n\n        // Delete snapshot\n        deleteSnapshot(adminClient, coreName, snapshotMetaData.getName());\n\n        // Verify that the shared files are not deleted.\n        for (String fileName : sharedFiles) {\n          Path path = Paths.get(snapshotMetaData.getIndexDirPath(), fileName);\n          assertTrue(path + \" should exist.\", Files.exists(path));\n        }\n\n        // Verify that the non-shared files are deleted.\n        for (String fileName : nonSharedFiles) {\n          Path path = Paths.get(snapshotMetaData.getIndexDirPath(), fileName);\n          assertFalse(path + \" should not exist.\", Files.exists(path));\n        }\n        }\n      }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3e13696c44d3e2405098726359ab81dab178e7bc":["91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3e13696c44d3e2405098726359ab81dab178e7bc"],"91e2345fb81b6c1c7faefa550ee5eaafadc54486":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"3e13696c44d3e2405098726359ab81dab178e7bc":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3b013574eedcdbac35dc7e35b0ee616ffc38895d","91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"91e2345fb81b6c1c7faefa550ee5eaafadc54486":["3e13696c44d3e2405098726359ab81dab178e7bc","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}