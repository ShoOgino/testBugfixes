{"path":"lucene/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","commits":[{"id":"20e94e61fe5291647346b70437617e6b6c370408","date":1483783127,"type":1,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","pathOld":"lucene/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector#collect(int).mjava","sourceNew":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * leafComparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final T groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<T> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<T> sg = new CollectedSearchGroup<>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<T> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      leafComparators[compIDX].copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * comparators[compIDX].compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          leafComparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<T> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * leafComparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final GROUP_VALUE_TYPE groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<GROUP_VALUE_TYPE> sg = new CollectedSearchGroup<>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<GROUP_VALUE_TYPE> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      leafComparators[compIDX].copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * comparators[compIDX].compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          leafComparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","date":1484239864,"type":1,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","pathOld":"lucene/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector#collect(int).mjava","sourceNew":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * leafComparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final T groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<T> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<T> sg = new CollectedSearchGroup<>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<T> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      leafComparators[compIDX].copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * comparators[compIDX].compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          leafComparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<T> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * leafComparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final GROUP_VALUE_TYPE groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<GROUP_VALUE_TYPE> sg = new CollectedSearchGroup<>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<GROUP_VALUE_TYPE> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      leafComparators[compIDX].copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * comparators[compIDX].compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          leafComparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7ae958a739da1866696f442384393ba2f13e33e5","date":1491819018,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","pathOld":"lucene/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","sourceNew":"  @Override\n  public void collect(int doc) throws IOException {\n\n    if (isCompetitive(doc) == false)\n      return;\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    groupSelector.advanceTo(doc);\n    T groupValue = groupSelector.currentValue();\n\n    final CollectedSearchGroup<T> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<T> sg = new CollectedSearchGroup<>();\n        sg.groupValue = groupSelector.copyValue();\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<T> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = groupSelector.copyValue();\n      bottomGroup.topDoc = docBase + doc;\n\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      leafComparators[compIDX].copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * comparators[compIDX].compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          leafComparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<T> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * leafComparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final T groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<T> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<T> sg = new CollectedSearchGroup<>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<T> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      leafComparators[compIDX].copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * comparators[compIDX].compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          leafComparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<T> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54ca69905c5d9d1529286f06ab1d12c68f6c13cb","date":1492683554,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"lucene/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","pathOld":"lucene/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","sourceNew":"  @Override\n  public void collect(int doc) throws IOException {\n\n    if (isCompetitive(doc) == false)\n      return;\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    groupSelector.advanceTo(doc);\n    T groupValue = groupSelector.currentValue();\n\n    final CollectedSearchGroup<T> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<T> sg = new CollectedSearchGroup<>();\n        sg.groupValue = groupSelector.copyValue();\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<T> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = groupSelector.copyValue();\n      bottomGroup.topDoc = docBase + doc;\n\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      leafComparators[compIDX].copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * comparators[compIDX].compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          leafComparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<T> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * leafComparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final T groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<T> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<T> sg = new CollectedSearchGroup<>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<T> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      leafComparators[compIDX].copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * comparators[compIDX].compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          leafComparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<T> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["20e94e61fe5291647346b70437617e6b6c370408"],"20e94e61fe5291647346b70437617e6b6c370408":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","20e94e61fe5291647346b70437617e6b6c370408"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7ae958a739da1866696f442384393ba2f13e33e5"],"7ae958a739da1866696f442384393ba2f13e33e5":["20e94e61fe5291647346b70437617e6b6c370408"]},"commit2Childs":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":[],"20e94e61fe5291647346b70437617e6b6c370408":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","7ae958a739da1866696f442384393ba2f13e33e5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["20e94e61fe5291647346b70437617e6b6c370408","09ab8ee44ca898536770d0106a7c0ee4be4f0eb7"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7ae958a739da1866696f442384393ba2f13e33e5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}