{"path":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","commits":[{"id":"006838107b0cd2051371f3470740d23ec91b1886","date":1384950816,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"/dev/null","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    DocumentBuilder builder = new DocumentBuilder(taxoWriter, config);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(builder.build(doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getFacetCounts(taxoReader, config, c);\n\n    SimpleFacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ce7aff7772c162c15d520e31af46c555f60d5c3b","date":1385135519,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    DocumentBuilder builder = new DocumentBuilder(taxoWriter, config);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(builder.build(doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    SimpleFacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    DocumentBuilder builder = new DocumentBuilder(taxoWriter, config);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(builder.build(doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getFacetCounts(taxoReader, config, c);\n\n    SimpleFacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae75def1e2525383b6e1397ed97c44387da9941c","date":1385249238,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig(taxoWriter);\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    SimpleFacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    DocumentBuilder builder = new DocumentBuilder(taxoWriter, config);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(builder.build(doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    SimpleFacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"21d36d0db865f7b84026b447bec653469a6e66df","date":1385495602,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/simple/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig(taxoWriter);\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig(taxoWriter);\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    SimpleFacetsCollector c = new SimpleFacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    SimpleFacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"21d36d0db865f7b84026b447bec653469a6e66df":["ae75def1e2525383b6e1397ed97c44387da9941c"],"ce7aff7772c162c15d520e31af46c555f60d5c3b":["006838107b0cd2051371f3470740d23ec91b1886"],"006838107b0cd2051371f3470740d23ec91b1886":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ae75def1e2525383b6e1397ed97c44387da9941c":["ce7aff7772c162c15d520e31af46c555f60d5c3b"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["006838107b0cd2051371f3470740d23ec91b1886","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"21d36d0db865f7b84026b447bec653469a6e66df":[],"ce7aff7772c162c15d520e31af46c555f60d5c3b":["ae75def1e2525383b6e1397ed97c44387da9941c"],"006838107b0cd2051371f3470740d23ec91b1886":["ce7aff7772c162c15d520e31af46c555f60d5c3b"],"ae75def1e2525383b6e1397ed97c44387da9941c":["21d36d0db865f7b84026b447bec653469a6e66df"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["21d36d0db865f7b84026b447bec653469a6e66df","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}