{"path":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","commits":[{"id":"849494cf2f3a96af5c8c84995108ddd8456fcd04","date":1372277913,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n \n      \n      Configuration conf = new Configuration();\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      FileSystem fs;\n      try {\n        URI uri = new URI(hdfsUri);\n        fs = FileSystem.newInstance(uri, conf);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n      }\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<Long>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));;\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["add53de9835b2cd1a7a80b4e0036afee171c9fdf"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c51d60d4f34c66a3ee711805d96a5fbe0a83740","date":1372986050,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<Long>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));;\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n \n      \n      Configuration conf = new Configuration();\n      conf.setBoolean(\"fs.hdfs.impl.disable.cache\", true);\n      FileSystem fs;\n      try {\n        URI uri = new URI(hdfsUri);\n        fs = FileSystem.newInstance(uri, conf);\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n      }\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<Long>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));;\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":0,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<Long>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));;\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));;\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<Long>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));;\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a0c04b71951333291abc7f317109a6a5957bd28","date":1457097827,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));;\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));;\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"043df2e9a841864922c32756a44c939ed768cb89","date":1459876536,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = logReplayFinish::release;\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));;\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));;\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b6284684320a9808c41a5e43de958b2da22f89bd","date":1459977490,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = logReplayFinish::release;\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));;\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));;\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"add53de9835b2cd1a7a80b4e0036afee171c9fdf","date":1552937136,"type":3,"author":"Kevin Risden","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = logReplayFinish::release;\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = logReplayFinish::release;\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));;\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6bdf107cf16be0f22504ae184fed81596665a244","date":1576012524,"type":3,"author":"Kevin Risden","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = logReplayFinish::release;\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = logReplayFinish::release;\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a229cb50768e988c50a2106bdae3a92154f428bf","date":1576051038,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = logReplayFinish::release;\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = logReplayFinish::release;\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1","date":1579200426,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecoveryHdfs#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      TestInjection.skipIndexWriterCommitOnClose = true;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = logReplayFinish::release;\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = logReplayFinish::release;\n\n\n      clearIndex();\n      assertU(commit());\n\n      String logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n      \n      h.close();\n\n      String[] files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      for (String file : files) {\n        fs.delete(new Path(logDir, file), false);\n      }\n\n      assertEquals(0, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(TIMEOUT, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, HdfsUpdateLog.getLogList(fs, new Path(logDir)).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = HdfsUpdateLog.getLogList(fs, new Path(logDir));\n      Arrays.sort(files);\n\n      FSDataOutputStream dos = fs.create(new Path(new Path(logDir), files[files.length-1]), (short)1);\n      dos.writeUTF(\"This is a trashed log file that really shouldn't work at all, but we'll see..\");\n      dos.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["7c51d60d4f34c66a3ee711805d96a5fbe0a83740"],"043df2e9a841864922c32756a44c939ed768cb89":["3a0c04b71951333291abc7f317109a6a5957bd28"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","7c51d60d4f34c66a3ee711805d96a5fbe0a83740"],"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1":["6bdf107cf16be0f22504ae184fed81596665a244"],"3a0c04b71951333291abc7f317109a6a5957bd28":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"add53de9835b2cd1a7a80b4e0036afee171c9fdf":["b6284684320a9808c41a5e43de958b2da22f89bd"],"7c51d60d4f34c66a3ee711805d96a5fbe0a83740":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a229cb50768e988c50a2106bdae3a92154f428bf":["add53de9835b2cd1a7a80b4e0036afee171c9fdf","6bdf107cf16be0f22504ae184fed81596665a244"],"b6284684320a9808c41a5e43de958b2da22f89bd":["3a0c04b71951333291abc7f317109a6a5957bd28","043df2e9a841864922c32756a44c939ed768cb89"],"6bdf107cf16be0f22504ae184fed81596665a244":["add53de9835b2cd1a7a80b4e0036afee171c9fdf"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["3a0c04b71951333291abc7f317109a6a5957bd28"],"043df2e9a841864922c32756a44c939ed768cb89":["b6284684320a9808c41a5e43de958b2da22f89bd"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a0c04b71951333291abc7f317109a6a5957bd28":["043df2e9a841864922c32756a44c939ed768cb89","b6284684320a9808c41a5e43de958b2da22f89bd"],"add53de9835b2cd1a7a80b4e0036afee171c9fdf":["a229cb50768e988c50a2106bdae3a92154f428bf","6bdf107cf16be0f22504ae184fed81596665a244"],"7c51d60d4f34c66a3ee711805d96a5fbe0a83740":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","37a0f60745e53927c4c876cfe5b5a58170f0646c"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["7c51d60d4f34c66a3ee711805d96a5fbe0a83740"],"a229cb50768e988c50a2106bdae3a92154f428bf":[],"b6284684320a9808c41a5e43de958b2da22f89bd":["add53de9835b2cd1a7a80b4e0036afee171c9fdf"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["37a0f60745e53927c4c876cfe5b5a58170f0646c","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"6bdf107cf16be0f22504ae184fed81596665a244":["b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1","a229cb50768e988c50a2106bdae3a92154f428bf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","a229cb50768e988c50a2106bdae3a92154f428bf","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}