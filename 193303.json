{"path":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","commits":[{"id":"60ba444201d2570214b6fcf1d15600dc1a01f548","date":1313868045,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"/dev/null","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(1000);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = randomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = randomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n        }\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, new BytesRef(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = te.docs(null, docsEnum);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4","b03ea9834e2d1bc787272cb563d331fa60f8686d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b03ea9834e2d1bc787272cb563d331fa60f8686d","date":1313940162,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(1000);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, new BytesRef(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = te.docs(null, docsEnum);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(1000);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = randomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = randomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n        }\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, new BytesRef(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = te.docs(null, docsEnum);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["60ba444201d2570214b6fcf1d15600dc1a01f548"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4231f130465e144b1f115854690fe6c5afb61917","date":1318510129,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, new BytesRef(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = te.docs(null, docsEnum);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(1000);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, new BytesRef(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = te.docs(null, docsEnum);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"382fe3a6ca9745891afebda9b9a57cc158305545","date":1320952430,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(r, \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, new BytesRef(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = te.docs(null, docsEnum);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(r, \"id\");\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, new BytesRef(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = te.docs(null, docsEnum);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e6e919043fa85ee891123768dd655a98edbbf63c","date":1322225413,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(r, \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = te.docs(null, docsEnum);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(r, \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, new BytesRef(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = te.docs(null, docsEnum);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"872cff1d3a554e0cd64014cd97f88d3002b0f491","date":1323024658,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(r, \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(r, \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = te.docs(null, docsEnum);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b65b350ca9588f9fc76ce7d6804160d06c45ff42","date":1323026297,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(r, \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(r, \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = te.docs(null, docsEnum);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2dd6ecb8250c497ed227653279d6a4f470bfbb31","date":1326814483,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(new SlowMultiReaderWrapper(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(r, \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"386d1b0dcb065f1bfc494b1407cb41c536b95485","date":1327848512,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(new SlowMultiReaderWrapper(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(new SlowMultiReaderWrapper(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectRandom().mjava","sourceNew":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Tests Terms.intersect\n  public void testIntersectRandom() throws IOException {\n\n    final Directory dir = newDirectory();\n    final RandomIndexWriter w = new RandomIndexWriter(random, dir);\n    \n    final int numTerms = atLeast(300);\n\n    final Set<String> terms = new HashSet<String>();\n    final Collection<String> pendingTerms = new ArrayList<String>();\n    final Map<BytesRef,Integer> termToID = new HashMap<BytesRef,Integer>();\n    int id = 0;\n    while(terms.size() != numTerms) {\n      final String s = getRandomString();\n      if (!terms.contains(s)) {\n        terms.add(s);\n        pendingTerms.add(s);\n        if (random.nextInt(20) == 7) {\n          addDoc(w, pendingTerms, termToID, id++);\n        }\n      }\n    }\n    addDoc(w, pendingTerms, termToID, id++);\n\n    final BytesRef[] termsArray = new BytesRef[terms.size()];\n    final Set<BytesRef> termsSet = new HashSet<BytesRef>();\n    {\n      int upto = 0;\n      for(String s : terms) {\n        final BytesRef b = new BytesRef(s);\n        termsArray[upto++] = b;\n        termsSet.add(b);\n      }\n      Arrays.sort(termsArray);\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"\\nTEST: indexed terms (unicode order):\");\n      for(BytesRef t : termsArray) {\n        System.out.println(\"  \" + t.utf8ToString() + \" -> id:\" + termToID.get(t));\n      }\n    }\n\n    final IndexReader r = w.getReader();\n    w.close();\n\n    // NOTE: intentional insanity!!\n    final int[] docIDToID = FieldCache.DEFAULT.getInts(SlowCompositeReaderWrapper.wrap(r), \"id\", false);\n\n    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {\n\n      // TODO: can we also test infinite As here...?\n\n      // From the random terms, pick some ratio and compile an\n      // automaton:\n      final Set<String> acceptTerms = new HashSet<String>();\n      final TreeSet<BytesRef> sortedAcceptTerms = new TreeSet<BytesRef>();\n      final double keepPct = random.nextDouble();\n      Automaton a;\n      if (iter == 0) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: empty automaton\");\n        }\n        a = BasicAutomata.makeEmpty();\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: keepPct=\" + keepPct);\n        }\n        for (String s : terms) {\n          final String s2;\n          if (random.nextDouble() <= keepPct) {\n            s2 = s;\n          } else {\n            s2 = getRandomString();\n          }\n          acceptTerms.add(s2);\n          sortedAcceptTerms.add(new BytesRef(s2));\n        }\n        a = DaciukMihovAutomatonBuilder.build(sortedAcceptTerms);\n      }\n      final CompiledAutomaton c = new CompiledAutomaton(a, true, false);\n\n      final BytesRef[] acceptTermsArray = new BytesRef[acceptTerms.size()];\n      final Set<BytesRef> acceptTermsSet = new HashSet<BytesRef>();\n      int upto = 0;\n      for(String s : acceptTerms) {\n        final BytesRef b = new BytesRef(s);\n        acceptTermsArray[upto++] = b;\n        acceptTermsSet.add(b);\n        assertTrue(accepts(c, b));\n      }\n      Arrays.sort(acceptTermsArray);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: accept terms (unicode order):\");\n        for(BytesRef t : acceptTermsArray) {\n          System.out.println(\"  \" + t.utf8ToString() + (termsSet.contains(t) ? \" (exists)\" : \"\"));\n        }\n        System.out.println(a.toDot());\n      }\n\n      for(int iter2=0;iter2<100;iter2++) {\n        final BytesRef startTerm = acceptTermsArray.length == 0 || random.nextBoolean() ? null : acceptTermsArray[random.nextInt(acceptTermsArray.length)];\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter2=\" + iter2 + \" startTerm=\" + (startTerm == null ? \"<null>\" : startTerm.utf8ToString()));\n\n          if (startTerm != null) {\n            int state = c.runAutomaton.getInitialState();\n            for(int idx=0;idx<startTerm.length;idx++) {\n              final int label = startTerm.bytes[startTerm.offset+idx] & 0xff;\n              System.out.println(\"  state=\" + state + \" label=\" + label);\n              state = c.runAutomaton.step(state, label);\n              assertTrue(state != -1);\n            }\n            System.out.println(\"  state=\" + state);\n          }\n        }\n\n        final TermsEnum te = MultiFields.getTerms(r, \"f\").intersect(c, startTerm);\n\n        int loc;\n        if (startTerm == null) {\n          loc = 0;\n        } else {\n          loc = Arrays.binarySearch(termsArray, BytesRef.deepCopyOf(startTerm));\n          if (loc < 0) {\n            loc = -(loc+1);\n          } else {\n            // startTerm exists in index\n            loc++;\n          }\n        }\n        while(loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc])) {\n          loc++;\n        }\n\n        DocsEnum docsEnum = null;\n        while (loc < termsArray.length) {\n          final BytesRef expected = termsArray[loc];\n          final BytesRef actual = te.next();\n          if (VERBOSE) {\n            System.out.println(\"TEST:   next() expected=\" + expected.utf8ToString() + \" actual=\" + actual.utf8ToString());\n          }\n          assertEquals(expected, actual);\n          assertEquals(1, te.docFreq());\n          docsEnum = _TestUtil.docs(random, te, null, docsEnum, false);\n          final int docID = docsEnum.nextDoc();\n          assertTrue(docID != DocsEnum.NO_MORE_DOCS);\n          assertEquals(docIDToID[docID], termToID.get(expected).intValue());\n          do {\n            loc++;\n          } while (loc < termsArray.length && !acceptTermsSet.contains(termsArray[loc]));\n        }\n\n        assertNull(te.next());\n      }\n    }\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"4231f130465e144b1f115854690fe6c5afb61917":["b03ea9834e2d1bc787272cb563d331fa60f8686d"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["e6e919043fa85ee891123768dd655a98edbbf63c"],"382fe3a6ca9745891afebda9b9a57cc158305545":["4231f130465e144b1f115854690fe6c5afb61917"],"2dd6ecb8250c497ed227653279d6a4f470bfbb31":["872cff1d3a554e0cd64014cd97f88d3002b0f491"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["2dd6ecb8250c497ed227653279d6a4f470bfbb31","386d1b0dcb065f1bfc494b1407cb41c536b95485"],"60ba444201d2570214b6fcf1d15600dc1a01f548":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b03ea9834e2d1bc787272cb563d331fa60f8686d":["60ba444201d2570214b6fcf1d15600dc1a01f548"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":["e6e919043fa85ee891123768dd655a98edbbf63c","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"386d1b0dcb065f1bfc494b1407cb41c536b95485":["2dd6ecb8250c497ed227653279d6a4f470bfbb31"],"e6e919043fa85ee891123768dd655a98edbbf63c":["382fe3a6ca9745891afebda9b9a57cc158305545"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4231f130465e144b1f115854690fe6c5afb61917":["382fe3a6ca9745891afebda9b9a57cc158305545"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["2dd6ecb8250c497ed227653279d6a4f470bfbb31","b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"382fe3a6ca9745891afebda9b9a57cc158305545":["e6e919043fa85ee891123768dd655a98edbbf63c"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"2dd6ecb8250c497ed227653279d6a4f470bfbb31":["5cab9a86bd67202d20b6adc463008c8e982b070a","386d1b0dcb065f1bfc494b1407cb41c536b95485"],"60ba444201d2570214b6fcf1d15600dc1a01f548":["b03ea9834e2d1bc787272cb563d331fa60f8686d"],"b03ea9834e2d1bc787272cb563d331fa60f8686d":["4231f130465e144b1f115854690fe6c5afb61917"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["60ba444201d2570214b6fcf1d15600dc1a01f548"],"386d1b0dcb065f1bfc494b1407cb41c536b95485":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"e6e919043fa85ee891123768dd655a98edbbf63c":["872cff1d3a554e0cd64014cd97f88d3002b0f491","b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b65b350ca9588f9fc76ce7d6804160d06c45ff42","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}