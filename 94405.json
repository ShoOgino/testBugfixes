{"path":"src/java/org/apache/lucene/index/DocumentsWriter#appendPostings(ThreadState.FieldData[],TermInfosWriter,IndexOutput,IndexOutput).mjava","commits":[{"id":"4350b17bd363cd13a95171b8df1ca62ea4c3e71c","date":1183562198,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#appendPostings(ThreadState.FieldData[],TermInfosWriter,IndexOutput,IndexOutput).mjava","pathOld":"/dev/null","sourceNew":"  /* Walk through all unique text tokens (Posting\n   * instances) found in this field and serialize them\n   * into a single RAM segment. */\n  void appendPostings(ThreadState.FieldData[] fields,\n                      TermInfosWriter termsOut,\n                      IndexOutput freqOut,\n                      IndexOutput proxOut)\n    throws CorruptIndexException, IOException {\n\n    final String fieldName = fields[0].fieldInfo.name;\n    int numFields = fields.length;\n\n    final FieldMergeState[] mergeStates = new FieldMergeState[numFields];\n\n    for(int i=0;i<numFields;i++) {\n      FieldMergeState fms = mergeStates[i] = new FieldMergeState();\n      fms.field = fields[i];\n      fms.postings = fms.field.sortPostings();\n\n      assert fms.field.fieldInfo == fields[0].fieldInfo;\n\n      // Should always be true\n      boolean result = fms.nextTerm();\n      assert result;\n    }\n\n    Posting lastPosting = null;\n    final int skipInterval = termsOut.skipInterval;\n    currentFieldStorePayloads = fields[0].fieldInfo.storePayloads;\n\n    FieldMergeState[] termStates = new FieldMergeState[numFields];\n\n    while(numFields > 0) {\n\n      // Get the next term to merge\n      termStates[0] = mergeStates[0];\n      int numToMerge = 1;\n\n      for(int i=1;i<numFields;i++) {\n        final char[] text = mergeStates[i].text;\n        final int textOffset = mergeStates[i].textOffset;\n        final int cmp = compareText(text, textOffset, termStates[0].text, termStates[0].textOffset);\n\n        if (cmp < 0) {\n          termStates[0] = mergeStates[i];\n          numToMerge = 1;\n        } else if (cmp == 0)\n          termStates[numToMerge++] = mergeStates[i];\n      }\n\n      int df = 0;\n      int lastPayloadLength = -1;\n\n      int lastDoc = 0;\n\n      final char[] text = termStates[0].text;\n      final int start = termStates[0].textOffset;\n      int pos = start;\n      while(text[pos] != 0xffff)\n        pos++;\n\n      // TODO: can we avoid 2 new objects here?\n      Term term = new Term(fieldName, new String(text, start, pos-start));\n\n      long freqPointer = freqOut.getFilePointer();\n      long proxPointer = proxOut.getFilePointer();\n\n      skipListWriter.resetSkip();\n\n      // Now termStates has numToMerge FieldMergeStates\n      // which all share the same term.  Now we must\n      // interleave the docID streams.\n      while(numToMerge > 0) {\n        \n        if ((++df % skipInterval) == 0) {\n          skipListWriter.setSkipData(lastDoc, currentFieldStorePayloads, lastPayloadLength);\n          skipListWriter.bufferSkip(df);\n        }\n\n        FieldMergeState minState = termStates[0];\n        for(int i=1;i<numToMerge;i++)\n          if (termStates[i].docID < minState.docID)\n            minState = termStates[i];\n\n        final int doc = minState.docID;\n        final int termDocFreq = minState.termFreq;\n\n        assert doc < numDocsInRAM;\n        assert doc > lastDoc || df == 1;\n\n        final int newDocCode = (doc-lastDoc)<<1;\n        lastDoc = doc;\n\n        final ByteSliceReader prox = minState.prox;\n\n        // Carefully copy over the prox + payload info,\n        // changing the format to match Lucene's segment\n        // format.\n        for(int j=0;j<termDocFreq;j++) {\n          final int code = prox.readVInt();\n          if (currentFieldStorePayloads) {\n            final int payloadLength;\n            if ((code & 1) != 0) {\n              // This position has a payload\n              payloadLength = prox.readVInt();\n            } else\n              payloadLength = 0;\n            if (payloadLength != lastPayloadLength) {\n              proxOut.writeVInt(code|1);\n              proxOut.writeVInt(payloadLength);\n              lastPayloadLength = payloadLength;\n            } else\n              proxOut.writeVInt(code & (~1));\n            if (payloadLength > 0)\n              copyBytes(prox, proxOut, payloadLength);\n          } else {\n            assert 0 == (code & 1);\n            proxOut.writeVInt(code>>1);\n          }\n        }\n\n        if (1 == termDocFreq) {\n          freqOut.writeVInt(newDocCode|1);\n        } else {\n          freqOut.writeVInt(newDocCode);\n          freqOut.writeVInt(termDocFreq);\n        }\n\n        if (!minState.nextDoc()) {\n\n          // Remove from termStates\n          int upto = 0;\n          for(int i=0;i<numToMerge;i++)\n            if (termStates[i] != minState)\n              termStates[upto++] = termStates[i];\n          numToMerge--;\n          assert upto == numToMerge;\n\n          // Advance this state to the next term\n\n          if (!minState.nextTerm()) {\n            // OK, no more terms, so remove from mergeStates\n            // as well\n            upto = 0;\n            for(int i=0;i<numFields;i++)\n              if (mergeStates[i] != minState)\n                mergeStates[upto++] = mergeStates[i];\n            numFields--;\n            assert upto == numFields;\n          }\n        }\n      }\n\n      assert df > 0;\n\n      // Done merging this term\n\n      long skipPointer = skipListWriter.writeSkip(freqOut);\n\n      // Write term\n      termInfo.set(df, freqPointer, proxPointer, (int) (skipPointer - freqPointer));\n      termsOut.add(term, termInfo);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6a1f29c9b1051488fd5fa7d56c98db5f4388408","date":1196281221,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#appendPostings(ThreadState.FieldData[],TermInfosWriter,IndexOutput,IndexOutput).mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#appendPostings(ThreadState.FieldData[],TermInfosWriter,IndexOutput,IndexOutput).mjava","sourceNew":"  /* Walk through all unique text tokens (Posting\n   * instances) found in this field and serialize them\n   * into a single RAM segment. */\n  void appendPostings(ThreadState.FieldData[] fields,\n                      TermInfosWriter termsOut,\n                      IndexOutput freqOut,\n                      IndexOutput proxOut)\n    throws CorruptIndexException, IOException {\n\n    final String fieldName = fields[0].fieldInfo.name;\n    int numFields = fields.length;\n\n    final FieldMergeState[] mergeStates = new FieldMergeState[numFields];\n\n    for(int i=0;i<numFields;i++) {\n      FieldMergeState fms = mergeStates[i] = new FieldMergeState();\n      fms.field = fields[i];\n      fms.postings = fms.field.sortPostings();\n\n      assert fms.field.fieldInfo == fields[0].fieldInfo;\n\n      // Should always be true\n      boolean result = fms.nextTerm();\n      assert result;\n    }\n\n    final int skipInterval = termsOut.skipInterval;\n    currentFieldStorePayloads = fields[0].fieldInfo.storePayloads;\n\n    FieldMergeState[] termStates = new FieldMergeState[numFields];\n\n    while(numFields > 0) {\n\n      // Get the next term to merge\n      termStates[0] = mergeStates[0];\n      int numToMerge = 1;\n\n      for(int i=1;i<numFields;i++) {\n        final char[] text = mergeStates[i].text;\n        final int textOffset = mergeStates[i].textOffset;\n        final int cmp = compareText(text, textOffset, termStates[0].text, termStates[0].textOffset);\n\n        if (cmp < 0) {\n          termStates[0] = mergeStates[i];\n          numToMerge = 1;\n        } else if (cmp == 0)\n          termStates[numToMerge++] = mergeStates[i];\n      }\n\n      int df = 0;\n      int lastPayloadLength = -1;\n\n      int lastDoc = 0;\n\n      final char[] text = termStates[0].text;\n      final int start = termStates[0].textOffset;\n      int pos = start;\n      while(text[pos] != 0xffff)\n        pos++;\n\n      // TODO: can we avoid 2 new objects here?\n      Term term = new Term(fieldName, new String(text, start, pos-start));\n\n      long freqPointer = freqOut.getFilePointer();\n      long proxPointer = proxOut.getFilePointer();\n\n      skipListWriter.resetSkip();\n\n      // Now termStates has numToMerge FieldMergeStates\n      // which all share the same term.  Now we must\n      // interleave the docID streams.\n      while(numToMerge > 0) {\n        \n        if ((++df % skipInterval) == 0) {\n          skipListWriter.setSkipData(lastDoc, currentFieldStorePayloads, lastPayloadLength);\n          skipListWriter.bufferSkip(df);\n        }\n\n        FieldMergeState minState = termStates[0];\n        for(int i=1;i<numToMerge;i++)\n          if (termStates[i].docID < minState.docID)\n            minState = termStates[i];\n\n        final int doc = minState.docID;\n        final int termDocFreq = minState.termFreq;\n\n        assert doc < numDocsInRAM;\n        assert doc > lastDoc || df == 1;\n\n        final int newDocCode = (doc-lastDoc)<<1;\n        lastDoc = doc;\n\n        final ByteSliceReader prox = minState.prox;\n\n        // Carefully copy over the prox + payload info,\n        // changing the format to match Lucene's segment\n        // format.\n        for(int j=0;j<termDocFreq;j++) {\n          final int code = prox.readVInt();\n          if (currentFieldStorePayloads) {\n            final int payloadLength;\n            if ((code & 1) != 0) {\n              // This position has a payload\n              payloadLength = prox.readVInt();\n            } else\n              payloadLength = 0;\n            if (payloadLength != lastPayloadLength) {\n              proxOut.writeVInt(code|1);\n              proxOut.writeVInt(payloadLength);\n              lastPayloadLength = payloadLength;\n            } else\n              proxOut.writeVInt(code & (~1));\n            if (payloadLength > 0)\n              copyBytes(prox, proxOut, payloadLength);\n          } else {\n            assert 0 == (code & 1);\n            proxOut.writeVInt(code>>1);\n          }\n        }\n\n        if (1 == termDocFreq) {\n          freqOut.writeVInt(newDocCode|1);\n        } else {\n          freqOut.writeVInt(newDocCode);\n          freqOut.writeVInt(termDocFreq);\n        }\n\n        if (!minState.nextDoc()) {\n\n          // Remove from termStates\n          int upto = 0;\n          for(int i=0;i<numToMerge;i++)\n            if (termStates[i] != minState)\n              termStates[upto++] = termStates[i];\n          numToMerge--;\n          assert upto == numToMerge;\n\n          // Advance this state to the next term\n\n          if (!minState.nextTerm()) {\n            // OK, no more terms, so remove from mergeStates\n            // as well\n            upto = 0;\n            for(int i=0;i<numFields;i++)\n              if (mergeStates[i] != minState)\n                mergeStates[upto++] = mergeStates[i];\n            numFields--;\n            assert upto == numFields;\n          }\n        }\n      }\n\n      assert df > 0;\n\n      // Done merging this term\n\n      long skipPointer = skipListWriter.writeSkip(freqOut);\n\n      // Write term\n      termInfo.set(df, freqPointer, proxPointer, (int) (skipPointer - freqPointer));\n      termsOut.add(term, termInfo);\n    }\n  }\n\n","sourceOld":"  /* Walk through all unique text tokens (Posting\n   * instances) found in this field and serialize them\n   * into a single RAM segment. */\n  void appendPostings(ThreadState.FieldData[] fields,\n                      TermInfosWriter termsOut,\n                      IndexOutput freqOut,\n                      IndexOutput proxOut)\n    throws CorruptIndexException, IOException {\n\n    final String fieldName = fields[0].fieldInfo.name;\n    int numFields = fields.length;\n\n    final FieldMergeState[] mergeStates = new FieldMergeState[numFields];\n\n    for(int i=0;i<numFields;i++) {\n      FieldMergeState fms = mergeStates[i] = new FieldMergeState();\n      fms.field = fields[i];\n      fms.postings = fms.field.sortPostings();\n\n      assert fms.field.fieldInfo == fields[0].fieldInfo;\n\n      // Should always be true\n      boolean result = fms.nextTerm();\n      assert result;\n    }\n\n    Posting lastPosting = null;\n    final int skipInterval = termsOut.skipInterval;\n    currentFieldStorePayloads = fields[0].fieldInfo.storePayloads;\n\n    FieldMergeState[] termStates = new FieldMergeState[numFields];\n\n    while(numFields > 0) {\n\n      // Get the next term to merge\n      termStates[0] = mergeStates[0];\n      int numToMerge = 1;\n\n      for(int i=1;i<numFields;i++) {\n        final char[] text = mergeStates[i].text;\n        final int textOffset = mergeStates[i].textOffset;\n        final int cmp = compareText(text, textOffset, termStates[0].text, termStates[0].textOffset);\n\n        if (cmp < 0) {\n          termStates[0] = mergeStates[i];\n          numToMerge = 1;\n        } else if (cmp == 0)\n          termStates[numToMerge++] = mergeStates[i];\n      }\n\n      int df = 0;\n      int lastPayloadLength = -1;\n\n      int lastDoc = 0;\n\n      final char[] text = termStates[0].text;\n      final int start = termStates[0].textOffset;\n      int pos = start;\n      while(text[pos] != 0xffff)\n        pos++;\n\n      // TODO: can we avoid 2 new objects here?\n      Term term = new Term(fieldName, new String(text, start, pos-start));\n\n      long freqPointer = freqOut.getFilePointer();\n      long proxPointer = proxOut.getFilePointer();\n\n      skipListWriter.resetSkip();\n\n      // Now termStates has numToMerge FieldMergeStates\n      // which all share the same term.  Now we must\n      // interleave the docID streams.\n      while(numToMerge > 0) {\n        \n        if ((++df % skipInterval) == 0) {\n          skipListWriter.setSkipData(lastDoc, currentFieldStorePayloads, lastPayloadLength);\n          skipListWriter.bufferSkip(df);\n        }\n\n        FieldMergeState minState = termStates[0];\n        for(int i=1;i<numToMerge;i++)\n          if (termStates[i].docID < minState.docID)\n            minState = termStates[i];\n\n        final int doc = minState.docID;\n        final int termDocFreq = minState.termFreq;\n\n        assert doc < numDocsInRAM;\n        assert doc > lastDoc || df == 1;\n\n        final int newDocCode = (doc-lastDoc)<<1;\n        lastDoc = doc;\n\n        final ByteSliceReader prox = minState.prox;\n\n        // Carefully copy over the prox + payload info,\n        // changing the format to match Lucene's segment\n        // format.\n        for(int j=0;j<termDocFreq;j++) {\n          final int code = prox.readVInt();\n          if (currentFieldStorePayloads) {\n            final int payloadLength;\n            if ((code & 1) != 0) {\n              // This position has a payload\n              payloadLength = prox.readVInt();\n            } else\n              payloadLength = 0;\n            if (payloadLength != lastPayloadLength) {\n              proxOut.writeVInt(code|1);\n              proxOut.writeVInt(payloadLength);\n              lastPayloadLength = payloadLength;\n            } else\n              proxOut.writeVInt(code & (~1));\n            if (payloadLength > 0)\n              copyBytes(prox, proxOut, payloadLength);\n          } else {\n            assert 0 == (code & 1);\n            proxOut.writeVInt(code>>1);\n          }\n        }\n\n        if (1 == termDocFreq) {\n          freqOut.writeVInt(newDocCode|1);\n        } else {\n          freqOut.writeVInt(newDocCode);\n          freqOut.writeVInt(termDocFreq);\n        }\n\n        if (!minState.nextDoc()) {\n\n          // Remove from termStates\n          int upto = 0;\n          for(int i=0;i<numToMerge;i++)\n            if (termStates[i] != minState)\n              termStates[upto++] = termStates[i];\n          numToMerge--;\n          assert upto == numToMerge;\n\n          // Advance this state to the next term\n\n          if (!minState.nextTerm()) {\n            // OK, no more terms, so remove from mergeStates\n            // as well\n            upto = 0;\n            for(int i=0;i<numFields;i++)\n              if (mergeStates[i] != minState)\n                mergeStates[upto++] = mergeStates[i];\n            numFields--;\n            assert upto == numFields;\n          }\n        }\n      }\n\n      assert df > 0;\n\n      // Done merging this term\n\n      long skipPointer = skipListWriter.writeSkip(freqOut);\n\n      // Write term\n      termInfo.set(df, freqPointer, proxPointer, (int) (skipPointer - freqPointer));\n      termsOut.add(term, termInfo);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c1f822dcb4624ad203d96e63bcb23b498e1bd0a","date":1199647785,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#appendPostings(ThreadState.FieldData[],TermInfosWriter,IndexOutput,IndexOutput).mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#appendPostings(ThreadState.FieldData[],TermInfosWriter,IndexOutput,IndexOutput).mjava","sourceNew":"  /* Walk through all unique text tokens (Posting\n   * instances) found in this field and serialize them\n   * into a single RAM segment. */\n  void appendPostings(ThreadState.FieldData[] fields,\n                      TermInfosWriter termsOut,\n                      IndexOutput freqOut,\n                      IndexOutput proxOut)\n    throws CorruptIndexException, IOException {\n\n    final int fieldNumber = fields[0].fieldInfo.number;\n    int numFields = fields.length;\n\n    final FieldMergeState[] mergeStates = new FieldMergeState[numFields];\n\n    for(int i=0;i<numFields;i++) {\n      FieldMergeState fms = mergeStates[i] = new FieldMergeState();\n      fms.field = fields[i];\n      fms.postings = fms.field.sortPostings();\n\n      assert fms.field.fieldInfo == fields[0].fieldInfo;\n\n      // Should always be true\n      boolean result = fms.nextTerm();\n      assert result;\n    }\n\n    final int skipInterval = termsOut.skipInterval;\n    currentFieldStorePayloads = fields[0].fieldInfo.storePayloads;\n\n    FieldMergeState[] termStates = new FieldMergeState[numFields];\n\n    while(numFields > 0) {\n\n      // Get the next term to merge\n      termStates[0] = mergeStates[0];\n      int numToMerge = 1;\n\n      for(int i=1;i<numFields;i++) {\n        final char[] text = mergeStates[i].text;\n        final int textOffset = mergeStates[i].textOffset;\n        final int cmp = compareText(text, textOffset, termStates[0].text, termStates[0].textOffset);\n\n        if (cmp < 0) {\n          termStates[0] = mergeStates[i];\n          numToMerge = 1;\n        } else if (cmp == 0)\n          termStates[numToMerge++] = mergeStates[i];\n      }\n\n      int df = 0;\n      int lastPayloadLength = -1;\n\n      int lastDoc = 0;\n\n      final char[] text = termStates[0].text;\n      final int start = termStates[0].textOffset;\n      int pos = start;\n      while(text[pos] != 0xffff)\n        pos++;\n\n      long freqPointer = freqOut.getFilePointer();\n      long proxPointer = proxOut.getFilePointer();\n\n      skipListWriter.resetSkip();\n\n      // Now termStates has numToMerge FieldMergeStates\n      // which all share the same term.  Now we must\n      // interleave the docID streams.\n      while(numToMerge > 0) {\n        \n        if ((++df % skipInterval) == 0) {\n          skipListWriter.setSkipData(lastDoc, currentFieldStorePayloads, lastPayloadLength);\n          skipListWriter.bufferSkip(df);\n        }\n\n        FieldMergeState minState = termStates[0];\n        for(int i=1;i<numToMerge;i++)\n          if (termStates[i].docID < minState.docID)\n            minState = termStates[i];\n\n        final int doc = minState.docID;\n        final int termDocFreq = minState.termFreq;\n\n        assert doc < numDocsInRAM;\n        assert doc > lastDoc || df == 1;\n\n        final int newDocCode = (doc-lastDoc)<<1;\n        lastDoc = doc;\n\n        final ByteSliceReader prox = minState.prox;\n\n        // Carefully copy over the prox + payload info,\n        // changing the format to match Lucene's segment\n        // format.\n        for(int j=0;j<termDocFreq;j++) {\n          final int code = prox.readVInt();\n          if (currentFieldStorePayloads) {\n            final int payloadLength;\n            if ((code & 1) != 0) {\n              // This position has a payload\n              payloadLength = prox.readVInt();\n            } else\n              payloadLength = 0;\n            if (payloadLength != lastPayloadLength) {\n              proxOut.writeVInt(code|1);\n              proxOut.writeVInt(payloadLength);\n              lastPayloadLength = payloadLength;\n            } else\n              proxOut.writeVInt(code & (~1));\n            if (payloadLength > 0)\n              copyBytes(prox, proxOut, payloadLength);\n          } else {\n            assert 0 == (code & 1);\n            proxOut.writeVInt(code>>1);\n          }\n        }\n\n        if (1 == termDocFreq) {\n          freqOut.writeVInt(newDocCode|1);\n        } else {\n          freqOut.writeVInt(newDocCode);\n          freqOut.writeVInt(termDocFreq);\n        }\n\n        if (!minState.nextDoc()) {\n\n          // Remove from termStates\n          int upto = 0;\n          for(int i=0;i<numToMerge;i++)\n            if (termStates[i] != minState)\n              termStates[upto++] = termStates[i];\n          numToMerge--;\n          assert upto == numToMerge;\n\n          // Advance this state to the next term\n\n          if (!minState.nextTerm()) {\n            // OK, no more terms, so remove from mergeStates\n            // as well\n            upto = 0;\n            for(int i=0;i<numFields;i++)\n              if (mergeStates[i] != minState)\n                mergeStates[upto++] = mergeStates[i];\n            numFields--;\n            assert upto == numFields;\n          }\n        }\n      }\n\n      assert df > 0;\n\n      // Done merging this term\n\n      long skipPointer = skipListWriter.writeSkip(freqOut);\n\n      // Write term\n      termInfo.set(df, freqPointer, proxPointer, (int) (skipPointer - freqPointer));\n      termsOut.add(fieldNumber, text, start, pos-start, termInfo);\n    }\n  }\n\n","sourceOld":"  /* Walk through all unique text tokens (Posting\n   * instances) found in this field and serialize them\n   * into a single RAM segment. */\n  void appendPostings(ThreadState.FieldData[] fields,\n                      TermInfosWriter termsOut,\n                      IndexOutput freqOut,\n                      IndexOutput proxOut)\n    throws CorruptIndexException, IOException {\n\n    final String fieldName = fields[0].fieldInfo.name;\n    int numFields = fields.length;\n\n    final FieldMergeState[] mergeStates = new FieldMergeState[numFields];\n\n    for(int i=0;i<numFields;i++) {\n      FieldMergeState fms = mergeStates[i] = new FieldMergeState();\n      fms.field = fields[i];\n      fms.postings = fms.field.sortPostings();\n\n      assert fms.field.fieldInfo == fields[0].fieldInfo;\n\n      // Should always be true\n      boolean result = fms.nextTerm();\n      assert result;\n    }\n\n    final int skipInterval = termsOut.skipInterval;\n    currentFieldStorePayloads = fields[0].fieldInfo.storePayloads;\n\n    FieldMergeState[] termStates = new FieldMergeState[numFields];\n\n    while(numFields > 0) {\n\n      // Get the next term to merge\n      termStates[0] = mergeStates[0];\n      int numToMerge = 1;\n\n      for(int i=1;i<numFields;i++) {\n        final char[] text = mergeStates[i].text;\n        final int textOffset = mergeStates[i].textOffset;\n        final int cmp = compareText(text, textOffset, termStates[0].text, termStates[0].textOffset);\n\n        if (cmp < 0) {\n          termStates[0] = mergeStates[i];\n          numToMerge = 1;\n        } else if (cmp == 0)\n          termStates[numToMerge++] = mergeStates[i];\n      }\n\n      int df = 0;\n      int lastPayloadLength = -1;\n\n      int lastDoc = 0;\n\n      final char[] text = termStates[0].text;\n      final int start = termStates[0].textOffset;\n      int pos = start;\n      while(text[pos] != 0xffff)\n        pos++;\n\n      // TODO: can we avoid 2 new objects here?\n      Term term = new Term(fieldName, new String(text, start, pos-start));\n\n      long freqPointer = freqOut.getFilePointer();\n      long proxPointer = proxOut.getFilePointer();\n\n      skipListWriter.resetSkip();\n\n      // Now termStates has numToMerge FieldMergeStates\n      // which all share the same term.  Now we must\n      // interleave the docID streams.\n      while(numToMerge > 0) {\n        \n        if ((++df % skipInterval) == 0) {\n          skipListWriter.setSkipData(lastDoc, currentFieldStorePayloads, lastPayloadLength);\n          skipListWriter.bufferSkip(df);\n        }\n\n        FieldMergeState minState = termStates[0];\n        for(int i=1;i<numToMerge;i++)\n          if (termStates[i].docID < minState.docID)\n            minState = termStates[i];\n\n        final int doc = minState.docID;\n        final int termDocFreq = minState.termFreq;\n\n        assert doc < numDocsInRAM;\n        assert doc > lastDoc || df == 1;\n\n        final int newDocCode = (doc-lastDoc)<<1;\n        lastDoc = doc;\n\n        final ByteSliceReader prox = minState.prox;\n\n        // Carefully copy over the prox + payload info,\n        // changing the format to match Lucene's segment\n        // format.\n        for(int j=0;j<termDocFreq;j++) {\n          final int code = prox.readVInt();\n          if (currentFieldStorePayloads) {\n            final int payloadLength;\n            if ((code & 1) != 0) {\n              // This position has a payload\n              payloadLength = prox.readVInt();\n            } else\n              payloadLength = 0;\n            if (payloadLength != lastPayloadLength) {\n              proxOut.writeVInt(code|1);\n              proxOut.writeVInt(payloadLength);\n              lastPayloadLength = payloadLength;\n            } else\n              proxOut.writeVInt(code & (~1));\n            if (payloadLength > 0)\n              copyBytes(prox, proxOut, payloadLength);\n          } else {\n            assert 0 == (code & 1);\n            proxOut.writeVInt(code>>1);\n          }\n        }\n\n        if (1 == termDocFreq) {\n          freqOut.writeVInt(newDocCode|1);\n        } else {\n          freqOut.writeVInt(newDocCode);\n          freqOut.writeVInt(termDocFreq);\n        }\n\n        if (!minState.nextDoc()) {\n\n          // Remove from termStates\n          int upto = 0;\n          for(int i=0;i<numToMerge;i++)\n            if (termStates[i] != minState)\n              termStates[upto++] = termStates[i];\n          numToMerge--;\n          assert upto == numToMerge;\n\n          // Advance this state to the next term\n\n          if (!minState.nextTerm()) {\n            // OK, no more terms, so remove from mergeStates\n            // as well\n            upto = 0;\n            for(int i=0;i<numFields;i++)\n              if (mergeStates[i] != minState)\n                mergeStates[upto++] = mergeStates[i];\n            numFields--;\n            assert upto == numFields;\n          }\n        }\n      }\n\n      assert df > 0;\n\n      // Done merging this term\n\n      long skipPointer = skipListWriter.writeSkip(freqOut);\n\n      // Write term\n      termInfo.set(df, freqPointer, proxPointer, (int) (skipPointer - freqPointer));\n      termsOut.add(term, termInfo);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a0af3a442be522899177e5e11384a45a6784a3f","date":1205348952,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#appendPostings(DocumentsWriterFieldData[],TermInfosWriter,IndexOutput,IndexOutput).mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#appendPostings(ThreadState.FieldData[],TermInfosWriter,IndexOutput,IndexOutput).mjava","sourceNew":"  /* Walk through all unique text tokens (Posting\n   * instances) found in this field and serialize them\n   * into a single RAM segment. */\n  void appendPostings(DocumentsWriterFieldData[] fields,\n                      TermInfosWriter termsOut,\n                      IndexOutput freqOut,\n                      IndexOutput proxOut)\n    throws CorruptIndexException, IOException {\n\n    final int fieldNumber = fields[0].fieldInfo.number;\n    int numFields = fields.length;\n\n    final DocumentsWriterFieldMergeState[] mergeStates = new DocumentsWriterFieldMergeState[numFields];\n\n    for(int i=0;i<numFields;i++) {\n      DocumentsWriterFieldMergeState fms = mergeStates[i] = new DocumentsWriterFieldMergeState();\n      fms.field = fields[i];\n      fms.postings = fms.field.sortPostings();\n\n      assert fms.field.fieldInfo == fields[0].fieldInfo;\n\n      // Should always be true\n      boolean result = fms.nextTerm();\n      assert result;\n    }\n\n    final int skipInterval = termsOut.skipInterval;\n    currentFieldStorePayloads = fields[0].fieldInfo.storePayloads;\n\n    DocumentsWriterFieldMergeState[] termStates = new DocumentsWriterFieldMergeState[numFields];\n\n    while(numFields > 0) {\n\n      // Get the next term to merge\n      termStates[0] = mergeStates[0];\n      int numToMerge = 1;\n\n      for(int i=1;i<numFields;i++) {\n        final char[] text = mergeStates[i].text;\n        final int textOffset = mergeStates[i].textOffset;\n        final int cmp = compareText(text, textOffset, termStates[0].text, termStates[0].textOffset);\n\n        if (cmp < 0) {\n          termStates[0] = mergeStates[i];\n          numToMerge = 1;\n        } else if (cmp == 0)\n          termStates[numToMerge++] = mergeStates[i];\n      }\n\n      int df = 0;\n      int lastPayloadLength = -1;\n\n      int lastDoc = 0;\n\n      final char[] text = termStates[0].text;\n      final int start = termStates[0].textOffset;\n      int pos = start;\n      while(text[pos] != 0xffff)\n        pos++;\n\n      long freqPointer = freqOut.getFilePointer();\n      long proxPointer = proxOut.getFilePointer();\n\n      skipListWriter.resetSkip();\n\n      // Now termStates has numToMerge FieldMergeStates\n      // which all share the same term.  Now we must\n      // interleave the docID streams.\n      while(numToMerge > 0) {\n        \n        if ((++df % skipInterval) == 0) {\n          skipListWriter.setSkipData(lastDoc, currentFieldStorePayloads, lastPayloadLength);\n          skipListWriter.bufferSkip(df);\n        }\n\n        DocumentsWriterFieldMergeState minState = termStates[0];\n        for(int i=1;i<numToMerge;i++)\n          if (termStates[i].docID < minState.docID)\n            minState = termStates[i];\n\n        final int doc = minState.docID;\n        final int termDocFreq = minState.termFreq;\n\n        assert doc < numDocsInRAM;\n        assert doc > lastDoc || df == 1;\n\n        final int newDocCode = (doc-lastDoc)<<1;\n        lastDoc = doc;\n\n        final ByteSliceReader prox = minState.prox;\n\n        // Carefully copy over the prox + payload info,\n        // changing the format to match Lucene's segment\n        // format.\n        for(int j=0;j<termDocFreq;j++) {\n          final int code = prox.readVInt();\n          if (currentFieldStorePayloads) {\n            final int payloadLength;\n            if ((code & 1) != 0) {\n              // This position has a payload\n              payloadLength = prox.readVInt();\n            } else\n              payloadLength = 0;\n            if (payloadLength != lastPayloadLength) {\n              proxOut.writeVInt(code|1);\n              proxOut.writeVInt(payloadLength);\n              lastPayloadLength = payloadLength;\n            } else\n              proxOut.writeVInt(code & (~1));\n            if (payloadLength > 0)\n              copyBytes(prox, proxOut, payloadLength);\n          } else {\n            assert 0 == (code & 1);\n            proxOut.writeVInt(code>>1);\n          }\n        }\n\n        if (1 == termDocFreq) {\n          freqOut.writeVInt(newDocCode|1);\n        } else {\n          freqOut.writeVInt(newDocCode);\n          freqOut.writeVInt(termDocFreq);\n        }\n\n        if (!minState.nextDoc()) {\n\n          // Remove from termStates\n          int upto = 0;\n          for(int i=0;i<numToMerge;i++)\n            if (termStates[i] != minState)\n              termStates[upto++] = termStates[i];\n          numToMerge--;\n          assert upto == numToMerge;\n\n          // Advance this state to the next term\n\n          if (!minState.nextTerm()) {\n            // OK, no more terms, so remove from mergeStates\n            // as well\n            upto = 0;\n            for(int i=0;i<numFields;i++)\n              if (mergeStates[i] != minState)\n                mergeStates[upto++] = mergeStates[i];\n            numFields--;\n            assert upto == numFields;\n          }\n        }\n      }\n\n      assert df > 0;\n\n      // Done merging this term\n\n      long skipPointer = skipListWriter.writeSkip(freqOut);\n\n      // Write term\n      termInfo.set(df, freqPointer, proxPointer, (int) (skipPointer - freqPointer));\n      termsOut.add(fieldNumber, text, start, pos-start, termInfo);\n    }\n  }\n\n","sourceOld":"  /* Walk through all unique text tokens (Posting\n   * instances) found in this field and serialize them\n   * into a single RAM segment. */\n  void appendPostings(ThreadState.FieldData[] fields,\n                      TermInfosWriter termsOut,\n                      IndexOutput freqOut,\n                      IndexOutput proxOut)\n    throws CorruptIndexException, IOException {\n\n    final int fieldNumber = fields[0].fieldInfo.number;\n    int numFields = fields.length;\n\n    final FieldMergeState[] mergeStates = new FieldMergeState[numFields];\n\n    for(int i=0;i<numFields;i++) {\n      FieldMergeState fms = mergeStates[i] = new FieldMergeState();\n      fms.field = fields[i];\n      fms.postings = fms.field.sortPostings();\n\n      assert fms.field.fieldInfo == fields[0].fieldInfo;\n\n      // Should always be true\n      boolean result = fms.nextTerm();\n      assert result;\n    }\n\n    final int skipInterval = termsOut.skipInterval;\n    currentFieldStorePayloads = fields[0].fieldInfo.storePayloads;\n\n    FieldMergeState[] termStates = new FieldMergeState[numFields];\n\n    while(numFields > 0) {\n\n      // Get the next term to merge\n      termStates[0] = mergeStates[0];\n      int numToMerge = 1;\n\n      for(int i=1;i<numFields;i++) {\n        final char[] text = mergeStates[i].text;\n        final int textOffset = mergeStates[i].textOffset;\n        final int cmp = compareText(text, textOffset, termStates[0].text, termStates[0].textOffset);\n\n        if (cmp < 0) {\n          termStates[0] = mergeStates[i];\n          numToMerge = 1;\n        } else if (cmp == 0)\n          termStates[numToMerge++] = mergeStates[i];\n      }\n\n      int df = 0;\n      int lastPayloadLength = -1;\n\n      int lastDoc = 0;\n\n      final char[] text = termStates[0].text;\n      final int start = termStates[0].textOffset;\n      int pos = start;\n      while(text[pos] != 0xffff)\n        pos++;\n\n      long freqPointer = freqOut.getFilePointer();\n      long proxPointer = proxOut.getFilePointer();\n\n      skipListWriter.resetSkip();\n\n      // Now termStates has numToMerge FieldMergeStates\n      // which all share the same term.  Now we must\n      // interleave the docID streams.\n      while(numToMerge > 0) {\n        \n        if ((++df % skipInterval) == 0) {\n          skipListWriter.setSkipData(lastDoc, currentFieldStorePayloads, lastPayloadLength);\n          skipListWriter.bufferSkip(df);\n        }\n\n        FieldMergeState minState = termStates[0];\n        for(int i=1;i<numToMerge;i++)\n          if (termStates[i].docID < minState.docID)\n            minState = termStates[i];\n\n        final int doc = minState.docID;\n        final int termDocFreq = minState.termFreq;\n\n        assert doc < numDocsInRAM;\n        assert doc > lastDoc || df == 1;\n\n        final int newDocCode = (doc-lastDoc)<<1;\n        lastDoc = doc;\n\n        final ByteSliceReader prox = minState.prox;\n\n        // Carefully copy over the prox + payload info,\n        // changing the format to match Lucene's segment\n        // format.\n        for(int j=0;j<termDocFreq;j++) {\n          final int code = prox.readVInt();\n          if (currentFieldStorePayloads) {\n            final int payloadLength;\n            if ((code & 1) != 0) {\n              // This position has a payload\n              payloadLength = prox.readVInt();\n            } else\n              payloadLength = 0;\n            if (payloadLength != lastPayloadLength) {\n              proxOut.writeVInt(code|1);\n              proxOut.writeVInt(payloadLength);\n              lastPayloadLength = payloadLength;\n            } else\n              proxOut.writeVInt(code & (~1));\n            if (payloadLength > 0)\n              copyBytes(prox, proxOut, payloadLength);\n          } else {\n            assert 0 == (code & 1);\n            proxOut.writeVInt(code>>1);\n          }\n        }\n\n        if (1 == termDocFreq) {\n          freqOut.writeVInt(newDocCode|1);\n        } else {\n          freqOut.writeVInt(newDocCode);\n          freqOut.writeVInt(termDocFreq);\n        }\n\n        if (!minState.nextDoc()) {\n\n          // Remove from termStates\n          int upto = 0;\n          for(int i=0;i<numToMerge;i++)\n            if (termStates[i] != minState)\n              termStates[upto++] = termStates[i];\n          numToMerge--;\n          assert upto == numToMerge;\n\n          // Advance this state to the next term\n\n          if (!minState.nextTerm()) {\n            // OK, no more terms, so remove from mergeStates\n            // as well\n            upto = 0;\n            for(int i=0;i<numFields;i++)\n              if (mergeStates[i] != minState)\n                mergeStates[upto++] = mergeStates[i];\n            numFields--;\n            assert upto == numFields;\n          }\n        }\n      }\n\n      assert df > 0;\n\n      // Done merging this term\n\n      long skipPointer = skipListWriter.writeSkip(freqOut);\n\n      // Write term\n      termInfo.set(df, freqPointer, proxPointer, (int) (skipPointer - freqPointer));\n      termsOut.add(fieldNumber, text, start, pos-start, termInfo);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7c1f822dcb4624ad203d96e63bcb23b498e1bd0a":["b6a1f29c9b1051488fd5fa7d56c98db5f4388408"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5a0af3a442be522899177e5e11384a45a6784a3f":["7c1f822dcb4624ad203d96e63bcb23b498e1bd0a"],"b6a1f29c9b1051488fd5fa7d56c98db5f4388408":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5a0af3a442be522899177e5e11384a45a6784a3f"]},"commit2Childs":{"7c1f822dcb4624ad203d96e63bcb23b498e1bd0a":["5a0af3a442be522899177e5e11384a45a6784a3f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"5a0af3a442be522899177e5e11384a45a6784a3f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b6a1f29c9b1051488fd5fa7d56c98db5f4388408":["7c1f822dcb4624ad203d96e63bcb23b498e1bd0a"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["b6a1f29c9b1051488fd5fa7d56c98db5f4388408"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}