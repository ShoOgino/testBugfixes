{"path":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","commits":[{"id":"9fc47cb7b4346802411bb432f501ed0673d7119e","date":1512640179,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, scoreMode, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, scoreMode, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public boolean isCacheable(LeafReaderContext ctx) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.isCacheable(ctx);\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public boolean isCacheable(LeafReaderContext ctx) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.isCacheable(ctx);\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"417142ff08fda9cf0b72d5133e63097a166c6458","date":1512729693,"type":1,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,boolean,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, scoreMode, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, scoreMode, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public boolean isCacheable(LeafReaderContext ctx) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.isCacheable(ctx);\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, needsScores, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, needsScores, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public boolean isCacheable(LeafReaderContext ctx) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.isCacheable(ctx);\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"657704b225b01c6ff4bada5b6667f1f60aaaad0f","date":1523436207,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, scoreMode, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, scoreMode, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Matches matches(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.matches(context, doc);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public boolean isCacheable(LeafReaderContext ctx) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.isCacheable(ctx);\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, scoreMode, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, scoreMode, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public boolean isCacheable(LeafReaderContext ctx) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.isCacheable(ctx);\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"43345f1452f9510f8aaadae6156fe0c834e7d957","date":1523483670,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, scoreMode, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, scoreMode, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Matches matches(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.matches(context, doc);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public boolean isCacheable(LeafReaderContext ctx) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.isCacheable(ctx);\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, scoreMode, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, scoreMode, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public boolean isCacheable(LeafReaderContext ctx) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.isCacheable(ctx);\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7","date":1552575873,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/IndexOrDocValuesQuery#createWeight(IndexSearcher,ScoreMode,float).mjava","sourceNew":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, scoreMode, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, scoreMode, boost);\n    return new Weight(this) {\n      @Override\n      public Matches matches(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.matches(context, doc);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public boolean isCacheable(LeafReaderContext ctx) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.isCacheable(ctx);\n      }\n\n    };\n  }\n\n","sourceOld":"  @Override\n  public Weight createWeight(IndexSearcher searcher, ScoreMode scoreMode, float boost) throws IOException {\n    final Weight indexWeight = indexQuery.createWeight(searcher, scoreMode, boost);\n    final Weight dvWeight = dvQuery.createWeight(searcher, scoreMode, boost);\n    return new Weight(this) {\n      @Override\n      public void extractTerms(Set<Term> terms) {\n        indexWeight.extractTerms(terms);\n      }\n\n      @Override\n      public Matches matches(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.matches(context, doc);\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext context, int doc) throws IOException {\n        // We need to check a single doc, so the dv query should perform better\n        return dvWeight.explain(context, doc);\n      }\n\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n        // Bulk scorers need to consume the entire set of docs, so using an\n        // index structure should perform better\n        return indexWeight.bulkScorer(context);\n      }\n\n      @Override\n      public ScorerSupplier scorerSupplier(LeafReaderContext context) throws IOException {\n        final ScorerSupplier indexScorerSupplier = indexWeight.scorerSupplier(context);\n        final ScorerSupplier dvScorerSupplier = dvWeight.scorerSupplier(context);\n        if (indexScorerSupplier == null || dvScorerSupplier == null) {\n          return null;\n        }\n        return new ScorerSupplier() {\n          @Override\n          public Scorer get(long leadCost) throws IOException {\n            // At equal costs, doc values tend to be worse than points since they\n            // still need to perform one comparison per document while points can\n            // do much better than that given how values are organized. So we give\n            // an arbitrary 8x penalty to doc values.\n            final long threshold = cost() >>> 3;\n            if (threshold <= leadCost) {\n              return indexScorerSupplier.get(leadCost);\n            } else {\n              return dvScorerSupplier.get(leadCost);\n            }\n          }\n\n          @Override\n          public long cost() {\n            return indexScorerSupplier.cost();\n          }\n        };\n      }\n\n      @Override\n      public Scorer scorer(LeafReaderContext context) throws IOException {\n        ScorerSupplier scorerSupplier = scorerSupplier(context);\n        if (scorerSupplier == null) {\n          return null;\n        }\n        return scorerSupplier.get(Long.MAX_VALUE);\n      }\n\n      @Override\n      public boolean isCacheable(LeafReaderContext ctx) {\n        // Both index and dv query should return the same values, so we can use\n        // the index query's cachehelper here\n        return indexWeight.isCacheable(ctx);\n      }\n\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"657704b225b01c6ff4bada5b6667f1f60aaaad0f":["417142ff08fda9cf0b72d5133e63097a166c6458"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["417142ff08fda9cf0b72d5133e63097a166c6458","657704b225b01c6ff4bada5b6667f1f60aaaad0f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7"],"5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"417142ff08fda9cf0b72d5133e63097a166c6458":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9fc47cb7b4346802411bb432f501ed0673d7119e"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9fc47cb7b4346802411bb432f501ed0673d7119e","417142ff08fda9cf0b72d5133e63097a166c6458"],"657704b225b01c6ff4bada5b6667f1f60aaaad0f":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7"],"417142ff08fda9cf0b72d5133e63097a166c6458":["657704b225b01c6ff4bada5b6667f1f60aaaad0f","43345f1452f9510f8aaadae6156fe0c834e7d957"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"5b9ffb60dc4bdc972b1403ad2ab2f5b4d9ce4cf7":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}