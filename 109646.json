{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Stemmer#applyAffix(char[],int,int,int).mjava","commits":[{"id":"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e","date":1393532367,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Stemmer#applyAffix(char[],int,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell2/Stemmer#applyAffix(char[],int,int,int).mjava","sourceNew":"  /**\n   * Applies the affix rule to the given word, producing a list of stems if any are found\n   *\n   * @param strippedWord Word the affix has been removed and the strip added\n   * @param affix HunspellAffix representing the affix rule itself\n   * @param recursionDepth Level of recursion this stemming step is at\n   * @return List of stems for the word, or an empty list if none are found\n   */\n  List<CharsRef> applyAffix(char strippedWord[], int length, int affix, int recursionDepth) {\n    segment.setLength(0);\n    segment.append(strippedWord, 0, length);\n    \n    affixReader.setPosition(8 * affix);\n    char flag = (char) (affixReader.readShort() & 0xffff);\n    affixReader.skipBytes(2); // strip\n    int condition = (char) (affixReader.readShort() & 0xffff);\n    boolean crossProduct = (condition & 1) == 1;\n    condition >>>= 1;\n    char append = (char) (affixReader.readShort() & 0xffff);\n\n    Pattern pattern = dictionary.patterns.get(condition);\n    if (!pattern.matcher(segment).matches()) {\n      return Collections.emptyList();\n    }\n\n    List<CharsRef> stems = new ArrayList<CharsRef>();\n\n    char wordFlags[] = dictionary.lookupWord(strippedWord, 0, length, scratch);\n    if (wordFlags != null && Dictionary.hasFlag(wordFlags, flag)) {\n      stems.add(new CharsRef(strippedWord, 0, length));\n    }\n\n    if (crossProduct && recursionDepth < recursionCap) {\n      dictionary.flagLookup.get(append, scratch);\n      char appendFlags[] = Dictionary.decodeFlags(scratch);\n      stems.addAll(stem(strippedWord, length, appendFlags, ++recursionDepth));\n    }\n\n    return stems;\n  }\n\n","sourceOld":"  /**\n   * Applies the affix rule to the given word, producing a list of stems if any are found\n   *\n   * @param strippedWord Word the affix has been removed and the strip added\n   * @param affix HunspellAffix representing the affix rule itself\n   * @param recursionDepth Level of recursion this stemming step is at\n   * @return List of stems for the word, or an empty list if none are found\n   */\n  public List<CharsRef> applyAffix(char strippedWord[], int length, int affix, int recursionDepth) {\n    segment.setLength(0);\n    segment.append(strippedWord, 0, length);\n    \n    affixReader.setPosition(8 * affix);\n    char flag = (char) (affixReader.readShort() & 0xffff);\n    affixReader.skipBytes(2); // strip\n    int condition = (char) (affixReader.readShort() & 0xffff);\n    boolean crossProduct = (condition & 1) == 1;\n    condition >>>= 1;\n    char append = (char) (affixReader.readShort() & 0xffff);\n\n    Pattern pattern = dictionary.patterns.get(condition);\n    if (!pattern.matcher(segment).matches()) {\n      return Collections.emptyList();\n    }\n\n    List<CharsRef> stems = new ArrayList<CharsRef>();\n\n    char wordFlags[] = dictionary.lookupWord(strippedWord, 0, length, scratch);\n    if (wordFlags != null && Dictionary.hasFlag(wordFlags, flag)) {\n      stems.add(new CharsRef(strippedWord, 0, length));\n    }\n\n    if (crossProduct && recursionDepth < recursionCap) {\n      dictionary.flagLookup.get(append, scratch);\n      char appendFlags[] = Dictionary.decodeFlags(scratch);\n      stems.addAll(stem(strippedWord, length, appendFlags, ++recursionDepth));\n    }\n\n    return stems;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba791bce8103c79e38f957e9c5a53a75871bd918","date":1393539206,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Stemmer#applyAffix(char[],int,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemmer#applyAffix(char[],int,HunspellAffix,int).mjava","sourceNew":"  /**\n   * Applies the affix rule to the given word, producing a list of stems if any are found\n   *\n   * @param strippedWord Word the affix has been removed and the strip added\n   * @param affix HunspellAffix representing the affix rule itself\n   * @param recursionDepth Level of recursion this stemming step is at\n   * @return List of stems for the word, or an empty list if none are found\n   */\n  List<CharsRef> applyAffix(char strippedWord[], int length, int affix, int recursionDepth) {\n    segment.setLength(0);\n    segment.append(strippedWord, 0, length);\n    \n    affixReader.setPosition(8 * affix);\n    char flag = (char) (affixReader.readShort() & 0xffff);\n    affixReader.skipBytes(2); // strip\n    int condition = (char) (affixReader.readShort() & 0xffff);\n    boolean crossProduct = (condition & 1) == 1;\n    condition >>>= 1;\n    char append = (char) (affixReader.readShort() & 0xffff);\n\n    Pattern pattern = dictionary.patterns.get(condition);\n    if (!pattern.matcher(segment).matches()) {\n      return Collections.emptyList();\n    }\n\n    List<CharsRef> stems = new ArrayList<CharsRef>();\n\n    char wordFlags[] = dictionary.lookupWord(strippedWord, 0, length, scratch);\n    if (wordFlags != null && Dictionary.hasFlag(wordFlags, flag)) {\n      stems.add(new CharsRef(strippedWord, 0, length));\n    }\n\n    if (crossProduct && recursionDepth < recursionCap) {\n      dictionary.flagLookup.get(append, scratch);\n      char appendFlags[] = Dictionary.decodeFlags(scratch);\n      stems.addAll(stem(strippedWord, length, appendFlags, ++recursionDepth));\n    }\n\n    return stems;\n  }\n\n","sourceOld":"  /**\n   * Applies the affix rule to the given word, producing a list of stems if any are found\n   *\n   * @param strippedWord Word the affix has been removed and the strip added\n   * @param affix HunspellAffix representing the affix rule itself\n   * @param recursionDepth Level of recursion this stemming step is at\n   * @return List of stems for the word, or an empty list if none are found\n   */\n  @SuppressWarnings(\"unchecked\")\n  public List<Stem> applyAffix(char strippedWord[], int length, HunspellAffix affix, int recursionDepth) {\n    if(dictionary.isIgnoreCase()) {\n      charUtils.toLowerCase(strippedWord, 0, strippedWord.length);\n    }\n    segment.setLength(0);\n    segment.append(strippedWord, 0, length);\n    if (!affix.checkCondition(segment)) {\n      return Collections.EMPTY_LIST;\n    }\n\n    List<Stem> stems = new ArrayList<Stem>();\n\n    List<HunspellWord> words = dictionary.lookupWord(strippedWord, 0, length);\n    if (words != null) {\n      for (HunspellWord hunspellWord : words) {\n        if (hunspellWord.hasFlag(affix.getFlag())) {\n          stems.add(new Stem(strippedWord, length));\n        }\n      }\n    }\n\n    if (affix.isCrossProduct() && recursionDepth < recursionCap) {\n      stems.addAll(stem(strippedWord, length, affix.getAppendFlags(), ++recursionDepth));\n    }\n\n    return stems;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b58bd8dd457a9b46b007c641d5b6e747afb8904a","date":1393616676,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Stemmer#applyAffix(char[],int,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Stemmer#applyAffix(char[],int,int,int).mjava","sourceNew":"  /**\n   * Applies the affix rule to the given word, producing a list of stems if any are found\n   *\n   * @param strippedWord Word the affix has been removed and the strip added\n   * @param affix HunspellAffix representing the affix rule itself\n   * @param recursionDepth Level of recursion this stemming step is at\n   * @return List of stems for the word, or an empty list if none are found\n   */\n  List<CharsRef> applyAffix(char strippedWord[], int length, int affix, int recursionDepth) {\n    segment.setLength(0);\n    segment.append(strippedWord, 0, length);\n    \n    affixReader.setPosition(8 * affix);\n    char flag = (char) (affixReader.readShort() & 0xffff);\n    affixReader.skipBytes(2); // strip\n    int condition = (char) (affixReader.readShort() & 0xffff);\n    boolean crossProduct = (condition & 1) == 1;\n    condition >>>= 1;\n    char append = (char) (affixReader.readShort() & 0xffff);\n    \n    Pattern pattern = dictionary.patterns.get(condition);\n    if (!pattern.matcher(segment).matches()) {\n      return Collections.emptyList();\n    }\n\n    List<CharsRef> stems = new ArrayList<CharsRef>();\n\n    IntsRef forms = dictionary.lookupWord(strippedWord, 0, length);\n    if (forms != null) {\n      for (int i = 0; i < forms.length; i++) {\n        dictionary.flagLookup.get(forms.ints[forms.offset+i], scratch);\n        char wordFlags[] = Dictionary.decodeFlags(scratch);\n        if (wordFlags != null && Dictionary.hasFlag(wordFlags, flag)) {\n          stems.add(new CharsRef(strippedWord, 0, length));\n        }\n      }\n    }\n\n    if (crossProduct && recursionDepth < recursionCap) {\n      dictionary.flagLookup.get(append, scratch);\n      char appendFlags[] = Dictionary.decodeFlags(scratch);\n      stems.addAll(stem(strippedWord, length, appendFlags, ++recursionDepth));\n    }\n\n    return stems;\n  }\n\n","sourceOld":"  /**\n   * Applies the affix rule to the given word, producing a list of stems if any are found\n   *\n   * @param strippedWord Word the affix has been removed and the strip added\n   * @param affix HunspellAffix representing the affix rule itself\n   * @param recursionDepth Level of recursion this stemming step is at\n   * @return List of stems for the word, or an empty list if none are found\n   */\n  List<CharsRef> applyAffix(char strippedWord[], int length, int affix, int recursionDepth) {\n    segment.setLength(0);\n    segment.append(strippedWord, 0, length);\n    \n    affixReader.setPosition(8 * affix);\n    char flag = (char) (affixReader.readShort() & 0xffff);\n    affixReader.skipBytes(2); // strip\n    int condition = (char) (affixReader.readShort() & 0xffff);\n    boolean crossProduct = (condition & 1) == 1;\n    condition >>>= 1;\n    char append = (char) (affixReader.readShort() & 0xffff);\n\n    Pattern pattern = dictionary.patterns.get(condition);\n    if (!pattern.matcher(segment).matches()) {\n      return Collections.emptyList();\n    }\n\n    List<CharsRef> stems = new ArrayList<CharsRef>();\n\n    char wordFlags[] = dictionary.lookupWord(strippedWord, 0, length, scratch);\n    if (wordFlags != null && Dictionary.hasFlag(wordFlags, flag)) {\n      stems.add(new CharsRef(strippedWord, 0, length));\n    }\n\n    if (crossProduct && recursionDepth < recursionCap) {\n      dictionary.flagLookup.get(append, scratch);\n      char appendFlags[] = Dictionary.decodeFlags(scratch);\n      stems.addAll(stem(strippedWord, length, appendFlags, ++recursionDepth));\n    }\n\n    return stems;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7","date":1393724838,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Stemmer#applyAffix(char[],int,int,int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Stemmer#applyAffix(char[],int,int,int).mjava","sourceNew":"  /**\n   * Applies the affix rule to the given word, producing a list of stems if any are found\n   *\n   * @param strippedWord Word the affix has been removed and the strip added\n   * @param length valid length of stripped word\n   * @param affix HunspellAffix representing the affix rule itself\n   * @param prefixFlag when we already stripped a prefix, we cant simply recurse and check the suffix, unless both are compatible\n   *                   so we must check dictionary form against both to add it as a stem!\n   * @param recursionDepth current recursion depth\n   * @param prefix true if we are removing a prefix (false if its a suffix)\n   * @return List of stems for the word, or an empty list if none are found\n   */\n  List<CharsRef> applyAffix(char strippedWord[], int length, int affix, int prefixFlag, int recursionDepth, boolean prefix) {\n    segment.setLength(0);\n    segment.append(strippedWord, 0, length);\n    \n    // TODO: just pass this in from before, no need to decode it twice\n    affixReader.setPosition(8 * affix);\n    char flag = (char) (affixReader.readShort() & 0xffff);\n    affixReader.skipBytes(2); // strip\n    int condition = (char) (affixReader.readShort() & 0xffff);\n    boolean crossProduct = (condition & 1) == 1;\n    condition >>>= 1;\n    char append = (char) (affixReader.readShort() & 0xffff);\n    \n    Pattern pattern = dictionary.patterns.get(condition);\n    if (!pattern.matcher(segment).matches()) {\n      return Collections.emptyList();\n    }\n\n    List<CharsRef> stems = new ArrayList<CharsRef>();\n\n    IntsRef forms = dictionary.lookupWord(strippedWord, 0, length);\n    if (forms != null) {\n      for (int i = 0; i < forms.length; i++) {\n        dictionary.flagLookup.get(forms.ints[forms.offset+i], scratch);\n        char wordFlags[] = Dictionary.decodeFlags(scratch);\n        if (Dictionary.hasFlag(wordFlags, flag)) {\n          // confusing: in this one exception, we already chained the first prefix against the second,\n          // so it doesnt need to be checked against the word\n          boolean chainedPrefix = dictionary.complexPrefixes && recursionDepth == 1 && prefix;\n          if (chainedPrefix == false && prefixFlag >= 0 && !Dictionary.hasFlag(wordFlags, (char)prefixFlag)) {\n            // see if we can chain prefix thru the suffix continuation class (only if it has any!)\n            dictionary.flagLookup.get(append, scratch);\n            char appendFlags[] = Dictionary.decodeFlags(scratch);\n            if (!hasCrossCheckedFlag((char)prefixFlag, appendFlags, false)) {\n              continue;\n            }\n          }\n          stems.add(new CharsRef(strippedWord, 0, length));\n        }\n      }\n    }\n\n    if (crossProduct) {\n      if (recursionDepth == 0) {\n        if (prefix) {\n          // we took away the first prefix.\n          // COMPLEXPREFIXES = true:  combine with a second prefix and another suffix \n          // COMPLEXPREFIXES = false: combine with another suffix\n          stems.addAll(stem(strippedWord, length, affix, flag, flag, ++recursionDepth, dictionary.complexPrefixes, true, true));\n        } else if (!dictionary.complexPrefixes) {\n          // we took away a suffix.\n          // COMPLEXPREFIXES = true: we don't recurse! only one suffix allowed\n          // COMPLEXPREFIXES = false: combine with another suffix\n          stems.addAll(stem(strippedWord, length, affix, flag, prefixFlag, ++recursionDepth, false, true, false));\n        }\n      } else if (recursionDepth == 1) {\n        if (prefix && dictionary.complexPrefixes) {\n          // we took away the second prefix: go look for another suffix\n          stems.addAll(stem(strippedWord, length, affix, flag, flag, ++recursionDepth, false, true, true));\n        } else if (prefix == false && dictionary.complexPrefixes == false) {\n          // we took away a prefix, then a suffix: go look for another suffix\n          stems.addAll(stem(strippedWord, length, affix, flag, prefixFlag, ++recursionDepth, false, true, false));\n        }\n      }\n    }\n\n    return stems;\n  }\n\n","sourceOld":"  /**\n   * Applies the affix rule to the given word, producing a list of stems if any are found\n   *\n   * @param strippedWord Word the affix has been removed and the strip added\n   * @param affix HunspellAffix representing the affix rule itself\n   * @param recursionDepth Level of recursion this stemming step is at\n   * @return List of stems for the word, or an empty list if none are found\n   */\n  List<CharsRef> applyAffix(char strippedWord[], int length, int affix, int recursionDepth) {\n    segment.setLength(0);\n    segment.append(strippedWord, 0, length);\n    \n    affixReader.setPosition(8 * affix);\n    char flag = (char) (affixReader.readShort() & 0xffff);\n    affixReader.skipBytes(2); // strip\n    int condition = (char) (affixReader.readShort() & 0xffff);\n    boolean crossProduct = (condition & 1) == 1;\n    condition >>>= 1;\n    char append = (char) (affixReader.readShort() & 0xffff);\n    \n    Pattern pattern = dictionary.patterns.get(condition);\n    if (!pattern.matcher(segment).matches()) {\n      return Collections.emptyList();\n    }\n\n    List<CharsRef> stems = new ArrayList<CharsRef>();\n\n    IntsRef forms = dictionary.lookupWord(strippedWord, 0, length);\n    if (forms != null) {\n      for (int i = 0; i < forms.length; i++) {\n        dictionary.flagLookup.get(forms.ints[forms.offset+i], scratch);\n        char wordFlags[] = Dictionary.decodeFlags(scratch);\n        if (wordFlags != null && Dictionary.hasFlag(wordFlags, flag)) {\n          stems.add(new CharsRef(strippedWord, 0, length));\n        }\n      }\n    }\n\n    if (crossProduct && recursionDepth < recursionCap) {\n      dictionary.flagLookup.get(append, scratch);\n      char appendFlags[] = Dictionary.decodeFlags(scratch);\n      stems.addAll(stem(strippedWord, length, appendFlags, ++recursionDepth));\n    }\n\n    return stems;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7":["b58bd8dd457a9b46b007c641d5b6e747afb8904a"],"ba791bce8103c79e38f957e9c5a53a75871bd918":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","dc3f094cafa4a87b4066e1d6710fa4e6afe6260e"],"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b58bd8dd457a9b46b007c641d5b6e747afb8904a":["ba791bce8103c79e38f957e9c5a53a75871bd918"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7"]},"commit2Childs":{"1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ba791bce8103c79e38f957e9c5a53a75871bd918":["b58bd8dd457a9b46b007c641d5b6e747afb8904a"],"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e":["ba791bce8103c79e38f957e9c5a53a75871bd918"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ba791bce8103c79e38f957e9c5a53a75871bd918","dc3f094cafa4a87b4066e1d6710fa4e6afe6260e"],"b58bd8dd457a9b46b007c641d5b6e747afb8904a":["1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}