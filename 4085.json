{"path":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.mergedDocCount);\n\n    if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.mergedDocCount);\n\n    if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6bf7b763138020c9ff0a663319353a63590fd17f","date":1335900355,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.mergedDocCount);\n\n    if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.mergedDocCount);\n\n    if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"76923f6a33f2c4bec7f584e3f251261afe7ea276","date":1337149711,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.mergedDocCount);\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.mergedDocCount);\n\n    if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ff82b51516e4a8d24bb6182e5235be1c88b8ac2e","date":1337803615,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.mergedDocCount);\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.mergedDocCount);\n\n    if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert mergeState.fieldInfo.indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29e23e367cc757f42cdfce2bcbf21e68cd209cda","date":1343071560,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":["25433c5cacacb7a2055d62d4d36b0daf210e0a10"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"57635ff388fa1bee703f3b892a86a3e48975576a","date":1343077051,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"322360ac5185a8446d3e0b530b2068bef67cd3d5","date":1343669494,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, 0);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":["872cff1d3a554e0cd64014cd97f88d3002b0f491"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, 0);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, 0);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, false);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn, true);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, false);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, true);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bc124b3b129ef11a255212f3af482b771c5b3a6c","date":1344947616,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, 0);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, 0);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","date":1345029782,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, 0);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, 0);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c188105a9aae04f56c24996f98f8333fc825d2e","date":1345031914,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, 0);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, 0);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c93396a1df03720cb20e2c2f513a6fa59b21e4c","date":1345032673,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, 0);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, 0);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b05c56a41b733e02a189c48895922b5bd8c7f3d1","date":1345033322,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, 0);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, 0);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n        // set PayloadProcessor\n        if (mergeState.payloadProcessorProvider != null) {\n          for (int i = 0; i < mergeState.readers.size(); i++) {\n            if (mergeState.readerPayloadProcessor[i] != null) {\n              mergeState.currentPayloadProcessor[i] = mergeState.readerPayloadProcessor[i].getProcessor(mergeState.fieldInfo.name, term);\n            }\n          }\n        }\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15250ca94ba8ab3bcdd476daf6bf3f3febb92640","date":1355200097,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, DocsEnum.FLAG_NONE);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, 0);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, DocsEnum.FLAG_NONE);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, 0);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6de04d4fe93277012dfab5984e08a38de091bcd1","date":1359464792,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,IndexOptions,TermsEnum).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":"  /** Default merge impl */\n  public void merge(MergeState mergeState, IndexOptions indexOptions, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, DocsEnum.FLAG_NONE);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, indexOptions, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, indexOptions, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, indexOptions, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, indexOptions, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, DocsEnum.FLAG_NONE);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/TermsConsumer#merge(MergeState,TermsEnum).mjava","sourceNew":null,"sourceOld":"  /** Default merge impl */\n  public void merge(MergeState mergeState, TermsEnum termsEnum) throws IOException {\n\n    BytesRef term;\n    assert termsEnum != null;\n    long sumTotalTermFreq = 0;\n    long sumDocFreq = 0;\n    long sumDFsinceLastAbortCheck = 0;\n    FixedBitSet visitedDocs = new FixedBitSet(mergeState.segmentInfo.getDocCount());\n\n    IndexOptions indexOptions = mergeState.fieldInfo.getIndexOptions();\n    if (indexOptions == IndexOptions.DOCS_ONLY) {\n      if (docsEnum == null) {\n        docsEnum = new MappingMultiDocsEnum();\n      }\n      docsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsEnumIn, DocsEnum.FLAG_NONE);\n        if (docsEnumIn != null) {\n          docsEnum.reset(docsEnumIn);\n          final PostingsConsumer postingsConsumer = startTerm(term);\n          final TermStats stats = postingsConsumer.merge(mergeState, docsEnum, visitedDocs);\n          if (stats.docFreq > 0) {\n            finishTerm(term, stats);\n            sumTotalTermFreq += stats.docFreq;\n            sumDFsinceLastAbortCheck += stats.docFreq;\n            sumDocFreq += stats.docFreq;\n            if (sumDFsinceLastAbortCheck > 60000) {\n              mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n              sumDFsinceLastAbortCheck = 0;\n            }\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS) {\n      if (docsAndFreqsEnum == null) {\n        docsAndFreqsEnum = new MappingMultiDocsEnum();\n      }\n      docsAndFreqsEnum.setMergeState(mergeState);\n\n      MultiDocsEnum docsAndFreqsEnumIn = null;\n\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        docsAndFreqsEnumIn = (MultiDocsEnum) termsEnum.docs(null, docsAndFreqsEnumIn);\n        assert docsAndFreqsEnumIn != null;\n        docsAndFreqsEnum.reset(docsAndFreqsEnumIn);\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, docsAndFreqsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else if (indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) {\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn, DocsAndPositionsEnum.FLAG_PAYLOADS);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    } else {\n      assert indexOptions == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n      if (postingsEnum == null) {\n        postingsEnum = new MappingMultiDocsAndPositionsEnum();\n      }\n      postingsEnum.setMergeState(mergeState);\n      MultiDocsAndPositionsEnum postingsEnumIn = null;\n      while((term = termsEnum.next()) != null) {\n        // We can pass null for liveDocs, because the\n        // mapping enum will skip the non-live docs:\n        postingsEnumIn = (MultiDocsAndPositionsEnum) termsEnum.docsAndPositions(null, postingsEnumIn);\n        assert postingsEnumIn != null;\n        postingsEnum.reset(postingsEnumIn);\n\n        final PostingsConsumer postingsConsumer = startTerm(term);\n        final TermStats stats = postingsConsumer.merge(mergeState, postingsEnum, visitedDocs);\n        if (stats.docFreq > 0) {\n          finishTerm(term, stats);\n          sumTotalTermFreq += stats.totalTermFreq;\n          sumDFsinceLastAbortCheck += stats.docFreq;\n          sumDocFreq += stats.docFreq;\n          if (sumDFsinceLastAbortCheck > 60000) {\n            mergeState.checkAbort.work(sumDFsinceLastAbortCheck/5.0);\n            sumDFsinceLastAbortCheck = 0;\n          }\n        }\n      }\n    }\n    finish(indexOptions == IndexOptions.DOCS_ONLY ? -1 : sumTotalTermFreq, sumDocFreq, visitedDocs.cardinality());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["bc124b3b129ef11a255212f3af482b771c5b3a6c","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c","bc124b3b129ef11a255212f3af482b771c5b3a6c"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"ff82b51516e4a8d24bb6182e5235be1c88b8ac2e":["76923f6a33f2c4bec7f584e3f251261afe7ea276"],"29e23e367cc757f42cdfce2bcbf21e68cd209cda":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":["d6f074e73200c07d54f242d3880a8da5a35ff97b","bc124b3b129ef11a255212f3af482b771c5b3a6c"],"57635ff388fa1bee703f3b892a86a3e48975576a":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","29e23e367cc757f42cdfce2bcbf21e68cd209cda"],"76923f6a33f2c4bec7f584e3f251261afe7ea276":["6bf7b763138020c9ff0a663319353a63590fd17f"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["6bf7b763138020c9ff0a663319353a63590fd17f","ff82b51516e4a8d24bb6182e5235be1c88b8ac2e"],"aba371508186796cc6151d8223a5b4e16d02e26e":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","29e23e367cc757f42cdfce2bcbf21e68cd209cda"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["15250ca94ba8ab3bcdd476daf6bf3f3febb92640","6de04d4fe93277012dfab5984e08a38de091bcd1"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["bc124b3b129ef11a255212f3af482b771c5b3a6c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["57635ff388fa1bee703f3b892a86a3e48975576a","02331260bb246364779cb6f04919ca47900d01bb"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["aba371508186796cc6151d8223a5b4e16d02e26e","02331260bb246364779cb6f04919ca47900d01bb"],"bc124b3b129ef11a255212f3af482b771c5b3a6c":["02331260bb246364779cb6f04919ca47900d01bb"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["29e23e367cc757f42cdfce2bcbf21e68cd209cda"],"6de04d4fe93277012dfab5984e08a38de091bcd1":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"02331260bb246364779cb6f04919ca47900d01bb":["322360ac5185a8446d3e0b530b2068bef67cd3d5"],"6bf7b763138020c9ff0a663319353a63590fd17f":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["6de04d4fe93277012dfab5984e08a38de091bcd1"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["6bf7b763138020c9ff0a663319353a63590fd17f"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1"],"ff82b51516e4a8d24bb6182e5235be1c88b8ac2e":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"29e23e367cc757f42cdfce2bcbf21e68cd209cda":["57635ff388fa1bee703f3b892a86a3e48975576a","aba371508186796cc6151d8223a5b4e16d02e26e","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":[],"57635ff388fa1bee703f3b892a86a3e48975576a":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f"],"76923f6a33f2c4bec7f584e3f251261afe7ea276":["ff82b51516e4a8d24bb6182e5235be1c88b8ac2e"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["29e23e367cc757f42cdfce2bcbf21e68cd209cda","57635ff388fa1bee703f3b892a86a3e48975576a","aba371508186796cc6151d8223a5b4e16d02e26e"],"aba371508186796cc6151d8223a5b4e16d02e26e":["d6f074e73200c07d54f242d3880a8da5a35ff97b"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","d4d69c535930b5cce125cff868d40f6373dc27d4"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198"],"bc124b3b129ef11a255212f3af482b771c5b3a6c":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"6de04d4fe93277012dfab5984e08a38de091bcd1":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["02331260bb246364779cb6f04919ca47900d01bb"],"6bf7b763138020c9ff0a663319353a63590fd17f":["76923f6a33f2c4bec7f584e3f251261afe7ea276","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"02331260bb246364779cb6f04919ca47900d01bb":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","bc124b3b129ef11a255212f3af482b771c5b3a6c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}