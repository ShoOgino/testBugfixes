{"path":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testSingleChar().mjava","commits":[{"id":"089745617a0f9c49f3719652025f61c07e5ce4ae","date":1381543020,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testSingleChar().mjava","pathOld":"/dev/null","sourceNew":"  // Test some regular expressions as tokenization patterns\n  /** Test a configuration where each character is a term */\n  public void testSingleChar() throws Exception {\n    CharacterRunAutomaton single =\n        new CharacterRunAutomaton(new RegExp(\".\").toAutomaton());\n    Analyzer a = new MockAnalyzer(random(), single, false);\n    assertAnalyzesTo(a, \"foobar\",\n        new String[] { \"f\", \"o\", \"o\", \"b\", \"a\", \"r\" },\n        new int[] { 0, 1, 2, 3, 4, 5 },\n        new int[] { 1, 2, 3, 4, 5, 6 }\n    );\n    checkRandomData(random(), a, 100);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ac34f0c5bb9274821fb0cb18075234e02002e9bf","date":1402508126,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testSingleChar().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testSingleChar().mjava","sourceNew":"  // Test some regular expressions as tokenization patterns\n  /** Test a configuration where each character is a term */\n  public void testSingleChar() throws Exception {\n    CharacterRunAutomaton single =\n        new CharacterRunAutomaton(new RegExp(\".\").toLightAutomaton());\n    Analyzer a = new MockAnalyzer(random(), single, false);\n    assertAnalyzesTo(a, \"foobar\",\n        new String[] { \"f\", \"o\", \"o\", \"b\", \"a\", \"r\" },\n        new int[] { 0, 1, 2, 3, 4, 5 },\n        new int[] { 1, 2, 3, 4, 5, 6 }\n    );\n    checkRandomData(random(), a, 100);\n  }\n\n","sourceOld":"  // Test some regular expressions as tokenization patterns\n  /** Test a configuration where each character is a term */\n  public void testSingleChar() throws Exception {\n    CharacterRunAutomaton single =\n        new CharacterRunAutomaton(new RegExp(\".\").toAutomaton());\n    Analyzer a = new MockAnalyzer(random(), single, false);\n    assertAnalyzesTo(a, \"foobar\",\n        new String[] { \"f\", \"o\", \"o\", \"b\", \"a\", \"r\" },\n        new int[] { 0, 1, 2, 3, 4, 5 },\n        new int[] { 1, 2, 3, 4, 5, 6 }\n    );\n    checkRandomData(random(), a, 100);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ca1c732df8923f5624f6c06b1dcca9e69d98c96","date":1402957391,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testSingleChar().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testSingleChar().mjava","sourceNew":"  // Test some regular expressions as tokenization patterns\n  /** Test a configuration where each character is a term */\n  public void testSingleChar() throws Exception {\n    CharacterRunAutomaton single =\n        new CharacterRunAutomaton(new RegExp(\".\").toAutomaton());\n    Analyzer a = new MockAnalyzer(random(), single, false);\n    assertAnalyzesTo(a, \"foobar\",\n        new String[] { \"f\", \"o\", \"o\", \"b\", \"a\", \"r\" },\n        new int[] { 0, 1, 2, 3, 4, 5 },\n        new int[] { 1, 2, 3, 4, 5, 6 }\n    );\n    checkRandomData(random(), a, 100);\n  }\n\n","sourceOld":"  // Test some regular expressions as tokenization patterns\n  /** Test a configuration where each character is a term */\n  public void testSingleChar() throws Exception {\n    CharacterRunAutomaton single =\n        new CharacterRunAutomaton(new RegExp(\".\").toLightAutomaton());\n    Analyzer a = new MockAnalyzer(random(), single, false);\n    assertAnalyzesTo(a, \"foobar\",\n        new String[] { \"f\", \"o\", \"o\", \"b\", \"a\", \"r\" },\n        new int[] { 0, 1, 2, 3, 4, 5 },\n        new int[] { 1, 2, 3, 4, 5, 6 }\n    );\n    checkRandomData(random(), a, 100);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a","date":1429550638,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testSingleChar().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer#testSingleChar().mjava","sourceNew":"  // Test some regular expressions as tokenization patterns\n  /** Test a configuration where each character is a term */\n  public void testSingleChar() throws Exception {\n    CharacterRunAutomaton single =\n        new CharacterRunAutomaton(new RegExp(\".\").toAutomaton());\n    Analyzer a = new MockAnalyzer(random(), single, false);\n    assertAnalyzesTo(a, \"foobar\",\n        new String[] { \"f\", \"o\", \"o\", \"b\", \"a\", \"r\" },\n        new int[] { 0, 1, 2, 3, 4, 5 },\n        new int[] { 1, 2, 3, 4, 5, 6 }\n    );\n    checkRandomData(random(), a, 100);\n  }\n\n","sourceOld":"  // Test some regular expressions as tokenization patterns\n  /** Test a configuration where each character is a term */\n  public void testSingleChar() throws Exception {\n    CharacterRunAutomaton single =\n        new CharacterRunAutomaton(new RegExp(\".\").toAutomaton());\n    Analyzer a = new MockAnalyzer(random(), single, false);\n    assertAnalyzesTo(a, \"foobar\",\n        new String[] { \"f\", \"o\", \"o\", \"b\", \"a\", \"r\" },\n        new int[] { 0, 1, 2, 3, 4, 5 },\n        new int[] { 1, 2, 3, 4, 5, 6 }\n    );\n    checkRandomData(random(), a, 100);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["ac34f0c5bb9274821fb0cb18075234e02002e9bf"],"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a":["089745617a0f9c49f3719652025f61c07e5ce4ae"],"089745617a0f9c49f3719652025f61c07e5ce4ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ac34f0c5bb9274821fb0cb18075234e02002e9bf":["089745617a0f9c49f3719652025f61c07e5ce4ae"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["089745617a0f9c49f3719652025f61c07e5ce4ae"],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":[],"b52491e71f0d5d0f0160d6ed0d39e0dd661be68a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ac34f0c5bb9274821fb0cb18075234e02002e9bf":["4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"089745617a0f9c49f3719652025f61c07e5ce4ae":["b52491e71f0d5d0f0160d6ed0d39e0dd661be68a","ac34f0c5bb9274821fb0cb18075234e02002e9bf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4ca1c732df8923f5624f6c06b1dcca9e69d98c96","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}