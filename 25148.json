{"path":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterMTQ#testTokenStreamIsClosed().mjava","commits":[{"id":"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2","date":1475611903,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterMTQ#testTokenStreamIsClosed().mjava","pathOld":"/dev/null","sourceNew":"  public void testTokenStreamIsClosed() throws IOException {\n    // note: test is a derivative of testWithMaxLen()\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    Field body = new Field(\"body\", \"\", fieldType);\n    Document doc = new Document();\n    doc.add(body);\n\n    body.setStringValue(\"Alpha Bravo foo foo foo. Foo foo Alpha Bravo\");\n    if (random().nextBoolean()) { // sometimes add a 2nd value (maybe matters?)\n      doc.add(new Field(\"body\", \"2nd value Alpha Bravo\", fieldType));\n    }\n    iw.addDocument(doc);\n\n    IndexReader ir = iw.getReader();\n    iw.close();\n\n    // use this buggy Analyzer at highlight time\n    Analyzer buggyAnalyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer buggyTokenizer = new Tokenizer() {\n          @Override\n          public boolean incrementToken() throws IOException {\n            throw new IOException(\"EXPECTED\");\n          }\n        };\n        return new TokenStreamComponents(buggyTokenizer);\n      }\n    };\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = new UnifiedHighlighter(searcher, buggyAnalyzer);\n    highlighter.setHandleMultiTermQuery(true);\n    if (rarely()) {\n      highlighter.setMaxLength(25);//a little past first sentence\n    }\n\n    boolean hasClauses = false;\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    if (random().nextBoolean()) {\n      hasClauses = true;\n      queryBuilder.add(new TermQuery(new Term(\"body\", \"alpha\")), BooleanClause.Occur.MUST);\n    }\n    if (!hasClauses || random().nextBoolean()) {\n      queryBuilder.add(new PrefixQuery(new Term(\"body\", \"bra\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    try {\n      String snippets[] = highlighter.highlight(\"body\", query, topDocs, 2);\n      // don't even care what the results are; just want to test exception behavior\n      if (fieldType == UHTestHelper.reanalysisType) {\n        fail(\"Expecting EXPECTED IOException\");\n      }\n    } catch (IOException e) {\n      if (!e.getMessage().equals(\"EXPECTED\")) {\n        throw e;\n      }\n    }\n    ir.close();\n\n    // Now test we can get the tokenStream without it puking due to IllegalStateException for not calling close()\n\n    try (TokenStream ts = buggyAnalyzer.tokenStream(\"body\", \"anything\")) {\n      ts.reset();// hopefully doesn't throw\n      // don't call incrementToken; we know it's buggy ;-)\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterMTQ#testTokenStreamIsClosed().mjava","pathOld":"/dev/null","sourceNew":"  public void testTokenStreamIsClosed() throws IOException {\n    // note: test is a derivative of testWithMaxLen()\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    Field body = new Field(\"body\", \"\", fieldType);\n    Document doc = new Document();\n    doc.add(body);\n\n    body.setStringValue(\"Alpha Bravo foo foo foo. Foo foo Alpha Bravo\");\n    if (random().nextBoolean()) { // sometimes add a 2nd value (maybe matters?)\n      doc.add(new Field(\"body\", \"2nd value Alpha Bravo\", fieldType));\n    }\n    iw.addDocument(doc);\n\n    IndexReader ir = iw.getReader();\n    iw.close();\n\n    // use this buggy Analyzer at highlight time\n    Analyzer buggyAnalyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer buggyTokenizer = new Tokenizer() {\n          @Override\n          public boolean incrementToken() throws IOException {\n            throw new IOException(\"EXPECTED\");\n          }\n        };\n        return new TokenStreamComponents(buggyTokenizer);\n      }\n    };\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = new UnifiedHighlighter(searcher, buggyAnalyzer);\n    highlighter.setHandleMultiTermQuery(true);\n    if (rarely()) {\n      highlighter.setMaxLength(25);//a little past first sentence\n    }\n\n    boolean hasClauses = false;\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    if (random().nextBoolean()) {\n      hasClauses = true;\n      queryBuilder.add(new TermQuery(new Term(\"body\", \"alpha\")), BooleanClause.Occur.MUST);\n    }\n    if (!hasClauses || random().nextBoolean()) {\n      queryBuilder.add(new PrefixQuery(new Term(\"body\", \"bra\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    try {\n      String snippets[] = highlighter.highlight(\"body\", query, topDocs, 2);\n      // don't even care what the results are; just want to test exception behavior\n      if (fieldType == UHTestHelper.reanalysisType) {\n        fail(\"Expecting EXPECTED IOException\");\n      }\n    } catch (IOException e) {\n      if (!e.getMessage().equals(\"EXPECTED\")) {\n        throw e;\n      }\n    }\n    ir.close();\n\n    // Now test we can get the tokenStream without it puking due to IllegalStateException for not calling close()\n\n    try (TokenStream ts = buggyAnalyzer.tokenStream(\"body\", \"anything\")) {\n      ts.reset();// hopefully doesn't throw\n      // don't call incrementToken; we know it's buggy ;-)\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2e9861e4a2b724d9fc51b618714c579491b78d7","date":1479244606,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterMTQ#testTokenStreamIsClosed().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterMTQ#testTokenStreamIsClosed().mjava","sourceNew":"  public void testTokenStreamIsClosed() throws Exception {\n    // note: test is a derivative of testWithMaxLen()\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    Field body = new Field(\"body\", \"\", fieldType);\n    Document doc = new Document();\n    doc.add(body);\n\n    body.setStringValue(\"Alpha Bravo foo foo foo. Foo foo Alpha Bravo\");\n    if (random().nextBoolean()) { // sometimes add a 2nd value (maybe matters?)\n      doc.add(new Field(\"body\", \"2nd value Alpha Bravo\", fieldType));\n    }\n    iw.addDocument(doc);\n\n    IndexReader ir = iw.getReader();\n    iw.close();\n\n    // use this buggy Analyzer at highlight time\n    Analyzer buggyAnalyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer buggyTokenizer = new Tokenizer() {\n          @Override\n          public boolean incrementToken() throws IOException {\n            throw new IOException(\"EXPECTED\");\n          }\n        };\n        return new TokenStreamComponents(buggyTokenizer);\n      }\n    };\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = new UnifiedHighlighter(searcher, buggyAnalyzer);\n    highlighter.setHandleMultiTermQuery(true);\n    if (rarely()) {\n      highlighter.setMaxLength(25);//a little past first sentence\n    }\n\n    boolean hasClauses = false;\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    if (random().nextBoolean()) {\n      hasClauses = true;\n      queryBuilder.add(new TermQuery(new Term(\"body\", \"alpha\")), BooleanClause.Occur.MUST);\n    }\n    if (!hasClauses || random().nextBoolean()) {\n      queryBuilder.add(new PrefixQuery(new Term(\"body\", \"bra\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    try {\n      String snippets[] = highlighter.highlight(\"body\", query, topDocs, 2);\n      // don't even care what the results are; just want to test exception behavior\n      if (fieldType == UHTestHelper.reanalysisType) {\n        fail(\"Expecting EXPECTED IOException\");\n      }\n    } catch (Exception e) {\n      if (!e.getMessage().contains(\"EXPECTED\")) {\n        throw e;\n      }\n    }\n    ir.close();\n\n    // Now test we can get the tokenStream without it puking due to IllegalStateException for not calling close()\n\n    try (TokenStream ts = buggyAnalyzer.tokenStream(\"body\", \"anything\")) {\n      ts.reset();// hopefully doesn't throw\n      // don't call incrementToken; we know it's buggy ;-)\n    }\n  }\n\n","sourceOld":"  public void testTokenStreamIsClosed() throws IOException {\n    // note: test is a derivative of testWithMaxLen()\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    Field body = new Field(\"body\", \"\", fieldType);\n    Document doc = new Document();\n    doc.add(body);\n\n    body.setStringValue(\"Alpha Bravo foo foo foo. Foo foo Alpha Bravo\");\n    if (random().nextBoolean()) { // sometimes add a 2nd value (maybe matters?)\n      doc.add(new Field(\"body\", \"2nd value Alpha Bravo\", fieldType));\n    }\n    iw.addDocument(doc);\n\n    IndexReader ir = iw.getReader();\n    iw.close();\n\n    // use this buggy Analyzer at highlight time\n    Analyzer buggyAnalyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer buggyTokenizer = new Tokenizer() {\n          @Override\n          public boolean incrementToken() throws IOException {\n            throw new IOException(\"EXPECTED\");\n          }\n        };\n        return new TokenStreamComponents(buggyTokenizer);\n      }\n    };\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = new UnifiedHighlighter(searcher, buggyAnalyzer);\n    highlighter.setHandleMultiTermQuery(true);\n    if (rarely()) {\n      highlighter.setMaxLength(25);//a little past first sentence\n    }\n\n    boolean hasClauses = false;\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    if (random().nextBoolean()) {\n      hasClauses = true;\n      queryBuilder.add(new TermQuery(new Term(\"body\", \"alpha\")), BooleanClause.Occur.MUST);\n    }\n    if (!hasClauses || random().nextBoolean()) {\n      queryBuilder.add(new PrefixQuery(new Term(\"body\", \"bra\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    try {\n      String snippets[] = highlighter.highlight(\"body\", query, topDocs, 2);\n      // don't even care what the results are; just want to test exception behavior\n      if (fieldType == UHTestHelper.reanalysisType) {\n        fail(\"Expecting EXPECTED IOException\");\n      }\n    } catch (IOException e) {\n      if (!e.getMessage().equals(\"EXPECTED\")) {\n        throw e;\n      }\n    }\n    ir.close();\n\n    // Now test we can get the tokenStream without it puking due to IllegalStateException for not calling close()\n\n    try (TokenStream ts = buggyAnalyzer.tokenStream(\"body\", \"anything\")) {\n      ts.reset();// hopefully doesn't throw\n      // don't call incrementToken; we know it's buggy ;-)\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a1ef55e1fff7ff44354432770ad8bc19be1fcc75","date":1479266056,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterMTQ#testTokenStreamIsClosed().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterMTQ#testTokenStreamIsClosed().mjava","sourceNew":"  public void testTokenStreamIsClosed() throws Exception {\n    // note: test is a derivative of testWithMaxLen()\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    Field body = new Field(\"body\", \"\", fieldType);\n    Document doc = new Document();\n    doc.add(body);\n\n    body.setStringValue(\"Alpha Bravo foo foo foo. Foo foo Alpha Bravo\");\n    if (random().nextBoolean()) { // sometimes add a 2nd value (maybe matters?)\n      doc.add(new Field(\"body\", \"2nd value Alpha Bravo\", fieldType));\n    }\n    iw.addDocument(doc);\n\n    IndexReader ir = iw.getReader();\n    iw.close();\n\n    // use this buggy Analyzer at highlight time\n    Analyzer buggyAnalyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer buggyTokenizer = new Tokenizer() {\n          @Override\n          public boolean incrementToken() throws IOException {\n            throw new IOException(\"EXPECTED\");\n          }\n        };\n        return new TokenStreamComponents(buggyTokenizer);\n      }\n    };\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = new UnifiedHighlighter(searcher, buggyAnalyzer);\n    highlighter.setHandleMultiTermQuery(true);\n    if (rarely()) {\n      highlighter.setMaxLength(25);//a little past first sentence\n    }\n\n    boolean hasClauses = false;\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    if (random().nextBoolean()) {\n      hasClauses = true;\n      queryBuilder.add(new TermQuery(new Term(\"body\", \"alpha\")), BooleanClause.Occur.MUST);\n    }\n    if (!hasClauses || random().nextBoolean()) {\n      queryBuilder.add(new PrefixQuery(new Term(\"body\", \"bra\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    try {\n      String snippets[] = highlighter.highlight(\"body\", query, topDocs, 2);\n      // don't even care what the results are; just want to test exception behavior\n      if (fieldType == UHTestHelper.reanalysisType) {\n        fail(\"Expecting EXPECTED IOException\");\n      }\n    } catch (Exception e) {\n      if (!e.getMessage().contains(\"EXPECTED\")) {\n        throw e;\n      }\n    }\n    ir.close();\n\n    // Now test we can get the tokenStream without it puking due to IllegalStateException for not calling close()\n\n    try (TokenStream ts = buggyAnalyzer.tokenStream(\"body\", \"anything\")) {\n      ts.reset();// hopefully doesn't throw\n      // don't call incrementToken; we know it's buggy ;-)\n    }\n  }\n\n","sourceOld":"  public void testTokenStreamIsClosed() throws IOException {\n    // note: test is a derivative of testWithMaxLen()\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    Field body = new Field(\"body\", \"\", fieldType);\n    Document doc = new Document();\n    doc.add(body);\n\n    body.setStringValue(\"Alpha Bravo foo foo foo. Foo foo Alpha Bravo\");\n    if (random().nextBoolean()) { // sometimes add a 2nd value (maybe matters?)\n      doc.add(new Field(\"body\", \"2nd value Alpha Bravo\", fieldType));\n    }\n    iw.addDocument(doc);\n\n    IndexReader ir = iw.getReader();\n    iw.close();\n\n    // use this buggy Analyzer at highlight time\n    Analyzer buggyAnalyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer buggyTokenizer = new Tokenizer() {\n          @Override\n          public boolean incrementToken() throws IOException {\n            throw new IOException(\"EXPECTED\");\n          }\n        };\n        return new TokenStreamComponents(buggyTokenizer);\n      }\n    };\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = new UnifiedHighlighter(searcher, buggyAnalyzer);\n    highlighter.setHandleMultiTermQuery(true);\n    if (rarely()) {\n      highlighter.setMaxLength(25);//a little past first sentence\n    }\n\n    boolean hasClauses = false;\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    if (random().nextBoolean()) {\n      hasClauses = true;\n      queryBuilder.add(new TermQuery(new Term(\"body\", \"alpha\")), BooleanClause.Occur.MUST);\n    }\n    if (!hasClauses || random().nextBoolean()) {\n      queryBuilder.add(new PrefixQuery(new Term(\"body\", \"bra\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    try {\n      String snippets[] = highlighter.highlight(\"body\", query, topDocs, 2);\n      // don't even care what the results are; just want to test exception behavior\n      if (fieldType == UHTestHelper.reanalysisType) {\n        fail(\"Expecting EXPECTED IOException\");\n      }\n    } catch (IOException e) {\n      if (!e.getMessage().equals(\"EXPECTED\")) {\n        throw e;\n      }\n    }\n    ir.close();\n\n    // Now test we can get the tokenStream without it puking due to IllegalStateException for not calling close()\n\n    try (TokenStream ts = buggyAnalyzer.tokenStream(\"body\", \"anything\")) {\n      ts.reset();// hopefully doesn't throw\n      // don't call incrementToken; we know it's buggy ;-)\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eef54e3d232eae0e9fc18d75e9b0c3d9ce04b571","date":1515642580,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterMTQ#testTokenStreamIsClosed().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterMTQ#testTokenStreamIsClosed().mjava","sourceNew":"  public void testTokenStreamIsClosed() throws Exception {\n    // note: test is a derivative of testWithMaxLen()\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    Field body = new Field(\"body\", \"\", fieldType);\n    Document doc = new Document();\n    doc.add(body);\n\n    body.setStringValue(\"Alpha Bravo foo foo foo. Foo foo Alpha Bravo\");\n    if (random().nextBoolean()) { // sometimes add a 2nd value (maybe matters?)\n      doc.add(new Field(\"body\", \"2nd value Alpha Bravo\", fieldType));\n    }\n    iw.addDocument(doc);\n\n    IndexReader ir = iw.getReader();\n    iw.close();\n\n    // use this buggy Analyzer at highlight time\n    Analyzer buggyAnalyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer buggyTokenizer = new Tokenizer() {\n          @Override\n          public boolean incrementToken() throws IOException {\n            throw new IOException(\"EXPECTED\");\n          }\n        };\n        return new TokenStreamComponents(buggyTokenizer);\n      }\n    };\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = randomUnifiedHighlighter(searcher, buggyAnalyzer);\n    highlighter.setHandleMultiTermQuery(true);\n    if (rarely()) {\n      highlighter.setMaxLength(25);//a little past first sentence\n    }\n\n    boolean hasClauses = false;\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    if (random().nextBoolean()) {\n      hasClauses = true;\n      queryBuilder.add(new TermQuery(new Term(\"body\", \"alpha\")), BooleanClause.Occur.MUST);\n    }\n    if (!hasClauses || random().nextBoolean()) {\n      queryBuilder.add(new PrefixQuery(new Term(\"body\", \"bra\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    try {\n      String snippets[] = highlighter.highlight(\"body\", query, topDocs, 2);\n      // don't even care what the results are; just want to test exception behavior\n      if (fieldType == UHTestHelper.reanalysisType) {\n        fail(\"Expecting EXPECTED IOException\");\n      }\n    } catch (Exception e) {\n      if (!e.getMessage().contains(\"EXPECTED\")) {\n        throw e;\n      }\n    }\n    ir.close();\n\n    // Now test we can get the tokenStream without it puking due to IllegalStateException for not calling close()\n\n    try (TokenStream ts = buggyAnalyzer.tokenStream(\"body\", \"anything\")) {\n      ts.reset();// hopefully doesn't throw\n      // don't call incrementToken; we know it's buggy ;-)\n    }\n  }\n\n","sourceOld":"  public void testTokenStreamIsClosed() throws Exception {\n    // note: test is a derivative of testWithMaxLen()\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    Field body = new Field(\"body\", \"\", fieldType);\n    Document doc = new Document();\n    doc.add(body);\n\n    body.setStringValue(\"Alpha Bravo foo foo foo. Foo foo Alpha Bravo\");\n    if (random().nextBoolean()) { // sometimes add a 2nd value (maybe matters?)\n      doc.add(new Field(\"body\", \"2nd value Alpha Bravo\", fieldType));\n    }\n    iw.addDocument(doc);\n\n    IndexReader ir = iw.getReader();\n    iw.close();\n\n    // use this buggy Analyzer at highlight time\n    Analyzer buggyAnalyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer buggyTokenizer = new Tokenizer() {\n          @Override\n          public boolean incrementToken() throws IOException {\n            throw new IOException(\"EXPECTED\");\n          }\n        };\n        return new TokenStreamComponents(buggyTokenizer);\n      }\n    };\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = new UnifiedHighlighter(searcher, buggyAnalyzer);\n    highlighter.setHandleMultiTermQuery(true);\n    if (rarely()) {\n      highlighter.setMaxLength(25);//a little past first sentence\n    }\n\n    boolean hasClauses = false;\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    if (random().nextBoolean()) {\n      hasClauses = true;\n      queryBuilder.add(new TermQuery(new Term(\"body\", \"alpha\")), BooleanClause.Occur.MUST);\n    }\n    if (!hasClauses || random().nextBoolean()) {\n      queryBuilder.add(new PrefixQuery(new Term(\"body\", \"bra\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    try {\n      String snippets[] = highlighter.highlight(\"body\", query, topDocs, 2);\n      // don't even care what the results are; just want to test exception behavior\n      if (fieldType == UHTestHelper.reanalysisType) {\n        fail(\"Expecting EXPECTED IOException\");\n      }\n    } catch (Exception e) {\n      if (!e.getMessage().contains(\"EXPECTED\")) {\n        throw e;\n      }\n    }\n    ir.close();\n\n    // Now test we can get the tokenStream without it puking due to IllegalStateException for not calling close()\n\n    try (TokenStream ts = buggyAnalyzer.tokenStream(\"body\", \"anything\")) {\n      ts.reset();// hopefully doesn't throw\n      // don't call incrementToken; we know it's buggy ;-)\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterMTQ#testTokenStreamIsClosed().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/uhighlight/TestUnifiedHighlighterMTQ#testTokenStreamIsClosed().mjava","sourceNew":"  public void testTokenStreamIsClosed() throws Exception {\n    // note: test is a derivative of testWithMaxLen()\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    Field body = new Field(\"body\", \"\", fieldType);\n    Document doc = new Document();\n    doc.add(body);\n\n    body.setStringValue(\"Alpha Bravo foo foo foo. Foo foo Alpha Bravo\");\n    if (random().nextBoolean()) { // sometimes add a 2nd value (maybe matters?)\n      doc.add(new Field(\"body\", \"2nd value Alpha Bravo\", fieldType));\n    }\n    iw.addDocument(doc);\n\n    IndexReader ir = iw.getReader();\n    iw.close();\n\n    // use this buggy Analyzer at highlight time\n    Analyzer buggyAnalyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer buggyTokenizer = new Tokenizer() {\n          @Override\n          public boolean incrementToken() throws IOException {\n            throw new IOException(\"EXPECTED\");\n          }\n        };\n        return new TokenStreamComponents(buggyTokenizer);\n      }\n    };\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = randomUnifiedHighlighter(searcher, buggyAnalyzer);\n    highlighter.setHandleMultiTermQuery(true);\n    if (rarely()) {\n      highlighter.setMaxLength(25);//a little past first sentence\n    }\n\n    boolean hasClauses = false;\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    if (random().nextBoolean()) {\n      hasClauses = true;\n      queryBuilder.add(new TermQuery(new Term(\"body\", \"alpha\")), BooleanClause.Occur.MUST);\n    }\n    if (!hasClauses || random().nextBoolean()) {\n      queryBuilder.add(new PrefixQuery(new Term(\"body\", \"bra\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    try {\n      String snippets[] = highlighter.highlight(\"body\", query, topDocs, 2);\n      // don't even care what the results are; just want to test exception behavior\n      if (fieldType == UHTestHelper.reanalysisType) {\n        fail(\"Expecting EXPECTED IOException\");\n      }\n    } catch (Exception e) {\n      if (!e.getMessage().contains(\"EXPECTED\")) {\n        throw e;\n      }\n    }\n    ir.close();\n\n    // Now test we can get the tokenStream without it puking due to IllegalStateException for not calling close()\n\n    try (TokenStream ts = buggyAnalyzer.tokenStream(\"body\", \"anything\")) {\n      ts.reset();// hopefully doesn't throw\n      // don't call incrementToken; we know it's buggy ;-)\n    }\n  }\n\n","sourceOld":"  public void testTokenStreamIsClosed() throws Exception {\n    // note: test is a derivative of testWithMaxLen()\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, indexAnalyzer);\n\n    Field body = new Field(\"body\", \"\", fieldType);\n    Document doc = new Document();\n    doc.add(body);\n\n    body.setStringValue(\"Alpha Bravo foo foo foo. Foo foo Alpha Bravo\");\n    if (random().nextBoolean()) { // sometimes add a 2nd value (maybe matters?)\n      doc.add(new Field(\"body\", \"2nd value Alpha Bravo\", fieldType));\n    }\n    iw.addDocument(doc);\n\n    IndexReader ir = iw.getReader();\n    iw.close();\n\n    // use this buggy Analyzer at highlight time\n    Analyzer buggyAnalyzer = new Analyzer() {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName) {\n        Tokenizer buggyTokenizer = new Tokenizer() {\n          @Override\n          public boolean incrementToken() throws IOException {\n            throw new IOException(\"EXPECTED\");\n          }\n        };\n        return new TokenStreamComponents(buggyTokenizer);\n      }\n    };\n\n    IndexSearcher searcher = newSearcher(ir);\n    UnifiedHighlighter highlighter = new UnifiedHighlighter(searcher, buggyAnalyzer);\n    highlighter.setHandleMultiTermQuery(true);\n    if (rarely()) {\n      highlighter.setMaxLength(25);//a little past first sentence\n    }\n\n    boolean hasClauses = false;\n    BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();\n    if (random().nextBoolean()) {\n      hasClauses = true;\n      queryBuilder.add(new TermQuery(new Term(\"body\", \"alpha\")), BooleanClause.Occur.MUST);\n    }\n    if (!hasClauses || random().nextBoolean()) {\n      queryBuilder.add(new PrefixQuery(new Term(\"body\", \"bra\")), BooleanClause.Occur.MUST);\n    }\n    BooleanQuery query = queryBuilder.build();\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    try {\n      String snippets[] = highlighter.highlight(\"body\", query, topDocs, 2);\n      // don't even care what the results are; just want to test exception behavior\n      if (fieldType == UHTestHelper.reanalysisType) {\n        fail(\"Expecting EXPECTED IOException\");\n      }\n    } catch (Exception e) {\n      if (!e.getMessage().contains(\"EXPECTED\")) {\n        throw e;\n      }\n    }\n    ir.close();\n\n    // Now test we can get the tokenStream without it puking due to IllegalStateException for not calling close()\n\n    try (TokenStream ts = buggyAnalyzer.tokenStream(\"body\", \"anything\")) {\n      ts.reset();// hopefully doesn't throw\n      // don't call incrementToken; we know it's buggy ;-)\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b94236357aaa22b76c10629851fe4e376e0cea82":["f2e9861e4a2b724d9fc51b618714c579491b78d7","eef54e3d232eae0e9fc18d75e9b0c3d9ce04b571"],"f2e9861e4a2b724d9fc51b618714c579491b78d7":["1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a1ef55e1fff7ff44354432770ad8bc19be1fcc75":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","f2e9861e4a2b724d9fc51b618714c579491b78d7"],"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"eef54e3d232eae0e9fc18d75e9b0c3d9ce04b571":["f2e9861e4a2b724d9fc51b618714c579491b78d7"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b94236357aaa22b76c10629851fe4e376e0cea82"]},"commit2Childs":{"b94236357aaa22b76c10629851fe4e376e0cea82":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f2e9861e4a2b724d9fc51b618714c579491b78d7":["b94236357aaa22b76c10629851fe4e376e0cea82","a1ef55e1fff7ff44354432770ad8bc19be1fcc75","eef54e3d232eae0e9fc18d75e9b0c3d9ce04b571"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a1ef55e1fff7ff44354432770ad8bc19be1fcc75":[],"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2":["f2e9861e4a2b724d9fc51b618714c579491b78d7","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"eef54e3d232eae0e9fc18d75e9b0c3d9ce04b571":["b94236357aaa22b76c10629851fe4e376e0cea82"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a1ef55e1fff7ff44354432770ad8bc19be1fcc75"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a1ef55e1fff7ff44354432770ad8bc19be1fcc75","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}