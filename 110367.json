{"path":"src/java/org/apache/lucene/index/IndexModifier#setMaxFieldLength(int).mjava","commits":[{"id":"0afa0bff72bc189cdf6fc95f80d80365a6417e3b","date":1118096970,"type":0,"author":"Daniel Naber","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexModifier#setMaxFieldLength(int).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.<p/>\n   * Note that this effectively truncates large documents, excluding from the\n   * index terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accomodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than 10,000 terms will be indexed for a field.\n   * @see IndexWriter#setMaxFieldLength(int)\n   * @throws IllegalStateException if the index is closed\n   */\n  public void setMaxFieldLength(int maxFieldLength) throws IOException {\n    synchronized(directory) {\n      assureOpen();\n      createIndexWriter();\n      indexWriter.setMaxFieldLength(maxFieldLength);\n      this.maxFieldLength = maxFieldLength;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f1c07442989a088ee318404ce08a4c3bce7845e8","date":1118098638,"type":3,"author":"Daniel Naber","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexModifier#setMaxFieldLength(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexModifier#setMaxFieldLength(int).mjava","sourceNew":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.<p/>\n   * Note that this effectively truncates large documents, excluding from the\n   * index terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accomodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than 10,000 terms will be indexed for a field.\n   * @see IndexWriter#setMaxFieldLength(int)\n   * @throws IllegalStateException if the index is closed\n   */\n  public void setMaxFieldLength(int maxFieldLength) {\n    synchronized(directory) {\n      assureOpen();\n      if (indexWriter != null) {\n        indexWriter.setMaxFieldLength(maxFieldLength);\n      }\n      this.maxFieldLength = maxFieldLength;\n    }\n  }\n\n","sourceOld":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.<p/>\n   * Note that this effectively truncates large documents, excluding from the\n   * index terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accomodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than 10,000 terms will be indexed for a field.\n   * @see IndexWriter#setMaxFieldLength(int)\n   * @throws IllegalStateException if the index is closed\n   */\n  public void setMaxFieldLength(int maxFieldLength) throws IOException {\n    synchronized(directory) {\n      assureOpen();\n      createIndexWriter();\n      indexWriter.setMaxFieldLength(maxFieldLength);\n      this.maxFieldLength = maxFieldLength;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add7d922e63099fbce8f0a1b31216df7ef5067f1","date":1252002701,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexModifier#setMaxFieldLength(int).mjava","pathOld":"src/java/org/apache/lucene/index/IndexModifier#setMaxFieldLength(int).mjava","sourceNew":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.<p/>\n   * Note that this effectively truncates large documents, excluding from the\n   * index terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accommodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than 10,000 terms will be indexed for a field.\n   * @see IndexWriter#setMaxFieldLength(int)\n   * @throws IllegalStateException if the index is closed\n   */\n  public void setMaxFieldLength(int maxFieldLength) {\n    synchronized(directory) {\n      assureOpen();\n      if (indexWriter != null) {\n        indexWriter.setMaxFieldLength(maxFieldLength);\n      }\n      this.maxFieldLength = maxFieldLength;\n    }\n  }\n\n","sourceOld":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.<p/>\n   * Note that this effectively truncates large documents, excluding from the\n   * index terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accomodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than 10,000 terms will be indexed for a field.\n   * @see IndexWriter#setMaxFieldLength(int)\n   * @throws IllegalStateException if the index is closed\n   */\n  public void setMaxFieldLength(int maxFieldLength) {\n    synchronized(directory) {\n      assureOpen();\n      if (indexWriter != null) {\n        indexWriter.setMaxFieldLength(maxFieldLength);\n      }\n      this.maxFieldLength = maxFieldLength;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eaea03be31988a41275d45a429ac71ff0ad740fb","date":1254612554,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/index/IndexModifier#setMaxFieldLength(int).mjava","sourceNew":null,"sourceOld":"  /**\n   * The maximum number of terms that will be indexed for a single field in a\n   * document.  This limits the amount of memory required for indexing, so that\n   * collections with very large files will not crash the indexing process by\n   * running out of memory.<p/>\n   * Note that this effectively truncates large documents, excluding from the\n   * index terms that occur further in the document.  If you know your source\n   * documents are large, be sure to set this value high enough to accommodate\n   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit\n   * is your memory, but you should anticipate an OutOfMemoryError.<p/>\n   * By default, no more than 10,000 terms will be indexed for a field.\n   * @see IndexWriter#setMaxFieldLength(int)\n   * @throws IllegalStateException if the index is closed\n   */\n  public void setMaxFieldLength(int maxFieldLength) {\n    synchronized(directory) {\n      assureOpen();\n      if (indexWriter != null) {\n        indexWriter.setMaxFieldLength(maxFieldLength);\n      }\n      this.maxFieldLength = maxFieldLength;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"eaea03be31988a41275d45a429ac71ff0ad740fb":["add7d922e63099fbce8f0a1b31216df7ef5067f1"],"f1c07442989a088ee318404ce08a4c3bce7845e8":["0afa0bff72bc189cdf6fc95f80d80365a6417e3b"],"add7d922e63099fbce8f0a1b31216df7ef5067f1":["f1c07442989a088ee318404ce08a4c3bce7845e8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0afa0bff72bc189cdf6fc95f80d80365a6417e3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["eaea03be31988a41275d45a429ac71ff0ad740fb"]},"commit2Childs":{"eaea03be31988a41275d45a429ac71ff0ad740fb":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f1c07442989a088ee318404ce08a4c3bce7845e8":["add7d922e63099fbce8f0a1b31216df7ef5067f1"],"add7d922e63099fbce8f0a1b31216df7ef5067f1":["eaea03be31988a41275d45a429ac71ff0ad740fb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0afa0bff72bc189cdf6fc95f80d80365a6417e3b"],"0afa0bff72bc189cdf6fc95f80d80365a6417e3b":["f1c07442989a088ee318404ce08a4c3bce7845e8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}