{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareOnCommitMerge(SegmentInfos,AtomicBoolean).mjava","commits":[{"id":"c2a23476693f2bd9a4b44cc3187c429a2e21dac2","date":1593289545,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareOnCommitMerge(SegmentInfos,AtomicBoolean).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * This optimization allows a commit to wait for merges on smallish segments to\n   * reduce the eventual number of tiny segments in the commit point.  We wrap a {@code OneMerge} to\n   * update the {@code committingSegmentInfos} once the merge has finished.  We replace the source segments\n   * in the SIS that we are going to commit with the freshly merged segment, but ignore all deletions and updates\n   * that are made to documents in the merged segment while it was merging.  The updates that are made do not belong to\n   * the point-in-time commit point and should therefore not be included. See the clone call in {@code onMergeComplete}\n   * below.  We also ensure that we pull the merge readers while holding {@code IndexWriter}'s lock.  Otherwise\n   * we could see concurrent deletions/updates applied that do not belong to the segment.\n   */\n  private MergePolicy.MergeSpecification prepareOnCommitMerge(SegmentInfos committingSegmentInfos, AtomicBoolean includeInCommit) throws IOException {\n    assert Thread.holdsLock(this);\n    MergePolicy.MergeSpecification onCommitMerges = updatePendingMerges(new OneMergeWrappingMergePolicy(config.getMergePolicy(), toWrap ->\n        new MergePolicy.OneMerge(toWrap.segments) {\n          SegmentCommitInfo origInfo;\n          AtomicBoolean onlyOnce = new AtomicBoolean(false);\n\n          @Override\n          public void mergeFinished(boolean committed, boolean segmentDropped) throws IOException {\n            assert Thread.holdsLock(IndexWriter.this);\n\n            // includedInCommit will be set (above, by our caller) to false if the allowed max wall clock\n            // time (IWC.getMaxCommitMergeWaitMillis()) has elapsed, which means we did not make the timeout\n            // and will not commit our merge to the to-be-commited SegmentInfos\n            \n            if (segmentDropped == false\n                && committed\n                && includeInCommit.get()) {\n\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"now apply merge during commit: \" + toWrap.segString());\n              }\n\n              // make sure onMergeComplete really was called:\n              assert origInfo != null;\n\n              deleter.incRef(origInfo.files());\n              Set<String> mergedSegmentNames = new HashSet<>();\n              for (SegmentCommitInfo sci : segments) {\n                mergedSegmentNames.add(sci.info.name);\n              }\n              List<SegmentCommitInfo> toCommitMergedAwaySegments = new ArrayList<>();\n              for (SegmentCommitInfo sci : committingSegmentInfos) {\n                if (mergedSegmentNames.contains(sci.info.name)) {\n                  toCommitMergedAwaySegments.add(sci);\n                  deleter.decRef(sci.files());\n                }\n              }\n              // Construct a OneMerge that applies to toCommit\n              MergePolicy.OneMerge applicableMerge = new MergePolicy.OneMerge(toCommitMergedAwaySegments);\n              applicableMerge.info = origInfo;\n              long segmentCounter = Long.parseLong(origInfo.info.name.substring(1), Character.MAX_RADIX);\n              committingSegmentInfos.counter = Math.max(committingSegmentInfos.counter, segmentCounter + 1);\n              committingSegmentInfos.applyMergeChanges(applicableMerge, false);\n            } else {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"skip apply merge during commit: \" + toWrap.segString());\n              }\n            }\n            toWrap.mergeFinished(committed, false);\n            super.mergeFinished(committed, segmentDropped);\n          }\n\n          @Override\n          void onMergeComplete() {\n            // clone the target info to make sure we have the original info without the updated del and update gens\n            origInfo = info.clone();\n          }\n\n          @Override\n          void initMergeReaders(IOUtils.IOFunction<SegmentCommitInfo, MergePolicy.MergeReader> readerFactory) throws IOException {\n            if (onlyOnce.compareAndSet(false, true)) {\n              // we do this only once below to pull readers as point in time readers with respect to the commit point\n              // we try to update\n              super.initMergeReaders(readerFactory);\n            }\n          }\n\n          @Override\n          public CodecReader wrapForMerge(CodecReader reader) throws IOException {\n            return toWrap.wrapForMerge(reader); // must delegate\n          }\n        }\n    ), MergeTrigger.COMMIT, UNBOUNDED_MAX_MERGE_SEGMENTS);\n    if (onCommitMerges != null) {\n      boolean closeReaders = true;\n      try {\n        for (MergePolicy.OneMerge merge : onCommitMerges.merges) {\n          IOContext context = new IOContext(merge.getStoreMergeInfo());\n          merge.initMergeReaders(\n              sci -> {\n                final ReadersAndUpdates rld = getPooledInstance(sci, true);\n                // calling setIsMerging is important since it causes the RaU to record all DV updates\n                // in a separate map in order to be applied to the merged segment after it's done\n                rld.setIsMerging();\n                return rld.getReaderForMerge(context);\n              });\n        }\n        closeReaders = false;\n      } finally {\n        if (closeReaders) {\n          IOUtils.applyToAll(onCommitMerges.merges, merge -> {\n            // that merge is broken we need to clean up after it - it's fine we still have the IW lock to do this\n            boolean removed = pendingMerges.remove(merge);\n            assert removed: \"merge should be pending but isn't: \" + merge.segString();\n            abortOneMerge(merge);\n            mergeFinish(merge);\n          });\n        }\n      }\n    }\n    return onCommitMerges;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f354ba79a5a3e8491ec2953f14f365a02c058ac","date":1598293148,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#preparePointInTimeMerge(SegmentInfos,BooleanSupplier,MergeTrigger,IOUtils.IOConsumer[SegmentCommitInfo]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareOnCommitMerge(SegmentInfos,AtomicBoolean).mjava","sourceNew":"  /**\n   * This optimization allows a commit/getReader to wait for merges on smallish segments to\n   * reduce the eventual number of tiny segments in the commit point / NRT Reader.  We wrap a {@code OneMerge} to\n   * update the {@code mergingSegmentInfos} once the merge has finished. We replace the source segments\n   * in the SIS that we are going to commit / open the reader on with the freshly merged segment, but ignore all deletions and updates\n   * that are made to documents in the merged segment while it was merging. The updates that are made do not belong to\n   * the point-in-time commit point / NRT READER and should therefore not be included. See the clone call in {@code onMergeComplete}\n   * below.  We also ensure that we pull the merge readers while holding {@code IndexWriter}'s lock.  Otherwise\n   * we could see concurrent deletions/updates applied that do not belong to the segment.\n   */\n  private MergePolicy.MergeSpecification preparePointInTimeMerge(SegmentInfos mergingSegmentInfos, BooleanSupplier stopCollectingMergeResults,\n                                                                 MergeTrigger trigger,\n                                                                 IOUtils.IOConsumer<SegmentCommitInfo> mergeFinished) throws IOException {\n    assert Thread.holdsLock(this);\n    assert trigger == MergeTrigger.GET_READER || trigger == MergeTrigger.COMMIT : \"illegal trigger: \" + trigger;\n    MergePolicy.MergeSpecification pointInTimeMerges = updatePendingMerges(new OneMergeWrappingMergePolicy(config.getMergePolicy(), toWrap ->\n        new MergePolicy.OneMerge(toWrap.segments) {\n          SegmentCommitInfo origInfo;\n          final AtomicBoolean onlyOnce = new AtomicBoolean(false);\n\n          @Override\n          public void mergeFinished(boolean committed, boolean segmentDropped) throws IOException {\n            assert Thread.holdsLock(IndexWriter.this);\n\n            // includedInCommit will be set (above, by our caller) to false if the allowed max wall clock\n            // time (IWC.getMaxCommitMergeWaitMillis()) has elapsed, which means we did not make the timeout\n            // and will not commit our merge to the to-be-committed SegmentInfos\n            if (segmentDropped == false\n                && committed\n                && stopCollectingMergeResults.getAsBoolean() == false) {\n\n              // make sure onMergeComplete really was called:\n              assert origInfo != null;\n\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"now apply merge during commit: \" + toWrap.segString());\n              }\n\n              if (trigger == MergeTrigger.COMMIT) {\n                // if we do this in a getReader call here this is obsolete since we already hold a reader that has\n                // incRef'd these files\n                deleter.incRef(origInfo.files());\n              }\n              Set<String> mergedSegmentNames = new HashSet<>();\n              for (SegmentCommitInfo sci : segments) {\n                mergedSegmentNames.add(sci.info.name);\n              }\n              List<SegmentCommitInfo> toCommitMergedAwaySegments = new ArrayList<>();\n              for (SegmentCommitInfo sci : mergingSegmentInfos) {\n                if (mergedSegmentNames.contains(sci.info.name)) {\n                  toCommitMergedAwaySegments.add(sci);\n                  if (trigger == MergeTrigger.COMMIT) {\n                    // if we do this in a getReader call here this is obsolete since we already hold a reader that has\n                    // incRef'd these files and will decRef them when it's closed\n                    deleter.decRef(sci.files());\n                  }\n                }\n              }\n              // Construct a OneMerge that applies to toCommit\n              MergePolicy.OneMerge applicableMerge = new MergePolicy.OneMerge(toCommitMergedAwaySegments);\n              applicableMerge.info = origInfo;\n              long segmentCounter = Long.parseLong(origInfo.info.name.substring(1), Character.MAX_RADIX);\n              mergingSegmentInfos.counter = Math.max(mergingSegmentInfos.counter, segmentCounter + 1);\n              mergingSegmentInfos.applyMergeChanges(applicableMerge, false);\n            } else {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"skip apply merge during commit: \" + toWrap.segString());\n              }\n            }\n            toWrap.mergeFinished(committed, segmentDropped);\n            super.mergeFinished(committed, segmentDropped);\n          }\n\n          @Override\n          void onMergeComplete() throws IOException {\n            assert Thread.holdsLock(IndexWriter.this);\n            if (stopCollectingMergeResults.getAsBoolean() == false\n                && isAborted() == false\n                && info.info.maxDoc() > 0/* never do this if the segment if dropped / empty */) {\n              mergeFinished.accept(info);\n              // clone the target info to make sure we have the original info without the updated del and update gens\n              origInfo = info.clone();\n            }\n            toWrap.onMergeComplete();\n            super.onMergeComplete();\n          }\n\n          @Override\n          void initMergeReaders(IOUtils.IOFunction<SegmentCommitInfo, MergePolicy.MergeReader> readerFactory) throws IOException {\n            if (onlyOnce.compareAndSet(false, true)) {\n              // we do this only once below to pull readers as point in time readers with respect to the commit point\n              // we try to update\n              super.initMergeReaders(readerFactory);\n            }\n          }\n\n          @Override\n          public CodecReader wrapForMerge(CodecReader reader) throws IOException {\n            return toWrap.wrapForMerge(reader); // must delegate\n          }\n        }\n    ), trigger, UNBOUNDED_MAX_MERGE_SEGMENTS);\n    if (pointInTimeMerges != null) {\n      boolean closeReaders = true;\n      try {\n        for (MergePolicy.OneMerge merge : pointInTimeMerges.merges) {\n          IOContext context = new IOContext(merge.getStoreMergeInfo());\n          merge.initMergeReaders(\n              sci -> {\n                final ReadersAndUpdates rld = getPooledInstance(sci, true);\n                // calling setIsMerging is important since it causes the RaU to record all DV updates\n                // in a separate map in order to be applied to the merged segment after it's done\n                rld.setIsMerging();\n                return rld.getReaderForMerge(context);\n              });\n        }\n        closeReaders = false;\n      } finally {\n        if (closeReaders) {\n          IOUtils.applyToAll(pointInTimeMerges.merges, merge -> {\n            // that merge is broken we need to clean up after it - it's fine we still have the IW lock to do this\n            boolean removed = pendingMerges.remove(merge);\n            assert removed: \"merge should be pending but isn't: \" + merge.segString();\n            try {\n              abortOneMerge(merge);\n            } finally {\n              mergeFinish(merge);\n            }\n          });\n        }\n      }\n    }\n    return pointInTimeMerges;\n  }\n\n","sourceOld":"  /**\n   * This optimization allows a commit to wait for merges on smallish segments to\n   * reduce the eventual number of tiny segments in the commit point.  We wrap a {@code OneMerge} to\n   * update the {@code committingSegmentInfos} once the merge has finished.  We replace the source segments\n   * in the SIS that we are going to commit with the freshly merged segment, but ignore all deletions and updates\n   * that are made to documents in the merged segment while it was merging.  The updates that are made do not belong to\n   * the point-in-time commit point and should therefore not be included. See the clone call in {@code onMergeComplete}\n   * below.  We also ensure that we pull the merge readers while holding {@code IndexWriter}'s lock.  Otherwise\n   * we could see concurrent deletions/updates applied that do not belong to the segment.\n   */\n  private MergePolicy.MergeSpecification prepareOnCommitMerge(SegmentInfos committingSegmentInfos, AtomicBoolean includeInCommit) throws IOException {\n    assert Thread.holdsLock(this);\n    MergePolicy.MergeSpecification onCommitMerges = updatePendingMerges(new OneMergeWrappingMergePolicy(config.getMergePolicy(), toWrap ->\n        new MergePolicy.OneMerge(toWrap.segments) {\n          SegmentCommitInfo origInfo;\n          AtomicBoolean onlyOnce = new AtomicBoolean(false);\n\n          @Override\n          public void mergeFinished(boolean committed, boolean segmentDropped) throws IOException {\n            assert Thread.holdsLock(IndexWriter.this);\n\n            // includedInCommit will be set (above, by our caller) to false if the allowed max wall clock\n            // time (IWC.getMaxCommitMergeWaitMillis()) has elapsed, which means we did not make the timeout\n            // and will not commit our merge to the to-be-commited SegmentInfos\n            \n            if (segmentDropped == false\n                && committed\n                && includeInCommit.get()) {\n\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"now apply merge during commit: \" + toWrap.segString());\n              }\n\n              // make sure onMergeComplete really was called:\n              assert origInfo != null;\n\n              deleter.incRef(origInfo.files());\n              Set<String> mergedSegmentNames = new HashSet<>();\n              for (SegmentCommitInfo sci : segments) {\n                mergedSegmentNames.add(sci.info.name);\n              }\n              List<SegmentCommitInfo> toCommitMergedAwaySegments = new ArrayList<>();\n              for (SegmentCommitInfo sci : committingSegmentInfos) {\n                if (mergedSegmentNames.contains(sci.info.name)) {\n                  toCommitMergedAwaySegments.add(sci);\n                  deleter.decRef(sci.files());\n                }\n              }\n              // Construct a OneMerge that applies to toCommit\n              MergePolicy.OneMerge applicableMerge = new MergePolicy.OneMerge(toCommitMergedAwaySegments);\n              applicableMerge.info = origInfo;\n              long segmentCounter = Long.parseLong(origInfo.info.name.substring(1), Character.MAX_RADIX);\n              committingSegmentInfos.counter = Math.max(committingSegmentInfos.counter, segmentCounter + 1);\n              committingSegmentInfos.applyMergeChanges(applicableMerge, false);\n            } else {\n              if (infoStream.isEnabled(\"IW\")) {\n                infoStream.message(\"IW\", \"skip apply merge during commit: \" + toWrap.segString());\n              }\n            }\n            toWrap.mergeFinished(committed, false);\n            super.mergeFinished(committed, segmentDropped);\n          }\n\n          @Override\n          void onMergeComplete() {\n            // clone the target info to make sure we have the original info without the updated del and update gens\n            origInfo = info.clone();\n          }\n\n          @Override\n          void initMergeReaders(IOUtils.IOFunction<SegmentCommitInfo, MergePolicy.MergeReader> readerFactory) throws IOException {\n            if (onlyOnce.compareAndSet(false, true)) {\n              // we do this only once below to pull readers as point in time readers with respect to the commit point\n              // we try to update\n              super.initMergeReaders(readerFactory);\n            }\n          }\n\n          @Override\n          public CodecReader wrapForMerge(CodecReader reader) throws IOException {\n            return toWrap.wrapForMerge(reader); // must delegate\n          }\n        }\n    ), MergeTrigger.COMMIT, UNBOUNDED_MAX_MERGE_SEGMENTS);\n    if (onCommitMerges != null) {\n      boolean closeReaders = true;\n      try {\n        for (MergePolicy.OneMerge merge : onCommitMerges.merges) {\n          IOContext context = new IOContext(merge.getStoreMergeInfo());\n          merge.initMergeReaders(\n              sci -> {\n                final ReadersAndUpdates rld = getPooledInstance(sci, true);\n                // calling setIsMerging is important since it causes the RaU to record all DV updates\n                // in a separate map in order to be applied to the merged segment after it's done\n                rld.setIsMerging();\n                return rld.getReaderForMerge(context);\n              });\n        }\n        closeReaders = false;\n      } finally {\n        if (closeReaders) {\n          IOUtils.applyToAll(onCommitMerges.merges, merge -> {\n            // that merge is broken we need to clean up after it - it's fine we still have the IW lock to do this\n            boolean removed = pendingMerges.remove(merge);\n            assert removed: \"merge should be pending but isn't: \" + merge.segString();\n            abortOneMerge(merge);\n            mergeFinish(merge);\n          });\n        }\n      }\n    }\n    return onCommitMerges;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c2a23476693f2bd9a4b44cc3187c429a2e21dac2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3f354ba79a5a3e8491ec2953f14f365a02c058ac":["c2a23476693f2bd9a4b44cc3187c429a2e21dac2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f354ba79a5a3e8491ec2953f14f365a02c058ac"]},"commit2Childs":{"c2a23476693f2bd9a4b44cc3187c429a2e21dac2":["3f354ba79a5a3e8491ec2953f14f365a02c058ac"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c2a23476693f2bd9a4b44cc3187c429a2e21dac2"],"3f354ba79a5a3e8491ec2953f14f365a02c058ac":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}