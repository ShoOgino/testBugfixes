{"path":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","commits":[{"id":"abb23fcc2461782ab204e61213240feb77d355aa","date":1422029612,"type":1,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#doTest().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    \n    indexThread = new StopableIndexingThread(controlClient, cloudClient, \"1\", true, maxDoc);\n    indexThread.start();\n    \n    indexThread2 = new StopableIndexingThread(controlClient, cloudClient, \"2\", true, maxDoc);\n    \n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    JettySolrRunner replica = chaosMonkey.stopShard(\"shard1\", 1).jetty;\n\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    replica.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    \n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n    \n    Thread.sleep(1000);\n  \n    waitForThingsToLevelOut(120);\n    \n    Thread.sleep(2000);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(5000);\n    \n    waitForRecoveriesToFinish(DEFAULT_COLLECTION, zkStateReader, false, true);\n\n    // test that leader and replica have same doc count\n    \n    String fail = checkShardConsistency(\"shard1\", false, false);\n    if (fail != null) {\n      fail(fail);\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.setParam(\"distrib\", \"false\");\n    long client1Docs = shardToJetty.get(\"shard1\").get(0).client.solrClient.query(query).getResults().getNumFound();\n    long client2Docs = shardToJetty.get(\"shard1\").get(1).client.solrClient.query(query).getResults().getNumFound();\n    \n    assertTrue(client1Docs > 0);\n    assertEquals(client1Docs, client2Docs);\n \n    // won't always pass yet...\n    //query(\"q\", \"*:*\", \"sort\", \"id desc\");\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    \n    indexThread = new StopableIndexingThread(controlClient, cloudClient, \"1\", true, maxDoc);\n    indexThread.start();\n    \n    indexThread2 = new StopableIndexingThread(controlClient, cloudClient, \"2\", true, maxDoc);\n    \n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    JettySolrRunner replica = chaosMonkey.stopShard(\"shard1\", 1).jetty;\n\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    replica.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    \n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n    \n    Thread.sleep(1000);\n  \n    waitForThingsToLevelOut(120);\n    \n    Thread.sleep(2000);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(5000);\n    \n    waitForRecoveriesToFinish(DEFAULT_COLLECTION, zkStateReader, false, true);\n\n    // test that leader and replica have same doc count\n    \n    String fail = checkShardConsistency(\"shard1\", false, false);\n    if (fail != null) {\n      fail(fail);\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.setParam(\"distrib\", \"false\");\n    long client1Docs = shardToJetty.get(\"shard1\").get(0).client.solrClient.query(query).getResults().getNumFound();\n    long client2Docs = shardToJetty.get(\"shard1\").get(1).client.solrClient.query(query).getResults().getNumFound();\n    \n    assertTrue(client1Docs > 0);\n    assertEquals(client1Docs, client2Docs);\n \n    // won't always pass yet...\n    //query(\"q\", \"*:*\", \"sort\", \"id desc\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6c94d2661bc1c14426980ec7882e951fdcff08d0","date":1427167177,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    \n    indexThread = new StopableIndexingThread(controlClient, cloudClient, \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StopableIndexingThread(controlClient, cloudClient, \"2\", true, maxDoc, 1, true);\n    \n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    JettySolrRunner replica = chaosMonkey.stopShard(\"shard1\", 1).jetty;\n\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    replica.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    \n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n    \n    Thread.sleep(1000);\n  \n    waitForThingsToLevelOut(120);\n    \n    Thread.sleep(2000);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(5000);\n    \n    waitForRecoveriesToFinish(DEFAULT_COLLECTION, zkStateReader, false, true);\n\n    // test that leader and replica have same doc count\n    \n    String fail = checkShardConsistency(\"shard1\", false, false);\n    if (fail != null) {\n      fail(fail);\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.setParam(\"distrib\", \"false\");\n    long client1Docs = shardToJetty.get(\"shard1\").get(0).client.solrClient.query(query).getResults().getNumFound();\n    long client2Docs = shardToJetty.get(\"shard1\").get(1).client.solrClient.query(query).getResults().getNumFound();\n    \n    assertTrue(client1Docs > 0);\n    assertEquals(client1Docs, client2Docs);\n \n    // won't always pass yet...\n    //query(\"q\", \"*:*\", \"sort\", \"id desc\");\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    \n    indexThread = new StopableIndexingThread(controlClient, cloudClient, \"1\", true, maxDoc);\n    indexThread.start();\n    \n    indexThread2 = new StopableIndexingThread(controlClient, cloudClient, \"2\", true, maxDoc);\n    \n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    JettySolrRunner replica = chaosMonkey.stopShard(\"shard1\", 1).jetty;\n\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    replica.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    \n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n    \n    Thread.sleep(1000);\n  \n    waitForThingsToLevelOut(120);\n    \n    Thread.sleep(2000);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(5000);\n    \n    waitForRecoveriesToFinish(DEFAULT_COLLECTION, zkStateReader, false, true);\n\n    // test that leader and replica have same doc count\n    \n    String fail = checkShardConsistency(\"shard1\", false, false);\n    if (fail != null) {\n      fail(fail);\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.setParam(\"distrib\", \"false\");\n    long client1Docs = shardToJetty.get(\"shard1\").get(0).client.solrClient.query(query).getResults().getNumFound();\n    long client2Docs = shardToJetty.get(\"shard1\").get(1).client.solrClient.query(query).getResults().getNumFound();\n    \n    assertTrue(client1Docs > 0);\n    assertEquals(client1Docs, client2Docs);\n \n    // won't always pass yet...\n    //query(\"q\", \"*:*\", \"sort\", \"id desc\");\n  }\n\n","bugFix":["19389fe47925b510b2811e2b385a75f7ad19dcca"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"98287baa2c8d136e801f366a73e27a23285b7b98","date":1427241813,"type":3,"author":"Ramkumar Aiyengar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    \n    indexThread = new StoppableIndexingThread(controlClient, cloudClient, \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StoppableIndexingThread(controlClient, cloudClient, \"2\", true, maxDoc, 1, true);\n\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    JettySolrRunner replica = chaosMonkey.stopShard(\"shard1\", 1).jetty;\n\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    replica.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    \n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n    \n    Thread.sleep(1000);\n  \n    waitForThingsToLevelOut(120);\n    \n    Thread.sleep(2000);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(5000);\n    \n    waitForRecoveriesToFinish(DEFAULT_COLLECTION, zkStateReader, false, true);\n\n    // test that leader and replica have same doc count\n    \n    String fail = checkShardConsistency(\"shard1\", false, false);\n    if (fail != null) {\n      fail(fail);\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.setParam(\"distrib\", \"false\");\n    long client1Docs = shardToJetty.get(\"shard1\").get(0).client.solrClient.query(query).getResults().getNumFound();\n    long client2Docs = shardToJetty.get(\"shard1\").get(1).client.solrClient.query(query).getResults().getNumFound();\n    \n    assertTrue(client1Docs > 0);\n    assertEquals(client1Docs, client2Docs);\n \n    // won't always pass yet...\n    //query(\"q\", \"*:*\", \"sort\", \"id desc\");\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    \n    indexThread = new StopableIndexingThread(controlClient, cloudClient, \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StopableIndexingThread(controlClient, cloudClient, \"2\", true, maxDoc, 1, true);\n    \n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    JettySolrRunner replica = chaosMonkey.stopShard(\"shard1\", 1).jetty;\n\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    replica.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    \n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n    \n    Thread.sleep(1000);\n  \n    waitForThingsToLevelOut(120);\n    \n    Thread.sleep(2000);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(5000);\n    \n    waitForRecoveriesToFinish(DEFAULT_COLLECTION, zkStateReader, false, true);\n\n    // test that leader and replica have same doc count\n    \n    String fail = checkShardConsistency(\"shard1\", false, false);\n    if (fail != null) {\n      fail(fail);\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.setParam(\"distrib\", \"false\");\n    long client1Docs = shardToJetty.get(\"shard1\").get(0).client.solrClient.query(query).getResults().getNumFound();\n    long client2Docs = shardToJetty.get(\"shard1\").get(1).client.solrClient.query(query).getResults().getNumFound();\n    \n    assertTrue(client1Docs > 0);\n    assertEquals(client1Docs, client2Docs);\n \n    // won't always pass yet...\n    //query(\"q\", \"*:*\", \"sort\", \"id desc\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    \n    indexThread = new StoppableIndexingThread(controlClient, cloudClient, \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StoppableIndexingThread(controlClient, cloudClient, \"2\", true, maxDoc, 1, true);\n\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    JettySolrRunner replica = chaosMonkey.stopShard(\"shard1\", 1).jetty;\n\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    replica.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    \n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n    \n    Thread.sleep(1000);\n  \n    waitForThingsToLevelOut(120);\n    \n    Thread.sleep(2000);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(5000);\n    \n    waitForRecoveriesToFinish(DEFAULT_COLLECTION, zkStateReader, false, true);\n\n    // test that leader and replica have same doc count\n    \n    String fail = checkShardConsistency(\"shard1\", false, false);\n    if (fail != null) {\n      fail(fail);\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.setParam(\"distrib\", \"false\");\n    long client1Docs = shardToJetty.get(\"shard1\").get(0).client.solrClient.query(query).getResults().getNumFound();\n    long client2Docs = shardToJetty.get(\"shard1\").get(1).client.solrClient.query(query).getResults().getNumFound();\n    \n    assertTrue(client1Docs > 0);\n    assertEquals(client1Docs, client2Docs);\n \n    // won't always pass yet...\n    //query(\"q\", \"*:*\", \"sort\", \"id desc\");\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    \n    indexThread = new StopableIndexingThread(controlClient, cloudClient, \"1\", true, maxDoc);\n    indexThread.start();\n    \n    indexThread2 = new StopableIndexingThread(controlClient, cloudClient, \"2\", true, maxDoc);\n    \n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    JettySolrRunner replica = chaosMonkey.stopShard(\"shard1\", 1).jetty;\n\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    replica.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    \n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n    \n    Thread.sleep(1000);\n  \n    waitForThingsToLevelOut(120);\n    \n    Thread.sleep(2000);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(5000);\n    \n    waitForRecoveriesToFinish(DEFAULT_COLLECTION, zkStateReader, false, true);\n\n    // test that leader and replica have same doc count\n    \n    String fail = checkShardConsistency(\"shard1\", false, false);\n    if (fail != null) {\n      fail(fail);\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.setParam(\"distrib\", \"false\");\n    long client1Docs = shardToJetty.get(\"shard1\").get(0).client.solrClient.query(query).getResults().getNumFound();\n    long client2Docs = shardToJetty.get(\"shard1\").get(1).client.solrClient.query(query).getResults().getNumFound();\n    \n    assertTrue(client1Docs > 0);\n    assertEquals(client1Docs, client2Docs);\n \n    // won't always pass yet...\n    //query(\"q\", \"*:*\", \"sort\", \"id desc\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a4efd3fffdd7acd625bb88e455c8097e17f75735","date":1477647201,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n\n    final String collection = \"recoverytest\";\n\n    CollectionAdminRequest.createCollection(collection, \"conf\", 1, 2)\n        .setMaxShardsPerNode(1)\n        .process(cluster.getSolrClient());\n    waitForState(\"Expected a collection with one shard and two replicas\", collection, clusterShape(1, 2));\n    cluster.getSolrClient().setDefaultCollection(collection);\n\n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    log.info(\"Indexing {} documents\", maxDoc);\n    \n    indexThread = new StoppableIndexingThread(null, cluster.getSolrClient(), \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StoppableIndexingThread(null, cluster.getSolrClient(), \"2\", true, maxDoc, 1, true);\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    DocCollection state = getCollectionState(collection);\n    Replica leader = state.getLeader(\"shard1\");\n    Replica replica = getRandomReplica(state.getSlice(\"shard1\"), (r) -> leader != r);\n\n    JettySolrRunner jetty = cluster.getReplicaJetty(replica);\n    jetty.stop();\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    jetty.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n\n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n\n    new UpdateRequest()\n        .commit(cluster.getSolrClient(), collection);\n\n    cluster.getSolrClient().waitForState(collection, 120, TimeUnit.SECONDS, clusterShape(1, 2));\n\n    // test that leader and replica have same doc count\n    state = getCollectionState(collection);\n    assertShardConsistency(state.getSlice(\"shard1\"), true);\n\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    \n    indexThread = new StoppableIndexingThread(controlClient, cloudClient, \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StoppableIndexingThread(controlClient, cloudClient, \"2\", true, maxDoc, 1, true);\n\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    JettySolrRunner replica = chaosMonkey.stopShard(\"shard1\", 1).jetty;\n\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    replica.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    \n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n    \n    Thread.sleep(1000);\n  \n    waitForThingsToLevelOut(120);\n    \n    Thread.sleep(2000);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(5000);\n    \n    waitForRecoveriesToFinish(DEFAULT_COLLECTION, zkStateReader, false, true);\n\n    // test that leader and replica have same doc count\n    \n    String fail = checkShardConsistency(\"shard1\", false, false);\n    if (fail != null) {\n      fail(fail);\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.setParam(\"distrib\", \"false\");\n    long client1Docs = shardToJetty.get(\"shard1\").get(0).client.solrClient.query(query).getResults().getNumFound();\n    long client2Docs = shardToJetty.get(\"shard1\").get(1).client.solrClient.query(query).getResults().getNumFound();\n    \n    assertTrue(client1Docs > 0);\n    assertEquals(client1Docs, client2Docs);\n \n    // won't always pass yet...\n    //query(\"q\", \"*:*\", \"sort\", \"id desc\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"59dce44d6a0b58c171de1d47ad8c0a75831f94fd","date":1477668573,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n\n    final String collection = \"recoverytest\";\n\n    CollectionAdminRequest.createCollection(collection, \"conf\", 1, 2)\n        .setMaxShardsPerNode(1)\n        .process(cluster.getSolrClient());\n    waitForState(\"Expected a collection with one shard and two replicas\", collection, clusterShape(1, 2));\n    cluster.getSolrClient().setDefaultCollection(collection);\n\n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    log.info(\"Indexing {} documents\", maxDoc);\n    \n    indexThread = new StoppableIndexingThread(null, cluster.getSolrClient(), \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StoppableIndexingThread(null, cluster.getSolrClient(), \"2\", true, maxDoc, 1, true);\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    DocCollection state = getCollectionState(collection);\n    Replica leader = state.getLeader(\"shard1\");\n    Replica replica = getRandomReplica(state.getSlice(\"shard1\"), (r) -> leader != r);\n\n    JettySolrRunner jetty = cluster.getReplicaJetty(replica);\n    jetty.stop();\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    jetty.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n\n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n\n    new UpdateRequest()\n        .commit(cluster.getSolrClient(), collection);\n\n    cluster.getSolrClient().waitForState(collection, 120, TimeUnit.SECONDS, clusterShape(1, 2));\n\n    // test that leader and replica have same doc count\n    state = getCollectionState(collection);\n    assertShardConsistency(state.getSlice(\"shard1\"), true);\n\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    \n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    \n    indexThread = new StoppableIndexingThread(controlClient, cloudClient, \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StoppableIndexingThread(controlClient, cloudClient, \"2\", true, maxDoc, 1, true);\n\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    JettySolrRunner replica = chaosMonkey.stopShard(\"shard1\", 1).jetty;\n\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    replica.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n    ZkStateReader zkStateReader = cloudClient.getZkStateReader();\n    \n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n    \n    Thread.sleep(1000);\n  \n    waitForThingsToLevelOut(120);\n    \n    Thread.sleep(2000);\n    \n    waitForThingsToLevelOut(30);\n    \n    Thread.sleep(5000);\n    \n    waitForRecoveriesToFinish(DEFAULT_COLLECTION, zkStateReader, false, true);\n\n    // test that leader and replica have same doc count\n    \n    String fail = checkShardConsistency(\"shard1\", false, false);\n    if (fail != null) {\n      fail(fail);\n    }\n    \n    SolrQuery query = new SolrQuery(\"*:*\");\n    query.setParam(\"distrib\", \"false\");\n    long client1Docs = shardToJetty.get(\"shard1\").get(0).client.solrClient.query(query).getResults().getNumFound();\n    long client2Docs = shardToJetty.get(\"shard1\").get(1).client.solrClient.query(query).getResults().getNumFound();\n    \n    assertTrue(client1Docs > 0);\n    assertEquals(client1Docs, client2Docs);\n \n    // won't always pass yet...\n    //query(\"q\", \"*:*\", \"sort\", \"id desc\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"11d6f92dfa9251d9da6d80ec5963a9cbecc90180","date":1530559969,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 28-June-2018\n  public void test() throws Exception {\n\n    final String collection = \"recoverytest\";\n\n    CollectionAdminRequest.createCollection(collection, \"conf\", 1, 2)\n        .setMaxShardsPerNode(1)\n        .process(cluster.getSolrClient());\n    waitForState(\"Expected a collection with one shard and two replicas\", collection, clusterShape(1, 2));\n    cluster.getSolrClient().setDefaultCollection(collection);\n\n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    log.info(\"Indexing {} documents\", maxDoc);\n    \n    indexThread = new StoppableIndexingThread(null, cluster.getSolrClient(), \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StoppableIndexingThread(null, cluster.getSolrClient(), \"2\", true, maxDoc, 1, true);\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    DocCollection state = getCollectionState(collection);\n    Replica leader = state.getLeader(\"shard1\");\n    Replica replica = getRandomReplica(state.getSlice(\"shard1\"), (r) -> leader != r);\n\n    JettySolrRunner jetty = cluster.getReplicaJetty(replica);\n    jetty.stop();\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    jetty.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n\n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n\n    new UpdateRequest()\n        .commit(cluster.getSolrClient(), collection);\n\n    cluster.getSolrClient().waitForState(collection, 120, TimeUnit.SECONDS, clusterShape(1, 2));\n\n    // test that leader and replica have same doc count\n    state = getCollectionState(collection);\n    assertShardConsistency(state.getSlice(\"shard1\"), true);\n\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n\n    final String collection = \"recoverytest\";\n\n    CollectionAdminRequest.createCollection(collection, \"conf\", 1, 2)\n        .setMaxShardsPerNode(1)\n        .process(cluster.getSolrClient());\n    waitForState(\"Expected a collection with one shard and two replicas\", collection, clusterShape(1, 2));\n    cluster.getSolrClient().setDefaultCollection(collection);\n\n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    log.info(\"Indexing {} documents\", maxDoc);\n    \n    indexThread = new StoppableIndexingThread(null, cluster.getSolrClient(), \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StoppableIndexingThread(null, cluster.getSolrClient(), \"2\", true, maxDoc, 1, true);\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    DocCollection state = getCollectionState(collection);\n    Replica leader = state.getLeader(\"shard1\");\n    Replica replica = getRandomReplica(state.getSlice(\"shard1\"), (r) -> leader != r);\n\n    JettySolrRunner jetty = cluster.getReplicaJetty(replica);\n    jetty.stop();\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    jetty.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n\n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n\n    new UpdateRequest()\n        .commit(cluster.getSolrClient(), collection);\n\n    cluster.getSolrClient().waitForState(collection, 120, TimeUnit.SECONDS, clusterShape(1, 2));\n\n    // test that leader and replica have same doc count\n    state = getCollectionState(collection);\n    assertShardConsistency(state.getSlice(\"shard1\"), true);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 28-June-2018\n  public void test() throws Exception {\n\n    final String collection = \"recoverytest\";\n\n    CollectionAdminRequest.createCollection(collection, \"conf\", 1, 2)\n        .setMaxShardsPerNode(1)\n        .process(cluster.getSolrClient());\n    waitForState(\"Expected a collection with one shard and two replicas\", collection, clusterShape(1, 2));\n    cluster.getSolrClient().setDefaultCollection(collection);\n\n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    log.info(\"Indexing {} documents\", maxDoc);\n    \n    indexThread = new StoppableIndexingThread(null, cluster.getSolrClient(), \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StoppableIndexingThread(null, cluster.getSolrClient(), \"2\", true, maxDoc, 1, true);\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    DocCollection state = getCollectionState(collection);\n    Replica leader = state.getLeader(\"shard1\");\n    Replica replica = getRandomReplica(state.getSlice(\"shard1\"), (r) -> leader != r);\n\n    JettySolrRunner jetty = cluster.getReplicaJetty(replica);\n    jetty.stop();\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    jetty.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n\n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n\n    new UpdateRequest()\n        .commit(cluster.getSolrClient(), collection);\n\n    cluster.getSolrClient().waitForState(collection, 120, TimeUnit.SECONDS, clusterShape(1, 2));\n\n    // test that leader and replica have same doc count\n    state = getCollectionState(collection);\n    assertShardConsistency(state.getSlice(\"shard1\"), true);\n\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n\n    final String collection = \"recoverytest\";\n\n    CollectionAdminRequest.createCollection(collection, \"conf\", 1, 2)\n        .setMaxShardsPerNode(1)\n        .process(cluster.getSolrClient());\n    waitForState(\"Expected a collection with one shard and two replicas\", collection, clusterShape(1, 2));\n    cluster.getSolrClient().setDefaultCollection(collection);\n\n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    log.info(\"Indexing {} documents\", maxDoc);\n    \n    indexThread = new StoppableIndexingThread(null, cluster.getSolrClient(), \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StoppableIndexingThread(null, cluster.getSolrClient(), \"2\", true, maxDoc, 1, true);\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    DocCollection state = getCollectionState(collection);\n    Replica leader = state.getLeader(\"shard1\");\n    Replica replica = getRandomReplica(state.getSlice(\"shard1\"), (r) -> leader != r);\n\n    JettySolrRunner jetty = cluster.getReplicaJetty(replica);\n    jetty.stop();\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    jetty.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n\n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n\n    new UpdateRequest()\n        .commit(cluster.getSolrClient(), collection);\n\n    cluster.getSolrClient().waitForState(collection, 120, TimeUnit.SECONDS, clusterShape(1, 2));\n\n    // test that leader and replica have same doc count\n    state = getCollectionState(collection);\n    assertShardConsistency(state.getSlice(\"shard1\"), true);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 28-June-2018\n  public void test() throws Exception {\n\n    final String collection = \"recoverytest\";\n\n    CollectionAdminRequest.createCollection(collection, \"conf\", 1, 2)\n        .setMaxShardsPerNode(1)\n        .process(cluster.getSolrClient());\n    waitForState(\"Expected a collection with one shard and two replicas\", collection, clusterShape(1, 2));\n    cluster.getSolrClient().setDefaultCollection(collection);\n\n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    log.info(\"Indexing {} documents\", maxDoc);\n    \n    indexThread = new StoppableIndexingThread(null, cluster.getSolrClient(), \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StoppableIndexingThread(null, cluster.getSolrClient(), \"2\", true, maxDoc, 1, true);\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    DocCollection state = getCollectionState(collection);\n    Replica leader = state.getLeader(\"shard1\");\n    Replica replica = getRandomReplica(state.getSlice(\"shard1\"), (r) -> leader != r);\n\n    JettySolrRunner jetty = cluster.getReplicaJetty(replica);\n    jetty.stop();\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    jetty.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n\n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n\n    new UpdateRequest()\n        .commit(cluster.getSolrClient(), collection);\n\n    cluster.getSolrClient().waitForState(collection, 120, TimeUnit.SECONDS, clusterShape(1, 2));\n\n    // test that leader and replica have same doc count\n    state = getCollectionState(collection);\n    assertShardConsistency(state.getSlice(\"shard1\"), true);\n\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n\n    final String collection = \"recoverytest\";\n\n    CollectionAdminRequest.createCollection(collection, \"conf\", 1, 2)\n        .setMaxShardsPerNode(1)\n        .process(cluster.getSolrClient());\n    waitForState(\"Expected a collection with one shard and two replicas\", collection, clusterShape(1, 2));\n    cluster.getSolrClient().setDefaultCollection(collection);\n\n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    log.info(\"Indexing {} documents\", maxDoc);\n    \n    indexThread = new StoppableIndexingThread(null, cluster.getSolrClient(), \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StoppableIndexingThread(null, cluster.getSolrClient(), \"2\", true, maxDoc, 1, true);\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    DocCollection state = getCollectionState(collection);\n    Replica leader = state.getLeader(\"shard1\");\n    Replica replica = getRandomReplica(state.getSlice(\"shard1\"), (r) -> leader != r);\n\n    JettySolrRunner jetty = cluster.getReplicaJetty(replica);\n    jetty.stop();\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    jetty.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n\n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n\n    new UpdateRequest()\n        .commit(cluster.getSolrClient(), collection);\n\n    cluster.getSolrClient().waitForState(collection, 120, TimeUnit.SECONDS, clusterShape(1, 2));\n\n    // test that leader and replica have same doc count\n    state = getCollectionState(collection);\n    assertShardConsistency(state.getSlice(\"shard1\"), true);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05a3c9b5f1dfb39879069eb1dac3ca104d3e4108","date":1533256859,"type":3,"author":"Erick","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","sourceNew":"  @Test\n  //commented 2-Aug-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 28-June-2018\n  public void test() throws Exception {\n\n    final String collection = \"recoverytest\";\n\n    CollectionAdminRequest.createCollection(collection, \"conf\", 1, 2)\n        .setMaxShardsPerNode(1)\n        .process(cluster.getSolrClient());\n    waitForState(\"Expected a collection with one shard and two replicas\", collection, clusterShape(1, 2));\n    cluster.getSolrClient().setDefaultCollection(collection);\n\n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    log.info(\"Indexing {} documents\", maxDoc);\n    \n    indexThread = new StoppableIndexingThread(null, cluster.getSolrClient(), \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StoppableIndexingThread(null, cluster.getSolrClient(), \"2\", true, maxDoc, 1, true);\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    DocCollection state = getCollectionState(collection);\n    Replica leader = state.getLeader(\"shard1\");\n    Replica replica = getRandomReplica(state.getSlice(\"shard1\"), (r) -> leader != r);\n\n    JettySolrRunner jetty = cluster.getReplicaJetty(replica);\n    jetty.stop();\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    jetty.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n\n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n\n    new UpdateRequest()\n        .commit(cluster.getSolrClient(), collection);\n\n    cluster.getSolrClient().waitForState(collection, 120, TimeUnit.SECONDS, clusterShape(1, 2));\n\n    // test that leader and replica have same doc count\n    state = getCollectionState(collection);\n    assertShardConsistency(state.getSlice(\"shard1\"), true);\n\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 28-June-2018\n  public void test() throws Exception {\n\n    final String collection = \"recoverytest\";\n\n    CollectionAdminRequest.createCollection(collection, \"conf\", 1, 2)\n        .setMaxShardsPerNode(1)\n        .process(cluster.getSolrClient());\n    waitForState(\"Expected a collection with one shard and two replicas\", collection, clusterShape(1, 2));\n    cluster.getSolrClient().setDefaultCollection(collection);\n\n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    log.info(\"Indexing {} documents\", maxDoc);\n    \n    indexThread = new StoppableIndexingThread(null, cluster.getSolrClient(), \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StoppableIndexingThread(null, cluster.getSolrClient(), \"2\", true, maxDoc, 1, true);\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    DocCollection state = getCollectionState(collection);\n    Replica leader = state.getLeader(\"shard1\");\n    Replica replica = getRandomReplica(state.getSlice(\"shard1\"), (r) -> leader != r);\n\n    JettySolrRunner jetty = cluster.getReplicaJetty(replica);\n    jetty.stop();\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    jetty.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n\n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n\n    new UpdateRequest()\n        .commit(cluster.getSolrClient(), collection);\n\n    cluster.getSolrClient().waitForState(collection, 120, TimeUnit.SECONDS, clusterShape(1, 2));\n\n    // test that leader and replica have same doc count\n    state = getCollectionState(collection);\n    assertShardConsistency(state.getSlice(\"shard1\"), true);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1edfe287b5d8d16a9effaad9cf334bedae0c8857","date":1561656486,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","sourceNew":"  @Test\n  //commented 2-Aug-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 28-June-2018\n  public void test() throws Exception {\n\n    final String collection = \"recoverytest\";\n\n    CollectionAdminRequest.createCollection(collection, \"conf\", 1, 2)\n        .setMaxShardsPerNode(1)\n        .process(cluster.getSolrClient());\n    waitForState(\"Expected a collection with one shard and two replicas\", collection, clusterShape(1, 2));\n    cluster.getSolrClient().setDefaultCollection(collection);\n\n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    log.info(\"Indexing {} documents\", maxDoc);\n    \n    final StoppableIndexingThread indexThread\n      = new StoppableIndexingThread(null, cluster.getSolrClient(), \"1\", true, maxDoc, 1, true);\n    threads.add(indexThread);\n    indexThread.start();\n    \n    final StoppableIndexingThread indexThread2\n      = new StoppableIndexingThread(null, cluster.getSolrClient(), \"2\", true, maxDoc, 1, true);\n    threads.add(indexThread2);\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    DocCollection state = getCollectionState(collection);\n    Replica leader = state.getLeader(\"shard1\");\n    Replica replica = getRandomReplica(state.getSlice(\"shard1\"), (r) -> leader != r);\n\n    JettySolrRunner jetty = cluster.getReplicaJetty(replica);\n    jetty.stop();\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    jetty.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n\n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n\n    new UpdateRequest()\n        .commit(cluster.getSolrClient(), collection);\n\n    cluster.getSolrClient().waitForState(collection, 120, TimeUnit.SECONDS, clusterShape(1, 2));\n\n    // test that leader and replica have same doc count\n    state = getCollectionState(collection);\n    assertShardConsistency(state.getSlice(\"shard1\"), true);\n\n  }\n\n","sourceOld":"  @Test\n  //commented 2-Aug-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 28-June-2018\n  public void test() throws Exception {\n\n    final String collection = \"recoverytest\";\n\n    CollectionAdminRequest.createCollection(collection, \"conf\", 1, 2)\n        .setMaxShardsPerNode(1)\n        .process(cluster.getSolrClient());\n    waitForState(\"Expected a collection with one shard and two replicas\", collection, clusterShape(1, 2));\n    cluster.getSolrClient().setDefaultCollection(collection);\n\n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    log.info(\"Indexing {} documents\", maxDoc);\n    \n    indexThread = new StoppableIndexingThread(null, cluster.getSolrClient(), \"1\", true, maxDoc, 1, true);\n    indexThread.start();\n    \n    indexThread2 = new StoppableIndexingThread(null, cluster.getSolrClient(), \"2\", true, maxDoc, 1, true);\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    DocCollection state = getCollectionState(collection);\n    Replica leader = state.getLeader(\"shard1\");\n    Replica replica = getRandomReplica(state.getSlice(\"shard1\"), (r) -> leader != r);\n\n    JettySolrRunner jetty = cluster.getReplicaJetty(replica);\n    jetty.stop();\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    jetty.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n\n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n\n    new UpdateRequest()\n        .commit(cluster.getSolrClient(), collection);\n\n    cluster.getSolrClient().waitForState(collection, 120, TimeUnit.SECONDS, clusterShape(1, 2));\n\n    // test that leader and replica have same doc count\n    state = getCollectionState(collection);\n    assertShardConsistency(state.getSlice(\"shard1\"), true);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest#test().mjava","sourceNew":"  @Test\n  //commented 2-Aug-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 28-June-2018\n  public void test() throws Exception {\n\n    final String collection = \"recoverytest\";\n\n    CollectionAdminRequest.createCollection(collection, \"conf\", 1, 2)\n        .process(cluster.getSolrClient());\n    waitForState(\"Expected a collection with one shard and two replicas\", collection, clusterShape(1, 2));\n    cluster.getSolrClient().setDefaultCollection(collection);\n\n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    log.info(\"Indexing {} documents\", maxDoc);\n    \n    final StoppableIndexingThread indexThread\n      = new StoppableIndexingThread(null, cluster.getSolrClient(), \"1\", true, maxDoc, 1, true);\n    threads.add(indexThread);\n    indexThread.start();\n    \n    final StoppableIndexingThread indexThread2\n      = new StoppableIndexingThread(null, cluster.getSolrClient(), \"2\", true, maxDoc, 1, true);\n    threads.add(indexThread2);\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    DocCollection state = getCollectionState(collection);\n    Replica leader = state.getLeader(\"shard1\");\n    Replica replica = getRandomReplica(state.getSlice(\"shard1\"), (r) -> leader != r);\n\n    JettySolrRunner jetty = cluster.getReplicaJetty(replica);\n    jetty.stop();\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    jetty.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n\n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n\n    new UpdateRequest()\n        .commit(cluster.getSolrClient(), collection);\n\n    cluster.getSolrClient().waitForState(collection, 120, TimeUnit.SECONDS, clusterShape(1, 2));\n\n    // test that leader and replica have same doc count\n    state = getCollectionState(collection);\n    assertShardConsistency(state.getSlice(\"shard1\"), true);\n\n  }\n\n","sourceOld":"  @Test\n  //commented 2-Aug-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 28-June-2018\n  public void test() throws Exception {\n\n    final String collection = \"recoverytest\";\n\n    CollectionAdminRequest.createCollection(collection, \"conf\", 1, 2)\n        .setMaxShardsPerNode(1)\n        .process(cluster.getSolrClient());\n    waitForState(\"Expected a collection with one shard and two replicas\", collection, clusterShape(1, 2));\n    cluster.getSolrClient().setDefaultCollection(collection);\n\n    // start a couple indexing threads\n    \n    int[] maxDocList = new int[] {300, 700, 1200, 1350, 3000};\n    int[] maxDocNightlyList = new int[] {3000, 7000, 12000, 30000, 45000, 60000};\n    \n    int maxDoc;\n    if (!TEST_NIGHTLY) {\n      maxDoc = maxDocList[random().nextInt(maxDocList.length - 1)];\n    } else {\n      maxDoc = maxDocNightlyList[random().nextInt(maxDocList.length - 1)];\n    }\n    log.info(\"Indexing {} documents\", maxDoc);\n    \n    final StoppableIndexingThread indexThread\n      = new StoppableIndexingThread(null, cluster.getSolrClient(), \"1\", true, maxDoc, 1, true);\n    threads.add(indexThread);\n    indexThread.start();\n    \n    final StoppableIndexingThread indexThread2\n      = new StoppableIndexingThread(null, cluster.getSolrClient(), \"2\", true, maxDoc, 1, true);\n    threads.add(indexThread2);\n    indexThread2.start();\n\n    // give some time to index...\n    int[] waitTimes = new int[] {200, 2000, 3000};\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n     \n    // bring shard replica down\n    DocCollection state = getCollectionState(collection);\n    Replica leader = state.getLeader(\"shard1\");\n    Replica replica = getRandomReplica(state.getSlice(\"shard1\"), (r) -> leader != r);\n\n    JettySolrRunner jetty = cluster.getReplicaJetty(replica);\n    jetty.stop();\n    \n    // wait a moment - lets allow some docs to be indexed so replication time is non 0\n    Thread.sleep(waitTimes[random().nextInt(waitTimes.length - 1)]);\n    \n    // bring shard replica up\n    jetty.start();\n    \n    // make sure replication can start\n    Thread.sleep(3000);\n\n    // stop indexing threads\n    indexThread.safeStop();\n    indexThread2.safeStop();\n    \n    indexThread.join();\n    indexThread2.join();\n\n    new UpdateRequest()\n        .commit(cluster.getSolrClient(), collection);\n\n    cluster.getSolrClient().waitForState(collection, 120, TimeUnit.SECONDS, clusterShape(1, 2));\n\n    // test that leader and replica have same doc count\n    state = getCollectionState(collection);\n    assertShardConsistency(state.getSlice(\"shard1\"), true);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a4efd3fffdd7acd625bb88e455c8097e17f75735":["98287baa2c8d136e801f366a73e27a23285b7b98"],"05a3c9b5f1dfb39879069eb1dac3ca104d3e4108":["11d6f92dfa9251d9da6d80ec5963a9cbecc90180"],"59dce44d6a0b58c171de1d47ad8c0a75831f94fd":["98287baa2c8d136e801f366a73e27a23285b7b98","a4efd3fffdd7acd625bb88e455c8097e17f75735"],"abb23fcc2461782ab204e61213240feb77d355aa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"6c94d2661bc1c14426980ec7882e951fdcff08d0":["abb23fcc2461782ab204e61213240feb77d355aa"],"98287baa2c8d136e801f366a73e27a23285b7b98":["6c94d2661bc1c14426980ec7882e951fdcff08d0"],"1edfe287b5d8d16a9effaad9cf334bedae0c8857":["05a3c9b5f1dfb39879069eb1dac3ca104d3e4108"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["1edfe287b5d8d16a9effaad9cf334bedae0c8857"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["abb23fcc2461782ab204e61213240feb77d355aa","98287baa2c8d136e801f366a73e27a23285b7b98"],"11d6f92dfa9251d9da6d80ec5963a9cbecc90180":["a4efd3fffdd7acd625bb88e455c8097e17f75735"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["a4efd3fffdd7acd625bb88e455c8097e17f75735","11d6f92dfa9251d9da6d80ec5963a9cbecc90180"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["a4efd3fffdd7acd625bb88e455c8097e17f75735","11d6f92dfa9251d9da6d80ec5963a9cbecc90180"]},"commit2Childs":{"a4efd3fffdd7acd625bb88e455c8097e17f75735":["59dce44d6a0b58c171de1d47ad8c0a75831f94fd","11d6f92dfa9251d9da6d80ec5963a9cbecc90180","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"05a3c9b5f1dfb39879069eb1dac3ca104d3e4108":["1edfe287b5d8d16a9effaad9cf334bedae0c8857"],"59dce44d6a0b58c171de1d47ad8c0a75831f94fd":[],"abb23fcc2461782ab204e61213240feb77d355aa":["6c94d2661bc1c14426980ec7882e951fdcff08d0","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"6c94d2661bc1c14426980ec7882e951fdcff08d0":["98287baa2c8d136e801f366a73e27a23285b7b98"],"98287baa2c8d136e801f366a73e27a23285b7b98":["a4efd3fffdd7acd625bb88e455c8097e17f75735","59dce44d6a0b58c171de1d47ad8c0a75831f94fd","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"1edfe287b5d8d16a9effaad9cf334bedae0c8857":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"11d6f92dfa9251d9da6d80ec5963a9cbecc90180":["05a3c9b5f1dfb39879069eb1dac3ca104d3e4108","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["abb23fcc2461782ab204e61213240feb77d355aa"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["59dce44d6a0b58c171de1d47ad8c0a75831f94fd","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}