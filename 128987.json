{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                         .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    assertEquals(\"only the stored and term vector files should exist in the directory\", 5 + extraFileCount, dir.listAll().length);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    assertEquals(\"no files should exist in the directory after rollback\", 0, dir.listAll().length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    assertEquals(\"expected a no-op close after IW.rollback()\", 0, dir.listAll().length);\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                         .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    assertEquals(\"only the stored and term vector files should exist in the directory\", 5 + extraFileCount, dir.listAll().length);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    assertEquals(\"no files should exist in the directory after rollback\", 0, dir.listAll().length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    assertEquals(\"expected a no-op close after IW.rollback()\", 0, dir.listAll().length);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n                                         .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    assertEquals(\"only the stored and term vector files should exist in the directory\", 5 + extraFileCount, dir.listAll().length);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    assertEquals(\"no files should exist in the directory after rollback\", 0, dir.listAll().length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    assertEquals(\"expected a no-op close after IW.rollback()\", 0, dir.listAll().length);\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random))\n                                         .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    assertEquals(\"only the stored and term vector files should exist in the directory\", 5 + extraFileCount, dir.listAll().length);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    assertEquals(\"no files should exist in the directory after rollback\", 0, dir.listAll().length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    assertEquals(\"expected a no-op close after IW.rollback()\", 0, dir.listAll().length);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eda61b1e90b490cc5837200e04c02639a0d272c7","date":1358795519,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n                                         .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (file.lastIndexOf('.') < 0\n          // don't count stored fields and term vectors in\n          || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n        ++computedExtraFileCount;\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    assertEquals(\"no files should exist in the directory after rollback\", 0, dir.listAll().length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    assertEquals(\"expected a no-op close after IW.rollback()\", 0, dir.listAll().length);\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n                                         .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    assertEquals(\"only the stored and term vector files should exist in the directory\", 5 + extraFileCount, dir.listAll().length);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    assertEquals(\"no files should exist in the directory after rollback\", 0, dir.listAll().length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    assertEquals(\"expected a no-op close after IW.rollback()\", 0, dir.listAll().length);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"07155cdd910937cdf6877e48884d5782845c8b8b","date":1358796205,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n                                         .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (file.lastIndexOf('.') < 0\n          // don't count stored fields and term vectors in\n          || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n        ++computedExtraFileCount;\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    assertEquals(\"no files should exist in the directory after rollback\", 0, dir.listAll().length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    assertEquals(\"expected a no-op close after IW.rollback()\", 0, dir.listAll().length);\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n                                         .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    assertEquals(\"only the stored and term vector files should exist in the directory\", 5 + extraFileCount, dir.listAll().length);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    assertEquals(\"no files should exist in the directory after rollback\", 0, dir.listAll().length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    assertEquals(\"expected a no-op close after IW.rollback()\", 0, dir.listAll().length);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"088a7ef694fd43d5d9a4d200c4005865f773d1e7","date":1371136274,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n                                         .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()).setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (file.lastIndexOf('.') < 0\n          // don't count stored fields and term vectors in\n          || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n        ++computedExtraFileCount;\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    assertEquals(\"no files should exist in the directory after rollback\", 0, dir.listAll().length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    assertEquals(\"expected a no-op close after IW.rollback()\", 0, dir.listAll().length);\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n                                         .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (file.lastIndexOf('.') < 0\n          // don't count stored fields and term vectors in\n          || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n        ++computedExtraFileCount;\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    assertEquals(\"no files should exist in the directory after rollback\", 0, dir.listAll().length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    assertEquals(\"expected a no-op close after IW.rollback()\", 0, dir.listAll().length);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"50805be75df24f05d29a4d2a496c7ec825cde9eb","date":1398078566,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n                                         .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()).setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (file.lastIndexOf('.') < 0\n          // don't count stored fields and term vectors in\n          || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n        ++computedExtraFileCount;\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertTrue(\"no files should exist in the directory after rollback\", allFiles.length == 0 || Arrays.equals(allFiles, new String[] { IndexWriter.WRITE_LOCK_NAME }));\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertTrue(\"expected a no-op close after IW.rollback()\", allFiles.length == 0 || Arrays.equals(allFiles, new String[] { IndexWriter.WRITE_LOCK_NAME }));\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n                                         .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()).setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (file.lastIndexOf('.') < 0\n          // don't count stored fields and term vectors in\n          || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n        ++computedExtraFileCount;\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    assertEquals(\"no files should exist in the directory after rollback\", 0, dir.listAll().length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    assertEquals(\"expected a no-op close after IW.rollback()\", 0, dir.listAll().length);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (file.lastIndexOf('.') < 0\n          // don't count stored fields and term vectors in\n          || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n        ++computedExtraFileCount;\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertTrue(\"no files should exist in the directory after rollback\", allFiles.length == 0 || Arrays.equals(allFiles, new String[] { IndexWriter.WRITE_LOCK_NAME }));\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertTrue(\"expected a no-op close after IW.rollback()\", allFiles.length == 0 || Arrays.equals(allFiles, new String[] { IndexWriter.WRITE_LOCK_NAME }));\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n                                         .setMaxBufferedDocs(2).setMergePolicy(newLogMergePolicy()).setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (file.lastIndexOf('.') < 0\n          // don't count stored fields and term vectors in\n          || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n        ++computedExtraFileCount;\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertTrue(\"no files should exist in the directory after rollback\", allFiles.length == 0 || Arrays.equals(allFiles, new String[] { IndexWriter.WRITE_LOCK_NAME }));\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertTrue(\"expected a no-op close after IW.rollback()\", allFiles.length == 0 || Arrays.equals(allFiles, new String[] { IndexWriter.WRITE_LOCK_NAME }));\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13","date":1409346855,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (file.lastIndexOf('.') < 0\n          // don't count stored fields and term vectors in\n          || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n        ++computedExtraFileCount;\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertTrue(\"no files should exist in the directory after rollback\", allFiles.length == 0 || Arrays.equals(allFiles, new String[] { IndexWriter.WRITE_LOCK_NAME }));\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertTrue(\"expected a no-op close after IW.rollback()\", allFiles.length == 0 || Arrays.equals(allFiles, new String[] { IndexWriter.WRITE_LOCK_NAME }));\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (file.lastIndexOf('.') < 0\n          // don't count stored fields and term vectors in\n          || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n        ++computedExtraFileCount;\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertTrue(\"no files should exist in the directory after rollback\", allFiles.length == 0 || Arrays.equals(allFiles, new String[] { IndexWriter.WRITE_LOCK_NAME }));\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertTrue(\"expected a no-op close after IW.rollback()\", allFiles.length == 0 || Arrays.equals(allFiles, new String[] { IndexWriter.WRITE_LOCK_NAME }));\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"22989c36ff05c657df26dd3377b37c9ad35859bc","date":1424477375,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) || \n          file.startsWith(IndexFileNames.SEGMENTS) || \n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in\n            || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount;\n    if (files.length == 1) {\n      assertTrue(files[0].endsWith(\"write.lock\"));\n      extraFileCount = 1;\n    } else {\n      assertEquals(0, files.length);\n      extraFileCount = 0;\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (file.lastIndexOf('.') < 0\n          // don't count stored fields and term vectors in\n          || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n        ++computedExtraFileCount;\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertTrue(\"no files should exist in the directory after rollback\", allFiles.length == 0 || Arrays.equals(allFiles, new String[] { IndexWriter.WRITE_LOCK_NAME }));\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertTrue(\"expected a no-op close after IW.rollback()\", allFiles.length == 0 || Arrays.equals(allFiles, new String[] { IndexWriter.WRITE_LOCK_NAME }));\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6bfe104fc023fadc9e709f8d17403d2cc61133fe","date":1454446396,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    \n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) || \n          file.startsWith(IndexFileNames.SEGMENTS) || \n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in\n            || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) || \n          file.startsWith(IndexFileNames.SEGMENTS) || \n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in\n            || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b470f36a9372c97283360b1304eacbde22df6c0d","date":1454765175,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    \n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) || \n          file.startsWith(IndexFileNames.SEGMENTS) || \n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in\n            || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) || \n          file.startsWith(IndexFileNames.SEGMENTS) || \n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in\n            || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    \n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) || \n          file.startsWith(IndexFileNames.SEGMENTS) || \n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in\n            || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) || \n          file.startsWith(IndexFileNames.SEGMENTS) || \n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in\n            || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a207d19eac354d649c3f0e2cce070017c78125e","date":1454776470,"type":3,"author":"Erick Erickson","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    \n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) || \n          file.startsWith(IndexFileNames.SEGMENTS) || \n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in\n            || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) || \n          file.startsWith(IndexFileNames.SEGMENTS) || \n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in\n            || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70a4487b07c49a1861c05720e04624826ecbe9fa","date":1580924108,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    \n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) || \n          file.startsWith(IndexFileNames.SEGMENTS) || \n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in, or any temporary files they might\n            || !Arrays.asList(\"fdt\", \"tvd\", \"tmp\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    \n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) || \n          file.startsWith(IndexFileNames.SEGMENTS) || \n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in\n            || !Arrays.asList(\"fdx\", \"fdt\", \"tvx\", \"tvd\", \"tvf\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe39f1a106531207c028defebbc9eb5bb489ac50","date":1592513789,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n\n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) ||\n          file.startsWith(IndexFileNames.SEGMENTS) ||\n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in, or any temporary files they might\n            || !Arrays.asList(\"fdt\", \"tvd\", \"tmp\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    \n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) || \n          file.startsWith(IndexFileNames.SEGMENTS) || \n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in, or any temporary files they might\n            || !Arrays.asList(\"fdt\", \"tvd\", \"tmp\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1182fe36fb5df768dc2da53f6d5338cbc07268ae","date":1592861749,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    \n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) || \n          file.startsWith(IndexFileNames.SEGMENTS) || \n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in, or any temporary files they might\n            || !Arrays.asList(\"fdt\", \"tvd\", \"tmp\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n\n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) ||\n          file.startsWith(IndexFileNames.SEGMENTS) ||\n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in, or any temporary files they might\n            || !Arrays.asList(\"fdt\", \"tvd\", \"tmp\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c2a23476693f2bd9a4b44cc3187c429a2e21dac2","date":1593289545,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n\n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) ||\n          file.startsWith(IndexFileNames.SEGMENTS) ||\n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in, or any temporary files they might\n            || !Arrays.asList(\"fdt\", \"tvd\", \"tmp\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n    \n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) || \n          file.startsWith(IndexFileNames.SEGMENTS) || \n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in, or any temporary files they might\n            || !Arrays.asList(\"fdt\", \"tvd\", \"tmp\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2b78d8dfe50af510bace3600bfc4cfa0b031f776","date":1598430423,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testEmptyDirRollback().mjava","sourceNew":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n\n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) ||\n          file.startsWith(IndexFileNames.SEGMENTS) ||\n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in, or any temporary files they might\n            || !Arrays.asList(\"fdm\", \"fdt\", \"tvm\", \"tvd\", \"tmp\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","sourceOld":"  public void testEmptyDirRollback() throws Exception {\n    // TODO: generalize this test\n    assumeFalse(\"test makes assumptions about file counts\", Codec.getDefault() instanceof SimpleTextCodec);\n    // Tests that if IW is created over an empty Directory, some documents are\n    // indexed, flushed (but not committed) and then IW rolls back, then no\n    // files are left in the Directory.\n    Directory dir = newDirectory();\n\n    String[] origFiles = dir.listAll();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2)\n                                                .setMergePolicy(newLogMergePolicy())\n                                                .setUseCompoundFile(false));\n    String[] files = dir.listAll();\n\n    // Creating over empty dir should not create any files,\n    // or, at most the write.lock file\n    final int extraFileCount = files.length - origFiles.length;\n    if (extraFileCount == 1) {\n      assertTrue(Arrays.asList(files).contains(IndexWriter.WRITE_LOCK_NAME));\n    } else {\n      Arrays.sort(origFiles);\n      Arrays.sort(files);\n      assertArrayEquals(origFiles, files);\n    }\n\n    Document doc = new Document();\n    FieldType customType = new FieldType(TextField.TYPE_STORED);\n    customType.setStoreTermVectors(true);\n    customType.setStoreTermVectorPositions(true);\n    customType.setStoreTermVectorOffsets(true);\n    // create as many files as possible\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n    // Adding just one document does not call flush yet.\n    int computedExtraFileCount = 0;\n    for (String file : dir.listAll()) {\n      if (IndexWriter.WRITE_LOCK_NAME.equals(file) ||\n          file.startsWith(IndexFileNames.SEGMENTS) ||\n          IndexFileNames.CODEC_FILE_PATTERN.matcher(file).matches()) {\n        if (file.lastIndexOf('.') < 0\n            // don't count stored fields and term vectors in, or any temporary files they might\n            || !Arrays.asList(\"fdt\", \"tvd\", \"tmp\").contains(file.substring(file.lastIndexOf('.') + 1))) {\n          ++computedExtraFileCount;\n        }\n      }\n    }\n    assertEquals(\"only the stored and term vector files should exist in the directory\", extraFileCount, computedExtraFileCount);\n\n    doc = new Document();\n    doc.add(newField(\"c\", \"val\", customType));\n    writer.addDocument(doc);\n\n    // The second document should cause a flush.\n    assertTrue(\"flush should have occurred and files should have been created\", dir.listAll().length > 5 + extraFileCount);\n\n    // After rollback, IW should remove all files\n    writer.rollback();\n    String allFiles[] = dir.listAll();\n    assertEquals(\"no files should exist in the directory after rollback\", origFiles.length + extraFileCount, allFiles.length);\n\n    // Since we rolled-back above, that close should be a no-op\n    writer.close();\n    allFiles = dir.listAll();\n    assertEquals(\"expected a no-op close after IW.rollback()\", origFiles.length + extraFileCount, allFiles.length);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"2b78d8dfe50af510bace3600bfc4cfa0b031f776":["c2a23476693f2bd9a4b44cc3187c429a2e21dac2"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["50805be75df24f05d29a4d2a496c7ec825cde9eb"],"eda61b1e90b490cc5837200e04c02639a0d272c7":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5a207d19eac354d649c3f0e2cce070017c78125e":["22989c36ff05c657df26dd3377b37c9ad35859bc","b470f36a9372c97283360b1304eacbde22df6c0d"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["22989c36ff05c657df26dd3377b37c9ad35859bc","b470f36a9372c97283360b1304eacbde22df6c0d"],"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"fe39f1a106531207c028defebbc9eb5bb489ac50":["70a4487b07c49a1861c05720e04624826ecbe9fa"],"07155cdd910937cdf6877e48884d5782845c8b8b":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","eda61b1e90b490cc5837200e04c02639a0d272c7"],"c2a23476693f2bd9a4b44cc3187c429a2e21dac2":["1182fe36fb5df768dc2da53f6d5338cbc07268ae"],"70a4487b07c49a1861c05720e04624826ecbe9fa":["5a207d19eac354d649c3f0e2cce070017c78125e"],"088a7ef694fd43d5d9a4d200c4005865f773d1e7":["eda61b1e90b490cc5837200e04c02639a0d272c7"],"b470f36a9372c97283360b1304eacbde22df6c0d":["22989c36ff05c657df26dd3377b37c9ad35859bc","6bfe104fc023fadc9e709f8d17403d2cc61133fe"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"50805be75df24f05d29a4d2a496c7ec825cde9eb":["088a7ef694fd43d5d9a4d200c4005865f773d1e7"],"6bfe104fc023fadc9e709f8d17403d2cc61133fe":["22989c36ff05c657df26dd3377b37c9ad35859bc"],"22989c36ff05c657df26dd3377b37c9ad35859bc":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13"],"1182fe36fb5df768dc2da53f6d5338cbc07268ae":["fe39f1a106531207c028defebbc9eb5bb489ac50"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2b78d8dfe50af510bace3600bfc4cfa0b031f776"]},"commit2Childs":{"2b78d8dfe50af510bace3600bfc4cfa0b031f776":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13"],"eda61b1e90b490cc5837200e04c02639a0d272c7":["07155cdd910937cdf6877e48884d5782845c8b8b","088a7ef694fd43d5d9a4d200c4005865f773d1e7"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"5a207d19eac354d649c3f0e2cce070017c78125e":["70a4487b07c49a1861c05720e04624826ecbe9fa"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":[],"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13":["22989c36ff05c657df26dd3377b37c9ad35859bc"],"fe39f1a106531207c028defebbc9eb5bb489ac50":["1182fe36fb5df768dc2da53f6d5338cbc07268ae"],"07155cdd910937cdf6877e48884d5782845c8b8b":[],"c2a23476693f2bd9a4b44cc3187c429a2e21dac2":["2b78d8dfe50af510bace3600bfc4cfa0b031f776"],"70a4487b07c49a1861c05720e04624826ecbe9fa":["fe39f1a106531207c028defebbc9eb5bb489ac50"],"088a7ef694fd43d5d9a4d200c4005865f773d1e7":["50805be75df24f05d29a4d2a496c7ec825cde9eb"],"b470f36a9372c97283360b1304eacbde22df6c0d":["5a207d19eac354d649c3f0e2cce070017c78125e","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"50805be75df24f05d29a4d2a496c7ec825cde9eb":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"6bfe104fc023fadc9e709f8d17403d2cc61133fe":["b470f36a9372c97283360b1304eacbde22df6c0d"],"22989c36ff05c657df26dd3377b37c9ad35859bc":["5a207d19eac354d649c3f0e2cce070017c78125e","1e6acbaae7af722f17204ceccf0f7db5753eccf3","b470f36a9372c97283360b1304eacbde22df6c0d","6bfe104fc023fadc9e709f8d17403d2cc61133fe"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["eda61b1e90b490cc5837200e04c02639a0d272c7","07155cdd910937cdf6877e48884d5782845c8b8b"],"1182fe36fb5df768dc2da53f6d5338cbc07268ae":["c2a23476693f2bd9a4b44cc3187c429a2e21dac2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["1e6acbaae7af722f17204ceccf0f7db5753eccf3","07155cdd910937cdf6877e48884d5782845c8b8b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}