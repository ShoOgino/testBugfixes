{"path":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","pathOld":"src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","sourceNew":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarity(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n  }\n\n","sourceOld":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarity(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c","date":1281477834,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","sourceNew":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarity(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","sourceOld":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarity(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","sourceNew":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarity(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","sourceOld":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarity(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c8323d210478d76a02372693d254b69aac614689","date":1295877066,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","sourceNew":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarity(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","sourceOld":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarity(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9325c7ff9928fabe81c28553b41fc7aa57dfab","date":1295896411,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","sourceNew":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarityProvider(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","sourceOld":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarity(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb9b72f7c3d7827c64dd4ec580ded81778da361d","date":1295897920,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","sourceNew":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarityProvider(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","sourceOld":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarity(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","sourceNew":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarityProvider(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","sourceOld":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarity(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = query.getSpans(searcher.getIndexReader());\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    assertTrue(\"spans is not an instanceof \" + TermSpans.class, spans instanceof TermSpans);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"160d004a0e8f5361a446f9d01456aee1c1af20dc","date":1301061642,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","sourceNew":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new FullSimilarity();\n      }\n    });\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","sourceOld":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarityProvider(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","sourceNew":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new FullSimilarity();\n      }\n    });\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","sourceOld":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarityProvider(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0ef0193974807e4bddf5432a6b0287fe4d6c9df","date":1301476645,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","sourceNew":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new FullSimilarity();\n      }\n    });\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","sourceOld":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarityProvider(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3a0403b45dfe384fae4a1b6e96c3265d000c498","date":1321445981,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","sourceNew":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexReader reader = IndexReader.open(directory);\n    IndexSearcher theSearcher = new IndexSearcher(reader);\n    theSearcher.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new FullSimilarity();\n      }\n    });\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n    reader.close();\n  }\n\n","sourceOld":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexSearcher theSearcher = new IndexSearcher(directory, true);\n    theSearcher.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new FullSimilarity();\n      }\n    });\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e7c2454a6a8237bfd0e953f5b940838408c9055","date":1323649300,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","sourceNew":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexReader reader = IndexReader.open(directory);\n    IndexSearcher theSearcher = new IndexSearcher(reader);\n    theSearcher.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new FullSimilarity();\n      }\n    });\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    reader.close();\n  }\n\n","sourceOld":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexReader reader = IndexReader.open(directory);\n    IndexSearcher theSearcher = new IndexSearcher(reader);\n    theSearcher.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new FullSimilarity();\n      }\n    });\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","date":1323720782,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","sourceNew":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexReader reader = IndexReader.open(directory);\n    IndexSearcher theSearcher = new IndexSearcher(reader);\n    theSearcher.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new FullSimilarity();\n      }\n    });\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    reader.close();\n  }\n\n","sourceOld":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexReader reader = IndexReader.open(directory);\n    IndexSearcher theSearcher = new IndexSearcher(reader);\n    theSearcher.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new FullSimilarity();\n      }\n    });\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    theSearcher.close();\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1ab42b0756bdd98ac6a6767b5a77d10d9ba12b4b","date":1328532481,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","sourceNew":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexReader reader = IndexReader.open(directory);\n    IndexSearcher theSearcher = new IndexSearcher(reader);\n    theSearcher.setSimilarity(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    reader.close();\n  }\n\n","sourceOld":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexReader reader = IndexReader.open(directory);\n    IndexSearcher theSearcher = new IndexSearcher(reader);\n    theSearcher.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new FullSimilarity();\n      }\n    });\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery#testIgnoreSpanScorer().mjava","sourceNew":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexReader reader = IndexReader.open(directory);\n    IndexSearcher theSearcher = new IndexSearcher(reader);\n    theSearcher.setSimilarity(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    reader.close();\n  }\n\n","sourceOld":"  //Set includeSpanScore to false, in which case just the payload score comes through.\n  public void testIgnoreSpanScorer() throws Exception {\n    PayloadTermQuery query = new PayloadTermQuery(new Term(PayloadHelper.MULTI_FIELD, \"seventy\"),\n            new MaxPayloadFunction(), false);\n\n    IndexReader reader = IndexReader.open(directory);\n    IndexSearcher theSearcher = new IndexSearcher(reader);\n    theSearcher.setSimilarity(new FullSimilarity());\n    TopDocs hits = searcher.search(query, null, 100);\n    assertTrue(\"hits is null and it shouldn't be\", hits != null);\n    assertTrue(\"hits Size: \" + hits.totalHits + \" is not: \" + 100, hits.totalHits == 100);\n\n    //they should all have the exact same score, because they all contain seventy once, and we set\n    //all the other similarity factors to be 1\n\n    //System.out.println(\"Hash: \" + seventyHash + \" Twice Hash: \" + 2*seventyHash);\n    assertTrue(hits.getMaxScore() + \" does not equal: \" + 4.0, hits.getMaxScore() == 4.0);\n    //there should be exactly 10 items that score a 4, all the rest should score a 2\n    //The 10 items are: 70 + i*100 where i in [0-9]\n    int numTens = 0;\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      ScoreDoc doc = hits.scoreDocs[i];\n      if (doc.doc % 10 == 0) {\n        numTens++;\n        assertTrue(doc.score + \" does not equal: \" + 4.0, doc.score == 4.0);\n      } else {\n        assertTrue(doc.score + \" does not equal: \" + 2, doc.score == 2);\n      }\n    }\n    assertTrue(numTens + \" does not equal: \" + 10, numTens == 10);\n    CheckHits.checkExplanations(query, \"field\", searcher, true);\n    Spans spans = MultiSpansWrapper.wrap(searcher.getTopReaderContext(), query);\n    assertTrue(\"spans is null and it shouldn't be\", spans != null);\n    //should be two matches per document\n    int count = 0;\n    //100 hits times 2 matches per hit, we should have 200 in count\n    while (spans.next()) {\n      count++;\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c8323d210478d76a02372693d254b69aac614689":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["1ab42b0756bdd98ac6a6767b5a77d10d9ba12b4b"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["a3a0403b45dfe384fae4a1b6e96c3265d000c498","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"1ab42b0756bdd98ac6a6767b5a77d10d9ba12b4b":["0e7c2454a6a8237bfd0e953f5b940838408c9055"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["9454a6510e2db155fb01faa5c049b06ece95fab9","1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"bb9b72f7c3d7827c64dd4ec580ded81778da361d":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","fd9325c7ff9928fabe81c28553b41fc7aa57dfab"],"fd9325c7ff9928fabe81c28553b41fc7aa57dfab":["c8323d210478d76a02372693d254b69aac614689"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["bb9b72f7c3d7827c64dd4ec580ded81778da361d","160d004a0e8f5361a446f9d01456aee1c1af20dc"],"160d004a0e8f5361a446f9d01456aee1c1af20dc":["fd9325c7ff9928fabe81c28553b41fc7aa57dfab"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["a3a0403b45dfe384fae4a1b6e96c3265d000c498"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["29ef99d61cda9641b6250bf9567329a6e65f901d","160d004a0e8f5361a446f9d01456aee1c1af20dc"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c","fd9325c7ff9928fabe81c28553b41fc7aa57dfab"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a3a0403b45dfe384fae4a1b6e96c3265d000c498":["160d004a0e8f5361a446f9d01456aee1c1af20dc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"c8323d210478d76a02372693d254b69aac614689":["fd9325c7ff9928fabe81c28553b41fc7aa57dfab"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":[],"1ab42b0756bdd98ac6a6767b5a77d10d9ba12b4b":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bb9b72f7c3d7827c64dd4ec580ded81778da361d"],"bb9b72f7c3d7827c64dd4ec580ded81778da361d":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"fd9325c7ff9928fabe81c28553b41fc7aa57dfab":["bb9b72f7c3d7827c64dd4ec580ded81778da361d","160d004a0e8f5361a446f9d01456aee1c1af20dc","29ef99d61cda9641b6250bf9567329a6e65f901d"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":[],"160d004a0e8f5361a446f9d01456aee1c1af20dc":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df","d619839baa8ce5503e496b94a9e42ad6f079293f","a3a0403b45dfe384fae4a1b6e96c3265d000c498"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","1ab42b0756bdd98ac6a6767b5a77d10d9ba12b4b"],"d619839baa8ce5503e496b94a9e42ad6f079293f":[],"29ef99d61cda9641b6250bf9567329a6e65f901d":["d619839baa8ce5503e496b94a9e42ad6f079293f"],"1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c":["c8323d210478d76a02372693d254b69aac614689","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","29ef99d61cda9641b6250bf9567329a6e65f901d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a3a0403b45dfe384fae4a1b6e96c3265d000c498":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","1a2e46fd1b7cbc52d7d6461a6ef99e7107ae2a9c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","c0ef0193974807e4bddf5432a6b0287fe4d6c9df","d619839baa8ce5503e496b94a9e42ad6f079293f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}