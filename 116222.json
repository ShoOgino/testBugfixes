{"path":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinkPhrases().mjava","commits":[{"id":"b305cb92ee47ddf7b15c6eeefe489c04d05b22ba","date":1199456955,"type":0,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinkPhrases().mjava","pathOld":"/dev/null","sourceNew":"  public void testLinkPhrases() throws Exception {\n    String test = \"click [[link here]] click [http://lucene.apache.org here]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    Token token = new Token();\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"click\", new String(token.termBuffer(), 0, token.termLength()).equals(\"click\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"link\", new String(token.termBuffer(), 0, token.termLength()).equals(\"link\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 0, token.getPositionIncrement() == 0);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"here\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"here\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"click\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"click\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 0, token.getPositionIncrement() == 0);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"here\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"here\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"95692f9a6440b2a1c83c2c8ae5224be54319db4c","date":1199477722,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinkPhrases().mjava","pathOld":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinkPhrases().mjava","sourceNew":"  public void testLinkPhrases() throws Exception {\n    String test = \"click [[link here again]] click [http://lucene.apache.org here again]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    Token token = new Token();\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"click\", new String(token.termBuffer(), 0, token.termLength()).equals(\"click\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"link\", new String(token.termBuffer(), 0, token.termLength()).equals(\"link\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"here\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"here\") == true);\n    //The link, and here should be at the same position for phrases to work\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 0, token.getPositionIncrement() == 0);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"again\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"again\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"click\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"click\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"here\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"here\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 0, token.getPositionIncrement() == 0);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"again\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"again\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    \n  }\n\n","sourceOld":"  public void testLinkPhrases() throws Exception {\n    String test = \"click [[link here]] click [http://lucene.apache.org here]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    Token token = new Token();\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"click\", new String(token.termBuffer(), 0, token.termLength()).equals(\"click\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"link\", new String(token.termBuffer(), 0, token.termLength()).equals(\"link\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 0, token.getPositionIncrement() == 0);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"here\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"here\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"click\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"click\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 0, token.getPositionIncrement() == 0);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"here\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"here\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"48aaa86d97259d1aa57d972cae27fe4f522aa70d","date":1199478983,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinkPhrases().mjava","pathOld":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinkPhrases().mjava","sourceNew":"  public void testLinkPhrases() throws Exception {\n    String test = \"click [[link here again]] click [http://lucene.apache.org here again]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    Token token = new Token();\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"click\", new String(token.termBuffer(), 0, token.termLength()).equals(\"click\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"link\", new String(token.termBuffer(), 0, token.termLength()).equals(\"link\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"here\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"here\") == true);\n    //The link, and here should be at the same position for phrases to work\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"again\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"again\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"click\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"click\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"here\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"here\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 0, token.getPositionIncrement() == 0);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"again\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"again\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    \n  }\n\n","sourceOld":"  public void testLinkPhrases() throws Exception {\n    String test = \"click [[link here again]] click [http://lucene.apache.org here again]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    Token token = new Token();\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"click\", new String(token.termBuffer(), 0, token.termLength()).equals(\"click\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"link\", new String(token.termBuffer(), 0, token.termLength()).equals(\"link\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"here\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"here\") == true);\n    //The link, and here should be at the same position for phrases to work\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 0, token.getPositionIncrement() == 0);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"again\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"again\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"click\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"click\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"here\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"here\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 0, token.getPositionIncrement() == 0);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"again\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"again\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"decc8a7344e9231708f9991fa09db2cafec7a2dd","date":1201187153,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinkPhrases().mjava","pathOld":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinkPhrases().mjava","sourceNew":"  public void testLinkPhrases() throws Exception {\n\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(LINK_PHRASES));\n    checkLinkPhrases(tf);\n    \n  }\n\n","sourceOld":"  public void testLinkPhrases() throws Exception {\n    String test = \"click [[link here again]] click [http://lucene.apache.org here again]\";\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));\n    Token token = new Token();\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"click\", new String(token.termBuffer(), 0, token.termLength()).equals(\"click\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"link\", new String(token.termBuffer(), 0, token.termLength()).equals(\"link\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"here\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"here\") == true);\n    //The link, and here should be at the same position for phrases to work\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"again\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"again\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"click\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"click\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"http://lucene.apache.org\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"http://lucene.apache.org\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"here\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"here\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 0, token.getPositionIncrement() == 0);\n\n    token = tf.next(token);\n    assertTrue(\"token is null and it shouldn't be\", token != null);\n    assertTrue(new String(token.termBuffer(), 0, token.termLength()) + \" is not equal to \" + \"again\",\n            new String(token.termBuffer(), 0, token.termLength()).equals(\"again\") == true);\n    assertTrue(token.getPositionIncrement() + \" does not equal: \" + 1, token.getPositionIncrement() == 1);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinkPhrases().mjava","pathOld":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLinkPhrases().mjava","sourceNew":"  public void testLinkPhrases() throws Exception {\n\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(LINK_PHRASES));\n    checkLinkPhrases(tf);\n    \n  }\n\n","sourceOld":"  public void testLinkPhrases() throws Exception {\n\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(LINK_PHRASES));\n    checkLinkPhrases(tf);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"decc8a7344e9231708f9991fa09db2cafec7a2dd":["48aaa86d97259d1aa57d972cae27fe4f522aa70d"],"b305cb92ee47ddf7b15c6eeefe489c04d05b22ba":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"95692f9a6440b2a1c83c2c8ae5224be54319db4c":["b305cb92ee47ddf7b15c6eeefe489c04d05b22ba"],"48aaa86d97259d1aa57d972cae27fe4f522aa70d":["95692f9a6440b2a1c83c2c8ae5224be54319db4c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["decc8a7344e9231708f9991fa09db2cafec7a2dd"]},"commit2Childs":{"decc8a7344e9231708f9991fa09db2cafec7a2dd":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"b305cb92ee47ddf7b15c6eeefe489c04d05b22ba":["95692f9a6440b2a1c83c2c8ae5224be54319db4c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b305cb92ee47ddf7b15c6eeefe489c04d05b22ba"],"95692f9a6440b2a1c83c2c8ae5224be54319db4c":["48aaa86d97259d1aa57d972cae27fe4f522aa70d"],"48aaa86d97259d1aa57d972cae27fe4f522aa70d":["decc8a7344e9231708f9991fa09db2cafec7a2dd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}