{"path":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TokenInfoDictionaryTest#testEnumerateAll().mjava","commits":[{"id":"e3010cab237afb0b81c042f263115756e3cc6d67","date":1564503244,"type":1,"author":"Namgyu Kim","isMerge":false,"pathNew":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TokenInfoDictionaryTest#testEnumerateAll().mjava","pathOld":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TestTokenInfoDictionary#testEnumerateAll().mjava","sourceNew":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    IntsRefFSTEnum.InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char[] chars = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertFalse(surfaceForm.isEmpty());\n      assertEquals(surfaceForm.trim(), surfaceForm);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n\n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertTrue(leftPOS == rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertTrue(reading != null);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertTrue(leftPOS == rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              assertFalse(morph.surfaceForm.isEmpty());\n              assertEquals(morph.surfaceForm.trim(), morph.surfaceForm);\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","sourceOld":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char chars[] = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertFalse(surfaceForm.isEmpty());\n      assertEquals(surfaceForm.trim(), surfaceForm);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n      \n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertTrue(leftPOS == rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertTrue(reading != null);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertTrue(leftPOS == rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              assertFalse(morph.surfaceForm.isEmpty());\n              assertEquals(morph.surfaceForm.trim(), morph.surfaceForm);\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8061ddd97f3352007d927dae445884a6f3d857b","date":1564988276,"type":1,"author":"Atri Sharma","isMerge":true,"pathNew":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TokenInfoDictionaryTest#testEnumerateAll().mjava","pathOld":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TestTokenInfoDictionary#testEnumerateAll().mjava","sourceNew":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    IntsRefFSTEnum.InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char[] chars = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertFalse(surfaceForm.isEmpty());\n      assertEquals(surfaceForm.trim(), surfaceForm);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n\n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertTrue(leftPOS == rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertTrue(reading != null);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertTrue(leftPOS == rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              assertFalse(morph.surfaceForm.isEmpty());\n              assertEquals(morph.surfaceForm.trim(), morph.surfaceForm);\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","sourceOld":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char chars[] = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertFalse(surfaceForm.isEmpty());\n      assertEquals(surfaceForm.trim(), surfaceForm);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n      \n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertTrue(leftPOS == rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertTrue(reading != null);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertTrue(leftPOS == rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              assertFalse(morph.surfaceForm.isEmpty());\n              assertEquals(morph.surfaceForm.trim(), morph.surfaceForm);\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ac9f7831922bb899baba6064894c8ebb795cdee2","date":1566842943,"type":3,"author":"Namgyu Kim","isMerge":false,"pathNew":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TokenInfoDictionaryTest#testEnumerateAll().mjava","pathOld":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TokenInfoDictionaryTest#testEnumerateAll().mjava","sourceNew":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    IntsRefFSTEnum.InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char[] chars = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertFalse(surfaceForm.isEmpty());\n      assertEquals(surfaceForm.trim(), surfaceForm);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n\n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertSame(leftPOS, rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertNotNull(reading);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertSame(leftPOS, rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              assertFalse(morph.surfaceForm.isEmpty());\n              assertEquals(morph.surfaceForm.trim(), morph.surfaceForm);\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","sourceOld":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    IntsRefFSTEnum.InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char[] chars = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertFalse(surfaceForm.isEmpty());\n      assertEquals(surfaceForm.trim(), surfaceForm);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n\n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertTrue(leftPOS == rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertTrue(reading != null);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertTrue(leftPOS == rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              assertFalse(morph.surfaceForm.isEmpty());\n              assertEquals(morph.surfaceForm.trim(), morph.surfaceForm);\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57c6c784f777a2cc8fa014507ea129526822714d","date":1579733373,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TokenInfoDictionaryTest#testEnumerateAll().mjava","pathOld":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TokenInfoDictionaryTest#testEnumerateAll().mjava","sourceNew":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  @Slow\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    IntsRefFSTEnum.InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char[] chars = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertFalse(surfaceForm.isEmpty());\n      assertEquals(surfaceForm.trim(), surfaceForm);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n\n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertSame(leftPOS, rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertNotNull(reading);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertSame(leftPOS, rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              assertFalse(morph.surfaceForm.isEmpty());\n              assertEquals(morph.surfaceForm.trim(), morph.surfaceForm);\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","sourceOld":"  /** enumerates the entire FST/lookup data and just does basic sanity checks */\n  public void testEnumerateAll() throws Exception {\n    // just for debugging\n    int numTerms = 0;\n    int numWords = 0;\n    int lastWordId = -1;\n    int lastSourceId = -1;\n    CharacterDefinition charDef = CharacterDefinition.getInstance();\n    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();\n    ConnectionCosts matrix = ConnectionCosts.getInstance();\n    FST<Long> fst = tid.getFST().getInternalFST();\n    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<>(fst);\n    IntsRefFSTEnum.InputOutput<Long> mapping;\n    IntsRef scratch = new IntsRef();\n    while ((mapping = fstEnum.next()) != null) {\n      numTerms++;\n      IntsRef input = mapping.input;\n      char[] chars = new char[input.length];\n      for (int i = 0; i < chars.length; i++) {\n        chars[i] = (char)input.ints[input.offset+i];\n      }\n      String surfaceForm = new String(chars);\n      assertFalse(surfaceForm.isEmpty());\n      assertEquals(surfaceForm.trim(), surfaceForm);\n      assertTrue(UnicodeUtil.validUTF16String(surfaceForm));\n\n      Long output = mapping.output;\n      int sourceId = output.intValue();\n      // we walk in order, terms, sourceIds, and wordIds should always be increasing\n      assertTrue(sourceId > lastSourceId);\n      lastSourceId = sourceId;\n      tid.lookupWordIds(sourceId, scratch);\n      for (int i = 0; i < scratch.length; i++) {\n        numWords++;\n        int wordId = scratch.ints[scratch.offset+i];\n        assertTrue(wordId > lastWordId);\n        lastWordId = wordId;\n\n        int leftId = tid.getLeftId(wordId);\n        int rightId = tid.getRightId(wordId);\n\n        matrix.get(rightId, leftId);\n\n        tid.getWordCost(wordId);\n\n        POS.Type type = tid.getPOSType(wordId);\n        POS.Tag leftPOS = tid.getLeftPOS(wordId);\n        POS.Tag rightPOS = tid.getRightPOS(wordId);\n\n        if (type == POS.Type.MORPHEME) {\n          assertSame(leftPOS, rightPOS);\n          String reading = tid.getReading(wordId);\n          boolean isHanja = charDef.isHanja(surfaceForm.charAt(0));\n          if (isHanja) {\n            assertNotNull(reading);\n            for (int j = 0; j < reading.length(); j++) {\n              assertTrue(charDef.isHangul(reading.charAt(j)));\n            }\n          }\n          if (reading != null) {\n            assertTrue(UnicodeUtil.validUTF16String(reading));\n          }\n        } else {\n          if (type == POS.Type.COMPOUND) {\n            assertSame(leftPOS, rightPOS);\n            assertTrue(leftPOS == POS.Tag.NNG || rightPOS == POS.Tag.NNP);\n          }\n          Dictionary.Morpheme[] decompound = tid.getMorphemes(wordId,  chars, 0, chars.length);\n          if (decompound != null) {\n            int offset = 0;\n            for (Dictionary.Morpheme morph : decompound) {\n              assertTrue(UnicodeUtil.validUTF16String(morph.surfaceForm));\n              assertFalse(morph.surfaceForm.isEmpty());\n              assertEquals(morph.surfaceForm.trim(), morph.surfaceForm);\n              if (type != POS.Type.INFLECT) {\n                assertEquals(morph.surfaceForm, surfaceForm.substring(offset, offset + morph.surfaceForm.length()));\n                offset += morph.surfaceForm.length();\n              }\n            }\n            assertTrue(offset <= surfaceForm.length());\n          }\n        }\n      }\n    }\n    if (VERBOSE) {\n      System.out.println(\"checked \" + numTerms + \" terms, \" + numWords + \" words.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"57c6c784f777a2cc8fa014507ea129526822714d":["ac9f7831922bb899baba6064894c8ebb795cdee2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e3010cab237afb0b81c042f263115756e3cc6d67":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ac9f7831922bb899baba6064894c8ebb795cdee2":["e3010cab237afb0b81c042f263115756e3cc6d67"],"f8061ddd97f3352007d927dae445884a6f3d857b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e3010cab237afb0b81c042f263115756e3cc6d67"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["57c6c784f777a2cc8fa014507ea129526822714d"]},"commit2Childs":{"57c6c784f777a2cc8fa014507ea129526822714d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e3010cab237afb0b81c042f263115756e3cc6d67","f8061ddd97f3352007d927dae445884a6f3d857b"],"e3010cab237afb0b81c042f263115756e3cc6d67":["ac9f7831922bb899baba6064894c8ebb795cdee2","f8061ddd97f3352007d927dae445884a6f3d857b"],"ac9f7831922bb899baba6064894c8ebb795cdee2":["57c6c784f777a2cc8fa014507ea129526822714d"],"f8061ddd97f3352007d927dae445884a6f3d857b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f8061ddd97f3352007d927dae445884a6f3d857b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}