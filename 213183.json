{"path":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","commits":[{"id":"4350b17bd363cd13a95171b8df1ca62ea4c3e71c","date":1183562198,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"/dev/null","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  private synchronized void balanceRAM() {\n\n    if (ramBufferSize == 0.0 || postingsIsFull)\n      return;\n\n    // We free our allocations if we've allocated 5% over\n    // our allowed RAM buffer\n    final long freeTrigger = (long) (1.05 * ramBufferSize);\n    final long freeLevel = (long) (0.95 * ramBufferSize);\n    \n    // We flush when we've used our target usage\n    final long flushTrigger = (long) ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n      if (infoStream != null)\n        infoStream.println(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                           \" vs trigger=\" + toMB(flushTrigger) +\n                           \" allocMB=\" + toMB(numBytesAlloc) +\n                           \" vs trigger=\" + toMB(freeTrigger) +\n                           \" postingsFree=\" + toMB(postingsFreeCount*POSTING_NUM_BYTE) +\n                           \" byteBlockFree=\" + toMB(freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                           \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      // When we've crossed 100% of our target Postings\n      // RAM usage, try to free up until we're back down\n      // to 95%\n      final long startBytesAlloc = numBytesAlloc;\n\n      final int postingsFreeChunk = (int) (BYTE_BLOCK_SIZE / POSTING_NUM_BYTE);\n\n      int iter = 0;\n\n      // We free equally from each pool in 64 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      while(numBytesAlloc > freeLevel) {\n        if (0 == freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == postingsFreeCount) {\n          // Nothing else to free -- must flush now.\n          postingsIsFull = true;\n          if (infoStream != null)\n            infoStream.println(\"    nothing to free; now set postingsIsFull\");\n          break;\n        }\n\n        if ((0 == iter % 3) && freeByteBlocks.size() > 0) {\n          freeByteBlocks.remove(freeByteBlocks.size()-1);\n          numBytesAlloc -= BYTE_BLOCK_SIZE;\n        }\n\n        if ((1 == iter % 3) && freeCharBlocks.size() > 0) {\n          freeCharBlocks.remove(freeCharBlocks.size()-1);\n          numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n        }\n\n        if ((2 == iter % 3) && postingsFreeCount > 0) {\n          final int numToFree;\n          if (postingsFreeCount >= postingsFreeChunk)\n            numToFree = postingsFreeChunk;\n          else\n            numToFree = postingsFreeCount;\n          Arrays.fill(postingsFreeList, postingsFreeCount-numToFree, postingsFreeCount, null);\n          postingsFreeCount -= numToFree;\n          numBytesAlloc -= numToFree * POSTING_NUM_BYTE;\n        }\n\n        iter++;\n      }\n      \n      if (infoStream != null)\n        infoStream.println(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      if (numBytesUsed > flushTrigger) {\n        if (infoStream != null)\n          infoStream.println(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                             \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                             \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n        postingsIsFull = true;\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["4404b358bf2902b2da0b8eef5ea0a68acd37674b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2558ddf9e14a97bc597f5b72bb3ecb5b7f6bba8e","date":1191352543,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  private synchronized void balanceRAM() {\n\n    if (ramBufferSize == IndexWriter.DISABLE_AUTO_FLUSH || bufferIsFull)\n      return;\n\n    // We free our allocations if we've allocated 5% over\n    // our allowed RAM buffer\n    final long freeTrigger = (long) (1.05 * ramBufferSize);\n    final long freeLevel = (long) (0.95 * ramBufferSize);\n    \n    // We flush when we've used our target usage\n    final long flushTrigger = (long) ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n      if (infoStream != null)\n        infoStream.println(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                           \" vs trigger=\" + toMB(flushTrigger) +\n                           \" allocMB=\" + toMB(numBytesAlloc) +\n                           \" vs trigger=\" + toMB(freeTrigger) +\n                           \" postingsFree=\" + toMB(postingsFreeCount*POSTING_NUM_BYTE) +\n                           \" byteBlockFree=\" + toMB(freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                           \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      // When we've crossed 100% of our target Postings\n      // RAM usage, try to free up until we're back down\n      // to 95%\n      final long startBytesAlloc = numBytesAlloc;\n\n      final int postingsFreeChunk = (int) (BYTE_BLOCK_SIZE / POSTING_NUM_BYTE);\n\n      int iter = 0;\n\n      // We free equally from each pool in 64 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      while(numBytesAlloc > freeLevel) {\n        if (0 == freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == postingsFreeCount) {\n          // Nothing else to free -- must flush now.\n          bufferIsFull = true;\n          if (infoStream != null)\n            infoStream.println(\"    nothing to free; now set bufferIsFull\");\n          break;\n        }\n\n        if ((0 == iter % 3) && freeByteBlocks.size() > 0) {\n          freeByteBlocks.remove(freeByteBlocks.size()-1);\n          numBytesAlloc -= BYTE_BLOCK_SIZE;\n        }\n\n        if ((1 == iter % 3) && freeCharBlocks.size() > 0) {\n          freeCharBlocks.remove(freeCharBlocks.size()-1);\n          numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n        }\n\n        if ((2 == iter % 3) && postingsFreeCount > 0) {\n          final int numToFree;\n          if (postingsFreeCount >= postingsFreeChunk)\n            numToFree = postingsFreeChunk;\n          else\n            numToFree = postingsFreeCount;\n          Arrays.fill(postingsFreeList, postingsFreeCount-numToFree, postingsFreeCount, null);\n          postingsFreeCount -= numToFree;\n          numBytesAlloc -= numToFree * POSTING_NUM_BYTE;\n        }\n\n        iter++;\n      }\n      \n      if (infoStream != null)\n        infoStream.println(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      if (numBytesUsed > flushTrigger) {\n        if (infoStream != null)\n          infoStream.println(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                             \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                             \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n        bufferIsFull = true;\n      }\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  private synchronized void balanceRAM() {\n\n    if (ramBufferSize == 0.0 || postingsIsFull)\n      return;\n\n    // We free our allocations if we've allocated 5% over\n    // our allowed RAM buffer\n    final long freeTrigger = (long) (1.05 * ramBufferSize);\n    final long freeLevel = (long) (0.95 * ramBufferSize);\n    \n    // We flush when we've used our target usage\n    final long flushTrigger = (long) ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n      if (infoStream != null)\n        infoStream.println(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                           \" vs trigger=\" + toMB(flushTrigger) +\n                           \" allocMB=\" + toMB(numBytesAlloc) +\n                           \" vs trigger=\" + toMB(freeTrigger) +\n                           \" postingsFree=\" + toMB(postingsFreeCount*POSTING_NUM_BYTE) +\n                           \" byteBlockFree=\" + toMB(freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                           \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      // When we've crossed 100% of our target Postings\n      // RAM usage, try to free up until we're back down\n      // to 95%\n      final long startBytesAlloc = numBytesAlloc;\n\n      final int postingsFreeChunk = (int) (BYTE_BLOCK_SIZE / POSTING_NUM_BYTE);\n\n      int iter = 0;\n\n      // We free equally from each pool in 64 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      while(numBytesAlloc > freeLevel) {\n        if (0 == freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == postingsFreeCount) {\n          // Nothing else to free -- must flush now.\n          postingsIsFull = true;\n          if (infoStream != null)\n            infoStream.println(\"    nothing to free; now set postingsIsFull\");\n          break;\n        }\n\n        if ((0 == iter % 3) && freeByteBlocks.size() > 0) {\n          freeByteBlocks.remove(freeByteBlocks.size()-1);\n          numBytesAlloc -= BYTE_BLOCK_SIZE;\n        }\n\n        if ((1 == iter % 3) && freeCharBlocks.size() > 0) {\n          freeCharBlocks.remove(freeCharBlocks.size()-1);\n          numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n        }\n\n        if ((2 == iter % 3) && postingsFreeCount > 0) {\n          final int numToFree;\n          if (postingsFreeCount >= postingsFreeChunk)\n            numToFree = postingsFreeChunk;\n          else\n            numToFree = postingsFreeCount;\n          Arrays.fill(postingsFreeList, postingsFreeCount-numToFree, postingsFreeCount, null);\n          postingsFreeCount -= numToFree;\n          numBytesAlloc -= numToFree * POSTING_NUM_BYTE;\n        }\n\n        iter++;\n      }\n      \n      if (infoStream != null)\n        infoStream.println(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      if (numBytesUsed > flushTrigger) {\n        if (infoStream != null)\n          infoStream.println(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                             \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                             \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n        postingsIsFull = true;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"176324efd1eab6bd44a6d81c27c9b3a1a175ba3d","date":1202734547,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  private synchronized void balanceRAM() {\n\n    if (ramBufferSize == IndexWriter.DISABLE_AUTO_FLUSH || bufferIsFull)\n      return;\n\n    // We free our allocations if we've allocated 5% over\n    // our allowed RAM buffer\n    final long freeTrigger = (long) (1.05 * ramBufferSize);\n    final long freeLevel = (long) (0.95 * ramBufferSize);\n    \n    // We flush when we've used our target usage\n    final long flushTrigger = (long) ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n      if (infoStream != null)\n        infoStream.println(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                           \" vs trigger=\" + toMB(flushTrigger) +\n                           \" allocMB=\" + toMB(numBytesAlloc) +\n                           \" vs trigger=\" + toMB(freeTrigger) +\n                           \" postingsFree=\" + toMB(postingsFreeCount*POSTING_NUM_BYTE) +\n                           \" byteBlockFree=\" + toMB(freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                           \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      // When we've crossed 100% of our target Postings\n      // RAM usage, try to free up until we're back down\n      // to 95%\n      final long startBytesAlloc = numBytesAlloc;\n\n      final int postingsFreeChunk = (int) (BYTE_BLOCK_SIZE / POSTING_NUM_BYTE);\n\n      int iter = 0;\n\n      // We free equally from each pool in 64 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      while(numBytesAlloc > freeLevel) {\n        if (0 == freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == postingsFreeCount) {\n          // Nothing else to free -- must flush now.\n          bufferIsFull = true;\n          if (infoStream != null)\n            infoStream.println(\"    nothing to free; now set bufferIsFull\");\n          break;\n        }\n\n        if ((0 == iter % 3) && freeByteBlocks.size() > 0) {\n          freeByteBlocks.remove(freeByteBlocks.size()-1);\n          numBytesAlloc -= BYTE_BLOCK_SIZE;\n        }\n\n        if ((1 == iter % 3) && freeCharBlocks.size() > 0) {\n          freeCharBlocks.remove(freeCharBlocks.size()-1);\n          numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n        }\n\n        if ((2 == iter % 3) && postingsFreeCount > 0) {\n          final int numToFree;\n          if (postingsFreeCount >= postingsFreeChunk)\n            numToFree = postingsFreeChunk;\n          else\n            numToFree = postingsFreeCount;\n          Arrays.fill(postingsFreeList, postingsFreeCount-numToFree, postingsFreeCount, null);\n          postingsFreeCount -= numToFree;\n          postingsAllocCount -= numToFree;\n          numBytesAlloc -= numToFree * POSTING_NUM_BYTE;\n        }\n\n        iter++;\n      }\n      \n      if (infoStream != null)\n        infoStream.println(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      if (numBytesUsed > flushTrigger) {\n        if (infoStream != null)\n          infoStream.println(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                             \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                             \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n        bufferIsFull = true;\n      }\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  private synchronized void balanceRAM() {\n\n    if (ramBufferSize == IndexWriter.DISABLE_AUTO_FLUSH || bufferIsFull)\n      return;\n\n    // We free our allocations if we've allocated 5% over\n    // our allowed RAM buffer\n    final long freeTrigger = (long) (1.05 * ramBufferSize);\n    final long freeLevel = (long) (0.95 * ramBufferSize);\n    \n    // We flush when we've used our target usage\n    final long flushTrigger = (long) ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n      if (infoStream != null)\n        infoStream.println(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                           \" vs trigger=\" + toMB(flushTrigger) +\n                           \" allocMB=\" + toMB(numBytesAlloc) +\n                           \" vs trigger=\" + toMB(freeTrigger) +\n                           \" postingsFree=\" + toMB(postingsFreeCount*POSTING_NUM_BYTE) +\n                           \" byteBlockFree=\" + toMB(freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                           \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      // When we've crossed 100% of our target Postings\n      // RAM usage, try to free up until we're back down\n      // to 95%\n      final long startBytesAlloc = numBytesAlloc;\n\n      final int postingsFreeChunk = (int) (BYTE_BLOCK_SIZE / POSTING_NUM_BYTE);\n\n      int iter = 0;\n\n      // We free equally from each pool in 64 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      while(numBytesAlloc > freeLevel) {\n        if (0 == freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == postingsFreeCount) {\n          // Nothing else to free -- must flush now.\n          bufferIsFull = true;\n          if (infoStream != null)\n            infoStream.println(\"    nothing to free; now set bufferIsFull\");\n          break;\n        }\n\n        if ((0 == iter % 3) && freeByteBlocks.size() > 0) {\n          freeByteBlocks.remove(freeByteBlocks.size()-1);\n          numBytesAlloc -= BYTE_BLOCK_SIZE;\n        }\n\n        if ((1 == iter % 3) && freeCharBlocks.size() > 0) {\n          freeCharBlocks.remove(freeCharBlocks.size()-1);\n          numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n        }\n\n        if ((2 == iter % 3) && postingsFreeCount > 0) {\n          final int numToFree;\n          if (postingsFreeCount >= postingsFreeChunk)\n            numToFree = postingsFreeChunk;\n          else\n            numToFree = postingsFreeCount;\n          Arrays.fill(postingsFreeList, postingsFreeCount-numToFree, postingsFreeCount, null);\n          postingsFreeCount -= numToFree;\n          numBytesAlloc -= numToFree * POSTING_NUM_BYTE;\n        }\n\n        iter++;\n      }\n      \n      if (infoStream != null)\n        infoStream.println(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      if (numBytesUsed > flushTrigger) {\n        if (infoStream != null)\n          infoStream.println(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                             \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                             \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n        bufferIsFull = true;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2684bcb2a921b6b5b76f64ba986564ab1ef0649d","date":1202988124,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  synchronized void balanceRAM() {\n\n    if (ramBufferSize == IndexWriter.DISABLE_AUTO_FLUSH || bufferIsFull)\n      return;\n\n    // We free our allocations if we've allocated 5% over\n    // our allowed RAM buffer\n    final long freeTrigger = (long) (1.05 * ramBufferSize);\n    final long freeLevel = (long) (0.95 * ramBufferSize);\n    \n    // We flush when we've used our target usage\n    final long flushTrigger = (long) ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n      if (infoStream != null)\n        infoStream.println(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                           \" vs trigger=\" + toMB(flushTrigger) +\n                           \" allocMB=\" + toMB(numBytesAlloc) +\n                           \" vs trigger=\" + toMB(freeTrigger) +\n                           \" postingsFree=\" + toMB(postingsFreeCount*POSTING_NUM_BYTE) +\n                           \" byteBlockFree=\" + toMB(freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                           \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      // When we've crossed 100% of our target Postings\n      // RAM usage, try to free up until we're back down\n      // to 95%\n      final long startBytesAlloc = numBytesAlloc;\n\n      final int postingsFreeChunk = (int) (BYTE_BLOCK_SIZE / POSTING_NUM_BYTE);\n\n      int iter = 0;\n\n      // We free equally from each pool in 64 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      while(numBytesAlloc > freeLevel) {\n        if (0 == freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == postingsFreeCount) {\n          // Nothing else to free -- must flush now.\n          bufferIsFull = true;\n          if (infoStream != null)\n            infoStream.println(\"    nothing to free; now set bufferIsFull\");\n          break;\n        }\n\n        if ((0 == iter % 3) && freeByteBlocks.size() > 0) {\n          freeByteBlocks.remove(freeByteBlocks.size()-1);\n          numBytesAlloc -= BYTE_BLOCK_SIZE;\n        }\n\n        if ((1 == iter % 3) && freeCharBlocks.size() > 0) {\n          freeCharBlocks.remove(freeCharBlocks.size()-1);\n          numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n        }\n\n        if ((2 == iter % 3) && postingsFreeCount > 0) {\n          final int numToFree;\n          if (postingsFreeCount >= postingsFreeChunk)\n            numToFree = postingsFreeChunk;\n          else\n            numToFree = postingsFreeCount;\n          Arrays.fill(postingsFreeList, postingsFreeCount-numToFree, postingsFreeCount, null);\n          postingsFreeCount -= numToFree;\n          postingsAllocCount -= numToFree;\n          numBytesAlloc -= numToFree * POSTING_NUM_BYTE;\n        }\n\n        iter++;\n      }\n      \n      if (infoStream != null)\n        infoStream.println(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      if (numBytesUsed > flushTrigger) {\n        if (infoStream != null)\n          infoStream.println(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                             \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                             \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n        bufferIsFull = true;\n      }\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  private synchronized void balanceRAM() {\n\n    if (ramBufferSize == IndexWriter.DISABLE_AUTO_FLUSH || bufferIsFull)\n      return;\n\n    // We free our allocations if we've allocated 5% over\n    // our allowed RAM buffer\n    final long freeTrigger = (long) (1.05 * ramBufferSize);\n    final long freeLevel = (long) (0.95 * ramBufferSize);\n    \n    // We flush when we've used our target usage\n    final long flushTrigger = (long) ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n      if (infoStream != null)\n        infoStream.println(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                           \" vs trigger=\" + toMB(flushTrigger) +\n                           \" allocMB=\" + toMB(numBytesAlloc) +\n                           \" vs trigger=\" + toMB(freeTrigger) +\n                           \" postingsFree=\" + toMB(postingsFreeCount*POSTING_NUM_BYTE) +\n                           \" byteBlockFree=\" + toMB(freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                           \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      // When we've crossed 100% of our target Postings\n      // RAM usage, try to free up until we're back down\n      // to 95%\n      final long startBytesAlloc = numBytesAlloc;\n\n      final int postingsFreeChunk = (int) (BYTE_BLOCK_SIZE / POSTING_NUM_BYTE);\n\n      int iter = 0;\n\n      // We free equally from each pool in 64 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      while(numBytesAlloc > freeLevel) {\n        if (0 == freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == postingsFreeCount) {\n          // Nothing else to free -- must flush now.\n          bufferIsFull = true;\n          if (infoStream != null)\n            infoStream.println(\"    nothing to free; now set bufferIsFull\");\n          break;\n        }\n\n        if ((0 == iter % 3) && freeByteBlocks.size() > 0) {\n          freeByteBlocks.remove(freeByteBlocks.size()-1);\n          numBytesAlloc -= BYTE_BLOCK_SIZE;\n        }\n\n        if ((1 == iter % 3) && freeCharBlocks.size() > 0) {\n          freeCharBlocks.remove(freeCharBlocks.size()-1);\n          numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n        }\n\n        if ((2 == iter % 3) && postingsFreeCount > 0) {\n          final int numToFree;\n          if (postingsFreeCount >= postingsFreeChunk)\n            numToFree = postingsFreeChunk;\n          else\n            numToFree = postingsFreeCount;\n          Arrays.fill(postingsFreeList, postingsFreeCount-numToFree, postingsFreeCount, null);\n          postingsFreeCount -= numToFree;\n          postingsAllocCount -= numToFree;\n          numBytesAlloc -= numToFree * POSTING_NUM_BYTE;\n        }\n\n        iter++;\n      }\n      \n      if (infoStream != null)\n        infoStream.println(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      if (numBytesUsed > flushTrigger) {\n        if (infoStream != null)\n          infoStream.println(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                             \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                             \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n        bufferIsFull = true;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"84acdfa12c18361ff932244db20470fce117e52d","date":1206384355,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  synchronized void balanceRAM() {\n\n    if (ramBufferSize == IndexWriter.DISABLE_AUTO_FLUSH || bufferIsFull)\n      return;\n\n    // We free our allocations if we've allocated 5% over\n    // our allowed RAM buffer\n    final long freeTrigger = (long) (1.05 * ramBufferSize);\n    final long freeLevel = (long) (0.95 * ramBufferSize);\n    \n    // We flush when we've used our target usage\n    final long flushTrigger = (long) ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" postingsFree=\" + toMB(postingsFreeCount*POSTING_NUM_BYTE) +\n                \" byteBlockFree=\" + toMB(freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      // When we've crossed 100% of our target Postings\n      // RAM usage, try to free up until we're back down\n      // to 95%\n      final long startBytesAlloc = numBytesAlloc;\n\n      final int postingsFreeChunk = (int) (BYTE_BLOCK_SIZE / POSTING_NUM_BYTE);\n\n      int iter = 0;\n\n      // We free equally from each pool in 64 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      while(numBytesAlloc > freeLevel) {\n        if (0 == freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == postingsFreeCount) {\n          // Nothing else to free -- must flush now.\n          bufferIsFull = true;\n          if (infoStream != null)\n            message(\"    nothing to free; now set bufferIsFull\");\n          break;\n        }\n\n        if ((0 == iter % 3) && freeByteBlocks.size() > 0) {\n          freeByteBlocks.remove(freeByteBlocks.size()-1);\n          numBytesAlloc -= BYTE_BLOCK_SIZE;\n        }\n\n        if ((1 == iter % 3) && freeCharBlocks.size() > 0) {\n          freeCharBlocks.remove(freeCharBlocks.size()-1);\n          numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n        }\n\n        if ((2 == iter % 3) && postingsFreeCount > 0) {\n          final int numToFree;\n          if (postingsFreeCount >= postingsFreeChunk)\n            numToFree = postingsFreeChunk;\n          else\n            numToFree = postingsFreeCount;\n          Arrays.fill(postingsFreeList, postingsFreeCount-numToFree, postingsFreeCount, null);\n          postingsFreeCount -= numToFree;\n          postingsAllocCount -= numToFree;\n          numBytesAlloc -= numToFree * POSTING_NUM_BYTE;\n        }\n\n        iter++;\n      }\n      \n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      if (numBytesUsed > flushTrigger) {\n        if (infoStream != null)\n          message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                  \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                  \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n        bufferIsFull = true;\n      }\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  synchronized void balanceRAM() {\n\n    if (ramBufferSize == IndexWriter.DISABLE_AUTO_FLUSH || bufferIsFull)\n      return;\n\n    // We free our allocations if we've allocated 5% over\n    // our allowed RAM buffer\n    final long freeTrigger = (long) (1.05 * ramBufferSize);\n    final long freeLevel = (long) (0.95 * ramBufferSize);\n    \n    // We flush when we've used our target usage\n    final long flushTrigger = (long) ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n      if (infoStream != null)\n        infoStream.println(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                           \" vs trigger=\" + toMB(flushTrigger) +\n                           \" allocMB=\" + toMB(numBytesAlloc) +\n                           \" vs trigger=\" + toMB(freeTrigger) +\n                           \" postingsFree=\" + toMB(postingsFreeCount*POSTING_NUM_BYTE) +\n                           \" byteBlockFree=\" + toMB(freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                           \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      // When we've crossed 100% of our target Postings\n      // RAM usage, try to free up until we're back down\n      // to 95%\n      final long startBytesAlloc = numBytesAlloc;\n\n      final int postingsFreeChunk = (int) (BYTE_BLOCK_SIZE / POSTING_NUM_BYTE);\n\n      int iter = 0;\n\n      // We free equally from each pool in 64 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      while(numBytesAlloc > freeLevel) {\n        if (0 == freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == postingsFreeCount) {\n          // Nothing else to free -- must flush now.\n          bufferIsFull = true;\n          if (infoStream != null)\n            infoStream.println(\"    nothing to free; now set bufferIsFull\");\n          break;\n        }\n\n        if ((0 == iter % 3) && freeByteBlocks.size() > 0) {\n          freeByteBlocks.remove(freeByteBlocks.size()-1);\n          numBytesAlloc -= BYTE_BLOCK_SIZE;\n        }\n\n        if ((1 == iter % 3) && freeCharBlocks.size() > 0) {\n          freeCharBlocks.remove(freeCharBlocks.size()-1);\n          numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n        }\n\n        if ((2 == iter % 3) && postingsFreeCount > 0) {\n          final int numToFree;\n          if (postingsFreeCount >= postingsFreeChunk)\n            numToFree = postingsFreeChunk;\n          else\n            numToFree = postingsFreeCount;\n          Arrays.fill(postingsFreeList, postingsFreeCount-numToFree, postingsFreeCount, null);\n          postingsFreeCount -= numToFree;\n          postingsAllocCount -= numToFree;\n          numBytesAlloc -= numToFree * POSTING_NUM_BYTE;\n        }\n\n        iter++;\n      }\n      \n      if (infoStream != null)\n        infoStream.println(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      if (numBytesUsed > flushTrigger) {\n        if (infoStream != null)\n          infoStream.println(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                             \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                             \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n        bufferIsFull = true;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["4404b358bf2902b2da0b8eef5ea0a68acd37674b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e8f450af7a7b034413833ed2a9508f99264ea49a","date":1211042958,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  synchronized void balanceRAM() {\n\n    if (ramBufferSize == IndexWriter.DISABLE_AUTO_FLUSH || bufferIsFull)\n      return;\n\n    // We free our allocations if we've allocated 5% over\n    // our allowed RAM buffer\n    final long freeTrigger = (long) (1.05 * ramBufferSize);\n    final long freeLevel = (long) (0.95 * ramBufferSize);\n    \n    // We flush when we've used our target usage\n    final long flushTrigger = (long) ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" postingsFree=\" + toMB(postingsFreeCount*POSTING_NUM_BYTE) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      // When we've crossed 100% of our target Postings\n      // RAM usage, try to free up until we're back down\n      // to 95%\n      final long startBytesAlloc = numBytesAlloc;\n\n      final int postingsFreeChunk = (int) (BYTE_BLOCK_SIZE / POSTING_NUM_BYTE);\n\n      int iter = 0;\n\n      // We free equally from each pool in 64 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      while(numBytesAlloc > freeLevel) {\n        if (0 == byteBlockAllocator.freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == postingsFreeCount) {\n          // Nothing else to free -- must flush now.\n          bufferIsFull = true;\n          if (infoStream != null)\n            message(\"    nothing to free; now set bufferIsFull\");\n          break;\n        }\n\n        if ((0 == iter % 3) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n          byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n          numBytesAlloc -= BYTE_BLOCK_SIZE;\n        }\n\n        if ((1 == iter % 3) && freeCharBlocks.size() > 0) {\n          freeCharBlocks.remove(freeCharBlocks.size()-1);\n          numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n        }\n\n        if ((2 == iter % 3) && postingsFreeCount > 0) {\n          final int numToFree;\n          if (postingsFreeCount >= postingsFreeChunk)\n            numToFree = postingsFreeChunk;\n          else\n            numToFree = postingsFreeCount;\n          Arrays.fill(postingsFreeList, postingsFreeCount-numToFree, postingsFreeCount, null);\n          postingsFreeCount -= numToFree;\n          postingsAllocCount -= numToFree;\n          numBytesAlloc -= numToFree * POSTING_NUM_BYTE;\n        }\n\n        iter++;\n      }\n      \n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      if (numBytesUsed > flushTrigger) {\n        if (infoStream != null)\n          message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                  \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                  \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n        bufferIsFull = true;\n      }\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  synchronized void balanceRAM() {\n\n    if (ramBufferSize == IndexWriter.DISABLE_AUTO_FLUSH || bufferIsFull)\n      return;\n\n    // We free our allocations if we've allocated 5% over\n    // our allowed RAM buffer\n    final long freeTrigger = (long) (1.05 * ramBufferSize);\n    final long freeLevel = (long) (0.95 * ramBufferSize);\n    \n    // We flush when we've used our target usage\n    final long flushTrigger = (long) ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" postingsFree=\" + toMB(postingsFreeCount*POSTING_NUM_BYTE) +\n                \" byteBlockFree=\" + toMB(freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      // When we've crossed 100% of our target Postings\n      // RAM usage, try to free up until we're back down\n      // to 95%\n      final long startBytesAlloc = numBytesAlloc;\n\n      final int postingsFreeChunk = (int) (BYTE_BLOCK_SIZE / POSTING_NUM_BYTE);\n\n      int iter = 0;\n\n      // We free equally from each pool in 64 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      while(numBytesAlloc > freeLevel) {\n        if (0 == freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == postingsFreeCount) {\n          // Nothing else to free -- must flush now.\n          bufferIsFull = true;\n          if (infoStream != null)\n            message(\"    nothing to free; now set bufferIsFull\");\n          break;\n        }\n\n        if ((0 == iter % 3) && freeByteBlocks.size() > 0) {\n          freeByteBlocks.remove(freeByteBlocks.size()-1);\n          numBytesAlloc -= BYTE_BLOCK_SIZE;\n        }\n\n        if ((1 == iter % 3) && freeCharBlocks.size() > 0) {\n          freeCharBlocks.remove(freeCharBlocks.size()-1);\n          numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n        }\n\n        if ((2 == iter % 3) && postingsFreeCount > 0) {\n          final int numToFree;\n          if (postingsFreeCount >= postingsFreeChunk)\n            numToFree = postingsFreeChunk;\n          else\n            numToFree = postingsFreeCount;\n          Arrays.fill(postingsFreeList, postingsFreeCount-numToFree, postingsFreeCount, null);\n          postingsFreeCount -= numToFree;\n          postingsAllocCount -= numToFree;\n          numBytesAlloc -= numToFree * POSTING_NUM_BYTE;\n        }\n\n        iter++;\n      }\n      \n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      if (numBytesUsed > flushTrigger) {\n        if (infoStream != null)\n          message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                  \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                  \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n        bufferIsFull = true;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5350389bf83287111f7760b9e3db3af8e3648474","date":1216372812,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  void balanceRAM() {\n\n    // We flush when we've used our target usage\n    final long flushTrigger = (long) ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      final long startBytesAlloc = numBytesAlloc;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesAlloc > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == byteBlockAllocator.freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed > flushTrigger;\n            if (infoStream != null) {\n              if (numBytesUsed > flushTrigger)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            assert numBytesUsed <= numBytesAlloc;\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesAlloc -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 4) && freeCharBlocks.size() > 0) {\n            freeCharBlocks.remove(freeCharBlocks.size()-1);\n            numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n          }\n\n          if ((2 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesAlloc -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      synchronized(this) {\n\n        if (numBytesUsed > flushTrigger) {\n          if (infoStream != null)\n            message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                    \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                    \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n          bufferIsFull = true;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  synchronized void balanceRAM() {\n\n    if (ramBufferSize == IndexWriter.DISABLE_AUTO_FLUSH || bufferIsFull)\n      return;\n\n    // We free our allocations if we've allocated 5% over\n    // our allowed RAM buffer\n    final long freeTrigger = (long) (1.05 * ramBufferSize);\n    final long freeLevel = (long) (0.95 * ramBufferSize);\n    \n    // We flush when we've used our target usage\n    final long flushTrigger = (long) ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" postingsFree=\" + toMB(postingsFreeCount*POSTING_NUM_BYTE) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      // When we've crossed 100% of our target Postings\n      // RAM usage, try to free up until we're back down\n      // to 95%\n      final long startBytesAlloc = numBytesAlloc;\n\n      final int postingsFreeChunk = (int) (BYTE_BLOCK_SIZE / POSTING_NUM_BYTE);\n\n      int iter = 0;\n\n      // We free equally from each pool in 64 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      while(numBytesAlloc > freeLevel) {\n        if (0 == byteBlockAllocator.freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == postingsFreeCount) {\n          // Nothing else to free -- must flush now.\n          bufferIsFull = true;\n          if (infoStream != null)\n            message(\"    nothing to free; now set bufferIsFull\");\n          break;\n        }\n\n        if ((0 == iter % 3) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n          byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n          numBytesAlloc -= BYTE_BLOCK_SIZE;\n        }\n\n        if ((1 == iter % 3) && freeCharBlocks.size() > 0) {\n          freeCharBlocks.remove(freeCharBlocks.size()-1);\n          numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n        }\n\n        if ((2 == iter % 3) && postingsFreeCount > 0) {\n          final int numToFree;\n          if (postingsFreeCount >= postingsFreeChunk)\n            numToFree = postingsFreeChunk;\n          else\n            numToFree = postingsFreeCount;\n          Arrays.fill(postingsFreeList, postingsFreeCount-numToFree, postingsFreeCount, null);\n          postingsFreeCount -= numToFree;\n          postingsAllocCount -= numToFree;\n          numBytesAlloc -= numToFree * POSTING_NUM_BYTE;\n        }\n\n        iter++;\n      }\n      \n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      if (numBytesUsed > flushTrigger) {\n        if (infoStream != null)\n          message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                  \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                  \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n        bufferIsFull = true;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["4404b358bf2902b2da0b8eef5ea0a68acd37674b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"052fac7830290bd38a04cddee1a121ee07656b56","date":1245780702,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  void balanceRAM() {\n\n    // We flush when we've used our target usage\n    final long flushTrigger = ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      final long startBytesAlloc = numBytesAlloc;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesAlloc > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == byteBlockAllocator.freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed > flushTrigger;\n            if (infoStream != null) {\n              if (numBytesUsed > flushTrigger)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            assert numBytesUsed <= numBytesAlloc;\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesAlloc -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 4) && freeCharBlocks.size() > 0) {\n            freeCharBlocks.remove(freeCharBlocks.size()-1);\n            numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n          }\n\n          if ((2 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesAlloc -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      synchronized(this) {\n\n        if (numBytesUsed > flushTrigger) {\n          if (infoStream != null)\n            message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                    \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                    \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n          bufferIsFull = true;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  void balanceRAM() {\n\n    // We flush when we've used our target usage\n    final long flushTrigger = (long) ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      final long startBytesAlloc = numBytesAlloc;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesAlloc > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == byteBlockAllocator.freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed > flushTrigger;\n            if (infoStream != null) {\n              if (numBytesUsed > flushTrigger)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            assert numBytesUsed <= numBytesAlloc;\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesAlloc -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 4) && freeCharBlocks.size() > 0) {\n            freeCharBlocks.remove(freeCharBlocks.size()-1);\n            numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n          }\n\n          if ((2 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesAlloc -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      synchronized(this) {\n\n        if (numBytesUsed > flushTrigger) {\n          if (infoStream != null)\n            message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                    \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                    \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n          bufferIsFull = true;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4404b358bf2902b2da0b8eef5ea0a68acd37674b","date":1247143497,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  void balanceRAM() {\n\n    // We flush when we've used our target usage\n    final long flushTrigger = ramBufferSize;\n\n    final long deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n\n    if (numBytesAlloc+deletesRAMUsed > freeTrigger) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      final long startBytesAlloc = numBytesAlloc + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesAlloc+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == byteBlockAllocator.freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed+deletesRAMUsed > flushTrigger;\n            if (infoStream != null) {\n              if (numBytesUsed > flushTrigger)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            assert numBytesUsed <= numBytesAlloc;\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesAlloc -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 4) && freeCharBlocks.size() > 0) {\n            freeCharBlocks.remove(freeCharBlocks.size()-1);\n            numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n          }\n\n          if ((2 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesAlloc -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      synchronized(this) {\n\n        if (numBytesUsed+deletesRAMUsed > flushTrigger) {\n          if (infoStream != null)\n            message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                    \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                    \" deletesMB=\" + nf.format(deletesRAMUsed/1024./1024.) +\n                    \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n          bufferIsFull = true;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  void balanceRAM() {\n\n    // We flush when we've used our target usage\n    final long flushTrigger = ramBufferSize;\n\n    if (numBytesAlloc > freeTrigger) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      final long startBytesAlloc = numBytesAlloc;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesAlloc > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == byteBlockAllocator.freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed > flushTrigger;\n            if (infoStream != null) {\n              if (numBytesUsed > flushTrigger)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            assert numBytesUsed <= numBytesAlloc;\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesAlloc -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 4) && freeCharBlocks.size() > 0) {\n            freeCharBlocks.remove(freeCharBlocks.size()-1);\n            numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n          }\n\n          if ((2 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesAlloc -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc)/1024./1024.) + \" usedMB=\" + nf.format(numBytesUsed/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      synchronized(this) {\n\n        if (numBytesUsed > flushTrigger) {\n          if (infoStream != null)\n            message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                    \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                    \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n          bufferIsFull = true;\n        }\n      }\n    }\n  }\n\n","bugFix":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c","5350389bf83287111f7760b9e3db3af8e3648474","84acdfa12c18361ff932244db20470fce117e52d"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d55ce084f816da26b3f2797175b2d96431111bcd","date":1267721178,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have four pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data), char blocks (holds\n   * characters in the term) and per-doc buffers (stored fields/term vectors).  \n   * Different docs require varying amount of storage from \n   * these four classes.\n   * \n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  void balanceRAM() {\n\n    // We flush when we've used our target usage\n    final long flushTrigger = ramBufferSize;\n\n    final long deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n\n    if (numBytesAlloc+deletesRAMUsed > freeTrigger) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" perDocFree=\" + toMB(perDocAllocator.freeByteBlocks.size()*PER_DOC_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      final long startBytesAlloc = numBytesAlloc + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesAlloc+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.freeByteBlocks.size() \n              && 0 == byteBlockAllocator.freeByteBlocks.size() \n              && 0 == freeCharBlocks.size() \n              && 0 == freeIntBlocks.size() \n              && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed+deletesRAMUsed > flushTrigger;\n            if (infoStream != null) {\n              if (numBytesUsed > flushTrigger)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            assert numBytesUsed <= numBytesAlloc;\n            break;\n          }\n\n          if ((0 == iter % 5) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesAlloc -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 5) && freeCharBlocks.size() > 0) {\n            freeCharBlocks.remove(freeCharBlocks.size()-1);\n            numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n          }\n\n          if ((2 == iter % 5) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesAlloc -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n\n          if ((3 == iter % 5) && perDocAllocator.freeByteBlocks.size() > 0) {\n            // Remove upwards of 32 blocks (each block is 1K)\n            for (int i = 0; i < 32; ++i) {\n              perDocAllocator.freeByteBlocks.remove(perDocAllocator.freeByteBlocks.size() - 1);\n              numBytesAlloc -= PER_DOC_BLOCK_SIZE;\n              if (perDocAllocator.freeByteBlocks.size() == 0) {\n                break;\n              }\n            }\n          }\n        }\n\n        if ((4 == iter % 5) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      synchronized(this) {\n\n        if (numBytesUsed+deletesRAMUsed > flushTrigger) {\n          if (infoStream != null)\n            message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                    \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                    \" deletesMB=\" + nf.format(deletesRAMUsed/1024./1024.) +\n                    \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n          bufferIsFull = true;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /* We have three pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data) and char blocks (holds\n   * characters in the term).  Different docs require\n   * varying amount of storage from these three classes.\n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  void balanceRAM() {\n\n    // We flush when we've used our target usage\n    final long flushTrigger = ramBufferSize;\n\n    final long deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n\n    if (numBytesAlloc+deletesRAMUsed > freeTrigger) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      final long startBytesAlloc = numBytesAlloc + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesAlloc+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == byteBlockAllocator.freeByteBlocks.size() && 0 == freeCharBlocks.size() && 0 == freeIntBlocks.size() && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed+deletesRAMUsed > flushTrigger;\n            if (infoStream != null) {\n              if (numBytesUsed > flushTrigger)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            assert numBytesUsed <= numBytesAlloc;\n            break;\n          }\n\n          if ((0 == iter % 4) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesAlloc -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 4) && freeCharBlocks.size() > 0) {\n            freeCharBlocks.remove(freeCharBlocks.size()-1);\n            numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n          }\n\n          if ((2 == iter % 4) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesAlloc -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n        }\n\n        if ((3 == iter % 4) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      synchronized(this) {\n\n        if (numBytesUsed+deletesRAMUsed > flushTrigger) {\n          if (infoStream != null)\n            message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                    \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                    \" deletesMB=\" + nf.format(deletesRAMUsed/1024./1024.) +\n                    \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n          bufferIsFull = true;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","pathOld":"src/java/org/apache/lucene/index/DocumentsWriter#balanceRAM().mjava","sourceNew":"  /* We have four pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data), char blocks (holds\n   * characters in the term) and per-doc buffers (stored fields/term vectors).  \n   * Different docs require varying amount of storage from \n   * these four classes.\n   * \n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  void balanceRAM() {\n\n    // We flush when we've used our target usage\n    final long flushTrigger = ramBufferSize;\n\n    final long deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n\n    if (numBytesAlloc+deletesRAMUsed > freeTrigger) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" perDocFree=\" + toMB(perDocAllocator.freeByteBlocks.size()*PER_DOC_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      final long startBytesAlloc = numBytesAlloc + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesAlloc+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.freeByteBlocks.size() \n              && 0 == byteBlockAllocator.freeByteBlocks.size() \n              && 0 == freeCharBlocks.size() \n              && 0 == freeIntBlocks.size() \n              && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed+deletesRAMUsed > flushTrigger;\n            if (infoStream != null) {\n              if (numBytesUsed > flushTrigger)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            assert numBytesUsed <= numBytesAlloc;\n            break;\n          }\n\n          if ((0 == iter % 5) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesAlloc -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 5) && freeCharBlocks.size() > 0) {\n            freeCharBlocks.remove(freeCharBlocks.size()-1);\n            numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n          }\n\n          if ((2 == iter % 5) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesAlloc -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n\n          if ((3 == iter % 5) && perDocAllocator.freeByteBlocks.size() > 0) {\n            // Remove upwards of 32 blocks (each block is 1K)\n            for (int i = 0; i < 32; ++i) {\n              perDocAllocator.freeByteBlocks.remove(perDocAllocator.freeByteBlocks.size() - 1);\n              numBytesAlloc -= PER_DOC_BLOCK_SIZE;\n              if (perDocAllocator.freeByteBlocks.size() == 0) {\n                break;\n              }\n            }\n          }\n        }\n\n        if ((4 == iter % 5) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      synchronized(this) {\n\n        if (numBytesUsed+deletesRAMUsed > flushTrigger) {\n          if (infoStream != null)\n            message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                    \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                    \" deletesMB=\" + nf.format(deletesRAMUsed/1024./1024.) +\n                    \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n          bufferIsFull = true;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /* We have four pools of RAM: Postings, byte blocks\n   * (holds freq/prox posting data), char blocks (holds\n   * characters in the term) and per-doc buffers (stored fields/term vectors).  \n   * Different docs require varying amount of storage from \n   * these four classes.\n   * \n   * For example, docs with many unique single-occurrence\n   * short terms will use up the Postings RAM and hardly any\n   * of the other two.  Whereas docs with very large terms\n   * will use alot of char blocks RAM and relatively less of\n   * the other two.  This method just frees allocations from\n   * the pools once we are over-budget, which balances the\n   * pools to match the current docs. */\n  void balanceRAM() {\n\n    // We flush when we've used our target usage\n    final long flushTrigger = ramBufferSize;\n\n    final long deletesRAMUsed = deletesInRAM.bytesUsed+deletesFlushed.bytesUsed;\n\n    if (numBytesAlloc+deletesRAMUsed > freeTrigger) {\n\n      if (infoStream != null)\n        message(\"  RAM: now balance allocations: usedMB=\" + toMB(numBytesUsed) +\n                \" vs trigger=\" + toMB(flushTrigger) +\n                \" allocMB=\" + toMB(numBytesAlloc) +\n                \" deletesMB=\" + toMB(deletesRAMUsed) +\n                \" vs trigger=\" + toMB(freeTrigger) +\n                \" byteBlockFree=\" + toMB(byteBlockAllocator.freeByteBlocks.size()*BYTE_BLOCK_SIZE) +\n                \" perDocFree=\" + toMB(perDocAllocator.freeByteBlocks.size()*PER_DOC_BLOCK_SIZE) +\n                \" charBlockFree=\" + toMB(freeCharBlocks.size()*CHAR_BLOCK_SIZE*CHAR_NUM_BYTE));\n\n      final long startBytesAlloc = numBytesAlloc + deletesRAMUsed;\n\n      int iter = 0;\n\n      // We free equally from each pool in 32 KB\n      // chunks until we are below our threshold\n      // (freeLevel)\n\n      boolean any = true;\n\n      while(numBytesAlloc+deletesRAMUsed > freeLevel) {\n      \n        synchronized(this) {\n          if (0 == perDocAllocator.freeByteBlocks.size() \n              && 0 == byteBlockAllocator.freeByteBlocks.size() \n              && 0 == freeCharBlocks.size() \n              && 0 == freeIntBlocks.size() \n              && !any) {\n            // Nothing else to free -- must flush now.\n            bufferIsFull = numBytesUsed+deletesRAMUsed > flushTrigger;\n            if (infoStream != null) {\n              if (numBytesUsed > flushTrigger)\n                message(\"    nothing to free; now set bufferIsFull\");\n              else\n                message(\"    nothing to free\");\n            }\n            assert numBytesUsed <= numBytesAlloc;\n            break;\n          }\n\n          if ((0 == iter % 5) && byteBlockAllocator.freeByteBlocks.size() > 0) {\n            byteBlockAllocator.freeByteBlocks.remove(byteBlockAllocator.freeByteBlocks.size()-1);\n            numBytesAlloc -= BYTE_BLOCK_SIZE;\n          }\n\n          if ((1 == iter % 5) && freeCharBlocks.size() > 0) {\n            freeCharBlocks.remove(freeCharBlocks.size()-1);\n            numBytesAlloc -= CHAR_BLOCK_SIZE * CHAR_NUM_BYTE;\n          }\n\n          if ((2 == iter % 5) && freeIntBlocks.size() > 0) {\n            freeIntBlocks.remove(freeIntBlocks.size()-1);\n            numBytesAlloc -= INT_BLOCK_SIZE * INT_NUM_BYTE;\n          }\n\n          if ((3 == iter % 5) && perDocAllocator.freeByteBlocks.size() > 0) {\n            // Remove upwards of 32 blocks (each block is 1K)\n            for (int i = 0; i < 32; ++i) {\n              perDocAllocator.freeByteBlocks.remove(perDocAllocator.freeByteBlocks.size() - 1);\n              numBytesAlloc -= PER_DOC_BLOCK_SIZE;\n              if (perDocAllocator.freeByteBlocks.size() == 0) {\n                break;\n              }\n            }\n          }\n        }\n\n        if ((4 == iter % 5) && any)\n          // Ask consumer to free any recycled state\n          any = consumer.freeRAM();\n\n        iter++;\n      }\n\n      if (infoStream != null)\n        message(\"    after free: freedMB=\" + nf.format((startBytesAlloc-numBytesAlloc-deletesRAMUsed)/1024./1024.) + \" usedMB=\" + nf.format((numBytesUsed+deletesRAMUsed)/1024./1024.) + \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.));\n      \n    } else {\n      // If we have not crossed the 100% mark, but have\n      // crossed the 95% mark of RAM we are actually\n      // using, go ahead and flush.  This prevents\n      // over-allocating and then freeing, with every\n      // flush.\n      synchronized(this) {\n\n        if (numBytesUsed+deletesRAMUsed > flushTrigger) {\n          if (infoStream != null)\n            message(\"  RAM: now flush @ usedMB=\" + nf.format(numBytesUsed/1024./1024.) +\n                    \" allocMB=\" + nf.format(numBytesAlloc/1024./1024.) +\n                    \" deletesMB=\" + nf.format(deletesRAMUsed/1024./1024.) +\n                    \" triggerMB=\" + nf.format(flushTrigger/1024./1024.));\n\n          bufferIsFull = true;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e8f450af7a7b034413833ed2a9508f99264ea49a":["84acdfa12c18361ff932244db20470fce117e52d"],"176324efd1eab6bd44a6d81c27c9b3a1a175ba3d":["2558ddf9e14a97bc597f5b72bb3ecb5b7f6bba8e"],"d55ce084f816da26b3f2797175b2d96431111bcd":["4404b358bf2902b2da0b8eef5ea0a68acd37674b"],"84acdfa12c18361ff932244db20470fce117e52d":["2684bcb2a921b6b5b76f64ba986564ab1ef0649d"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2684bcb2a921b6b5b76f64ba986564ab1ef0649d":["176324efd1eab6bd44a6d81c27c9b3a1a175ba3d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2558ddf9e14a97bc597f5b72bb3ecb5b7f6bba8e":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"4404b358bf2902b2da0b8eef5ea0a68acd37674b":["052fac7830290bd38a04cddee1a121ee07656b56"],"052fac7830290bd38a04cddee1a121ee07656b56":["5350389bf83287111f7760b9e3db3af8e3648474"],"5350389bf83287111f7760b9e3db3af8e3648474":["e8f450af7a7b034413833ed2a9508f99264ea49a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["d55ce084f816da26b3f2797175b2d96431111bcd"]},"commit2Childs":{"e8f450af7a7b034413833ed2a9508f99264ea49a":["5350389bf83287111f7760b9e3db3af8e3648474"],"176324efd1eab6bd44a6d81c27c9b3a1a175ba3d":["2684bcb2a921b6b5b76f64ba986564ab1ef0649d"],"d55ce084f816da26b3f2797175b2d96431111bcd":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"84acdfa12c18361ff932244db20470fce117e52d":["e8f450af7a7b034413833ed2a9508f99264ea49a"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["2558ddf9e14a97bc597f5b72bb3ecb5b7f6bba8e"],"2684bcb2a921b6b5b76f64ba986564ab1ef0649d":["84acdfa12c18361ff932244db20470fce117e52d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"2558ddf9e14a97bc597f5b72bb3ecb5b7f6bba8e":["176324efd1eab6bd44a6d81c27c9b3a1a175ba3d"],"4404b358bf2902b2da0b8eef5ea0a68acd37674b":["d55ce084f816da26b3f2797175b2d96431111bcd"],"052fac7830290bd38a04cddee1a121ee07656b56":["4404b358bf2902b2da0b8eef5ea0a68acd37674b"],"5350389bf83287111f7760b9e3db3af8e3648474":["052fac7830290bd38a04cddee1a121ee07656b56"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}