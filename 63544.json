{"path":"lucene/replicator/src/java/org/apache/lucene/replicator/nrt/CopyJob#_transferAndCancel(CopyJob).mjava","commits":[{"id":"0d49a158012a8ff48f328a4558e4bfcffbaed16f","date":1453677440,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/replicator/src/java/org/apache/lucene/replicator/nrt/CopyJob#_transferAndCancel(CopyJob).mjava","pathOld":"/dev/null","sourceNew":"  private synchronized void _transferAndCancel(CopyJob prevJob) throws IOException {\n\n    // Caller must already be sync'd on prevJob:\n    assert Thread.holdsLock(prevJob);\n\n    if (prevJob.exc != null) {\n      // Already cancelled\n      dest.message(\"xfer: prevJob was already cancelled; skip transfer\");\n      return;\n    }\n\n    // Cancel the previous job\n    prevJob.exc = new Throwable();\n\n    // Carry over already copied files that we also want to copy\n    Iterator<Map.Entry<String,FileMetaData>> it = toCopy.iterator();\n    long bytesAlreadyCopied = 0;\n\n    // Iterate over all files we think we need to copy:\n    while (it.hasNext()) {\n      Map.Entry<String,FileMetaData> ent = it.next();\n      String fileName = ent.getKey();\n      String prevTmpFileName = prevJob.copiedFiles.get(fileName);\n      if (prevTmpFileName != null) {\n        // This fileName is common to both jobs, and the old job already finished copying it (to a temp file), so we keep it:\n        long fileLength = ent.getValue().length;\n        bytesAlreadyCopied += fileLength;\n        dest.message(\"xfer: carry over already-copied file \" + fileName + \" (\" + prevTmpFileName + \", \" + fileLength + \" bytes)\");\n        copiedFiles.put(fileName, prevTmpFileName);\n\n        // So we don't try to delete it, below:\n        prevJob.copiedFiles.remove(fileName);\n\n        // So it's not in our copy list anymore:\n        it.remove();\n      } else if (prevJob.current != null && prevJob.current.name.equals(fileName)) {\n        // This fileName is common to both jobs, and it's the file that the previous job was in the process of copying.  In this case\n        // we continue copying it from the prevoius job.  This is important for cases where we are copying over a large file\n        // because otherwise we could keep failing the NRT copy and restarting this file from the beginning and never catch up:\n        dest.message(\"xfer: carry over in-progress file \" + fileName + \" (\" + prevJob.current.tmpName + \") bytesCopied=\" + prevJob.current.getBytesCopied() + \" of \" + prevJob.current.bytesToCopy);\n        bytesAlreadyCopied += prevJob.current.getBytesCopied();\n\n        assert current == null;\n\n        // must set current first, before writing/read to c.in/out in case that hits an exception, so that we then close the temp\n        // IndexOutput when cancelling ourselves:\n        current = newCopyOneFile(prevJob.current);\n\n        // Tell our new (primary) connection we'd like to copy this file first, but resuming from how many bytes we already copied last time:\n        // We do this even if bytesToCopy == bytesCopied, because we still need to readLong() the checksum from the primary connection:\n        assert prevJob.current.getBytesCopied() <= prevJob.current.bytesToCopy;\n\n        prevJob.current = null;\n\n        totBytes += current.metaData.length;\n\n        // So it's not in our copy list anymore:\n        it.remove();\n      } else {\n        dest.message(\"xfer: file \" + fileName + \" will be fully copied\");\n      }\n    }\n    dest.message(\"xfer: \" + bytesAlreadyCopied + \" bytes already copied of \" + totBytes);\n\n    // Delete all temp files the old job wrote but we don't need:\n    dest.message(\"xfer: now delete old temp files: \" + prevJob.copiedFiles.values());\n    IOUtils.deleteFilesIgnoringExceptions(dest.dir, prevJob.copiedFiles.values());\n\n    if (prevJob.current != null) { \n      IOUtils.closeWhileHandlingException(prevJob.current);\n      if (Node.VERBOSE_FILES) {\n        dest.message(\"remove partial file \" + prevJob.current.tmpName);\n      }\n      dest.deleter.deleteNewFile(prevJob.current.tmpName);\n      prevJob.current = null;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"68496c2200e559fb7802f7575427b7a482659afb","date":1455207618,"type":0,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/replicator/src/java/org/apache/lucene/replicator/nrt/CopyJob#_transferAndCancel(CopyJob).mjava","pathOld":"/dev/null","sourceNew":"  private synchronized void _transferAndCancel(CopyJob prevJob) throws IOException {\n\n    // Caller must already be sync'd on prevJob:\n    assert Thread.holdsLock(prevJob);\n\n    if (prevJob.exc != null) {\n      // Already cancelled\n      dest.message(\"xfer: prevJob was already cancelled; skip transfer\");\n      return;\n    }\n\n    // Cancel the previous job\n    prevJob.exc = new Throwable();\n\n    // Carry over already copied files that we also want to copy\n    Iterator<Map.Entry<String,FileMetaData>> it = toCopy.iterator();\n    long bytesAlreadyCopied = 0;\n\n    // Iterate over all files we think we need to copy:\n    while (it.hasNext()) {\n      Map.Entry<String,FileMetaData> ent = it.next();\n      String fileName = ent.getKey();\n      String prevTmpFileName = prevJob.copiedFiles.get(fileName);\n      if (prevTmpFileName != null) {\n        // This fileName is common to both jobs, and the old job already finished copying it (to a temp file), so we keep it:\n        long fileLength = ent.getValue().length;\n        bytesAlreadyCopied += fileLength;\n        dest.message(\"xfer: carry over already-copied file \" + fileName + \" (\" + prevTmpFileName + \", \" + fileLength + \" bytes)\");\n        copiedFiles.put(fileName, prevTmpFileName);\n\n        // So we don't try to delete it, below:\n        prevJob.copiedFiles.remove(fileName);\n\n        // So it's not in our copy list anymore:\n        it.remove();\n      } else if (prevJob.current != null && prevJob.current.name.equals(fileName)) {\n        // This fileName is common to both jobs, and it's the file that the previous job was in the process of copying.  In this case\n        // we continue copying it from the prevoius job.  This is important for cases where we are copying over a large file\n        // because otherwise we could keep failing the NRT copy and restarting this file from the beginning and never catch up:\n        dest.message(\"xfer: carry over in-progress file \" + fileName + \" (\" + prevJob.current.tmpName + \") bytesCopied=\" + prevJob.current.getBytesCopied() + \" of \" + prevJob.current.bytesToCopy);\n        bytesAlreadyCopied += prevJob.current.getBytesCopied();\n\n        assert current == null;\n\n        // must set current first, before writing/read to c.in/out in case that hits an exception, so that we then close the temp\n        // IndexOutput when cancelling ourselves:\n        current = newCopyOneFile(prevJob.current);\n\n        // Tell our new (primary) connection we'd like to copy this file first, but resuming from how many bytes we already copied last time:\n        // We do this even if bytesToCopy == bytesCopied, because we still need to readLong() the checksum from the primary connection:\n        assert prevJob.current.getBytesCopied() <= prevJob.current.bytesToCopy;\n\n        prevJob.current = null;\n\n        totBytes += current.metaData.length;\n\n        // So it's not in our copy list anymore:\n        it.remove();\n      } else {\n        dest.message(\"xfer: file \" + fileName + \" will be fully copied\");\n      }\n    }\n    dest.message(\"xfer: \" + bytesAlreadyCopied + \" bytes already copied of \" + totBytes);\n\n    // Delete all temp files the old job wrote but we don't need:\n    dest.message(\"xfer: now delete old temp files: \" + prevJob.copiedFiles.values());\n    IOUtils.deleteFilesIgnoringExceptions(dest.dir, prevJob.copiedFiles.values());\n\n    if (prevJob.current != null) { \n      IOUtils.closeWhileHandlingException(prevJob.current);\n      if (Node.VERBOSE_FILES) {\n        dest.message(\"remove partial file \" + prevJob.current.tmpName);\n      }\n      dest.deleter.deleteNewFile(prevJob.current.tmpName);\n      prevJob.current = null;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"68496c2200e559fb7802f7575427b7a482659afb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0d49a158012a8ff48f328a4558e4bfcffbaed16f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["68496c2200e559fb7802f7575427b7a482659afb"],"0d49a158012a8ff48f328a4558e4bfcffbaed16f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["68496c2200e559fb7802f7575427b7a482659afb","0d49a158012a8ff48f328a4558e4bfcffbaed16f"],"68496c2200e559fb7802f7575427b7a482659afb":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0d49a158012a8ff48f328a4558e4bfcffbaed16f":["68496c2200e559fb7802f7575427b7a482659afb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}