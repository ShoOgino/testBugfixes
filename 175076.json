{"path":"lucene/src/java/org/apache/lucene/store/CompoundFileDirectory#readLegacyEntries(IndexInput,int).mjava","commits":[{"id":"0aab6e810b4b0d3743d6a048be0602801f4b3920","date":1308671625,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/store/CompoundFileDirectory#readLegacyEntries(IndexInput,int).mjava","pathOld":"/dev/null","sourceNew":"  private static Map<String, FileEntry> readLegacyEntries(IndexInput stream,\n      int firstInt) throws CorruptIndexException, IOException {\n    final Map<String,FileEntry> entries = new HashMap<String,FileEntry>();\n    final int count;\n    final boolean stripSegmentName;\n    if (firstInt < CompoundFileWriter.FORMAT_PRE_VERSION) {\n      if (firstInt < CompoundFileWriter.FORMAT_CURRENT) {\n        throw new CorruptIndexException(\"Incompatible format version: \"\n            + firstInt + \" expected \" + CompoundFileWriter.FORMAT_CURRENT);\n      }\n      // It's a post-3.1 index, read the count.\n      count = stream.readVInt();\n      stripSegmentName = false;\n    } else {\n      count = firstInt;\n      stripSegmentName = true;\n    }\n    \n    // read the directory and init files\n    long streamLength = stream.length();\n    FileEntry entry = null;\n    for (int i=0; i<count; i++) {\n      long offset = stream.readLong();\n      if (offset < 0 || offset > streamLength) {\n        throw new CorruptIndexException(\"Invalid CFS entry offset: \" + offset);\n      }\n      String id = stream.readString();\n      \n      if (stripSegmentName) {\n        // Fix the id to not include the segment names. This is relevant for\n        // pre-3.1 indexes.\n        id = IndexFileNames.stripSegmentName(id);\n      }\n      \n      if (entry != null) {\n        // set length of the previous entry\n        entry.length = offset - entry.offset;\n      }\n      \n      entry = new FileEntry();\n      entry.offset = offset;\n      entries.put(id, entry);\n    }\n    \n    // set the length of the final entry\n    if (entry != null) {\n      entry.length = streamLength - entry.offset;\n    }\n    \n    return entries;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/store/CompoundFileDirectory#readLegacyEntries(IndexInput,int).mjava","pathOld":"/dev/null","sourceNew":"  private static Map<String, FileEntry> readLegacyEntries(IndexInput stream,\n      int firstInt) throws CorruptIndexException, IOException {\n    final Map<String,FileEntry> entries = new HashMap<String,FileEntry>();\n    final int count;\n    final boolean stripSegmentName;\n    if (firstInt < CompoundFileWriter.FORMAT_PRE_VERSION) {\n      if (firstInt < CompoundFileWriter.FORMAT_CURRENT) {\n        throw new CorruptIndexException(\"Incompatible format version: \"\n            + firstInt + \" expected \" + CompoundFileWriter.FORMAT_CURRENT);\n      }\n      // It's a post-3.1 index, read the count.\n      count = stream.readVInt();\n      stripSegmentName = false;\n    } else {\n      count = firstInt;\n      stripSegmentName = true;\n    }\n    \n    // read the directory and init files\n    long streamLength = stream.length();\n    FileEntry entry = null;\n    for (int i=0; i<count; i++) {\n      long offset = stream.readLong();\n      if (offset < 0 || offset > streamLength) {\n        throw new CorruptIndexException(\"Invalid CFS entry offset: \" + offset);\n      }\n      String id = stream.readString();\n      \n      if (stripSegmentName) {\n        // Fix the id to not include the segment names. This is relevant for\n        // pre-3.1 indexes.\n        id = IndexFileNames.stripSegmentName(id);\n      }\n      \n      if (entry != null) {\n        // set length of the previous entry\n        entry.length = offset - entry.offset;\n      }\n      \n      entry = new FileEntry();\n      entry.offset = offset;\n      entries.put(id, entry);\n    }\n    \n    // set the length of the final entry\n    if (entry != null) {\n      entry.length = streamLength - entry.offset;\n    }\n    \n    return entries;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/store/CompoundFileDirectory#readLegacyEntries(IndexInput,int).mjava","pathOld":"/dev/null","sourceNew":"  private static Map<String, FileEntry> readLegacyEntries(IndexInput stream,\n      int firstInt) throws CorruptIndexException, IOException {\n    final Map<String,FileEntry> entries = new HashMap<String,FileEntry>();\n    final int count;\n    final boolean stripSegmentName;\n    if (firstInt < CompoundFileWriter.FORMAT_PRE_VERSION) {\n      if (firstInt < CompoundFileWriter.FORMAT_CURRENT) {\n        throw new CorruptIndexException(\"Incompatible format version: \"\n            + firstInt + \" expected \" + CompoundFileWriter.FORMAT_CURRENT);\n      }\n      // It's a post-3.1 index, read the count.\n      count = stream.readVInt();\n      stripSegmentName = false;\n    } else {\n      count = firstInt;\n      stripSegmentName = true;\n    }\n    \n    // read the directory and init files\n    long streamLength = stream.length();\n    FileEntry entry = null;\n    for (int i=0; i<count; i++) {\n      long offset = stream.readLong();\n      if (offset < 0 || offset > streamLength) {\n        throw new CorruptIndexException(\"Invalid CFS entry offset: \" + offset);\n      }\n      String id = stream.readString();\n      \n      if (stripSegmentName) {\n        // Fix the id to not include the segment names. This is relevant for\n        // pre-3.1 indexes.\n        id = IndexFileNames.stripSegmentName(id);\n      }\n      \n      if (entry != null) {\n        // set length of the previous entry\n        entry.length = offset - entry.offset;\n      }\n      \n      entry = new FileEntry();\n      entry.offset = offset;\n      entries.put(id, entry);\n    }\n    \n    // set the length of the final entry\n    if (entry != null) {\n      entry.length = streamLength - entry.offset;\n    }\n    \n    return entries;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/store/CompoundFileDirectory#readLegacyEntries(IndexInput,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/store/CompoundFileDirectory#readLegacyEntries(IndexInput,int).mjava","sourceNew":"  private static Map<String, FileEntry> readLegacyEntries(IndexInput stream,\n      int firstInt) throws CorruptIndexException, IOException {\n    final Map<String,FileEntry> entries = new HashMap<String,FileEntry>();\n    final int count;\n    final boolean stripSegmentName;\n    if (firstInt < CompoundFileWriter.FORMAT_PRE_VERSION) {\n      if (firstInt < CompoundFileWriter.FORMAT_CURRENT) {\n        throw new CorruptIndexException(\"Incompatible format version: \"\n            + firstInt + \" expected \" + CompoundFileWriter.FORMAT_CURRENT);\n      }\n      // It's a post-3.1 index, read the count.\n      count = stream.readVInt();\n      stripSegmentName = false;\n    } else {\n      count = firstInt;\n      stripSegmentName = true;\n    }\n    \n    // read the directory and init files\n    long streamLength = stream.length();\n    FileEntry entry = null;\n    for (int i=0; i<count; i++) {\n      long offset = stream.readLong();\n      if (offset < 0 || offset > streamLength) {\n        throw new CorruptIndexException(\"Invalid CFS entry offset: \" + offset);\n      }\n      String id = stream.readString();\n      \n      if (stripSegmentName) {\n        // Fix the id to not include the segment names. This is relevant for\n        // pre-3.1 indexes.\n        id = IndexFileNames.stripSegmentName(id);\n      }\n      \n      if (entry != null) {\n        // set length of the previous entry\n        entry.length = offset - entry.offset;\n      }\n      \n      entry = new FileEntry();\n      entry.offset = offset;\n\n      assert !entries.containsKey(id);\n\n      entries.put(id, entry);\n    }\n    \n    // set the length of the final entry\n    if (entry != null) {\n      entry.length = streamLength - entry.offset;\n    }\n    \n    return entries;\n  }\n\n","sourceOld":"  private static Map<String, FileEntry> readLegacyEntries(IndexInput stream,\n      int firstInt) throws CorruptIndexException, IOException {\n    final Map<String,FileEntry> entries = new HashMap<String,FileEntry>();\n    final int count;\n    final boolean stripSegmentName;\n    if (firstInt < CompoundFileWriter.FORMAT_PRE_VERSION) {\n      if (firstInt < CompoundFileWriter.FORMAT_CURRENT) {\n        throw new CorruptIndexException(\"Incompatible format version: \"\n            + firstInt + \" expected \" + CompoundFileWriter.FORMAT_CURRENT);\n      }\n      // It's a post-3.1 index, read the count.\n      count = stream.readVInt();\n      stripSegmentName = false;\n    } else {\n      count = firstInt;\n      stripSegmentName = true;\n    }\n    \n    // read the directory and init files\n    long streamLength = stream.length();\n    FileEntry entry = null;\n    for (int i=0; i<count; i++) {\n      long offset = stream.readLong();\n      if (offset < 0 || offset > streamLength) {\n        throw new CorruptIndexException(\"Invalid CFS entry offset: \" + offset);\n      }\n      String id = stream.readString();\n      \n      if (stripSegmentName) {\n        // Fix the id to not include the segment names. This is relevant for\n        // pre-3.1 indexes.\n        id = IndexFileNames.stripSegmentName(id);\n      }\n      \n      if (entry != null) {\n        // set length of the previous entry\n        entry.length = offset - entry.offset;\n      }\n      \n      entry = new FileEntry();\n      entry.offset = offset;\n      entries.put(id, entry);\n    }\n    \n    // set the length of the final entry\n    if (entry != null) {\n      entry.length = streamLength - entry.offset;\n    }\n    \n    return entries;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f1efe3edca215dd9891cb42af283fed96f792ca0","date":1320428891,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/store/CompoundFileDirectory#readLegacyEntries(IndexInput,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/store/CompoundFileDirectory#readLegacyEntries(IndexInput,int).mjava","sourceNew":"  private static Map<String, FileEntry> readLegacyEntries(IndexInput stream,\n      int firstInt) throws CorruptIndexException, IOException {\n    final Map<String,FileEntry> entries = new HashMap<String,FileEntry>();\n    final int count;\n    final boolean stripSegmentName;\n    if (firstInt < CompoundFileWriter.FORMAT_PRE_VERSION) {\n      if (firstInt < CompoundFileWriter.FORMAT_CURRENT) {\n        throw new CorruptIndexException(\"Incompatible format version: \"\n            + firstInt + \" expected \" + CompoundFileWriter.FORMAT_CURRENT + \" (resource: \" + stream + \")\");\n      }\n      // It's a post-3.1 index, read the count.\n      count = stream.readVInt();\n      stripSegmentName = false;\n    } else {\n      count = firstInt;\n      stripSegmentName = true;\n    }\n    \n    // read the directory and init files\n    long streamLength = stream.length();\n    FileEntry entry = null;\n    for (int i=0; i<count; i++) {\n      long offset = stream.readLong();\n      if (offset < 0 || offset > streamLength) {\n        throw new CorruptIndexException(\"Invalid CFS entry offset: \" + offset + \" (resource: \" + stream + \")\");\n      }\n      String id = stream.readString();\n      \n      if (stripSegmentName) {\n        // Fix the id to not include the segment names. This is relevant for\n        // pre-3.1 indexes.\n        id = IndexFileNames.stripSegmentName(id);\n      }\n      \n      if (entry != null) {\n        // set length of the previous entry\n        entry.length = offset - entry.offset;\n      }\n      \n      entry = new FileEntry();\n      entry.offset = offset;\n\n      assert !entries.containsKey(id);\n\n      entries.put(id, entry);\n    }\n    \n    // set the length of the final entry\n    if (entry != null) {\n      entry.length = streamLength - entry.offset;\n    }\n    \n    return entries;\n  }\n\n","sourceOld":"  private static Map<String, FileEntry> readLegacyEntries(IndexInput stream,\n      int firstInt) throws CorruptIndexException, IOException {\n    final Map<String,FileEntry> entries = new HashMap<String,FileEntry>();\n    final int count;\n    final boolean stripSegmentName;\n    if (firstInt < CompoundFileWriter.FORMAT_PRE_VERSION) {\n      if (firstInt < CompoundFileWriter.FORMAT_CURRENT) {\n        throw new CorruptIndexException(\"Incompatible format version: \"\n            + firstInt + \" expected \" + CompoundFileWriter.FORMAT_CURRENT);\n      }\n      // It's a post-3.1 index, read the count.\n      count = stream.readVInt();\n      stripSegmentName = false;\n    } else {\n      count = firstInt;\n      stripSegmentName = true;\n    }\n    \n    // read the directory and init files\n    long streamLength = stream.length();\n    FileEntry entry = null;\n    for (int i=0; i<count; i++) {\n      long offset = stream.readLong();\n      if (offset < 0 || offset > streamLength) {\n        throw new CorruptIndexException(\"Invalid CFS entry offset: \" + offset);\n      }\n      String id = stream.readString();\n      \n      if (stripSegmentName) {\n        // Fix the id to not include the segment names. This is relevant for\n        // pre-3.1 indexes.\n        id = IndexFileNames.stripSegmentName(id);\n      }\n      \n      if (entry != null) {\n        // set length of the previous entry\n        entry.length = offset - entry.offset;\n      }\n      \n      entry = new FileEntry();\n      entry.offset = offset;\n\n      assert !entries.containsKey(id);\n\n      entries.put(id, entry);\n    }\n    \n    // set the length of the final entry\n    if (entry != null) {\n      entry.length = streamLength - entry.offset;\n    }\n    \n    return entries;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readLegacyEntries(IndexInput,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/store/CompoundFileDirectory#readLegacyEntries(IndexInput,int).mjava","sourceNew":"  private static Map<String, FileEntry> readLegacyEntries(IndexInput stream,\n      int firstInt) throws CorruptIndexException, IOException {\n    final Map<String,FileEntry> entries = new HashMap<String,FileEntry>();\n    final int count;\n    final boolean stripSegmentName;\n    if (firstInt < CompoundFileWriter.FORMAT_PRE_VERSION) {\n      if (firstInt < CompoundFileWriter.FORMAT_CURRENT) {\n        throw new CorruptIndexException(\"Incompatible format version: \"\n            + firstInt + \" expected \" + CompoundFileWriter.FORMAT_CURRENT + \" (resource: \" + stream + \")\");\n      }\n      // It's a post-3.1 index, read the count.\n      count = stream.readVInt();\n      stripSegmentName = false;\n    } else {\n      count = firstInt;\n      stripSegmentName = true;\n    }\n    \n    // read the directory and init files\n    long streamLength = stream.length();\n    FileEntry entry = null;\n    for (int i=0; i<count; i++) {\n      long offset = stream.readLong();\n      if (offset < 0 || offset > streamLength) {\n        throw new CorruptIndexException(\"Invalid CFS entry offset: \" + offset + \" (resource: \" + stream + \")\");\n      }\n      String id = stream.readString();\n      \n      if (stripSegmentName) {\n        // Fix the id to not include the segment names. This is relevant for\n        // pre-3.1 indexes.\n        id = IndexFileNames.stripSegmentName(id);\n      }\n      \n      if (entry != null) {\n        // set length of the previous entry\n        entry.length = offset - entry.offset;\n      }\n      \n      entry = new FileEntry();\n      entry.offset = offset;\n\n      assert !entries.containsKey(id);\n\n      entries.put(id, entry);\n    }\n    \n    // set the length of the final entry\n    if (entry != null) {\n      entry.length = streamLength - entry.offset;\n    }\n    \n    return entries;\n  }\n\n","sourceOld":"  private static Map<String, FileEntry> readLegacyEntries(IndexInput stream,\n      int firstInt) throws CorruptIndexException, IOException {\n    final Map<String,FileEntry> entries = new HashMap<String,FileEntry>();\n    final int count;\n    final boolean stripSegmentName;\n    if (firstInt < CompoundFileWriter.FORMAT_PRE_VERSION) {\n      if (firstInt < CompoundFileWriter.FORMAT_CURRENT) {\n        throw new CorruptIndexException(\"Incompatible format version: \"\n            + firstInt + \" expected \" + CompoundFileWriter.FORMAT_CURRENT + \" (resource: \" + stream + \")\");\n      }\n      // It's a post-3.1 index, read the count.\n      count = stream.readVInt();\n      stripSegmentName = false;\n    } else {\n      count = firstInt;\n      stripSegmentName = true;\n    }\n    \n    // read the directory and init files\n    long streamLength = stream.length();\n    FileEntry entry = null;\n    for (int i=0; i<count; i++) {\n      long offset = stream.readLong();\n      if (offset < 0 || offset > streamLength) {\n        throw new CorruptIndexException(\"Invalid CFS entry offset: \" + offset + \" (resource: \" + stream + \")\");\n      }\n      String id = stream.readString();\n      \n      if (stripSegmentName) {\n        // Fix the id to not include the segment names. This is relevant for\n        // pre-3.1 indexes.\n        id = IndexFileNames.stripSegmentName(id);\n      }\n      \n      if (entry != null) {\n        // set length of the previous entry\n        entry.length = offset - entry.offset;\n      }\n      \n      entry = new FileEntry();\n      entry.offset = offset;\n\n      assert !entries.containsKey(id);\n\n      entries.put(id, entry);\n    }\n    \n    // set the length of the final entry\n    if (entry != null) {\n      entry.length = streamLength - entry.offset;\n    }\n    \n    return entries;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7b91922b55d15444d554721b352861d028eb8278":["0aab6e810b4b0d3743d6a048be0602801f4b3920"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["f1efe3edca215dd9891cb42af283fed96f792ca0"],"f1efe3edca215dd9891cb42af283fed96f792ca0":["7b91922b55d15444d554721b352861d028eb8278"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0aab6e810b4b0d3743d6a048be0602801f4b3920":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2553b00f699380c64959ccb27991289aae87be2e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0aab6e810b4b0d3743d6a048be0602801f4b3920"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0aab6e810b4b0d3743d6a048be0602801f4b3920"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"7b91922b55d15444d554721b352861d028eb8278":["f1efe3edca215dd9891cb42af283fed96f792ca0"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f1efe3edca215dd9891cb42af283fed96f792ca0":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0aab6e810b4b0d3743d6a048be0602801f4b3920","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"0aab6e810b4b0d3743d6a048be0602801f4b3920":["7b91922b55d15444d554721b352861d028eb8278","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"2553b00f699380c64959ccb27991289aae87be2e":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}