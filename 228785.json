{"path":"src/java/org/apache/solr/analysis/TrimFilter#incrementToken().mjava","commits":[{"id":"be29e0e2cef1fd569147732e48caf8538790339b","date":1250443738,"type":1,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/analysis/TrimFilter#incrementToken().mjava","pathOld":"src/java/org/apache/solr/analysis/TrimFilter#next(Token).mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    if (!input.incrementToken()) return false;\n\n    char[] termBuffer = termAtt.termBuffer();\n    int len = termAtt.termLength();\n    int start = 0;\n    int end = 0;\n    int endOff = 0;\n\n    // eat the first characters\n    //QUESTION: Should we use Character.isWhitespace() instead?\n    for (start = 0; start < len && termBuffer[start] <= ' '; start++) {\n    }\n    // eat the end characters\n    for (end = len; end >= start && termBuffer[end - 1] <= ' '; end--) {\n      endOff++;\n    }\n    if (start > 0 || end < len) {\n      if (start < end) {\n        termAtt.setTermBuffer(termBuffer, start, (end - start));\n      } else {\n        termAtt.setTermLength(0);\n      }\n      if (updateOffsets) {\n        int newStart = offsetAtt.startOffset()+start;\n        int newEnd = offsetAtt.endOffset() - (start<end ? endOff:0);\n        offsetAtt.setOffset(newStart, newEnd);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  @Override\n  public final Token next(Token in) throws IOException {\n    Token t = input.next(in);\n    if (null == t || null == t.termBuffer() || t.termLength() == 0){\n      return t;\n    }\n    char[] termBuffer = t.termBuffer();\n    int len = t.termLength();\n    int start = 0;\n    int end = 0;\n    int endOff = 0;\n\n    // eat the first characters\n    //QUESTION: Should we use Character.isWhitespace() instead?\n    for (start = 0; start < len && termBuffer[start] <= ' '; start++) {\n    }\n    // eat the end characters\n    for (end = len; end >= start && termBuffer[end - 1] <= ' '; end--) {\n      endOff++;\n    }\n    if (start > 0 || end < len) {\n      if (start < end) {\n        t.setTermBuffer(t.termBuffer(), start, (end - start));\n      } else {\n        t.setTermLength(0);\n      }\n      if (updateOffsets) {\n        t.setStartOffset(t.startOffset() + start);\n        if (start < end) {\n          t.setEndOffset(t.endOffset() - endOff);\n        } //else if end is less than, start, then the term length is 0, so, no need to bother w/ the end offset\n      }\n      /*t = new Token( t.termText().substring( start, end ),\n     t.startOffset()+start,\n     t.endOffset()-endOff,\n     t.type() );*/\n\n\n    }\n\n    return t;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"252b5e659a9ec7711b788d4bb0ab3b5093982cc4","date":1252415228,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"src/java/org/apache/solr/analysis/TrimFilter#incrementToken().mjava","pathOld":"src/java/org/apache/solr/analysis/TrimFilter#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    if (!input.incrementToken()) return false;\n\n    char[] termBuffer = termAtt.termBuffer();\n    int len = termAtt.termLength();\n    //TODO: Is this the right behavior or should we return false?  Currently, \"  \", returns true, so I think this should\n    //also return true\n    if (len == 0){\n      return true;\n    }\n    int start = 0;\n    int end = 0;\n    int endOff = 0;\n\n    // eat the first characters\n    //QUESTION: Should we use Character.isWhitespace() instead?\n    for (start = 0; start < len && termBuffer[start] <= ' '; start++) {\n    }\n    // eat the end characters\n    for (end = len; end >= start && termBuffer[end - 1] <= ' '; end--) {\n      endOff++;\n    }\n    if (start > 0 || end < len) {\n      if (start < end) {\n        termAtt.setTermBuffer(termBuffer, start, (end - start));\n      } else {\n        termAtt.setTermLength(0);\n      }\n      if (updateOffsets) {\n        int newStart = offsetAtt.startOffset()+start;\n        int newEnd = offsetAtt.endOffset() - (start<end ? endOff:0);\n        offsetAtt.setOffset(newStart, newEnd);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n    if (!input.incrementToken()) return false;\n\n    char[] termBuffer = termAtt.termBuffer();\n    int len = termAtt.termLength();\n    int start = 0;\n    int end = 0;\n    int endOff = 0;\n\n    // eat the first characters\n    //QUESTION: Should we use Character.isWhitespace() instead?\n    for (start = 0; start < len && termBuffer[start] <= ' '; start++) {\n    }\n    // eat the end characters\n    for (end = len; end >= start && termBuffer[end - 1] <= ' '; end--) {\n      endOff++;\n    }\n    if (start > 0 || end < len) {\n      if (start < end) {\n        termAtt.setTermBuffer(termBuffer, start, (end - start));\n      } else {\n        termAtt.setTermLength(0);\n      }\n      if (updateOffsets) {\n        int newStart = offsetAtt.startOffset()+start;\n        int newEnd = offsetAtt.endOffset() - (start<end ? endOff:0);\n        offsetAtt.setOffset(newStart, newEnd);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/TrimFilter#incrementToken().mjava","pathOld":"src/java/org/apache/solr/analysis/TrimFilter#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    if (!input.incrementToken()) return false;\n\n    char[] termBuffer = termAtt.termBuffer();\n    int len = termAtt.termLength();\n    //TODO: Is this the right behavior or should we return false?  Currently, \"  \", returns true, so I think this should\n    //also return true\n    if (len == 0){\n      return true;\n    }\n    int start = 0;\n    int end = 0;\n    int endOff = 0;\n\n    // eat the first characters\n    //QUESTION: Should we use Character.isWhitespace() instead?\n    for (start = 0; start < len && termBuffer[start] <= ' '; start++) {\n    }\n    // eat the end characters\n    for (end = len; end >= start && termBuffer[end - 1] <= ' '; end--) {\n      endOff++;\n    }\n    if (start > 0 || end < len) {\n      if (start < end) {\n        termAtt.setTermBuffer(termBuffer, start, (end - start));\n      } else {\n        termAtt.setTermLength(0);\n      }\n      if (updateOffsets) {\n        int newStart = offsetAtt.startOffset()+start;\n        int newEnd = offsetAtt.endOffset() - (start<end ? endOff:0);\n        offsetAtt.setOffset(newStart, newEnd);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n    if (!input.incrementToken()) return false;\n\n    char[] termBuffer = termAtt.termBuffer();\n    int len = termAtt.termLength();\n    //TODO: Is this the right behavior or should we return false?  Currently, \"  \", returns true, so I think this should\n    //also return true\n    if (len == 0){\n      return true;\n    }\n    int start = 0;\n    int end = 0;\n    int endOff = 0;\n\n    // eat the first characters\n    //QUESTION: Should we use Character.isWhitespace() instead?\n    for (start = 0; start < len && termBuffer[start] <= ' '; start++) {\n    }\n    // eat the end characters\n    for (end = len; end >= start && termBuffer[end - 1] <= ' '; end--) {\n      endOff++;\n    }\n    if (start > 0 || end < len) {\n      if (start < end) {\n        termAtt.setTermBuffer(termBuffer, start, (end - start));\n      } else {\n        termAtt.setTermLength(0);\n      }\n      if (updateOffsets) {\n        int newStart = offsetAtt.startOffset()+start;\n        int newEnd = offsetAtt.endOffset() - (start<end ? endOff:0);\n        offsetAtt.setOffset(newStart, newEnd);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"be29e0e2cef1fd569147732e48caf8538790339b":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"ad94625fb8d088209f46650c8097196fec67f00c":["252b5e659a9ec7711b788d4bb0ab3b5093982cc4"],"252b5e659a9ec7711b788d4bb0ab3b5093982cc4":["be29e0e2cef1fd569147732e48caf8538790339b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["be29e0e2cef1fd569147732e48caf8538790339b"],"be29e0e2cef1fd569147732e48caf8538790339b":["252b5e659a9ec7711b788d4bb0ab3b5093982cc4"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"252b5e659a9ec7711b788d4bb0ab3b5093982cc4":["ad94625fb8d088209f46650c8097196fec67f00c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}