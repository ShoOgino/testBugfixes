{"path":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"399d5903979ca52514d2bc7e3a362e1c45885c94","date":1333042474,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = (FieldInfos) fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d08eba3d52b63561ebf936481ce73e6b6a14aa03","date":1333879759,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final InvertedFieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","date":1333892281,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final InvertedFieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b","date":1337136355,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final MutableFieldInfos fieldInfos = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2dee33619431ada2a7a07f5fe2dbd94bac6a460","date":1337274029,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final MutableFieldInfos fieldInfos = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, -1,\n                                           SEGMENT, false, null, false, 0,\n                                           fieldInfos.hasProx(),\n                                           codec, null, fieldInfos.hasVectors(),\n                                           fieldInfos.hasDocValues(),\n                                           fieldInfos.hasNorms(),\n                                           fieldInfos.hasFreq());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final MutableFieldInfos fieldInfos = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc834f3412d287003cc04691da380b69ab983239","date":1337276089,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final MutableFieldInfos fieldInfos = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, -1,\n                                           SEGMENT, false, null, false, 0,\n                                           fieldInfos.hasProx(),\n                                           codec, null, fieldInfos.hasVectors());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final MutableFieldInfos fieldInfos = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, -1,\n                                           SEGMENT, false, null, false, 0,\n                                           fieldInfos.hasProx(),\n                                           codec, null, fieldInfos.hasVectors(),\n                                           fieldInfos.hasDocValues(),\n                                           fieldInfos.hasNorms(),\n                                           fieldInfos.hasFreq());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4a8b14bc4241c302311422d5c6f7627f8febb86e","date":1337291675,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final MutableFieldInfos fieldInfos = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, -1,\n                                           SEGMENT, false, null, false, 0,\n                                           fieldInfos.hasProx(),\n                                           codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final MutableFieldInfos fieldInfos = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, -1,\n                                           SEGMENT, false, null, false, 0,\n                                           fieldInfos.hasProx(),\n                                           codec, null, fieldInfos.hasVectors());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dc97c61094c5498702b29cc2e8309beac50c23dc","date":1337293692,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final MutableFieldInfos fieldInfos = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, -1,\n                                           SEGMENT, false, null, false, 0,\n                                           codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final MutableFieldInfos fieldInfos = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, -1,\n                                           SEGMENT, false, null, false, 0,\n                                           fieldInfos.hasProx(),\n                                           codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57d2758489b06da76bc6a037793d9ba347ce01fd","date":1337351495,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final MutableFieldInfos builder = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, -1,\n                                           SEGMENT, false, null, false, 0,\n                                           codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final MutableFieldInfos fieldInfos = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, -1,\n                                           SEGMENT, false, null, false, 0,\n                                           codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a851824c09818632c94eba41e60ef5e72e323c8e","date":1337355760,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, -1,\n                                           SEGMENT, false, null, false, 0,\n                                           codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final MutableFieldInfos builder = new MutableFieldInfos(new MutableFieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, -1,\n                                           SEGMENT, false, null, false, 0,\n                                           codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4356000e349e38c9fb48034695b7c309abd54557","date":1337460341,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1,\n                                           SEGMENT, false, null, false, 0,\n                                           codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1, -1,\n                                           SEGMENT, false, null, false, 0,\n                                           codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1,\n                                           SEGMENT, false, null, false,\n                                           codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1,\n                                           SEGMENT, false, null, false, 0,\n                                           codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"63caed6eb28209e181e97822c4c8fdf808884c3b","date":1337712793,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1,\n                                           SEGMENT, false, null, false,\n                                           codec, null, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1,\n                                           SEGMENT, false, null, false,\n                                           codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6a917aca07a305ab70118a83e84d931503441271","date":1337826487,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000,\n                                           null, false, codec, null, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, -1,\n                                           SEGMENT, false, null, false,\n                                           codec, null, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"764b942fd30efcae6e532c19771f32eeeb0037b2","date":1337868546,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000,\n                                           false, codec, null, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000,\n                                           null, false, codec, null, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000,\n                                           false, codec, null, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos fieldInfos = new FieldInfos(new FieldInfos.FieldNumberBiMap());\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], fieldInfos, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    FieldInfos clonedFieldInfos = fieldInfos.clone();\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(SEGMENT, 10000, dir, false, codec, clonedFieldInfos);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57ae3024996ccdb3c36c42cb890e1efb37df4ce8","date":1338343651,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000,\n                                           false, codec, null, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields, false);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000,\n                                           false, codec, null, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a45bec74b98f6fc05f52770cfb425739e6563960","date":1375119292,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000,\n                                           false, codec, null, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000,\n                                           false, codec, null, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000,\n                                           false, codec, null, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000,\n                                           false, codec, null, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random()), DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77f264c55cbf75404f8601ae7290d69157273a56","date":1380484282,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000,\n                                           false, codec, null, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"057a1793765d068ea9302f1a29e21734ee58d41e","date":1408130117,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Constants.LUCENE_MAIN_VERSION, SEGMENT, 10000, false, codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["5f6bd27530a2846413fe2d00030493c0e2d3a072"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c65d2864d936ccf22dc7ec14dd48b4dff7bacceb","date":1411653326,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["8521d944f9dfb45692ec28235dbf116d47ef69ba"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5f6bd27530a2846413fe2d00030493c0e2d3a072","date":1411811855,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":["057a1793765d068ea9302f1a29e21734ee58d41e"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f382b2e9f4ca7dbe98e2f15da70983ecfc02b171","date":1412231650,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId());\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId());\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    this.write(fieldInfos, dir, fields);\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8521d944f9dfb45692ec28235dbf116d47ef69ba","date":1417535150,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId(), new HashMap<>());\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId());\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":["c65d2864d936ccf22dc7ec14dd48b4dff7bacceb"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79700663e164dece87bed4adfd3e28bab6cb1385","date":1425241849,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId(), new HashMap<>());\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"299a2348fa24151d150182211b6208a38e5e3450","date":1425304608,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId(), new HashMap<>());\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, null, StringHelper.randomId(), new HashMap<>());\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ceaef6cfc68c8ab22a684192e469a8280f9e6e70","date":1462354657,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3d33e731a93d4b57e662ff094f64f94a745422d4","date":1463128289,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0ad30c6a479e764150a3316e57263319775f1df2","date":1463395403,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>());\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"31741cf1390044e38a2ec3127cf302ba841bfd75","date":1491292636,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92212fd254551a0b1156aafc3a1a6ed1a43932ad","date":1491296431,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7e4ca6dc9612ff741d8713743e2bccfae5eadac","date":1528093718,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder();\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790693f23f4e88a59fbb25e47cc25f6d493b03cb","date":1553077690,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, false, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"763da4a9605e47013078edc323b9d4b608f0f9e0","date":1555353576,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, false, newIOContext(random()), Collections.emptyMap()));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, false, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a4e83191a3e02851a0b67e5335e6922f3e9ea86d","date":1583489709,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, false, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, false, newIOContext(random()), Collections.emptyMap()));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bec68e7c41fed133827595747d853cad504e481e","date":1583501052,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCodecs#testRandomPostings().mjava","sourceNew":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testRandomPostings() throws Throwable {\n    final FieldInfos.Builder builder = new FieldInfos.Builder(new FieldInfos.FieldNumbers(null));\n\n    final FieldData[] fields = new FieldData[NUM_FIELDS];\n    for(int i=0;i<NUM_FIELDS;i++) {\n      final boolean omitTF = 0==(i%3);\n      final boolean storePayloads = 1==(i%3);\n      fields[i] = new FieldData(fieldNames[i], builder, this.makeRandomTerms(omitTF, storePayloads), omitTF, storePayloads);\n    }\n\n    final Directory dir = newDirectory();\n    final FieldInfos fieldInfos = builder.finish();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now write postings\");\n    }\n\n    Codec codec = Codec.getDefault();\n    final SegmentInfo si = new SegmentInfo(dir, Version.LATEST, Version.LATEST, SEGMENT, 10000, false, codec, Collections.emptyMap(), StringHelper.randomId(), new HashMap<>(), null);\n    this.write(si, fieldInfos, dir, fields);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now read postings\");\n    }\n    final FieldsProducer terms = codec.postingsFormat().fieldsProducer(new SegmentReadState(dir, si, fieldInfos, false, newIOContext(random())));\n\n    final Verify[] threads = new Verify[NUM_TEST_THREADS-1];\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i] = new Verify(si, fields, terms);\n      threads[i].setDaemon(true);\n      threads[i].start();\n    }\n\n    new Verify(si, fields, terms).run();\n\n    for(int i=0;i<NUM_TEST_THREADS-1;i++) {\n      threads[i].join();\n      assert !threads[i].failed;\n    }\n\n    terms.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4a8b14bc4241c302311422d5c6f7627f8febb86e":["fc834f3412d287003cc04691da380b69ab983239"],"6a917aca07a305ab70118a83e84d931503441271":["63caed6eb28209e181e97822c4c8fdf808884c3b"],"763da4a9605e47013078edc323b9d4b608f0f9e0":["790693f23f4e88a59fbb25e47cc25f6d493b03cb"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"764b942fd30efcae6e532c19771f32eeeb0037b2":["6a917aca07a305ab70118a83e84d931503441271"],"63caed6eb28209e181e97822c4c8fdf808884c3b":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"5f6bd27530a2846413fe2d00030493c0e2d3a072":["057a1793765d068ea9302f1a29e21734ee58d41e","c65d2864d936ccf22dc7ec14dd48b4dff7bacceb"],"a851824c09818632c94eba41e60ef5e72e323c8e":["57d2758489b06da76bc6a037793d9ba347ce01fd"],"0ad30c6a479e764150a3316e57263319775f1df2":["79700663e164dece87bed4adfd3e28bab6cb1385","3d33e731a93d4b57e662ff094f64f94a745422d4"],"057a1793765d068ea9302f1a29e21734ee58d41e":["77f264c55cbf75404f8601ae7290d69157273a56"],"f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["763da4a9605e47013078edc323b9d4b608f0f9e0"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["79700663e164dece87bed4adfd3e28bab6cb1385","0ad30c6a479e764150a3316e57263319775f1df2"],"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["8521d944f9dfb45692ec28235dbf116d47ef69ba","79700663e164dece87bed4adfd3e28bab6cb1385"],"4356000e349e38c9fb48034695b7c309abd54557":["a851824c09818632c94eba41e60ef5e72e323c8e"],"9bb9a29a5e71a90295f175df8919802993142c9a":["5f6bd27530a2846413fe2d00030493c0e2d3a072","f382b2e9f4ca7dbe98e2f15da70983ecfc02b171"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["31741cf1390044e38a2ec3127cf302ba841bfd75","b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"b7e4ca6dc9612ff741d8713743e2bccfae5eadac":["31741cf1390044e38a2ec3127cf302ba841bfd75"],"79700663e164dece87bed4adfd3e28bab6cb1385":["8521d944f9dfb45692ec28235dbf116d47ef69ba"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"],"77f264c55cbf75404f8601ae7290d69157273a56":["a45bec74b98f6fc05f52770cfb425739e6563960"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"299a2348fa24151d150182211b6208a38e5e3450":["8521d944f9dfb45692ec28235dbf116d47ef69ba","79700663e164dece87bed4adfd3e28bab6cb1385"],"790693f23f4e88a59fbb25e47cc25f6d493b03cb":["b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"f382b2e9f4ca7dbe98e2f15da70983ecfc02b171":["c65d2864d936ccf22dc7ec14dd48b4dff7bacceb"],"a45bec74b98f6fc05f52770cfb425739e6563960":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["4356000e349e38c9fb48034695b7c309abd54557"],"bec68e7c41fed133827595747d853cad504e481e":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"399d5903979ca52514d2bc7e3a362e1c45885c94":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"57d2758489b06da76bc6a037793d9ba347ce01fd":["dc97c61094c5498702b29cc2e8309beac50c23dc"],"dc97c61094c5498702b29cc2e8309beac50c23dc":["4a8b14bc4241c302311422d5c6f7627f8febb86e"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["399d5903979ca52514d2bc7e3a362e1c45885c94"],"fc834f3412d287003cc04691da380b69ab983239":["d2dee33619431ada2a7a07f5fe2dbd94bac6a460"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["79700663e164dece87bed4adfd3e28bab6cb1385","d470c8182e92b264680e34081b75e70a9f2b3c89"],"8521d944f9dfb45692ec28235dbf116d47ef69ba":["9bb9a29a5e71a90295f175df8919802993142c9a"],"d2dee33619431ada2a7a07f5fe2dbd94bac6a460":["f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","764b942fd30efcae6e532c19771f32eeeb0037b2"],"ceaef6cfc68c8ab22a684192e469a8280f9e6e70":["79700663e164dece87bed4adfd3e28bab6cb1385"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["79700663e164dece87bed4adfd3e28bab6cb1385","ceaef6cfc68c8ab22a684192e469a8280f9e6e70"],"f592209545c71895260367152601e9200399776d":["31741cf1390044e38a2ec3127cf302ba841bfd75","b7e4ca6dc9612ff741d8713743e2bccfae5eadac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bec68e7c41fed133827595747d853cad504e481e"],"c65d2864d936ccf22dc7ec14dd48b4dff7bacceb":["057a1793765d068ea9302f1a29e21734ee58d41e"]},"commit2Childs":{"4a8b14bc4241c302311422d5c6f7627f8febb86e":["dc97c61094c5498702b29cc2e8309beac50c23dc"],"6a917aca07a305ab70118a83e84d931503441271":["764b942fd30efcae6e532c19771f32eeeb0037b2"],"63caed6eb28209e181e97822c4c8fdf808884c3b":["6a917aca07a305ab70118a83e84d931503441271"],"763da4a9605e47013078edc323b9d4b608f0f9e0":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["399d5903979ca52514d2bc7e3a362e1c45885c94"],"764b942fd30efcae6e532c19771f32eeeb0037b2":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"5f6bd27530a2846413fe2d00030493c0e2d3a072":["9bb9a29a5e71a90295f175df8919802993142c9a"],"a851824c09818632c94eba41e60ef5e72e323c8e":["4356000e349e38c9fb48034695b7c309abd54557"],"0ad30c6a479e764150a3316e57263319775f1df2":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"057a1793765d068ea9302f1a29e21734ee58d41e":["5f6bd27530a2846413fe2d00030493c0e2d3a072","c65d2864d936ccf22dc7ec14dd48b4dff7bacceb"],"f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b":["d2dee33619431ada2a7a07f5fe2dbd94bac6a460"],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["bec68e7c41fed133827595747d853cad504e481e"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["b70042a8a492f7054d480ccdd2be9796510d4327","b7e4ca6dc9612ff741d8713743e2bccfae5eadac","f592209545c71895260367152601e9200399776d"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["31741cf1390044e38a2ec3127cf302ba841bfd75","92212fd254551a0b1156aafc3a1a6ed1a43932ad","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","a45bec74b98f6fc05f52770cfb425739e6563960"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"4356000e349e38c9fb48034695b7c309abd54557":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"9bb9a29a5e71a90295f175df8919802993142c9a":["8521d944f9dfb45692ec28235dbf116d47ef69ba"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"79700663e164dece87bed4adfd3e28bab6cb1385":["0ad30c6a479e764150a3316e57263319775f1df2","d470c8182e92b264680e34081b75e70a9f2b3c89","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","299a2348fa24151d150182211b6208a38e5e3450","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","ceaef6cfc68c8ab22a684192e469a8280f9e6e70","3d33e731a93d4b57e662ff094f64f94a745422d4"],"b7e4ca6dc9612ff741d8713743e2bccfae5eadac":["b70042a8a492f7054d480ccdd2be9796510d4327","790693f23f4e88a59fbb25e47cc25f6d493b03cb","f592209545c71895260367152601e9200399776d"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"77f264c55cbf75404f8601ae7290d69157273a56":["057a1793765d068ea9302f1a29e21734ee58d41e"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":[],"299a2348fa24151d150182211b6208a38e5e3450":[],"790693f23f4e88a59fbb25e47cc25f6d493b03cb":["763da4a9605e47013078edc323b9d4b608f0f9e0"],"f382b2e9f4ca7dbe98e2f15da70983ecfc02b171":["9bb9a29a5e71a90295f175df8919802993142c9a"],"a45bec74b98f6fc05f52770cfb425739e6563960":["77f264c55cbf75404f8601ae7290d69157273a56"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["63caed6eb28209e181e97822c4c8fdf808884c3b"],"57d2758489b06da76bc6a037793d9ba347ce01fd":["a851824c09818632c94eba41e60ef5e72e323c8e"],"bec68e7c41fed133827595747d853cad504e481e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"399d5903979ca52514d2bc7e3a362e1c45885c94":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"dc97c61094c5498702b29cc2e8309beac50c23dc":["57d2758489b06da76bc6a037793d9ba347ce01fd"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"fc834f3412d287003cc04691da380b69ab983239":["4a8b14bc4241c302311422d5c6f7627f8febb86e"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"8521d944f9dfb45692ec28235dbf116d47ef69ba":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","79700663e164dece87bed4adfd3e28bab6cb1385","299a2348fa24151d150182211b6208a38e5e3450"],"d2dee33619431ada2a7a07f5fe2dbd94bac6a460":["fc834f3412d287003cc04691da380b69ab983239"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"],"ceaef6cfc68c8ab22a684192e469a8280f9e6e70":["3d33e731a93d4b57e662ff094f64f94a745422d4"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["f6eee1e5a8555d83dd8f2f2e3c0a4ccec8e7cf9b","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["0ad30c6a479e764150a3316e57263319775f1df2"],"f592209545c71895260367152601e9200399776d":[],"c65d2864d936ccf22dc7ec14dd48b4dff7bacceb":["5f6bd27530a2846413fe2d00030493c0e2d3a072","f382b2e9f4ca7dbe98e2f15da70983ecfc02b171"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b70042a8a492f7054d480ccdd2be9796510d4327","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","92212fd254551a0b1156aafc3a1a6ed1a43932ad","299a2348fa24151d150182211b6208a38e5e3450","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}