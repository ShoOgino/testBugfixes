{"path":"src/test/org/apache/lucene/search/TestStressSort#testSort().mjava","commits":[{"id":"63bc3238545c6012bd44f5d294077997f236bc4e","date":1233087321,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestStressSort#testSort().mjava","pathOld":"/dev/null","sourceNew":"  public void testSort() throws Throwable {\n\n    // reverse & not\n    // all types\n    // restrictive & non restrictive searches (on contents)\n\n    create();\n\n    Sort[] sorts = new Sort[50];\n    int sortCount = 0;\n\n    for(int r=0;r<2;r++) {\n      Sort sort;\n      boolean reverse = 1 == r;\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"byte\", SortField.BYTE, reverse)});\n      \n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"short\", SortField.SHORT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"int\", SortField.INT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"long\", SortField.LONG, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"float\", SortField.FLOAT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"double\", SortField.DOUBLE, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_VAL, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL_DEM, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL_DEM2, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(null, SortField.SCORE, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(null, SortField.DOC, reverse)});\n    }\n\n    Query[] queries = new Query[4];\n    queries[0] = new MatchAllDocsQuery();\n    queries[1] = new TermQuery(new Term(\"contents\", \"x\"));  // matches every 10th doc\n    queries[2] = new TermQuery(new Term(\"contents\", \"y\"));  // matches every 100th doc\n    queries[3] = new TermQuery(new Term(\"contents\", \"z\"));  // matches every 1000th doc\n\n    for(int sx=0;sx<3;sx++) {\n      final IndexSearcher searcher;\n      if (sx == 0) {\n        searcher = searcherSingleSegment;\n      } else if (sx == 1) {\n        searcher = searcherFewSegment;\n      } else {\n        searcher = searcherMultiSegment;\n      }\n\n      for(int qx=0;qx<queries.length;qx++) {\n        final Query query = queries[qx];\n\n        for(int q=0;q<3;q++) {\n\n          final int queueSize;\n          if (q == 0) {\n            queueSize = 10;\n          } else if (q == 1) {\n            queueSize = 100;\n          } else {\n            queueSize = 1000;\n          }\n        \n          for(int s=0;s<sortCount;s++) {\n            Sort sort1 = sorts[s];\n\n            for(int s2=-1;s2<sortCount;s2++) {\n              Sort sort;\n              if (s2 == -1) {\n                // Single field sort\n                sort = sort1;\n              } else {\n                sort = new Sort(new SortField[] {sort1.getSort()[0], sorts[s2].getSort()[0]});\n              }\n\n              // Old\n              Sort oldSort = getOldSort(sort);\n\n              if (VERBOSE) {\n                System.out.println(\"query=\" + query);\n                if (sx == 0) {\n                  System.out.println(\"  single-segment index\");\n                } else if (sx == 1) {\n                  System.out.println(\"  few-segment index\");\n                } else {\n                  System.out.println(\"  many-segment index\");\n                }\n                System.out.println(\"  numHit=\" + queueSize);\n                System.out.println(\"  old=\" + oldSort);\n                System.out.println(\"  new=\" + sort);\n              }\n\n              TopDocs newHits = searcher.search(query, null, queueSize, sort);\n              TopDocs oldHits = searcher.search(query, null, queueSize, oldSort);\n\n              compare(oldHits, newHits);\n            }\n          }\n        }\n      }\n    }\n\n    close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cb1066f2afe9450585d0d10063ea4450085236f1","date":1233870820,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestStressSort#testSort().mjava","pathOld":"src/test/org/apache/lucene/search/TestStressSort#testSort().mjava","sourceNew":"  public void testSort() throws Throwable {\n    r = newRandom();\n\n    // reverse & not\n    // all types\n    // restrictive & non restrictive searches (on contents)\n\n    create();\n\n    Sort[] sorts = new Sort[50];\n    int sortCount = 0;\n\n    for(int r=0;r<2;r++) {\n      Sort sort;\n      boolean reverse = 1 == r;\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"byte\", SortField.BYTE, reverse)});\n      \n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"short\", SortField.SHORT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"int\", SortField.INT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"long\", SortField.LONG, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"float\", SortField.FLOAT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"double\", SortField.DOUBLE, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_VAL, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL_DEM, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL_DEM2, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(null, SortField.SCORE, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(null, SortField.DOC, reverse)});\n    }\n\n    Query[] queries = new Query[4];\n    queries[0] = new MatchAllDocsQuery();\n    queries[1] = new TermQuery(new Term(\"contents\", \"x\"));  // matches every 10th doc\n    queries[2] = new TermQuery(new Term(\"contents\", \"y\"));  // matches every 100th doc\n    queries[3] = new TermQuery(new Term(\"contents\", \"z\"));  // matches every 1000th doc\n\n    for(int sx=0;sx<3;sx++) {\n      final IndexSearcher searcher;\n      if (sx == 0) {\n        searcher = searcherSingleSegment;\n      } else if (sx == 1) {\n        searcher = searcherFewSegment;\n      } else {\n        searcher = searcherMultiSegment;\n      }\n\n      for(int qx=0;qx<queries.length;qx++) {\n        final Query query = queries[qx];\n\n        for(int q=0;q<3;q++) {\n\n          final int queueSize;\n          if (q == 0) {\n            queueSize = 10;\n          } else if (q == 1) {\n            queueSize = 100;\n          } else {\n            queueSize = 1000;\n          }\n        \n          for(int s=0;s<sortCount;s++) {\n            Sort sort1 = sorts[s];\n\n            for(int s2=-1;s2<sortCount;s2++) {\n              Sort sort;\n              if (s2 == -1) {\n                // Single field sort\n                sort = sort1;\n              } else {\n                sort = new Sort(new SortField[] {sort1.getSort()[0], sorts[s2].getSort()[0]});\n              }\n\n              // Old\n              Sort oldSort = getOldSort(sort);\n\n              if (VERBOSE) {\n                System.out.println(\"query=\" + query);\n                if (sx == 0) {\n                  System.out.println(\"  single-segment index\");\n                } else if (sx == 1) {\n                  System.out.println(\"  few-segment index\");\n                } else {\n                  System.out.println(\"  many-segment index\");\n                }\n                System.out.println(\"  numHit=\" + queueSize);\n                System.out.println(\"  old=\" + oldSort);\n                System.out.println(\"  new=\" + sort);\n              }\n\n              TopDocs newHits = searcher.search(query, null, queueSize, sort);\n              TopDocs oldHits = searcher.search(query, null, queueSize, oldSort);\n\n              compare(oldHits, newHits);\n            }\n          }\n        }\n      }\n    }\n\n    close();\n  }\n\n","sourceOld":"  public void testSort() throws Throwable {\n\n    // reverse & not\n    // all types\n    // restrictive & non restrictive searches (on contents)\n\n    create();\n\n    Sort[] sorts = new Sort[50];\n    int sortCount = 0;\n\n    for(int r=0;r<2;r++) {\n      Sort sort;\n      boolean reverse = 1 == r;\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"byte\", SortField.BYTE, reverse)});\n      \n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"short\", SortField.SHORT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"int\", SortField.INT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"long\", SortField.LONG, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"float\", SortField.FLOAT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"double\", SortField.DOUBLE, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_VAL, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL_DEM, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL_DEM2, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(null, SortField.SCORE, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(null, SortField.DOC, reverse)});\n    }\n\n    Query[] queries = new Query[4];\n    queries[0] = new MatchAllDocsQuery();\n    queries[1] = new TermQuery(new Term(\"contents\", \"x\"));  // matches every 10th doc\n    queries[2] = new TermQuery(new Term(\"contents\", \"y\"));  // matches every 100th doc\n    queries[3] = new TermQuery(new Term(\"contents\", \"z\"));  // matches every 1000th doc\n\n    for(int sx=0;sx<3;sx++) {\n      final IndexSearcher searcher;\n      if (sx == 0) {\n        searcher = searcherSingleSegment;\n      } else if (sx == 1) {\n        searcher = searcherFewSegment;\n      } else {\n        searcher = searcherMultiSegment;\n      }\n\n      for(int qx=0;qx<queries.length;qx++) {\n        final Query query = queries[qx];\n\n        for(int q=0;q<3;q++) {\n\n          final int queueSize;\n          if (q == 0) {\n            queueSize = 10;\n          } else if (q == 1) {\n            queueSize = 100;\n          } else {\n            queueSize = 1000;\n          }\n        \n          for(int s=0;s<sortCount;s++) {\n            Sort sort1 = sorts[s];\n\n            for(int s2=-1;s2<sortCount;s2++) {\n              Sort sort;\n              if (s2 == -1) {\n                // Single field sort\n                sort = sort1;\n              } else {\n                sort = new Sort(new SortField[] {sort1.getSort()[0], sorts[s2].getSort()[0]});\n              }\n\n              // Old\n              Sort oldSort = getOldSort(sort);\n\n              if (VERBOSE) {\n                System.out.println(\"query=\" + query);\n                if (sx == 0) {\n                  System.out.println(\"  single-segment index\");\n                } else if (sx == 1) {\n                  System.out.println(\"  few-segment index\");\n                } else {\n                  System.out.println(\"  many-segment index\");\n                }\n                System.out.println(\"  numHit=\" + queueSize);\n                System.out.println(\"  old=\" + oldSort);\n                System.out.println(\"  new=\" + sort);\n              }\n\n              TopDocs newHits = searcher.search(query, null, queueSize, sort);\n              TopDocs oldHits = searcher.search(query, null, queueSize, oldSort);\n\n              compare(oldHits, newHits);\n            }\n          }\n        }\n      }\n    }\n\n    close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e69f59b863731d864bf3047235e718f0f88f8841","date":1250105498,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestStressSort#testSort().mjava","pathOld":"src/test/org/apache/lucene/search/TestStressSort#testSort().mjava","sourceNew":"  public void testSort() throws Throwable {\n    r = newRandom();\n\n    // reverse & not\n    // all types\n    // restrictive & non restrictive searches (on contents)\n\n    create();\n\n    Sort[] sorts = new Sort[50];\n    int sortCount = 0;\n\n    for(int r=0;r<2;r++) {\n      Sort sort;\n      boolean reverse = 1 == r;\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"byte\", SortField.BYTE, reverse)});\n      \n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"short\", SortField.SHORT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"int\", SortField.INT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"long\", SortField.LONG, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"float\", SortField.FLOAT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"double\", SortField.DOUBLE, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_VAL, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"stringIdx\", SortField.STRING, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL_DEM, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL_DEM2, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(null, SortField.SCORE, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(null, SortField.DOC, reverse)});\n    }\n\n    Query[] queries = new Query[4];\n    queries[0] = new MatchAllDocsQuery();\n    queries[1] = new TermQuery(new Term(\"contents\", \"x\"));  // matches every 10th doc\n    queries[2] = new TermQuery(new Term(\"contents\", \"y\"));  // matches every 100th doc\n    queries[3] = new TermQuery(new Term(\"contents\", \"z\"));  // matches every 1000th doc\n\n    for(int sx=0;sx<3;sx++) {\n      final IndexSearcher searcher;\n      if (sx == 0) {\n        searcher = searcherSingleSegment;\n      } else if (sx == 1) {\n        searcher = searcherFewSegment;\n      } else {\n        searcher = searcherMultiSegment;\n      }\n\n      for(int qx=0;qx<queries.length;qx++) {\n        final Query query = queries[qx];\n\n        for(int q=0;q<3;q++) {\n\n          final int queueSize;\n          if (q == 0) {\n            queueSize = 10;\n          } else if (q == 1) {\n            queueSize = 100;\n          } else {\n            queueSize = 1000;\n          }\n        \n          for(int s=0;s<sortCount;s++) {\n            Sort sort1 = sorts[s];\n\n            for(int s2=-1;s2<sortCount;s2++) {\n              Sort sort;\n              if (s2 == -1) {\n                // Single field sort\n                sort = sort1;\n              } else {\n                sort = new Sort(new SortField[] {sort1.getSort()[0], sorts[s2].getSort()[0]});\n              }\n\n              // Old\n              Sort oldSort = getOldSort(sort);\n\n              if (VERBOSE) {\n                System.out.println(\"query=\" + query);\n                if (sx == 0) {\n                  System.out.println(\"  single-segment index\");\n                } else if (sx == 1) {\n                  System.out.println(\"  few-segment index\");\n                } else {\n                  System.out.println(\"  many-segment index\");\n                }\n                System.out.println(\"  numHit=\" + queueSize);\n                System.out.println(\"  old=\" + oldSort);\n                System.out.println(\"  new=\" + sort);\n              }\n\n              TopDocs newHits = searcher.search(query, null, queueSize, sort);\n              TopDocs oldHits = searcher.search(query, null, queueSize, oldSort);\n\n              compare(oldHits, newHits);\n            }\n          }\n        }\n      }\n    }\n\n    // we explicitly test the old sort method and\n    // compare with the new, so we expect to see SUBREADER\n    // sanity checks fail.\n    Insanity[] insanity = FieldCacheSanityChecker.checkSanity\n      (FieldCache.DEFAULT);\n    try {\n      int ignored = 0;\n      for (int i = 0; i < insanity.length; i++) {\n        if (insanity[i].getType() == InsanityType.SUBREADER) {\n          insanity[i] = new Insanity(InsanityType.EXPECTED,\n                                     insanity[i].getMsg(), \n                                     insanity[i].getCacheEntries());\n          ignored++;\n        }\n      }\n      assertEquals(\"Not all insane field cache usage was expected\",\n                   ignored, insanity.length);\n\n      insanity = null;\n    } finally {\n      // report this in the event of any exception/failure\n      // if no failure, then insanity will be null\n      if (null != insanity) {\n        dumpArray(getTestLabel() + \": Insane FieldCache usage(s)\", insanity, System.err);\n      }\n    }\n    // we've already checked FieldCache, purge so tearDown doesn't complain\n    purgeFieldCache(FieldCache.DEFAULT); // so\n\n    close();\n  }\n\n","sourceOld":"  public void testSort() throws Throwable {\n    r = newRandom();\n\n    // reverse & not\n    // all types\n    // restrictive & non restrictive searches (on contents)\n\n    create();\n\n    Sort[] sorts = new Sort[50];\n    int sortCount = 0;\n\n    for(int r=0;r<2;r++) {\n      Sort sort;\n      boolean reverse = 1 == r;\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"byte\", SortField.BYTE, reverse)});\n      \n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"short\", SortField.SHORT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"int\", SortField.INT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"long\", SortField.LONG, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"float\", SortField.FLOAT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"double\", SortField.DOUBLE, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_VAL, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL_DEM, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL_DEM2, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(null, SortField.SCORE, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(null, SortField.DOC, reverse)});\n    }\n\n    Query[] queries = new Query[4];\n    queries[0] = new MatchAllDocsQuery();\n    queries[1] = new TermQuery(new Term(\"contents\", \"x\"));  // matches every 10th doc\n    queries[2] = new TermQuery(new Term(\"contents\", \"y\"));  // matches every 100th doc\n    queries[3] = new TermQuery(new Term(\"contents\", \"z\"));  // matches every 1000th doc\n\n    for(int sx=0;sx<3;sx++) {\n      final IndexSearcher searcher;\n      if (sx == 0) {\n        searcher = searcherSingleSegment;\n      } else if (sx == 1) {\n        searcher = searcherFewSegment;\n      } else {\n        searcher = searcherMultiSegment;\n      }\n\n      for(int qx=0;qx<queries.length;qx++) {\n        final Query query = queries[qx];\n\n        for(int q=0;q<3;q++) {\n\n          final int queueSize;\n          if (q == 0) {\n            queueSize = 10;\n          } else if (q == 1) {\n            queueSize = 100;\n          } else {\n            queueSize = 1000;\n          }\n        \n          for(int s=0;s<sortCount;s++) {\n            Sort sort1 = sorts[s];\n\n            for(int s2=-1;s2<sortCount;s2++) {\n              Sort sort;\n              if (s2 == -1) {\n                // Single field sort\n                sort = sort1;\n              } else {\n                sort = new Sort(new SortField[] {sort1.getSort()[0], sorts[s2].getSort()[0]});\n              }\n\n              // Old\n              Sort oldSort = getOldSort(sort);\n\n              if (VERBOSE) {\n                System.out.println(\"query=\" + query);\n                if (sx == 0) {\n                  System.out.println(\"  single-segment index\");\n                } else if (sx == 1) {\n                  System.out.println(\"  few-segment index\");\n                } else {\n                  System.out.println(\"  many-segment index\");\n                }\n                System.out.println(\"  numHit=\" + queueSize);\n                System.out.println(\"  old=\" + oldSort);\n                System.out.println(\"  new=\" + sort);\n              }\n\n              TopDocs newHits = searcher.search(query, null, queueSize, sort);\n              TopDocs oldHits = searcher.search(query, null, queueSize, oldSort);\n\n              compare(oldHits, newHits);\n            }\n          }\n        }\n      }\n    }\n\n    close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ded38b25fe842ef1efc6715745bb8d8ed8e2fc99","date":1255432705,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestStressSort#testSort().mjava","pathOld":"src/test/org/apache/lucene/search/TestStressSort#testSort().mjava","sourceNew":"  public void testSort() throws Throwable {\n    r = newRandom();\n\n    // reverse & not\n    // all types\n    // restrictive & non restrictive searches (on contents)\n\n    create();\n\n    Sort[] sorts = new Sort[50];\n    int sortCount = 0;\n\n    for(int r=0;r<2;r++) {\n      Sort sort;\n      boolean reverse = 1 == r;\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"byte\", SortField.BYTE, reverse));\n      \n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"short\", SortField.SHORT, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"int\", SortField.INT, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"long\", SortField.LONG, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"float\", SortField.FLOAT, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"double\", SortField.DOUBLE, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"string\", SortField.STRING_VAL, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"stringIdx\", SortField.STRING, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(null, SortField.SCORE, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(null, SortField.DOC, reverse));\n    }\n\n    Query[] queries = new Query[4];\n    queries[0] = new MatchAllDocsQuery();\n    queries[1] = new TermQuery(new Term(\"contents\", \"x\"));  // matches every 10th doc\n    queries[2] = new TermQuery(new Term(\"contents\", \"y\"));  // matches every 100th doc\n    queries[3] = new TermQuery(new Term(\"contents\", \"z\"));  // matches every 1000th doc\n\n    for(int sx=0;sx<3;sx++) {\n      final IndexSearcher searcher;\n      if (sx == 0) {\n        searcher = searcherSingleSegment;\n      } else if (sx == 1) {\n        searcher = searcherFewSegment;\n      } else {\n        searcher = searcherMultiSegment;\n      }\n\n      for(int qx=0;qx<queries.length;qx++) {\n        final Query query = queries[qx];\n\n        for(int q=0;q<3;q++) {\n\n          final int queueSize;\n          if (q == 0) {\n            queueSize = 10;\n          } else if (q == 1) {\n            queueSize = 100;\n          } else {\n            queueSize = 1000;\n          }\n        \n          for(int s=0;s<sortCount;s++) {\n            Sort sort1 = sorts[s];\n\n            for(int s2=-1;s2<sortCount;s2++) {\n              Sort sort;\n              if (s2 == -1) {\n                // Single field sort\n                sort = sort1;\n              } else {\n                sort = new Sort(sort1.getSort()[0], sorts[s2].getSort()[0]);\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // we explicitly test the old sort method and\n    // compare with the new, so we expect to see SUBREADER\n    // sanity checks fail.\n    Insanity[] insanity = FieldCacheSanityChecker.checkSanity\n      (FieldCache.DEFAULT);\n    try {\n      int ignored = 0;\n      for (int i = 0; i < insanity.length; i++) {\n        if (insanity[i].getType() == InsanityType.SUBREADER) {\n          insanity[i] = new Insanity(InsanityType.EXPECTED,\n                                     insanity[i].getMsg(), \n                                     insanity[i].getCacheEntries());\n          ignored++;\n        }\n      }\n      assertEquals(\"Not all insane field cache usage was expected\",\n                   ignored, insanity.length);\n\n      insanity = null;\n    } finally {\n      // report this in the event of any exception/failure\n      // if no failure, then insanity will be null\n      if (null != insanity) {\n        dumpArray(getTestLabel() + \": Insane FieldCache usage(s)\", insanity, System.err);\n      }\n    }\n    // we've already checked FieldCache, purge so tearDown doesn't complain\n    purgeFieldCache(FieldCache.DEFAULT); // so\n\n    close();\n  }\n\n","sourceOld":"  public void testSort() throws Throwable {\n    r = newRandom();\n\n    // reverse & not\n    // all types\n    // restrictive & non restrictive searches (on contents)\n\n    create();\n\n    Sort[] sorts = new Sort[50];\n    int sortCount = 0;\n\n    for(int r=0;r<2;r++) {\n      Sort sort;\n      boolean reverse = 1 == r;\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"byte\", SortField.BYTE, reverse)});\n      \n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"short\", SortField.SHORT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"int\", SortField.INT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"long\", SortField.LONG, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"float\", SortField.FLOAT, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"double\", SortField.DOUBLE, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_VAL, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(\"stringIdx\", SortField.STRING, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL_DEM, reverse)});\n\n      //sorts[sortCount++] = sort = new Sort();\n      //sort.setSort(new SortField[] {new SortField(\"string\", SortField.STRING_ORD_VAL_DEM2, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(null, SortField.SCORE, reverse)});\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField[] {new SortField(null, SortField.DOC, reverse)});\n    }\n\n    Query[] queries = new Query[4];\n    queries[0] = new MatchAllDocsQuery();\n    queries[1] = new TermQuery(new Term(\"contents\", \"x\"));  // matches every 10th doc\n    queries[2] = new TermQuery(new Term(\"contents\", \"y\"));  // matches every 100th doc\n    queries[3] = new TermQuery(new Term(\"contents\", \"z\"));  // matches every 1000th doc\n\n    for(int sx=0;sx<3;sx++) {\n      final IndexSearcher searcher;\n      if (sx == 0) {\n        searcher = searcherSingleSegment;\n      } else if (sx == 1) {\n        searcher = searcherFewSegment;\n      } else {\n        searcher = searcherMultiSegment;\n      }\n\n      for(int qx=0;qx<queries.length;qx++) {\n        final Query query = queries[qx];\n\n        for(int q=0;q<3;q++) {\n\n          final int queueSize;\n          if (q == 0) {\n            queueSize = 10;\n          } else if (q == 1) {\n            queueSize = 100;\n          } else {\n            queueSize = 1000;\n          }\n        \n          for(int s=0;s<sortCount;s++) {\n            Sort sort1 = sorts[s];\n\n            for(int s2=-1;s2<sortCount;s2++) {\n              Sort sort;\n              if (s2 == -1) {\n                // Single field sort\n                sort = sort1;\n              } else {\n                sort = new Sort(new SortField[] {sort1.getSort()[0], sorts[s2].getSort()[0]});\n              }\n\n              // Old\n              Sort oldSort = getOldSort(sort);\n\n              if (VERBOSE) {\n                System.out.println(\"query=\" + query);\n                if (sx == 0) {\n                  System.out.println(\"  single-segment index\");\n                } else if (sx == 1) {\n                  System.out.println(\"  few-segment index\");\n                } else {\n                  System.out.println(\"  many-segment index\");\n                }\n                System.out.println(\"  numHit=\" + queueSize);\n                System.out.println(\"  old=\" + oldSort);\n                System.out.println(\"  new=\" + sort);\n              }\n\n              TopDocs newHits = searcher.search(query, null, queueSize, sort);\n              TopDocs oldHits = searcher.search(query, null, queueSize, oldSort);\n\n              compare(oldHits, newHits);\n            }\n          }\n        }\n      }\n    }\n\n    // we explicitly test the old sort method and\n    // compare with the new, so we expect to see SUBREADER\n    // sanity checks fail.\n    Insanity[] insanity = FieldCacheSanityChecker.checkSanity\n      (FieldCache.DEFAULT);\n    try {\n      int ignored = 0;\n      for (int i = 0; i < insanity.length; i++) {\n        if (insanity[i].getType() == InsanityType.SUBREADER) {\n          insanity[i] = new Insanity(InsanityType.EXPECTED,\n                                     insanity[i].getMsg(), \n                                     insanity[i].getCacheEntries());\n          ignored++;\n        }\n      }\n      assertEquals(\"Not all insane field cache usage was expected\",\n                   ignored, insanity.length);\n\n      insanity = null;\n    } finally {\n      // report this in the event of any exception/failure\n      // if no failure, then insanity will be null\n      if (null != insanity) {\n        dumpArray(getTestLabel() + \": Insane FieldCache usage(s)\", insanity, System.err);\n      }\n    }\n    // we've already checked FieldCache, purge so tearDown doesn't complain\n    purgeFieldCache(FieldCache.DEFAULT); // so\n\n    close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"90576423481ca5b715ad8c2ebce681817cabb3b1","date":1256332541,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"src/test/org/apache/lucene/search/TestStressSort#testSort().mjava","sourceNew":null,"sourceOld":"  public void testSort() throws Throwable {\n    r = newRandom();\n\n    // reverse & not\n    // all types\n    // restrictive & non restrictive searches (on contents)\n\n    create();\n\n    Sort[] sorts = new Sort[50];\n    int sortCount = 0;\n\n    for(int r=0;r<2;r++) {\n      Sort sort;\n      boolean reverse = 1 == r;\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"byte\", SortField.BYTE, reverse));\n      \n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"short\", SortField.SHORT, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"int\", SortField.INT, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"long\", SortField.LONG, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"float\", SortField.FLOAT, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"double\", SortField.DOUBLE, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"string\", SortField.STRING_VAL, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(\"stringIdx\", SortField.STRING, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(null, SortField.SCORE, reverse));\n\n      sorts[sortCount++] = sort = new Sort();\n      sort.setSort(new SortField(null, SortField.DOC, reverse));\n    }\n\n    Query[] queries = new Query[4];\n    queries[0] = new MatchAllDocsQuery();\n    queries[1] = new TermQuery(new Term(\"contents\", \"x\"));  // matches every 10th doc\n    queries[2] = new TermQuery(new Term(\"contents\", \"y\"));  // matches every 100th doc\n    queries[3] = new TermQuery(new Term(\"contents\", \"z\"));  // matches every 1000th doc\n\n    for(int sx=0;sx<3;sx++) {\n      final IndexSearcher searcher;\n      if (sx == 0) {\n        searcher = searcherSingleSegment;\n      } else if (sx == 1) {\n        searcher = searcherFewSegment;\n      } else {\n        searcher = searcherMultiSegment;\n      }\n\n      for(int qx=0;qx<queries.length;qx++) {\n        final Query query = queries[qx];\n\n        for(int q=0;q<3;q++) {\n\n          final int queueSize;\n          if (q == 0) {\n            queueSize = 10;\n          } else if (q == 1) {\n            queueSize = 100;\n          } else {\n            queueSize = 1000;\n          }\n        \n          for(int s=0;s<sortCount;s++) {\n            Sort sort1 = sorts[s];\n\n            for(int s2=-1;s2<sortCount;s2++) {\n              Sort sort;\n              if (s2 == -1) {\n                // Single field sort\n                sort = sort1;\n              } else {\n                sort = new Sort(sort1.getSort()[0], sorts[s2].getSort()[0]);\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // we explicitly test the old sort method and\n    // compare with the new, so we expect to see SUBREADER\n    // sanity checks fail.\n    Insanity[] insanity = FieldCacheSanityChecker.checkSanity\n      (FieldCache.DEFAULT);\n    try {\n      int ignored = 0;\n      for (int i = 0; i < insanity.length; i++) {\n        if (insanity[i].getType() == InsanityType.SUBREADER) {\n          insanity[i] = new Insanity(InsanityType.EXPECTED,\n                                     insanity[i].getMsg(), \n                                     insanity[i].getCacheEntries());\n          ignored++;\n        }\n      }\n      assertEquals(\"Not all insane field cache usage was expected\",\n                   ignored, insanity.length);\n\n      insanity = null;\n    } finally {\n      // report this in the event of any exception/failure\n      // if no failure, then insanity will be null\n      if (null != insanity) {\n        dumpArray(getTestLabel() + \": Insane FieldCache usage(s)\", insanity, System.err);\n      }\n    }\n    // we've already checked FieldCache, purge so tearDown doesn't complain\n    purgeFieldCache(FieldCache.DEFAULT); // so\n\n    close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"cb1066f2afe9450585d0d10063ea4450085236f1":["63bc3238545c6012bd44f5d294077997f236bc4e"],"e69f59b863731d864bf3047235e718f0f88f8841":["cb1066f2afe9450585d0d10063ea4450085236f1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"90576423481ca5b715ad8c2ebce681817cabb3b1":["ded38b25fe842ef1efc6715745bb8d8ed8e2fc99"],"ded38b25fe842ef1efc6715745bb8d8ed8e2fc99":["e69f59b863731d864bf3047235e718f0f88f8841"],"63bc3238545c6012bd44f5d294077997f236bc4e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["90576423481ca5b715ad8c2ebce681817cabb3b1"]},"commit2Childs":{"cb1066f2afe9450585d0d10063ea4450085236f1":["e69f59b863731d864bf3047235e718f0f88f8841"],"e69f59b863731d864bf3047235e718f0f88f8841":["ded38b25fe842ef1efc6715745bb8d8ed8e2fc99"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["63bc3238545c6012bd44f5d294077997f236bc4e"],"90576423481ca5b715ad8c2ebce681817cabb3b1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ded38b25fe842ef1efc6715745bb8d8ed8e2fc99":["90576423481ca5b715ad8c2ebce681817cabb3b1"],"63bc3238545c6012bd44f5d294077997f236bc4e":["cb1066f2afe9450585d0d10063ea4450085236f1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}