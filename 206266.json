{"path":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","sourceNew":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    boolean useCompoundDocStore = false;\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","sourceOld":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    boolean useCompoundDocStore = false;\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb10b6bcde550b87d8f10e5f010bd8f3021023b6","date":1274974592,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","sourceNew":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    boolean useCompoundDocStore = false;\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","sourceOld":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    boolean useCompoundDocStore = false;\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9b832cbed6eb3d54a8bb9339296bdda8eeb53014","date":1279708040,"type":4,"author":"Michael Busch","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","sourceNew":null,"sourceOld":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    boolean useCompoundDocStore = false;\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"334c1175813aea771a71728cd2c4ee4754fd0603","date":1279710173,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","pathOld":"/dev/null","sourceNew":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    boolean useCompoundDocStore = false;\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8fe956d65251358d755c56f14fe8380644790e47","date":1279711318,"type":4,"author":"Michael Busch","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","sourceNew":null,"sourceOld":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    boolean useCompoundDocStore = false;\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a186ae8733084223c22044e935e4ef848a143d1","date":1289694819,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","sourceNew":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    if (infoStream != null) {\n      message(\"flushDocStores segment=\" + docWriter.getDocStoreSegment());\n    }\n\n    boolean useCompoundDocStore = false;\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    if (infoStream != null) {\n      message(\"flushDocStores files=\" + docWriter.closedFiles());\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","sourceOld":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    boolean useCompoundDocStore = false;\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c498d3f8d75170b121f5eda2c6210ac5beb5d411","date":1289726298,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","sourceNew":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    if (infoStream != null) {\n      message(\"flushDocStores segment=\" + docWriter.getDocStoreSegment());\n    }\n\n    boolean useCompoundDocStore = false;\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    if (infoStream != null) {\n      message(\"flushDocStores files=\" + docWriter.closedFiles());\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","sourceOld":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    boolean useCompoundDocStore = false;\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5","date":1290247889,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","sourceNew":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    if (infoStream != null) {\n      message(\"flushDocStores segment=\" + docWriter.getDocStoreSegment());\n    }\n\n    boolean useCompoundDocStore = false;\n    if (infoStream != null) {\n      message(\"closeDocStores segment=\" + docWriter.getDocStoreSegment());\n    }\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    if (infoStream != null) {\n      message(\"flushDocStores files=\" + docWriter.closedFiles());\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","sourceOld":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    if (infoStream != null) {\n      message(\"flushDocStores segment=\" + docWriter.getDocStoreSegment());\n    }\n\n    boolean useCompoundDocStore = false;\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    if (infoStream != null) {\n      message(\"flushDocStores files=\" + docWriter.closedFiles());\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","sourceNew":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    if (infoStream != null) {\n      message(\"flushDocStores segment=\" + docWriter.getDocStoreSegment());\n    }\n\n    boolean useCompoundDocStore = false;\n    if (infoStream != null) {\n      message(\"closeDocStores segment=\" + docWriter.getDocStoreSegment());\n    }\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    if (infoStream != null) {\n      message(\"flushDocStores files=\" + docWriter.closedFiles());\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","sourceOld":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    if (infoStream != null) {\n      message(\"flushDocStores segment=\" + docWriter.getDocStoreSegment());\n    }\n\n    boolean useCompoundDocStore = false;\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    if (infoStream != null) {\n      message(\"flushDocStores files=\" + docWriter.closedFiles());\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"44fcbde6fb2ac44ee3b45e013e54a42911e689ff","date":1292065621,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","sourceNew":null,"sourceOld":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    if (infoStream != null) {\n      message(\"flushDocStores segment=\" + docWriter.getDocStoreSegment());\n    }\n\n    boolean useCompoundDocStore = false;\n    if (infoStream != null) {\n      message(\"closeDocStores segment=\" + docWriter.getDocStoreSegment());\n    }\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    if (infoStream != null) {\n      message(\"flushDocStores files=\" + docWriter.closedFiles());\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#flushDocStores().mjava","sourceNew":null,"sourceOld":"  /** Tells the docWriter to close its currently open shared\n   *  doc stores (stored fields & vectors files).\n   *  Return value specifices whether new doc store files are compound or not.\n   */\n  private synchronized boolean flushDocStores() throws IOException {\n\n    if (infoStream != null) {\n      message(\"flushDocStores segment=\" + docWriter.getDocStoreSegment());\n    }\n\n    boolean useCompoundDocStore = false;\n    if (infoStream != null) {\n      message(\"closeDocStores segment=\" + docWriter.getDocStoreSegment());\n    }\n\n    String docStoreSegment;\n\n    boolean success = false;\n    try {\n      docStoreSegment = docWriter.closeDocStore();\n      success = true;\n    } finally {\n      if (!success && infoStream != null) {\n        message(\"hit exception closing doc store segment\");\n      }\n    }\n\n    if (infoStream != null) {\n      message(\"flushDocStores files=\" + docWriter.closedFiles());\n    }\n\n    useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);\n      \n    if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {\n      // Now build compound doc store file\n\n      if (infoStream != null) {\n        message(\"create compound file \" + IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION));\n      }\n\n      success = false;\n\n      final int numSegments = segmentInfos.size();\n      final String compoundFileName = IndexFileNames.segmentFileName(docStoreSegment, \"\", IndexFileNames.COMPOUND_FILE_STORE_EXTENSION);\n\n      try {\n        CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, compoundFileName);\n        for (final String file :  docWriter.closedFiles() ) {\n          cfsWriter.addFile(file);\n        }\n      \n        // Perform the merge\n        cfsWriter.close();\n        success = true;\n\n      } finally {\n        if (!success) {\n          if (infoStream != null)\n            message(\"hit exception building compound file doc store for segment \" + docStoreSegment);\n          deleter.deleteFile(compoundFileName);\n          docWriter.abort();\n        }\n      }\n\n      for(int i=0;i<numSegments;i++) {\n        SegmentInfo si = segmentInfos.info(i);\n        if (si.getDocStoreOffset() != -1 &&\n            si.getDocStoreSegment().equals(docStoreSegment))\n          si.setDocStoreIsCompoundFile(true);\n      }\n\n      checkpoint();\n\n      // In case the files we just merged into a CFS were\n      // not previously checkpointed:\n      deleter.deleteNewFiles(docWriter.closedFiles());\n    }\n\n    return useCompoundDocStore;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5"],"2a186ae8733084223c22044e935e4ef848a143d1":["334c1175813aea771a71728cd2c4ee4754fd0603"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["334c1175813aea771a71728cd2c4ee4754fd0603","2a186ae8733084223c22044e935e4ef848a143d1"],"8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5":["2a186ae8733084223c22044e935e4ef848a143d1"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["3bb13258feba31ab676502787ab2e1779f129b7a","44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"334c1175813aea771a71728cd2c4ee4754fd0603":["9b832cbed6eb3d54a8bb9339296bdda8eeb53014"],"9b832cbed6eb3d54a8bb9339296bdda8eeb53014":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6"],"fb10b6bcde550b87d8f10e5f010bd8f3021023b6":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8fe956d65251358d755c56f14fe8380644790e47":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6"],"3bb13258feba31ab676502787ab2e1779f129b7a":["c498d3f8d75170b121f5eda2c6210ac5beb5d411","8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2a186ae8733084223c22044e935e4ef848a143d1":["c498d3f8d75170b121f5eda2c6210ac5beb5d411","8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["3bb13258feba31ab676502787ab2e1779f129b7a"],"8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff","3bb13258feba31ab676502787ab2e1779f129b7a"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":[],"334c1175813aea771a71728cd2c4ee4754fd0603":["2a186ae8733084223c22044e935e4ef848a143d1","c498d3f8d75170b121f5eda2c6210ac5beb5d411"],"9b832cbed6eb3d54a8bb9339296bdda8eeb53014":["334c1175813aea771a71728cd2c4ee4754fd0603"],"fb10b6bcde550b87d8f10e5f010bd8f3021023b6":["9b832cbed6eb3d54a8bb9339296bdda8eeb53014","8fe956d65251358d755c56f14fe8380644790e47"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"8fe956d65251358d755c56f14fe8380644790e47":[],"3bb13258feba31ab676502787ab2e1779f129b7a":["ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["fb10b6bcde550b87d8f10e5f010bd8f3021023b6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","8fe956d65251358d755c56f14fe8380644790e47","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}