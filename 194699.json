{"path":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","commits":[{"id":"2b0f649857e40b1429ab946a302da32f695eed9f","date":1339002543,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"/dev/null","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa\", TextField.TYPE_UNSTORED));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newField(\"field\", \"bbb\", StringField.TYPE_UNSTORED));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newField(\"field\", \"ccc\", TextField.TYPE_UNSTORED));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = r.getSequentialSubReaders()[0];\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, false).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2","02331260bb246364779cb6f04919ca47900d01bb"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = r.getSequentialSubReaders()[0];\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, false).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"aaa\", TextField.TYPE_UNSTORED));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newField(\"field\", \"bbb\", StringField.TYPE_UNSTORED));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newField(\"field\", \"ccc\", TextField.TYPE_UNSTORED));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = r.getSequentialSubReaders()[0];\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, false).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["2b0f649857e40b1429ab946a302da32f695eed9f"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","date":1340090669,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, false).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = r.getSequentialSubReaders()[0];\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, false).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, 0).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, 0).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, 0).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, false).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["2b0f649857e40b1429ab946a302da32f695eed9f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, 0).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, 0).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, 0).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, false).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, 0).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, 0).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, 0).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, false).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, false).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, false).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15250ca94ba8ab3bcdd476daf6bf3f3febb92640","date":1355200097,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, 0).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, 0).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, 0).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, 0).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, 0).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, 0).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, 0).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.shutdown();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ac34f0c5bb9274821fb0cb18075234e02002e9bf","date":1402508126,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.shutdown();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    LightAutomaton automaton = new RegExp(\".*\", RegExp.NONE).toLightAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.shutdown();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ca1c732df8923f5624f6c06b1dcca9e69d98c96","date":1402957391,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.shutdown();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.shutdown();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    LightAutomaton automaton = new RegExp(\".*\", RegExp.NONE).toLightAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c84485629d80d203608e8975a1139de9933cc38","date":1403166128,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.shutdown();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.shutdown();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();    \n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.shutdown();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.shutdown();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.shutdown();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    AtomicReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.postings(null, null, PostingsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, null, PostingsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, null, PostingsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, null, PostingsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, null, PostingsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, null, PostingsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, null, PostingsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.docs(null, null, DocsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.postings(null, null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.postings(null, null, PostingsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, null, PostingsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, null, PostingsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, null, PostingsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, null, PostingsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, null, PostingsEnum.FLAG_NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, null, PostingsEnum.FLAG_NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.postings(null, null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","date":1457644139,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlyLeafReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlySegmentReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b","date":1497408244,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlyLeafReader(r);\n    Terms terms = sub.terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlyLeafReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","date":1498028748,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlyLeafReader(r);\n    Terms terms = sub.terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlyLeafReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlyLeafReader(r);\n    Terms terms = sub.terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlyLeafReader(r);\n    Terms terms = sub.fields().terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"165c905a42bedc7c7d1acb37b177498306b7e866","date":1518704038,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestTermsEnum#testIntersectBasic().mjava","sourceNew":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlyLeafReader(r);\n    Terms terms = sub.terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testIntersectBasic() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(new LogDocMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"aaa\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newStringField(\"field\", \"bbb\", Field.Store.NO));\n    w.addDocument(doc);\n\n    doc = new Document();\n    doc.add(newTextField(\"field\", \"ccc\", Field.Store.NO));\n    w.addDocument(doc);\n\n    w.forceMerge(1);\n    DirectoryReader r = w.getReader();\n    w.close();\n    LeafReader sub = getOnlyLeafReader(r);\n    Terms terms = sub.terms(\"field\");\n    Automaton automaton = new RegExp(\".*\", RegExp.NONE).toAutomaton();\n    CompiledAutomaton ca = new CompiledAutomaton(automaton, false, false);    \n    TermsEnum te = terms.intersect(ca, null);\n    assertEquals(\"aaa\", te.next().utf8ToString());\n    assertEquals(0, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"abc\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    te = terms.intersect(ca, new BytesRef(\"aaa\"));\n    assertEquals(\"bbb\", te.next().utf8ToString());\n    assertEquals(1, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertEquals(\"ccc\", te.next().utf8ToString());\n    assertEquals(2, te.postings(null, PostingsEnum.NONE).nextDoc());\n    assertNull(te.next());\n\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["02331260bb246364779cb6f04919ca47900d01bb","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["2b0f649857e40b1429ab946a302da32f695eed9f"],"165c905a42bedc7c7d1acb37b177498306b7e866":["28288370235ed02234a64753cdbf0c6ec096304a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["ac34f0c5bb9274821fb0cb18075234e02002e9bf"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"5c84485629d80d203608e8975a1139de9933cc38":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a","4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"2b0f649857e40b1429ab946a302da32f695eed9f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["5c84485629d80d203608e8975a1139de9933cc38"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"51f5280f31484820499077f41fcdfe92d527d9dc":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"28288370235ed02234a64753cdbf0c6ec096304a":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["02331260bb246364779cb6f04919ca47900d01bb"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","02331260bb246364779cb6f04919ca47900d01bb"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","02331260bb246364779cb6f04919ca47900d01bb"],"ac34f0c5bb9274821fb0cb18075234e02002e9bf":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["165c905a42bedc7c7d1acb37b177498306b7e866"],"02331260bb246364779cb6f04919ca47900d01bb":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b":["28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["51f5280f31484820499077f41fcdfe92d527d9dc"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["e588e8c82e32e29ef3837c0b06a2ad34f3c51a2b","28288370235ed02234a64753cdbf0c6ec096304a","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"165c905a42bedc7c7d1acb37b177498306b7e866":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["2b0f649857e40b1429ab946a302da32f695eed9f"],"4ca1c732df8923f5624f6c06b1dcca9e69d98c96":["5c84485629d80d203608e8975a1139de9933cc38"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["5c84485629d80d203608e8975a1139de9933cc38","ac34f0c5bb9274821fb0cb18075234e02002e9bf"],"5c84485629d80d203608e8975a1139de9933cc38":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"2b0f649857e40b1429ab946a302da32f695eed9f":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","02331260bb246364779cb6f04919ca47900d01bb"],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"28288370235ed02234a64753cdbf0c6ec096304a":["165c905a42bedc7c7d1acb37b177498306b7e866"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"ac34f0c5bb9274821fb0cb18075234e02002e9bf":["4ca1c732df8923f5624f6c06b1dcca9e69d98c96"],"2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9":[],"02331260bb246364779cb6f04919ca47900d01bb":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","15250ca94ba8ab3bcdd476daf6bf3f3febb92640","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","2a3ed3f77cdd034e789d00d1ca8bb7054c9fb8e9","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}