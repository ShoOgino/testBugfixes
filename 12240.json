{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer#testOffsets().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer#testOffsets().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer#testOffsets().mjava","sourceNew":"  // LUCENE-1441\n  public void testOffsets() throws Exception {\n    TokenStream stream = new KeywordAnalyzer().tokenStream(\"field\", new StringReader(\"abcd\"));\n    OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n    stream.reset();\n    assertTrue(stream.incrementToken());\n    assertEquals(0, offsetAtt.startOffset());\n    assertEquals(4, offsetAtt.endOffset());\n  }\n\n","sourceOld":"  // LUCENE-1441\n  public void testOffsets() throws Exception {\n    TokenStream stream = new KeywordAnalyzer().tokenStream(\"field\", new StringReader(\"abcd\"));\n    OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n    stream.reset();\n    assertTrue(stream.incrementToken());\n    assertEquals(0, offsetAtt.startOffset());\n    assertEquals(4, offsetAtt.endOffset());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"782ed6a4b4ba50ec19734fc8db4e570ee193d627","date":1381127065,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer#testOffsets().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer#testOffsets().mjava","sourceNew":"  // LUCENE-1441\n  public void testOffsets() throws Exception {\n    try (TokenStream stream = new KeywordAnalyzer().tokenStream(\"field\", new StringReader(\"abcd\"))) {\n      OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n      stream.reset();\n      assertTrue(stream.incrementToken());\n      assertEquals(0, offsetAtt.startOffset());\n      assertEquals(4, offsetAtt.endOffset());\n      assertFalse(stream.incrementToken());\n      stream.end();\n    }\n  }\n\n","sourceOld":"  // LUCENE-1441\n  public void testOffsets() throws Exception {\n    TokenStream stream = new KeywordAnalyzer().tokenStream(\"field\", new StringReader(\"abcd\"));\n    OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n    stream.reset();\n    assertTrue(stream.incrementToken());\n    assertEquals(0, offsetAtt.startOffset());\n    assertEquals(4, offsetAtt.endOffset());\n  }\n\n","bugFix":["480d01e5b0ef8efb136d51670fec297ae5ae2c9c","cf7efd82433f3f64684711c16edfd149db6af111","69e043c521d4e8db770cc140c63f5ef51f03426a"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a56958d7f71a28824f20031ffbb2e13502a0274e","date":1425573902,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer#testOffsets().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer#testOffsets().mjava","sourceNew":"  // LUCENE-1441\n  public void testOffsets() throws Exception {\n    try (Analyzer analyzer = new KeywordAnalyzer();\n         TokenStream stream = analyzer.tokenStream(\"field\", new StringReader(\"abcd\"))) {\n      OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n      stream.reset();\n      assertTrue(stream.incrementToken());\n      assertEquals(0, offsetAtt.startOffset());\n      assertEquals(4, offsetAtt.endOffset());\n      assertFalse(stream.incrementToken());\n      stream.end();\n    }\n  }\n\n","sourceOld":"  // LUCENE-1441\n  public void testOffsets() throws Exception {\n    try (TokenStream stream = new KeywordAnalyzer().tokenStream(\"field\", new StringReader(\"abcd\"))) {\n      OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n      stream.reset();\n      assertTrue(stream.incrementToken());\n      assertEquals(0, offsetAtt.startOffset());\n      assertEquals(4, offsetAtt.endOffset());\n      assertFalse(stream.incrementToken());\n      stream.end();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer#testOffsets().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestKeywordAnalyzer#testOffsets().mjava","sourceNew":"  // LUCENE-1441\n  public void testOffsets() throws Exception {\n    try (Analyzer analyzer = new KeywordAnalyzer();\n         TokenStream stream = analyzer.tokenStream(\"field\", new StringReader(\"abcd\"))) {\n      OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n      stream.reset();\n      assertTrue(stream.incrementToken());\n      assertEquals(0, offsetAtt.startOffset());\n      assertEquals(4, offsetAtt.endOffset());\n      assertFalse(stream.incrementToken());\n      stream.end();\n    }\n  }\n\n","sourceOld":"  // LUCENE-1441\n  public void testOffsets() throws Exception {\n    try (TokenStream stream = new KeywordAnalyzer().tokenStream(\"field\", new StringReader(\"abcd\"))) {\n      OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n      stream.reset();\n      assertTrue(stream.incrementToken());\n      assertEquals(0, offsetAtt.startOffset());\n      assertEquals(4, offsetAtt.endOffset());\n      assertFalse(stream.incrementToken());\n      stream.end();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["782ed6a4b4ba50ec19734fc8db4e570ee193d627","a56958d7f71a28824f20031ffbb2e13502a0274e"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a56958d7f71a28824f20031ffbb2e13502a0274e"]},"commit2Childs":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","a56958d7f71a28824f20031ffbb2e13502a0274e"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}