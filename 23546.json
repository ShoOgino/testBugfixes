{"path":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","pathOld":"modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","sourceNew":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", new StringReader(\"abcd\")),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n  }\n\n","sourceOld":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", new StringReader(\"abcd\")),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c83d6c4335f31cae14f625a222bc842f20073dcd","date":1373306148,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","pathOld":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","sourceNew":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n  }\n\n","sourceOld":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", new StringReader(\"abcd\")),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n  }\n\n","bugFix":["0984ad47974c2d5d354519ddb2aa8358973a6271"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","pathOld":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","sourceNew":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n  }\n\n","sourceOld":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", new StringReader(\"abcd\")),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff4227bb146f97aabae888091c19e48c88dbb0db","date":1406758576,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","pathOld":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","sourceNew":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n  }\n\n","sourceOld":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cdab62f058ea765dd33deb05b4f19b7d626c801","date":1406803479,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","pathOld":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","sourceNew":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n  }\n\n","sourceOld":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"379db3ad24c4f0214f30a122265a6d6be003a99d","date":1407537768,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","pathOld":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","sourceNew":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n  }\n\n","sourceOld":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a56958d7f71a28824f20031ffbb2e13502a0274e","date":1425573902,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","pathOld":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","sourceNew":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n    a.close();\n  }\n\n","sourceOld":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","pathOld":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","sourceNew":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n    a.close();\n  }\n\n","sourceOld":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6a269c1ddba3f8c9fa9a40572ecc538eddda41a","date":1528054850,"type":3,"author":"Michael Braun","isMerge":false,"pathNew":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","pathOld":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","sourceNew":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              4\n    );\n    a.close();\n  }\n\n","sourceOld":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n    a.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"628903f37b6c442da0d390db1c6af9a0e74d41a7","date":1531736685,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","pathOld":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","sourceNew":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              4\n    );\n    a.close();\n  }\n\n","sourceOld":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n    a.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","pathOld":"lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer#testUserDict3().mjava","sourceNew":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              4\n    );\n    a.close();\n  }\n\n","sourceOld":"  // Copied from TestJapaneseTokenizer, to make sure passing\n  // user dict to analyzer works:\n  public void testUserDict3() throws Exception {\n    // Test entry that breaks into multiple tokens:\n    final Analyzer a = new JapaneseAnalyzer(TestJapaneseTokenizer.readDict(),\n                                            Mode.SEARCH,\n                                            JapaneseAnalyzer.getDefaultStopSet(),\n                                            JapaneseAnalyzer.getDefaultStopTags());\n    assertTokenStreamContents(a.tokenStream(\"foo\", \"abcd\"),\n                              new String[] { \"a\", \"b\", \"cd\"  },\n                              new int[] { 0, 1, 2 },\n                              new int[] { 1, 2, 4 },\n                              new Integer(4)\n    );\n    a.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ff4227bb146f97aabae888091c19e48c88dbb0db":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"b6a269c1ddba3f8c9fa9a40572ecc538eddda41a":["a56958d7f71a28824f20031ffbb2e13502a0274e"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["b89678825b68eccaf09e6ab71675fc0b0af1e099","c83d6c4335f31cae14f625a222bc842f20073dcd"],"628903f37b6c442da0d390db1c6af9a0e74d41a7":["a56958d7f71a28824f20031ffbb2e13502a0274e","b6a269c1ddba3f8c9fa9a40572ecc538eddda41a"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["379db3ad24c4f0214f30a122265a6d6be003a99d","a56958d7f71a28824f20031ffbb2e13502a0274e"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["a56958d7f71a28824f20031ffbb2e13502a0274e","628903f37b6c442da0d390db1c6af9a0e74d41a7"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a56958d7f71a28824f20031ffbb2e13502a0274e":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["ff4227bb146f97aabae888091c19e48c88dbb0db"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["628903f37b6c442da0d390db1c6af9a0e74d41a7"]},"commit2Childs":{"ff4227bb146f97aabae888091c19e48c88dbb0db":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"b6a269c1ddba3f8c9fa9a40572ecc538eddda41a":["628903f37b6c442da0d390db1c6af9a0e74d41a7"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"628903f37b6c442da0d390db1c6af9a0e74d41a7":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["37a0f60745e53927c4c876cfe5b5a58170f0646c","c83d6c4335f31cae14f625a222bc842f20073dcd"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"c83d6c4335f31cae14f625a222bc842f20073dcd":["ff4227bb146f97aabae888091c19e48c88dbb0db","37a0f60745e53927c4c876cfe5b5a58170f0646c"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","a56958d7f71a28824f20031ffbb2e13502a0274e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["b6a269c1ddba3f8c9fa9a40572ecc538eddda41a","628903f37b6c442da0d390db1c6af9a0e74d41a7","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5"],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}