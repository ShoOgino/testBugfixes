{"path":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","commits":[{"id":"ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1","date":1523453934,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(60000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["042b92cf48996255bedb0c3c4bf772d7e06e4dea","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"43345f1452f9510f8aaadae6156fe0c834e7d957","date":1523483670,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(60000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e4aa99957dcb54cefbbec762eb896b084deac1b9","date":1526471995,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(60000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"43ad790248d7f7daee5d9cced548c546f37c7218","date":1527269998,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 21-May-2018\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0532cd2ef583ac8047d77493ec05c81836f483c2","date":1527687859,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 21-May-2018\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d258391604e4db84e1b051753202638de242ee22","date":1528468626,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12392\")\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b8cde5442ed20c0c3ffd14ea2e2a64609367c193","date":1528792993,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  //@LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12392\")\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  @LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12392\")\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6b55cd711a129fb7fc4c3c4672d652149c9a4faa","date":1528813320,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  //@LuceneTestCase.BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12392\")\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f607a0a2e930f55385c7a24afb68ef661ef7e3ee","date":1530823671,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":["042b92cf48996255bedb0c3c4bf772d7e06e4dea"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"042b92cf48996255bedb0c3c4bf772d7e06e4dea","date":1534272102,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":["ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1","f607a0a2e930f55385c7a24afb68ef661ef7e3ee"],"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"976feb6756f29529c6ce5b578e7d6fa8b1efcb30","date":1535461878,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing\");\n    assertNotNull(\"'capturing' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fc18bc8ea2e2c1e308757ff50671c774438e9f3e","date":1538052583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int i = 0; i < 10; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 5; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    \n    if (SPEED == 1) {\n      cluster.waitForActiveCollection(collectionName, 2, 4);\n    } else {\n      CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n          CloudTestUtils.clusterShape(2, 2, false, true));\n    }\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 05-Jul-2018\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n        CloudTestUtils.clusterShape(2, 2, false, true));\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":["ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1","042b92cf48996255bedb0c3c4bf772d7e06e4dea"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"89948af0461fead48f44ba8fb7866f107ce83f22","date":1545157711,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    \n    if (SPEED == 1) {\n      cluster.waitForActiveCollection(collectionName, 2, 4);\n    } else {\n      CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n          CloudTestUtils.clusterShape(2, 2, false, true));\n    }\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    \n    if (SPEED == 1) {\n      cluster.waitForActiveCollection(collectionName, 2, 4);\n    } else {\n      CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n          CloudTestUtils.clusterShape(2, 2, false, true));\n    }\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5","date":1556572478,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    \n    if (SPEED == 1) {\n      cluster.waitForActiveCollection(collectionName, 2, 4);\n    } else {\n      CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n          CloudUtil.clusterShape(2, 2, false, true));\n    }\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    \n    if (SPEED == 1) {\n      cluster.waitForActiveCollection(collectionName, 2, 4);\n    } else {\n      CloudTestUtils.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n          CloudTestUtils.clusterShape(2, 2, false, true));\n    }\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2d80c1ad9241ae005a167d7ee8ac473601b0e57c","date":1559036097,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  //@AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    \n    if (SPEED == 1) {\n      cluster.waitForActiveCollection(collectionName, 2, 4);\n    } else {\n      CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n          CloudUtil.clusterShape(2, 2, false, true));\n    }\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  @AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    \n    if (SPEED == 1) {\n      cluster.waitForActiveCollection(collectionName, 2, 4);\n    } else {\n      CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n          CloudUtil.clusterShape(2, 2, false, true));\n    }\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a97a72dc16d01fda8ca5c9e0264b3604e30ab539","date":1565639985,"type":3,"author":"Megan Carey","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    \n    if (SPEED == 1) {\n      cluster.waitForActiveCollection(collectionName, 2, 4);\n    } else {\n      CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n          CloudUtil.clusterShape(2, 2, false, true));\n    }\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  //@AwaitsFix(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    \n    if (SPEED == 1) {\n      cluster.waitForActiveCollection(collectionName, 2, 4);\n    } else {\n      CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n          CloudUtil.clusterShape(2, 2, false, true));\n    }\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aa2585c33d5d66a1c837c312221eb55ddb3c4300","date":1592493170,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    \n    if (SPEED == 1) {\n      cluster.waitForActiveCollection(collectionName, 2, 4);\n    } else {\n      CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n          CloudUtil.clusterShape(2, 2, false, true));\n    }\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    @SuppressWarnings({\"rawtypes\"})\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    @SuppressWarnings({\"unchecked\"})\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      @SuppressWarnings({\"unchecked\"})\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    @SuppressWarnings({\"unchecked\"})\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    \n    if (SPEED == 1) {\n      cluster.waitForActiveCollection(collectionName, 2, 4);\n    } else {\n      CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n          CloudUtil.clusterShape(2, 2, false, true));\n    }\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2);\n    create.process(solrClient);\n    \n    if (SPEED == 1) {\n      cluster.waitForActiveCollection(collectionName, 2, 4);\n    } else {\n      CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n          CloudUtil.clusterShape(2, 2, false, true));\n    }\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    @SuppressWarnings({\"rawtypes\"})\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    @SuppressWarnings({\"unchecked\"})\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      @SuppressWarnings({\"unchecked\"})\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    @SuppressWarnings({\"unchecked\"})\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","sourceOld":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2).setMaxShardsPerNode(2);\n    create.process(solrClient);\n    \n    if (SPEED == 1) {\n      cluster.waitForActiveCollection(collectionName, 2, 4);\n    } else {\n      CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n          CloudUtil.clusterShape(2, 2, false, true));\n    }\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    @SuppressWarnings({\"rawtypes\"})\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    @SuppressWarnings({\"unchecked\"})\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      @SuppressWarnings({\"unchecked\"})\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    @SuppressWarnings({\"unchecked\"})\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest#testMergeIntegration().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testMergeIntegration() throws Exception {\n    String collectionName = \"testMergeIntegration_collection\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,\n        \"conf\", 2, 2);\n    create.process(solrClient);\n    \n    if (SPEED == 1) {\n      cluster.waitForActiveCollection(collectionName, 2, 4);\n    } else {\n      CloudUtil.waitForState(cloudManager, \"failed to create \" + collectionName, collectionName,\n          CloudUtil.clusterShape(2, 2, false, true));\n    }\n\n    for (int i = 0; i < 20; i++) {\n      SolrInputDocument doc = new SolrInputDocument(\"id\", \"id-\" + (i * 100));\n      solrClient.add(collectionName, doc);\n    }\n    solrClient.commit(collectionName);\n\n    long waitForSeconds = 3 + random().nextInt(5);\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'index_size_trigger3',\" +\n        \"'event' : 'indexSize',\" +\n        \"'waitFor' : '\" + waitForSeconds + \"s',\" +\n        \"'aboveDocs' : 40,\" +\n        \"'belowDocs' : 4,\" +\n        \"'enabled' : false,\" +\n        \"'actions' : [{'name' : 'compute_plan', 'class' : 'solr.ComputePlanAction'},\" +\n        \"{'name' : 'execute_plan', 'class' : '\" + ExecutePlanAction.class.getName() + \"'}]\" +\n        \"}}\";\n    @SuppressWarnings({\"rawtypes\"})\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    String setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'capturing3',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['STARTED','ABORTED','SUCCEEDED','FAILED'],\" +\n        \"'beforeAction' : ['compute_plan','execute_plan'],\" +\n        \"'afterAction' : ['compute_plan','execute_plan'],\" +\n        \"'class' : '\" + CapturingTriggerListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setListenerCommand = \"{\" +\n        \"'set-listener' : \" +\n        \"{\" +\n        \"'name' : 'finished',\" +\n        \"'trigger' : 'index_size_trigger3',\" +\n        \"'stage' : ['SUCCEEDED'],\" +\n        \"'class' : '\" + FinishedProcessingListener.class.getName() + \"'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setListenerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    // delete some docs to trigger a merge\n    for (int i = 0; i < 15; i++) {\n      solrClient.deleteById(collectionName, \"id-\" + (i * 100));\n    }\n    solrClient.commit(collectionName);\n\n    // enable the trigger\n    String resumeTriggerCommand = \"{\" +\n        \"'resume-trigger' : {\" +\n        \"'name' : 'index_size_trigger3'\" +\n        \"}\" +\n        \"}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, resumeTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(\"success\", response.get(\"result\").toString());\n\n    timeSource.sleep(TimeUnit.MILLISECONDS.convert(waitForSeconds + 1, TimeUnit.SECONDS));\n\n    boolean await = finished.await(90000 / SPEED, TimeUnit.MILLISECONDS);\n    assertTrue(\"did not finish processing in time\", await);\n    assertEquals(1, listenerEvents.size());\n    List<CapturedEvent> events = listenerEvents.get(\"capturing3\");\n    assertNotNull(\"'capturing3' events not found\", events);\n    assertEquals(\"events: \" + events, 6, events.size());\n    assertEquals(TriggerEventProcessorStage.STARTED, events.get(0).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(1).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(2).stage);\n    assertEquals(TriggerEventProcessorStage.BEFORE_ACTION, events.get(3).stage);\n    assertEquals(TriggerEventProcessorStage.AFTER_ACTION, events.get(4).stage);\n    assertEquals(TriggerEventProcessorStage.SUCCEEDED, events.get(5).stage);\n    // check ops\n    @SuppressWarnings({\"unchecked\"})\n    List<TriggerEvent.Op> ops = (List<TriggerEvent.Op>) events.get(4).event.getProperty(TriggerEvent.REQUESTED_OPS);\n    assertNotNull(\"should contain requestedOps\", ops);\n    assertTrue(\"number of ops: \" + ops, ops.size() > 0);\n    for (TriggerEvent.Op op : ops) {\n      assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction());\n      @SuppressWarnings({\"unchecked\"})\n      Set<Pair<String, String>> hints = (Set<Pair<String, String>>)op.getHints().get(Suggester.Hint.COLL_SHARD);\n      assertNotNull(\"hints\", hints);\n      assertEquals(\"hints\", 2, hints.size());\n      Pair<String, String> p = hints.iterator().next();\n      assertEquals(collectionName, p.first());\n    }\n\n    // TODO: fix this once MERGESHARDS is supported\n    @SuppressWarnings({\"unchecked\"})\n    List<TriggerEvent.Op> unsupportedOps = (List<TriggerEvent.Op>)events.get(2).context.get(\"properties.unsupportedOps\");\n    assertNotNull(\"should have unsupportedOps\", unsupportedOps);\n    assertEquals(unsupportedOps.toString() + \"\\n\" + ops, ops.size(), unsupportedOps.size());\n    unsupportedOps.forEach(op -> assertEquals(CollectionParams.CollectionAction.MERGESHARDS, op.getAction()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fc18bc8ea2e2c1e308757ff50671c774438e9f3e":["976feb6756f29529c6ce5b578e7d6fa8b1efcb30"],"e4aa99957dcb54cefbbec762eb896b084deac1b9":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"3f504512a03d978990cbff30db0522b354e846db":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["fc18bc8ea2e2c1e308757ff50671c774438e9f3e"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1"],"43ad790248d7f7daee5d9cced548c546f37c7218":["e4aa99957dcb54cefbbec762eb896b084deac1b9"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"a97a72dc16d01fda8ca5c9e0264b3604e30ab539":["2d80c1ad9241ae005a167d7ee8ac473601b0e57c"],"d258391604e4db84e1b051753202638de242ee22":["0532cd2ef583ac8047d77493ec05c81836f483c2"],"042b92cf48996255bedb0c3c4bf772d7e06e4dea":["f607a0a2e930f55385c7a24afb68ef661ef7e3ee"],"b8cde5442ed20c0c3ffd14ea2e2a64609367c193":["d258391604e4db84e1b051753202638de242ee22"],"0532cd2ef583ac8047d77493ec05c81836f483c2":["43ad790248d7f7daee5d9cced548c546f37c7218"],"6b55cd711a129fb7fc4c3c4672d652149c9a4faa":["b8cde5442ed20c0c3ffd14ea2e2a64609367c193"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["0532cd2ef583ac8047d77493ec05c81836f483c2","f607a0a2e930f55385c7a24afb68ef661ef7e3ee"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["a97a72dc16d01fda8ca5c9e0264b3604e30ab539"],"ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2d80c1ad9241ae005a167d7ee8ac473601b0e57c":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["89948af0461fead48f44ba8fb7866f107ce83f22"],"f607a0a2e930f55385c7a24afb68ef661ef7e3ee":["6b55cd711a129fb7fc4c3c4672d652149c9a4faa"],"976feb6756f29529c6ce5b578e7d6fa8b1efcb30":["042b92cf48996255bedb0c3c4bf772d7e06e4dea"],"89948af0461fead48f44ba8fb7866f107ce83f22":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f504512a03d978990cbff30db0522b354e846db"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["0532cd2ef583ac8047d77493ec05c81836f483c2","f607a0a2e930f55385c7a24afb68ef661ef7e3ee"]},"commit2Childs":{"fc18bc8ea2e2c1e308757ff50671c774438e9f3e":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"e4aa99957dcb54cefbbec762eb896b084deac1b9":["43ad790248d7f7daee5d9cced548c546f37c7218"],"3f504512a03d978990cbff30db0522b354e846db":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["89948af0461fead48f44ba8fb7866f107ce83f22"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["e4aa99957dcb54cefbbec762eb896b084deac1b9"],"43ad790248d7f7daee5d9cced548c546f37c7218":["0532cd2ef583ac8047d77493ec05c81836f483c2"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["3f504512a03d978990cbff30db0522b354e846db"],"a97a72dc16d01fda8ca5c9e0264b3604e30ab539":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"d258391604e4db84e1b051753202638de242ee22":["b8cde5442ed20c0c3ffd14ea2e2a64609367c193"],"042b92cf48996255bedb0c3c4bf772d7e06e4dea":["976feb6756f29529c6ce5b578e7d6fa8b1efcb30"],"0532cd2ef583ac8047d77493ec05c81836f483c2":["d258391604e4db84e1b051753202638de242ee22","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"b8cde5442ed20c0c3ffd14ea2e2a64609367c193":["6b55cd711a129fb7fc4c3c4672d652149c9a4faa"],"6b55cd711a129fb7fc4c3c4672d652149c9a4faa":["f607a0a2e930f55385c7a24afb68ef661ef7e3ee"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["43345f1452f9510f8aaadae6156fe0c834e7d957","ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1"],"2d80c1ad9241ae005a167d7ee8ac473601b0e57c":["a97a72dc16d01fda8ca5c9e0264b3604e30ab539"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["2d80c1ad9241ae005a167d7ee8ac473601b0e57c"],"f607a0a2e930f55385c7a24afb68ef661ef7e3ee":["042b92cf48996255bedb0c3c4bf772d7e06e4dea","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"976feb6756f29529c6ce5b578e7d6fa8b1efcb30":["fc18bc8ea2e2c1e308757ff50671c774438e9f3e"],"89948af0461fead48f44ba8fb7866f107ce83f22":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}