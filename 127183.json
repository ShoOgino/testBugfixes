{"path":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(Directory,String,int,int,int,double).mjava","commits":[{"id":"e3ce1ef883d26aa73919aa2d53991726e96caa13","date":1445421402,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(Directory,String,int,int,int,double).mjava","pathOld":"/dev/null","sourceNew":"  public BKDWriter(Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + RamUsageEstimator.NUM_BYTES_LONG + RamUsageEstimator.NUM_BYTES_INT;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["1e52a98a3809d9d747b7694f15f80b7018403ef5","1e52a98a3809d9d747b7694f15f80b7018403ef5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b9f70b31079ec002469ee49df3b8f9bd8d10df23","date":1447755747,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(Directory,String,int,int,int,double).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(Directory,String,int,int,int,double).mjava","sourceNew":"  public BKDWriter(Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + RamUsageEstimator.NUM_BYTES_LONG + RamUsageEstimator.NUM_BYTES_INT;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n  }\n\n","sourceOld":"  public BKDWriter(Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + RamUsageEstimator.NUM_BYTES_LONG + RamUsageEstimator.NUM_BYTES_INT;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n  }\n\n","bugFix":null,"bugIntro":["1e52a98a3809d9d747b7694f15f80b7018403ef5","1e52a98a3809d9d747b7694f15f80b7018403ef5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ecf331f9d7bdd234863d2df2bb5c1f019979422f","date":1452250335,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(Directory,String,int,int,int,double).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(Directory,String,int,int,int,double).mjava","sourceNew":"  public BKDWriter(Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + RamUsageEstimator.NUM_BYTES_LONG + RamUsageEstimator.NUM_BYTES_INT;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n  }\n\n","sourceOld":"  public BKDWriter(Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + RamUsageEstimator.NUM_BYTES_LONG + RamUsageEstimator.NUM_BYTES_INT;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n  }\n\n","bugFix":null,"bugIntro":["1e52a98a3809d9d747b7694f15f80b7018403ef5","1e52a98a3809d9d747b7694f15f80b7018403ef5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f226a8b088dd9c8f6ab287a77237c4aa00a238e5","date":1456187572,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(Directory,String,int,int,int,double).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(Directory,String,int,int,int,double).mjava","sourceNew":"  public BKDWriter(Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n  }\n\n","sourceOld":"  public BKDWriter(Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + RamUsageEstimator.NUM_BYTES_LONG + RamUsageEstimator.NUM_BYTES_INT;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"419a8f52c6635419beb951255cacbbb281044c57","date":1456189353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(Directory,String,int,int,int,double).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(Directory,String,int,int,int,double).mjava","sourceNew":"  public BKDWriter(Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n  }\n\n","sourceOld":"  public BKDWriter(Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + RamUsageEstimator.NUM_BYTES_LONG + RamUsageEstimator.NUM_BYTES_INT;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"adc9dc8ef0ce617b940a039fd12f79e8b098cc7f","date":1456936072,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(Directory,String,int,int,int,double).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(Directory,String,int,int,int,double).mjava","sourceNew":"  public BKDWriter(Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n\n    this.maxMBSortInHeap = maxMBSortInHeap;\n  }\n\n","sourceOld":"  public BKDWriter(Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n  }\n\n","bugFix":null,"bugIntro":["1e52a98a3809d9d747b7694f15f80b7018403ef5","1e52a98a3809d9d747b7694f15f80b7018403ef5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"251c5b33f0a2c8988550b63c78ed22b0e84524e5","date":1456961997,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(int,Directory,String,int,int,int,double).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(Directory,String,int,int,int,double).mjava","sourceNew":"  public BKDWriter(int maxDoc, Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    docsSeen = new FixedBitSet(maxDoc);\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n\n    this.maxMBSortInHeap = maxMBSortInHeap;\n  }\n\n","sourceOld":"  public BKDWriter(Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n\n    this.maxMBSortInHeap = maxMBSortInHeap;\n  }\n\n","bugFix":null,"bugIntro":["1e52a98a3809d9d747b7694f15f80b7018403ef5","1e52a98a3809d9d747b7694f15f80b7018403ef5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cf1a614098b46c9c22afebd7b898ae4d1d2fc273","date":1457088850,"type":5,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(int,Directory,String,int,int,int,double).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#BKDWriter(Directory,String,int,int,int,double).mjava","sourceNew":"  public BKDWriter(int maxDoc, Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    docsSeen = new FixedBitSet(maxDoc);\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n\n    this.maxMBSortInHeap = maxMBSortInHeap;\n  }\n\n","sourceOld":"  public BKDWriter(Directory tempDir, String tempFileNamePrefix, int numDims, int bytesPerDim, int maxPointsInLeafNode, double maxMBSortInHeap) throws IOException {\n    verifyParams(numDims, maxPointsInLeafNode, maxMBSortInHeap);\n    // We use tracking dir to deal with removing files on exception, so each place that\n    // creates temp files doesn't need crazy try/finally/sucess logic:\n    this.tempDir = new TrackingDirectoryWrapper(tempDir);\n    this.tempFileNamePrefix = tempFileNamePrefix;\n    this.maxPointsInLeafNode = maxPointsInLeafNode;\n    this.numDims = numDims;\n    this.bytesPerDim = bytesPerDim;\n    packedBytesLength = numDims * bytesPerDim;\n\n    scratchDiff = new byte[bytesPerDim];\n    scratchPackedValue = new byte[packedBytesLength];\n    scratch1 = new byte[packedBytesLength];\n    scratch2 = new byte[packedBytesLength];\n    commonPrefixLengths = new int[numDims];\n\n    minPackedValue = new byte[packedBytesLength];\n    maxPackedValue = new byte[packedBytesLength];\n\n    // dimensional values (numDims * bytesPerDim) + ord (long) + docID (int)\n    bytesPerDoc = packedBytesLength + Long.BYTES + Integer.BYTES;\n\n    // As we recurse, we compute temporary partitions of the data, halving the\n    // number of points at each recursion.  Once there are few enough points,\n    // we can switch to sorting in heap instead of offline (on disk).  At any\n    // time in the recursion, we hold the number of points at that level, plus\n    // all recursive halves (i.e. 16 + 8 + 4 + 2) so the memory usage is 2X\n    // what that level would consume, so we multiply by 0.5 to convert from\n    // bytes to points here.  Each dimension has its own sorted partition, so\n    // we must divide by numDims as wel.\n\n    maxPointsSortInHeap = (int) (0.5 * (maxMBSortInHeap * 1024 * 1024) / (bytesPerDoc * numDims));\n\n    // Finally, we must be able to hold at least the leaf node in heap during build:\n    if (maxPointsSortInHeap < maxPointsInLeafNode) {\n      throw new IllegalArgumentException(\"maxMBSortInHeap=\" + maxMBSortInHeap + \" only allows for maxPointsSortInHeap=\" + maxPointsSortInHeap + \", but this is less than maxPointsInLeafNode=\" + maxPointsInLeafNode + \"; either increase maxMBSortInHeap or decrease maxPointsInLeafNode\");\n    }\n\n    // We write first maxPointsSortInHeap in heap, then cutover to offline for additional points:\n    heapPointWriter = new HeapPointWriter(16, maxPointsSortInHeap, packedBytesLength);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"251c5b33f0a2c8988550b63c78ed22b0e84524e5":["adc9dc8ef0ce617b940a039fd12f79e8b098cc7f"],"ecf331f9d7bdd234863d2df2bb5c1f019979422f":["b9f70b31079ec002469ee49df3b8f9bd8d10df23"],"b9f70b31079ec002469ee49df3b8f9bd8d10df23":["e3ce1ef883d26aa73919aa2d53991726e96caa13"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"419a8f52c6635419beb951255cacbbb281044c57":["ecf331f9d7bdd234863d2df2bb5c1f019979422f","f226a8b088dd9c8f6ab287a77237c4aa00a238e5"],"f226a8b088dd9c8f6ab287a77237c4aa00a238e5":["ecf331f9d7bdd234863d2df2bb5c1f019979422f"],"e3ce1ef883d26aa73919aa2d53991726e96caa13":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["419a8f52c6635419beb951255cacbbb281044c57","251c5b33f0a2c8988550b63c78ed22b0e84524e5"],"adc9dc8ef0ce617b940a039fd12f79e8b098cc7f":["419a8f52c6635419beb951255cacbbb281044c57"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"]},"commit2Childs":{"251c5b33f0a2c8988550b63c78ed22b0e84524e5":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"ecf331f9d7bdd234863d2df2bb5c1f019979422f":["419a8f52c6635419beb951255cacbbb281044c57","f226a8b088dd9c8f6ab287a77237c4aa00a238e5"],"b9f70b31079ec002469ee49df3b8f9bd8d10df23":["ecf331f9d7bdd234863d2df2bb5c1f019979422f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e3ce1ef883d26aa73919aa2d53991726e96caa13"],"419a8f52c6635419beb951255cacbbb281044c57":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273","adc9dc8ef0ce617b940a039fd12f79e8b098cc7f"],"f226a8b088dd9c8f6ab287a77237c4aa00a238e5":["419a8f52c6635419beb951255cacbbb281044c57"],"e3ce1ef883d26aa73919aa2d53991726e96caa13":["b9f70b31079ec002469ee49df3b8f9bd8d10df23"],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"adc9dc8ef0ce617b940a039fd12f79e8b098cc7f":["251c5b33f0a2c8988550b63c78ed22b0e84524e5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}