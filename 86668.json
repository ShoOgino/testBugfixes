{"path":"solr/core/src/java/org/apache/solr/cloud/autoscaling/InactiveShardPlanAction#process(TriggerEvent,ActionContext).mjava","commits":[{"id":"9c6c0dad4932399aec99b4818086cb1772773916","date":1520515900,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/InactiveShardPlanAction#process(TriggerEvent,ActionContext).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void process(TriggerEvent event, ActionContext context) throws Exception {\n    SolrCloudManager cloudManager = context.getCloudManager();\n    ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n    Map<String, List<String>> cleanup = new LinkedHashMap<>();\n    Map<String, List<String>> inactive = new LinkedHashMap<>();\n    state.forEachCollection(coll ->\n      coll.getSlices().forEach(s -> {\n        if (Slice.State.INACTIVE.equals(s.getState())) {\n          inactive.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          String tstampStr = s.getStr(ZkStateReader.STATE_TIMESTAMP_PROP);\n          if (tstampStr == null || tstampStr.isEmpty()) {\n            return;\n          }\n          long timestamp = Long.parseLong(tstampStr);\n          // this timestamp uses epoch time\n          long currentTime = cloudManager.getTimeSource().getEpochTime();\n          long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n          log.debug(\"{}/{}: tstamp={}, time={}, delta={}\", coll.getName(), s.getName(), timestamp, currentTime, delta);\n          if (delta > cleanupTTL) {\n            log.debug(\"-- delete inactive {} / {}\", coll.getName(), s.getName());\n            List<SolrRequest> operations = (List<SolrRequest>)context.getProperties().computeIfAbsent(\"operations\", k -> new ArrayList<>());\n            operations.add(CollectionAdminRequest.deleteShard(coll.getName(), s.getName()));\n            cleanup.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          }\n        }\n      })\n    );\n    if (!cleanup.isEmpty()) {\n      Map<String, Object> results = new LinkedHashMap<>();\n      results.put(\"inactive\", inactive);\n      results.put(\"cleanup\", cleanup);\n      context.getProperties().put(getName(), results);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4412883c12067d8a4e2a354aa8adc58c32be1d6","date":1521129281,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/InactiveShardPlanAction#process(TriggerEvent,ActionContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/InactiveShardPlanAction#process(TriggerEvent,ActionContext).mjava","sourceNew":"  @Override\n  public void process(TriggerEvent event, ActionContext context) throws Exception {\n    SolrCloudManager cloudManager = context.getCloudManager();\n    ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n    Map<String, List<String>> cleanup = new LinkedHashMap<>();\n    Map<String, List<String>> inactive = new LinkedHashMap<>();\n    state.forEachCollection(coll ->\n      coll.getSlices().forEach(s -> {\n        if (Slice.State.INACTIVE.equals(s.getState())) {\n          inactive.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          String tstampStr = s.getStr(ZkStateReader.STATE_TIMESTAMP_PROP);\n          if (tstampStr == null || tstampStr.isEmpty()) {\n            return;\n          }\n          long timestamp = Long.parseLong(tstampStr);\n          // this timestamp uses epoch time\n          long currentTime = cloudManager.getTimeSource().getEpochTimeNs();\n          long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n          log.debug(\"{}/{}: tstamp={}, time={}, delta={}\", coll.getName(), s.getName(), timestamp, currentTime, delta);\n          if (delta > cleanupTTL) {\n            log.debug(\"-- delete inactive {} / {}\", coll.getName(), s.getName());\n            List<SolrRequest> operations = (List<SolrRequest>)context.getProperties().computeIfAbsent(\"operations\", k -> new ArrayList<>());\n            operations.add(CollectionAdminRequest.deleteShard(coll.getName(), s.getName()));\n            cleanup.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          }\n        }\n      })\n    );\n    if (!cleanup.isEmpty()) {\n      Map<String, Object> results = new LinkedHashMap<>();\n      results.put(\"inactive\", inactive);\n      results.put(\"cleanup\", cleanup);\n      context.getProperties().put(getName(), results);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(TriggerEvent event, ActionContext context) throws Exception {\n    SolrCloudManager cloudManager = context.getCloudManager();\n    ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n    Map<String, List<String>> cleanup = new LinkedHashMap<>();\n    Map<String, List<String>> inactive = new LinkedHashMap<>();\n    state.forEachCollection(coll ->\n      coll.getSlices().forEach(s -> {\n        if (Slice.State.INACTIVE.equals(s.getState())) {\n          inactive.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          String tstampStr = s.getStr(ZkStateReader.STATE_TIMESTAMP_PROP);\n          if (tstampStr == null || tstampStr.isEmpty()) {\n            return;\n          }\n          long timestamp = Long.parseLong(tstampStr);\n          // this timestamp uses epoch time\n          long currentTime = cloudManager.getTimeSource().getEpochTime();\n          long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n          log.debug(\"{}/{}: tstamp={}, time={}, delta={}\", coll.getName(), s.getName(), timestamp, currentTime, delta);\n          if (delta > cleanupTTL) {\n            log.debug(\"-- delete inactive {} / {}\", coll.getName(), s.getName());\n            List<SolrRequest> operations = (List<SolrRequest>)context.getProperties().computeIfAbsent(\"operations\", k -> new ArrayList<>());\n            operations.add(CollectionAdminRequest.deleteShard(coll.getName(), s.getName()));\n            cleanup.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          }\n        }\n      })\n    );\n    if (!cleanup.isEmpty()) {\n      Map<String, Object> results = new LinkedHashMap<>();\n      results.put(\"inactive\", inactive);\n      results.put(\"cleanup\", cleanup);\n      context.getProperties().put(getName(), results);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae70f2df00762dfce0455c0e39381848762662e5","date":1539113410,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/InactiveShardPlanAction#process(TriggerEvent,ActionContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/InactiveShardPlanAction#process(TriggerEvent,ActionContext).mjava","sourceNew":"  @Override\n  public void process(TriggerEvent event, ActionContext context) throws Exception {\n    SolrCloudManager cloudManager = context.getCloudManager();\n    ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n    Map<String, List<String>> cleanup = new LinkedHashMap<>();\n    Map<String, List<String>> inactive = new LinkedHashMap<>();\n    Map<String, Map<String, Object>> staleLocks = new LinkedHashMap<>();\n    state.forEachCollection(coll ->\n      coll.getSlices().forEach(s -> {\n        if (Slice.State.INACTIVE.equals(s.getState())) {\n          inactive.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          String tstampStr = s.getStr(ZkStateReader.STATE_TIMESTAMP_PROP);\n          if (tstampStr == null || tstampStr.isEmpty()) {\n            return;\n          }\n          long timestamp = Long.parseLong(tstampStr);\n          // this timestamp uses epoch time\n          long currentTime = cloudManager.getTimeSource().getEpochTimeNs();\n          long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n          log.debug(\"{}/{}: tstamp={}, time={}, delta={}\", coll.getName(), s.getName(), timestamp, currentTime, delta);\n          if (delta > cleanupTTL) {\n            log.debug(\"-- delete inactive {} / {}\", coll.getName(), s.getName());\n            List<SolrRequest> operations = (List<SolrRequest>)context.getProperties().computeIfAbsent(\"operations\", k -> new ArrayList<>());\n            operations.add(CollectionAdminRequest.deleteShard(coll.getName(), s.getName()));\n            cleanup.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          }\n        }\n        // check for stale shard split locks\n        String parentPath = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + coll.getName();\n        List<String> locks;\n        try {\n          locks = cloudManager.getDistribStateManager().listData(parentPath).stream()\n              .filter(name -> name.endsWith(\"-splitting\"))\n              .collect(Collectors.toList());\n          for (String lock : locks) {\n            try {\n              String lockPath = parentPath + \"/\" + lock;\n              Map<String, Object> lockData = Utils.getJson(cloudManager.getDistribStateManager(), lockPath);\n              String tstampStr = (String)lockData.get(ZkStateReader.STATE_TIMESTAMP_PROP);\n              if (tstampStr == null || tstampStr.isEmpty()) {\n                return;\n              }\n              long timestamp = Long.parseLong(tstampStr);\n              // this timestamp uses epoch time\n              long currentTime = cloudManager.getTimeSource().getEpochTimeNs();\n              long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n              log.debug(\"{}/{}: locktstamp={}, time={}, delta={}\", coll.getName(), lock, timestamp, currentTime, delta);\n              if (delta > cleanupTTL) {\n                log.debug(\"-- delete inactive split lock for {}/{}, delta={}\", coll.getName(), lock, delta);\n                cloudManager.getDistribStateManager().removeData(lockPath, -1);\n                lockData.put(\"currentTimeNs\", currentTime);\n                lockData.put(\"deltaSec\", delta);\n                lockData.put(\"ttlSec\", cleanupTTL);\n                staleLocks.put(coll.getName() + \"/\" + lock, lockData);\n              } else {\n                log.debug(\"-- lock \" + coll.getName() + \"/\" + lock + \" still active (delta=\" + delta + \")\");\n              }\n            } catch (NoSuchElementException nse) {\n              // already removed by someone else - ignore\n            }\n          }\n        } catch (Exception e) {\n          log.warn(\"Exception checking for inactive shard split locks in \" + parentPath, e);\n        }\n      })\n    );\n    Map<String, Object> results = new LinkedHashMap<>();\n    if (!cleanup.isEmpty()) {\n      results.put(\"inactive\", inactive);\n      results.put(\"cleanup\", cleanup);\n    }\n    if (!staleLocks.isEmpty()) {\n      results.put(\"staleLocks\", staleLocks);\n    }\n    if (!results.isEmpty()) {\n      context.getProperties().put(getName(), results);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(TriggerEvent event, ActionContext context) throws Exception {\n    SolrCloudManager cloudManager = context.getCloudManager();\n    ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n    Map<String, List<String>> cleanup = new LinkedHashMap<>();\n    Map<String, List<String>> inactive = new LinkedHashMap<>();\n    state.forEachCollection(coll ->\n      coll.getSlices().forEach(s -> {\n        if (Slice.State.INACTIVE.equals(s.getState())) {\n          inactive.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          String tstampStr = s.getStr(ZkStateReader.STATE_TIMESTAMP_PROP);\n          if (tstampStr == null || tstampStr.isEmpty()) {\n            return;\n          }\n          long timestamp = Long.parseLong(tstampStr);\n          // this timestamp uses epoch time\n          long currentTime = cloudManager.getTimeSource().getEpochTimeNs();\n          long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n          log.debug(\"{}/{}: tstamp={}, time={}, delta={}\", coll.getName(), s.getName(), timestamp, currentTime, delta);\n          if (delta > cleanupTTL) {\n            log.debug(\"-- delete inactive {} / {}\", coll.getName(), s.getName());\n            List<SolrRequest> operations = (List<SolrRequest>)context.getProperties().computeIfAbsent(\"operations\", k -> new ArrayList<>());\n            operations.add(CollectionAdminRequest.deleteShard(coll.getName(), s.getName()));\n            cleanup.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          }\n        }\n      })\n    );\n    if (!cleanup.isEmpty()) {\n      Map<String, Object> results = new LinkedHashMap<>();\n      results.put(\"inactive\", inactive);\n      results.put(\"cleanup\", cleanup);\n      context.getProperties().put(getName(), results);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e35f2dde06b35aa9904949a3a93fabd090371077","date":1587906921,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/InactiveShardPlanAction#process(TriggerEvent,ActionContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/InactiveShardPlanAction#process(TriggerEvent,ActionContext).mjava","sourceNew":"  @Override\n  public void process(TriggerEvent event, ActionContext context) throws Exception {\n    SolrCloudManager cloudManager = context.getCloudManager();\n    ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n    Map<String, List<String>> cleanup = new LinkedHashMap<>();\n    Map<String, List<String>> inactive = new LinkedHashMap<>();\n    Map<String, Map<String, Object>> staleLocks = new LinkedHashMap<>();\n    state.forEachCollection(coll ->\n      coll.getSlices().forEach(s -> {\n        if (Slice.State.INACTIVE.equals(s.getState())) {\n          inactive.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          String tstampStr = s.getStr(ZkStateReader.STATE_TIMESTAMP_PROP);\n          if (tstampStr == null || tstampStr.isEmpty()) {\n            return;\n          }\n          long timestamp = Long.parseLong(tstampStr);\n          // this timestamp uses epoch time\n          long currentTime = cloudManager.getTimeSource().getEpochTimeNs();\n          long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n          if (log.isDebugEnabled()) {\n            log.debug(\"{}/{}: tstamp={}, time={}, delta={}\", coll.getName(), s.getName(), timestamp, currentTime, delta);\n          }\n          if (delta > cleanupTTL) {\n            if (log.isDebugEnabled()) {\n              log.debug(\"-- delete inactive {} / {}\", coll.getName(), s.getName());\n            }\n            List<SolrRequest> operations = (List<SolrRequest>)context.getProperties().computeIfAbsent(\"operations\", k -> new ArrayList<>());\n            operations.add(CollectionAdminRequest.deleteShard(coll.getName(), s.getName()));\n            cleanup.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          }\n        }\n        // check for stale shard split locks\n        String parentPath = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + coll.getName();\n        List<String> locks;\n        try {\n          locks = cloudManager.getDistribStateManager().listData(parentPath).stream()\n              .filter(name -> name.endsWith(\"-splitting\"))\n              .collect(Collectors.toList());\n          for (String lock : locks) {\n            try {\n              String lockPath = parentPath + \"/\" + lock;\n              Map<String, Object> lockData = Utils.getJson(cloudManager.getDistribStateManager(), lockPath);\n              String tstampStr = (String)lockData.get(ZkStateReader.STATE_TIMESTAMP_PROP);\n              if (tstampStr == null || tstampStr.isEmpty()) {\n                return;\n              }\n              long timestamp = Long.parseLong(tstampStr);\n              // this timestamp uses epoch time\n              long currentTime = cloudManager.getTimeSource().getEpochTimeNs();\n              long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n              if (log.isDebugEnabled()) {\n                log.debug(\"{}/{}: locktstamp={}, time={}, delta={}\", coll.getName(), lock, timestamp, currentTime, delta);\n              }\n              if (delta > cleanupTTL) {\n                if (log.isDebugEnabled()) {\n                  log.debug(\"-- delete inactive split lock for {}/{}, delta={}\", coll.getName(), lock, delta);\n                }\n                cloudManager.getDistribStateManager().removeData(lockPath, -1);\n                lockData.put(\"currentTimeNs\", currentTime);\n                lockData.put(\"deltaSec\", delta);\n                lockData.put(\"ttlSec\", cleanupTTL);\n                staleLocks.put(coll.getName() + \"/\" + lock, lockData);\n              } else {\n                if (log.isDebugEnabled()) {\n                  log.debug(\"-- lock {}/{} still active (delta={})\", coll.getName(), lock, delta);\n                }\n              }\n            } catch (NoSuchElementException nse) {\n              // already removed by someone else - ignore\n            }\n          }\n        } catch (Exception e) {\n          log.warn(\"Exception checking for inactive shard split locks in {}\", parentPath, e);\n        }\n      })\n    );\n    Map<String, Object> results = new LinkedHashMap<>();\n    if (!cleanup.isEmpty()) {\n      results.put(\"inactive\", inactive);\n      results.put(\"cleanup\", cleanup);\n    }\n    if (!staleLocks.isEmpty()) {\n      results.put(\"staleLocks\", staleLocks);\n    }\n    if (!results.isEmpty()) {\n      context.getProperties().put(getName(), results);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(TriggerEvent event, ActionContext context) throws Exception {\n    SolrCloudManager cloudManager = context.getCloudManager();\n    ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n    Map<String, List<String>> cleanup = new LinkedHashMap<>();\n    Map<String, List<String>> inactive = new LinkedHashMap<>();\n    Map<String, Map<String, Object>> staleLocks = new LinkedHashMap<>();\n    state.forEachCollection(coll ->\n      coll.getSlices().forEach(s -> {\n        if (Slice.State.INACTIVE.equals(s.getState())) {\n          inactive.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          String tstampStr = s.getStr(ZkStateReader.STATE_TIMESTAMP_PROP);\n          if (tstampStr == null || tstampStr.isEmpty()) {\n            return;\n          }\n          long timestamp = Long.parseLong(tstampStr);\n          // this timestamp uses epoch time\n          long currentTime = cloudManager.getTimeSource().getEpochTimeNs();\n          long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n          log.debug(\"{}/{}: tstamp={}, time={}, delta={}\", coll.getName(), s.getName(), timestamp, currentTime, delta);\n          if (delta > cleanupTTL) {\n            log.debug(\"-- delete inactive {} / {}\", coll.getName(), s.getName());\n            List<SolrRequest> operations = (List<SolrRequest>)context.getProperties().computeIfAbsent(\"operations\", k -> new ArrayList<>());\n            operations.add(CollectionAdminRequest.deleteShard(coll.getName(), s.getName()));\n            cleanup.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          }\n        }\n        // check for stale shard split locks\n        String parentPath = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + coll.getName();\n        List<String> locks;\n        try {\n          locks = cloudManager.getDistribStateManager().listData(parentPath).stream()\n              .filter(name -> name.endsWith(\"-splitting\"))\n              .collect(Collectors.toList());\n          for (String lock : locks) {\n            try {\n              String lockPath = parentPath + \"/\" + lock;\n              Map<String, Object> lockData = Utils.getJson(cloudManager.getDistribStateManager(), lockPath);\n              String tstampStr = (String)lockData.get(ZkStateReader.STATE_TIMESTAMP_PROP);\n              if (tstampStr == null || tstampStr.isEmpty()) {\n                return;\n              }\n              long timestamp = Long.parseLong(tstampStr);\n              // this timestamp uses epoch time\n              long currentTime = cloudManager.getTimeSource().getEpochTimeNs();\n              long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n              log.debug(\"{}/{}: locktstamp={}, time={}, delta={}\", coll.getName(), lock, timestamp, currentTime, delta);\n              if (delta > cleanupTTL) {\n                log.debug(\"-- delete inactive split lock for {}/{}, delta={}\", coll.getName(), lock, delta);\n                cloudManager.getDistribStateManager().removeData(lockPath, -1);\n                lockData.put(\"currentTimeNs\", currentTime);\n                lockData.put(\"deltaSec\", delta);\n                lockData.put(\"ttlSec\", cleanupTTL);\n                staleLocks.put(coll.getName() + \"/\" + lock, lockData);\n              } else {\n                log.debug(\"-- lock \" + coll.getName() + \"/\" + lock + \" still active (delta=\" + delta + \")\");\n              }\n            } catch (NoSuchElementException nse) {\n              // already removed by someone else - ignore\n            }\n          }\n        } catch (Exception e) {\n          log.warn(\"Exception checking for inactive shard split locks in \" + parentPath, e);\n        }\n      })\n    );\n    Map<String, Object> results = new LinkedHashMap<>();\n    if (!cleanup.isEmpty()) {\n      results.put(\"inactive\", inactive);\n      results.put(\"cleanup\", cleanup);\n    }\n    if (!staleLocks.isEmpty()) {\n      results.put(\"staleLocks\", staleLocks);\n    }\n    if (!results.isEmpty()) {\n      context.getProperties().put(getName(), results);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"daa0f21a44e235a2299ea1fa913898b182dd7cce","date":1590952026,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/InactiveShardPlanAction#process(TriggerEvent,ActionContext).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/InactiveShardPlanAction#process(TriggerEvent,ActionContext).mjava","sourceNew":"  @Override\n  public void process(TriggerEvent event, ActionContext context) throws Exception {\n    SolrCloudManager cloudManager = context.getCloudManager();\n    ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n    Map<String, List<String>> cleanup = new LinkedHashMap<>();\n    Map<String, List<String>> inactive = new LinkedHashMap<>();\n    Map<String, Map<String, Object>> staleLocks = new LinkedHashMap<>();\n    state.forEachCollection(coll ->\n      coll.getSlices().forEach(s -> {\n        if (Slice.State.INACTIVE.equals(s.getState())) {\n          inactive.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          String tstampStr = s.getStr(ZkStateReader.STATE_TIMESTAMP_PROP);\n          if (tstampStr == null || tstampStr.isEmpty()) {\n            return;\n          }\n          long timestamp = Long.parseLong(tstampStr);\n          // this timestamp uses epoch time\n          long currentTime = cloudManager.getTimeSource().getEpochTimeNs();\n          long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n          if (log.isDebugEnabled()) {\n            log.debug(\"{}/{}: tstamp={}, time={}, delta={}\", coll.getName(), s.getName(), timestamp, currentTime, delta);\n          }\n          if (delta > cleanupTTL) {\n            if (log.isDebugEnabled()) {\n              log.debug(\"-- delete inactive {} / {}\", coll.getName(), s.getName());\n            }\n            @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n            List<SolrRequest> operations = (List<SolrRequest>)context.getProperties().computeIfAbsent(\"operations\", k -> new ArrayList<>());\n            operations.add(CollectionAdminRequest.deleteShard(coll.getName(), s.getName()));\n            cleanup.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          }\n        }\n        // check for stale shard split locks\n        String parentPath = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + coll.getName();\n        List<String> locks;\n        try {\n          locks = cloudManager.getDistribStateManager().listData(parentPath).stream()\n              .filter(name -> name.endsWith(\"-splitting\"))\n              .collect(Collectors.toList());\n          for (String lock : locks) {\n            try {\n              String lockPath = parentPath + \"/\" + lock;\n              Map<String, Object> lockData = Utils.getJson(cloudManager.getDistribStateManager(), lockPath);\n              String tstampStr = (String)lockData.get(ZkStateReader.STATE_TIMESTAMP_PROP);\n              if (tstampStr == null || tstampStr.isEmpty()) {\n                return;\n              }\n              long timestamp = Long.parseLong(tstampStr);\n              // this timestamp uses epoch time\n              long currentTime = cloudManager.getTimeSource().getEpochTimeNs();\n              long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n              if (log.isDebugEnabled()) {\n                log.debug(\"{}/{}: locktstamp={}, time={}, delta={}\", coll.getName(), lock, timestamp, currentTime, delta);\n              }\n              if (delta > cleanupTTL) {\n                if (log.isDebugEnabled()) {\n                  log.debug(\"-- delete inactive split lock for {}/{}, delta={}\", coll.getName(), lock, delta);\n                }\n                cloudManager.getDistribStateManager().removeData(lockPath, -1);\n                lockData.put(\"currentTimeNs\", currentTime);\n                lockData.put(\"deltaSec\", delta);\n                lockData.put(\"ttlSec\", cleanupTTL);\n                staleLocks.put(coll.getName() + \"/\" + lock, lockData);\n              } else {\n                if (log.isDebugEnabled()) {\n                  log.debug(\"-- lock {}/{} still active (delta={})\", coll.getName(), lock, delta);\n                }\n              }\n            } catch (NoSuchElementException nse) {\n              // already removed by someone else - ignore\n            }\n          }\n        } catch (Exception e) {\n          log.warn(\"Exception checking for inactive shard split locks in {}\", parentPath, e);\n        }\n      })\n    );\n    Map<String, Object> results = new LinkedHashMap<>();\n    if (!cleanup.isEmpty()) {\n      results.put(\"inactive\", inactive);\n      results.put(\"cleanup\", cleanup);\n    }\n    if (!staleLocks.isEmpty()) {\n      results.put(\"staleLocks\", staleLocks);\n    }\n    if (!results.isEmpty()) {\n      context.getProperties().put(getName(), results);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(TriggerEvent event, ActionContext context) throws Exception {\n    SolrCloudManager cloudManager = context.getCloudManager();\n    ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n    Map<String, List<String>> cleanup = new LinkedHashMap<>();\n    Map<String, List<String>> inactive = new LinkedHashMap<>();\n    Map<String, Map<String, Object>> staleLocks = new LinkedHashMap<>();\n    state.forEachCollection(coll ->\n      coll.getSlices().forEach(s -> {\n        if (Slice.State.INACTIVE.equals(s.getState())) {\n          inactive.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          String tstampStr = s.getStr(ZkStateReader.STATE_TIMESTAMP_PROP);\n          if (tstampStr == null || tstampStr.isEmpty()) {\n            return;\n          }\n          long timestamp = Long.parseLong(tstampStr);\n          // this timestamp uses epoch time\n          long currentTime = cloudManager.getTimeSource().getEpochTimeNs();\n          long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n          if (log.isDebugEnabled()) {\n            log.debug(\"{}/{}: tstamp={}, time={}, delta={}\", coll.getName(), s.getName(), timestamp, currentTime, delta);\n          }\n          if (delta > cleanupTTL) {\n            if (log.isDebugEnabled()) {\n              log.debug(\"-- delete inactive {} / {}\", coll.getName(), s.getName());\n            }\n            List<SolrRequest> operations = (List<SolrRequest>)context.getProperties().computeIfAbsent(\"operations\", k -> new ArrayList<>());\n            operations.add(CollectionAdminRequest.deleteShard(coll.getName(), s.getName()));\n            cleanup.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          }\n        }\n        // check for stale shard split locks\n        String parentPath = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + coll.getName();\n        List<String> locks;\n        try {\n          locks = cloudManager.getDistribStateManager().listData(parentPath).stream()\n              .filter(name -> name.endsWith(\"-splitting\"))\n              .collect(Collectors.toList());\n          for (String lock : locks) {\n            try {\n              String lockPath = parentPath + \"/\" + lock;\n              Map<String, Object> lockData = Utils.getJson(cloudManager.getDistribStateManager(), lockPath);\n              String tstampStr = (String)lockData.get(ZkStateReader.STATE_TIMESTAMP_PROP);\n              if (tstampStr == null || tstampStr.isEmpty()) {\n                return;\n              }\n              long timestamp = Long.parseLong(tstampStr);\n              // this timestamp uses epoch time\n              long currentTime = cloudManager.getTimeSource().getEpochTimeNs();\n              long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n              if (log.isDebugEnabled()) {\n                log.debug(\"{}/{}: locktstamp={}, time={}, delta={}\", coll.getName(), lock, timestamp, currentTime, delta);\n              }\n              if (delta > cleanupTTL) {\n                if (log.isDebugEnabled()) {\n                  log.debug(\"-- delete inactive split lock for {}/{}, delta={}\", coll.getName(), lock, delta);\n                }\n                cloudManager.getDistribStateManager().removeData(lockPath, -1);\n                lockData.put(\"currentTimeNs\", currentTime);\n                lockData.put(\"deltaSec\", delta);\n                lockData.put(\"ttlSec\", cleanupTTL);\n                staleLocks.put(coll.getName() + \"/\" + lock, lockData);\n              } else {\n                if (log.isDebugEnabled()) {\n                  log.debug(\"-- lock {}/{} still active (delta={})\", coll.getName(), lock, delta);\n                }\n              }\n            } catch (NoSuchElementException nse) {\n              // already removed by someone else - ignore\n            }\n          }\n        } catch (Exception e) {\n          log.warn(\"Exception checking for inactive shard split locks in {}\", parentPath, e);\n        }\n      })\n    );\n    Map<String, Object> results = new LinkedHashMap<>();\n    if (!cleanup.isEmpty()) {\n      results.put(\"inactive\", inactive);\n      results.put(\"cleanup\", cleanup);\n    }\n    if (!staleLocks.isEmpty()) {\n      results.put(\"staleLocks\", staleLocks);\n    }\n    if (!results.isEmpty()) {\n      context.getProperties().put(getName(), results);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/InactiveShardPlanAction#process(TriggerEvent,ActionContext).mjava","sourceNew":null,"sourceOld":"  @Override\n  public void process(TriggerEvent event, ActionContext context) throws Exception {\n    SolrCloudManager cloudManager = context.getCloudManager();\n    ClusterState state = cloudManager.getClusterStateProvider().getClusterState();\n    Map<String, List<String>> cleanup = new LinkedHashMap<>();\n    Map<String, List<String>> inactive = new LinkedHashMap<>();\n    Map<String, Map<String, Object>> staleLocks = new LinkedHashMap<>();\n    state.forEachCollection(coll ->\n      coll.getSlices().forEach(s -> {\n        if (Slice.State.INACTIVE.equals(s.getState())) {\n          inactive.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          String tstampStr = s.getStr(ZkStateReader.STATE_TIMESTAMP_PROP);\n          if (tstampStr == null || tstampStr.isEmpty()) {\n            return;\n          }\n          long timestamp = Long.parseLong(tstampStr);\n          // this timestamp uses epoch time\n          long currentTime = cloudManager.getTimeSource().getEpochTimeNs();\n          long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n          if (log.isDebugEnabled()) {\n            log.debug(\"{}/{}: tstamp={}, time={}, delta={}\", coll.getName(), s.getName(), timestamp, currentTime, delta);\n          }\n          if (delta > cleanupTTL) {\n            if (log.isDebugEnabled()) {\n              log.debug(\"-- delete inactive {} / {}\", coll.getName(), s.getName());\n            }\n            @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n            List<SolrRequest> operations = (List<SolrRequest>)context.getProperties().computeIfAbsent(\"operations\", k -> new ArrayList<>());\n            operations.add(CollectionAdminRequest.deleteShard(coll.getName(), s.getName()));\n            cleanup.computeIfAbsent(coll.getName(), c -> new ArrayList<>()).add(s.getName());\n          }\n        }\n        // check for stale shard split locks\n        String parentPath = ZkStateReader.COLLECTIONS_ZKNODE + \"/\" + coll.getName();\n        List<String> locks;\n        try {\n          locks = cloudManager.getDistribStateManager().listData(parentPath).stream()\n              .filter(name -> name.endsWith(\"-splitting\"))\n              .collect(Collectors.toList());\n          for (String lock : locks) {\n            try {\n              String lockPath = parentPath + \"/\" + lock;\n              Map<String, Object> lockData = Utils.getJson(cloudManager.getDistribStateManager(), lockPath);\n              String tstampStr = (String)lockData.get(ZkStateReader.STATE_TIMESTAMP_PROP);\n              if (tstampStr == null || tstampStr.isEmpty()) {\n                return;\n              }\n              long timestamp = Long.parseLong(tstampStr);\n              // this timestamp uses epoch time\n              long currentTime = cloudManager.getTimeSource().getEpochTimeNs();\n              long delta = TimeUnit.NANOSECONDS.toSeconds(currentTime - timestamp);\n              if (log.isDebugEnabled()) {\n                log.debug(\"{}/{}: locktstamp={}, time={}, delta={}\", coll.getName(), lock, timestamp, currentTime, delta);\n              }\n              if (delta > cleanupTTL) {\n                if (log.isDebugEnabled()) {\n                  log.debug(\"-- delete inactive split lock for {}/{}, delta={}\", coll.getName(), lock, delta);\n                }\n                cloudManager.getDistribStateManager().removeData(lockPath, -1);\n                lockData.put(\"currentTimeNs\", currentTime);\n                lockData.put(\"deltaSec\", delta);\n                lockData.put(\"ttlSec\", cleanupTTL);\n                staleLocks.put(coll.getName() + \"/\" + lock, lockData);\n              } else {\n                if (log.isDebugEnabled()) {\n                  log.debug(\"-- lock {}/{} still active (delta={})\", coll.getName(), lock, delta);\n                }\n              }\n            } catch (NoSuchElementException nse) {\n              // already removed by someone else - ignore\n            }\n          }\n        } catch (Exception e) {\n          log.warn(\"Exception checking for inactive shard split locks in {}\", parentPath, e);\n        }\n      })\n    );\n    Map<String, Object> results = new LinkedHashMap<>();\n    if (!cleanup.isEmpty()) {\n      results.put(\"inactive\", inactive);\n      results.put(\"cleanup\", cleanup);\n    }\n    if (!staleLocks.isEmpty()) {\n      results.put(\"staleLocks\", staleLocks);\n    }\n    if (!results.isEmpty()) {\n      context.getProperties().put(getName(), results);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9c6c0dad4932399aec99b4818086cb1772773916":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3f504512a03d978990cbff30db0522b354e846db":["daa0f21a44e235a2299ea1fa913898b182dd7cce"],"daa0f21a44e235a2299ea1fa913898b182dd7cce":["e35f2dde06b35aa9904949a3a93fabd090371077"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d4412883c12067d8a4e2a354aa8adc58c32be1d6":["9c6c0dad4932399aec99b4818086cb1772773916"],"e35f2dde06b35aa9904949a3a93fabd090371077":["ae70f2df00762dfce0455c0e39381848762662e5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f504512a03d978990cbff30db0522b354e846db"],"ae70f2df00762dfce0455c0e39381848762662e5":["d4412883c12067d8a4e2a354aa8adc58c32be1d6"]},"commit2Childs":{"9c6c0dad4932399aec99b4818086cb1772773916":["d4412883c12067d8a4e2a354aa8adc58c32be1d6"],"3f504512a03d978990cbff30db0522b354e846db":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9c6c0dad4932399aec99b4818086cb1772773916"],"daa0f21a44e235a2299ea1fa913898b182dd7cce":["3f504512a03d978990cbff30db0522b354e846db"],"d4412883c12067d8a4e2a354aa8adc58c32be1d6":["ae70f2df00762dfce0455c0e39381848762662e5"],"e35f2dde06b35aa9904949a3a93fabd090371077":["daa0f21a44e235a2299ea1fa913898b182dd7cce"],"ae70f2df00762dfce0455c0e39381848762662e5":["e35f2dde06b35aa9904949a3a93fabd090371077"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}