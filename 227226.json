{"path":"solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorCloud#testVariousAdds(SolrClient).mjava","commits":[{"id":"f57cf082c4d2ee975c6a2034fcf3c13f9514e6ef","date":1458928975,"type":0,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorCloud#testVariousAdds(SolrClient).mjava","pathOld":"/dev/null","sourceNew":"  protected static void testVariousAdds(SolrClient client) throws Exception {\n    assertNotNull(\"client not initialized\", client);\n    \n    UpdateResponse rsp = null;\n\n    // 2 docs that are both on shard1, the first one should fail\n    for (int maxErrors : new int[] { -1, 2, 47, 10 }) {\n      // regardless of which of these maxErrors values we use, behavior should be the same...\n      rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                          \"maxErrors\", \"\"+maxErrors,\n                          \"commit\", \"true\"),\n                   doc(f(\"id\", S_ONE_PRE + \"42\"), f(\"foo_i\", \"bogus_value\")),\n                   doc(f(\"id\", S_ONE_PRE + \"666\"), f(\"foo_i\", \"1976\"))).process(client);\n      \n      assertEquals(0, rsp.getStatus());\n      assertUpdateTolerantAddErrors(\"single shard, 1st doc should fail\", rsp, S_ONE_PRE + \"42\");\n      assertEquals(0, client.commit().getStatus());\n      assertQueryDocIds(client, false, S_ONE_PRE + \"42\");\n      assertQueryDocIds(client, true, S_ONE_PRE + \"666\");\n\n      // ...only diff should be that we get an accurate report of the effective maxErrors\n      assertEquals(maxErrors, rsp.getResponseHeader().get(\"maxErrors\"));\n    }\n    \n    // 2 docs that are both on shard1, the second one should fail\n    \n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-not-set\",\n                        \"commit\", \"true\"),\n                 doc(f(\"id\", S_ONE_PRE + \"55\"), f(\"foo_i\", \"1976\")),\n                 doc(f(\"id\", S_ONE_PRE + \"77\"), f(\"foo_i\", \"bogus_val\"))).process(client);\n    \n    assertEquals(0, rsp.getStatus());\n    assertUpdateTolerantAddErrors(\"single shard, 2nd doc should fail\", rsp, S_ONE_PRE + \"77\");\n    assertQueryDocIds(client, false, S_ONE_PRE + \"77\");\n    assertQueryDocIds(client, true, S_ONE_PRE + \"666\", S_ONE_PRE + \"55\");\n    // since maxErrors is unset, we should get an \"unlimited\" value back\n    assertEquals(-1, rsp.getResponseHeader().get(\"maxErrors\"));\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n\n    // 2 docs on 2 diff shards, first of which should fail\n    \n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                        \"commit\", \"true\"),\n                 doc(f(\"id\", S_ONE_PRE + \"42\"), f(\"foo_i\", \"bogus_value\")),\n                 doc(f(\"id\", S_TWO_PRE + \"666\"), f(\"foo_i\", \"1976\"))).process(client);\n    \n    assertEquals(0, rsp.getStatus());\n    assertUpdateTolerantAddErrors(\"two shards, 1st doc should fail\", rsp, S_ONE_PRE + \"42\");\n    assertEquals(0, client.commit().getStatus());\n    assertQueryDocIds(client, false, S_ONE_PRE + \"42\");\n    assertQueryDocIds(client, true, S_TWO_PRE + \"666\");\n    \n    // 2 docs on 2 diff shards, second of which should fail\n\n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                        \"commit\", \"true\"),\n                 doc(f(\"id\", S_ONE_PRE + \"55\"), f(\"foo_i\", \"1976\")),\n                 doc(f(\"id\", S_TWO_PRE + \"77\"), f(\"foo_i\", \"bogus_val\"))).process(client);\n    \n    assertEquals(0, rsp.getStatus());\n    assertUpdateTolerantAddErrors(\"two shards, 2nd doc should fail\", rsp, S_TWO_PRE + \"77\");\n    assertQueryDocIds(client, false, S_TWO_PRE + \"77\");\n    assertQueryDocIds(client, true, S_TWO_PRE + \"666\", S_ONE_PRE + \"55\");\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n\n    // many docs from diff shards, 1 from each shard should fail\n    \n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                        \"commit\", \"true\"),\n                 doc(f(\"id\", S_ONE_PRE + \"11\")),\n                 doc(f(\"id\", S_TWO_PRE + \"21\")),\n                 doc(f(\"id\", S_ONE_PRE + \"12\")),\n                 doc(f(\"id\", S_TWO_PRE + \"22\"), f(\"foo_i\", \"bogus_val\")),\n                 doc(f(\"id\", S_ONE_PRE + \"13\")),\n                 doc(f(\"id\", S_TWO_PRE + \"23\")),\n                 doc(f(\"id\", S_ONE_PRE + \"14\")),\n                 doc(f(\"id\", S_TWO_PRE + \"24\")),\n                 doc(f(\"id\", S_ONE_PRE + \"15\"), f(\"foo_i\", \"bogus_val\")),\n                 doc(f(\"id\", S_TWO_PRE + \"25\")),\n                 doc(f(\"id\", S_ONE_PRE + \"16\")),\n                 doc(f(\"id\", S_TWO_PRE + \"26\"))).process(client);\n    \n    assertEquals(0, rsp.getStatus());\n    assertUpdateTolerantAddErrors(\"many docs, 1 from each shard should fail\", rsp,\n                                  S_ONE_PRE + \"15\",\n                                  S_TWO_PRE + \"22\");\n    assertQueryDocIds(client, false, S_TWO_PRE + \"22\", S_ONE_PRE + \"15\");\n    assertQueryDocIds(client, true,\n                      S_ONE_PRE + \"11\", S_TWO_PRE + \"21\", S_ONE_PRE + \"12\",\n                      S_ONE_PRE + \"13\", S_TWO_PRE + \"23\", S_ONE_PRE + \"14\", S_TWO_PRE + \"24\",\n                      S_TWO_PRE + \"25\", S_ONE_PRE + \"16\", S_TWO_PRE + \"26\");\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n\n    // many docs from diff shards, 1 from each shard should fail and 1 w/o uniqueKey\n    \n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                        \"commit\", \"true\"),\n                 doc(f(\"id\", S_ONE_PRE + \"11\")),\n                 doc(f(\"id\", S_TWO_PRE + \"21\")),\n                 doc(f(\"id\", S_ONE_PRE + \"12\")),\n                 doc(f(\"id\", S_TWO_PRE + \"22\"), f(\"foo_i\", \"bogus_val\")),\n                 doc(f(\"id\", S_ONE_PRE + \"13\")),\n                 doc(f(\"id\", S_TWO_PRE + \"23\")),\n                 doc(f(\"foo_i\", \"42\")),          // no \"id\"\n                 doc(f(\"id\", S_ONE_PRE + \"14\")),\n                 doc(f(\"id\", S_TWO_PRE + \"24\")),\n                 doc(f(\"id\", S_ONE_PRE + \"15\"), f(\"foo_i\", \"bogus_val\")),\n                 doc(f(\"id\", S_TWO_PRE + \"25\")),\n                 doc(f(\"id\", S_ONE_PRE + \"16\")),\n                 doc(f(\"id\", S_TWO_PRE + \"26\"))).process(client);\n    \n    assertEquals(0, rsp.getStatus());\n    assertUpdateTolerantAddErrors(\"many docs, 1 from each shard (+ no id) should fail\", rsp,\n                                  S_ONE_PRE + \"15\",\n                                  \"(unknown)\",\n                                  S_TWO_PRE + \"22\");\n    assertQueryDocIds(client, false, S_TWO_PRE + \"22\", S_ONE_PRE + \"15\");\n    assertQueryDocIds(client, true,\n                      S_ONE_PRE + \"11\", S_TWO_PRE + \"21\", S_ONE_PRE + \"12\",\n                      S_ONE_PRE + \"13\", S_TWO_PRE + \"23\", S_ONE_PRE + \"14\", S_TWO_PRE + \"24\",\n                      S_TWO_PRE + \"25\", S_ONE_PRE + \"16\", S_TWO_PRE + \"26\");\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n    \n    // many docs from diff shards, more then 10 (total) should fail\n\n    try {\n      rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                          \"commit\", \"true\"),\n                   doc(f(\"id\", S_ONE_PRE + \"11\")),\n                   doc(f(\"id\", S_TWO_PRE + \"21\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_ONE_PRE + \"12\")),\n                   doc(f(\"id\", S_TWO_PRE + \"22\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_ONE_PRE + \"13\")),\n                   doc(f(\"id\", S_TWO_PRE + \"23\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_ONE_PRE + \"14\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_TWO_PRE + \"24\")),\n                   doc(f(\"id\", S_ONE_PRE + \"15\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_TWO_PRE + \"25\")),\n                   doc(f(\"id\", S_ONE_PRE + \"16\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_TWO_PRE + \"26\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_ONE_PRE + \"17\")),\n                   doc(f(\"id\", S_TWO_PRE + \"27\")),\n                   doc(f(\"id\", S_ONE_PRE + \"18\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_TWO_PRE + \"28\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_ONE_PRE + \"19\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_TWO_PRE + \"29\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_ONE_PRE + \"10\")), // may be skipped, more then 10 fails\n                   doc(f(\"id\", S_TWO_PRE + \"20\"))  // may be skipped, more then 10 fails\n                   ).process(client);\n      \n      fail(\"did not get a top level exception when more then 10 docs failed: \" + rsp.toString());\n    } catch (SolrException e) {\n      // we can't make any reliable assertions about the error message, because\n      // it varies based on how the request was routed -- see SOLR-8830\n      assertEquals(\"not the type of error we were expecting (\"+e.code()+\"): \" + e.toString(),\n                   // NOTE: we always expect a 400 because we know that's what we would get from these types of errors\n                   // on a single node setup -- a 5xx type error isn't something we should have triggered\n                   400, e.code());\n\n      // verify that the Exceptions metadata can tell us what failed.\n      NamedList<String> remoteErrMetadata = e.getMetadata();\n      assertNotNull(\"no metadata in: \" + e.toString(), remoteErrMetadata);\n      Set<ToleratedUpdateError> actualKnownErrs\n        = new LinkedHashSet<ToleratedUpdateError>(remoteErrMetadata.size());\n      int actualKnownErrsCount = 0;\n      for (int i = 0; i < remoteErrMetadata.size(); i++) {\n        ToleratedUpdateError err =\n          ToleratedUpdateError.parseMetadataIfToleratedUpdateError(remoteErrMetadata.getName(i),\n                                                                   remoteErrMetadata.getVal(i));\n        if (null == err) {\n          // some metadata unrelated to this update processor\n          continue;\n        }\n        actualKnownErrsCount++;\n        actualKnownErrs.add(err);\n      }\n      assertEquals(\"wrong number of errors in metadata: \" + remoteErrMetadata.toString(),\n                   11, actualKnownErrsCount);\n      assertEquals(\"at least one dup error in metadata: \" + remoteErrMetadata.toString(),\n                   actualKnownErrsCount, actualKnownErrs.size());\n      for (ToleratedUpdateError err : actualKnownErrs) {\n        assertEquals(\"only expected type of error is ADD: \" + err,\n                     CmdType.ADD, err.getType());\n        assertTrue(\"failed err msg didn't match expected value: \" + err,\n                   err.getMessage().contains(\"bogus_val\"));\n      }\n    }\n    assertEquals(0, client.commit().getStatus()); // need to force since update didn't finish\n    assertQueryDocIds(client, false\n                      // explicitly failed\n                      , S_TWO_PRE + \"21\", S_TWO_PRE + \"22\", S_TWO_PRE + \"23\", S_ONE_PRE + \"14\"\n                      , S_ONE_PRE + \"15\", S_ONE_PRE + \"16\", S_TWO_PRE + \"26\", S_ONE_PRE + \"18\"\n                      , S_TWO_PRE + \"28\", S_ONE_PRE + \"19\", S_TWO_PRE + \"29\"\n                      //\n                      // // we can't assert for sure these docs were skipped\n                      // // depending on shard we hit, they may have been added async before errors were exceeded\n                      // , S_ONE_PRE + \"10\", S_TWO_PRE + \"20\" // skipped\n                      );\n    assertQueryDocIds(client, true,\n                      S_ONE_PRE + \"11\", S_ONE_PRE + \"12\", S_ONE_PRE + \"13\", S_TWO_PRE + \"24\",\n                      S_TWO_PRE + \"25\", S_ONE_PRE + \"17\", S_TWO_PRE + \"27\");\n    \n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n    \n    // many docs from diff shards, more then 10 from a single shard (two) should fail\n\n    try {\n      ArrayList<SolrInputDocument> docs = new ArrayList<SolrInputDocument>(30);\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"z\")));\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"z\")));\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"y\")));\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"y\")));\n      for (int i = 0; i < 11; i++) {\n        docs.add(doc(f(\"id\", S_ONE_PRE + i)));\n        docs.add(doc(f(\"id\", S_TWO_PRE + i), f(\"foo_i\", \"bogus_val\")));\n      }\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"x\"))); // may be skipped, more then 10 fails\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"x\"))); // may be skipped, more then 10 fails\n          \n      rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                          \"commit\", \"true\"),\n                   docs.toArray(new SolrInputDocument[docs.size()])).process(client);\n      \n      fail(\"did not get a top level exception when more then 10 docs failed: \" + rsp.toString());\n    } catch (SolrException e) {\n      // we can't make any reliable assertions about the error message, because\n      // it varies based on how the request was routed -- see SOLR-8830\n      assertEquals(\"not the type of error we were expecting (\"+e.code()+\"): \" + e.toString(),\n                   // NOTE: we always expect a 400 because we know that's what we would get from these types of errors\n                   // on a single node setup -- a 5xx type error isn't something we should have triggered\n                   400, e.code());\n\n      // verify that the Exceptions metadata can tell us what failed.\n      NamedList<String> remoteErrMetadata = e.getMetadata();\n      assertNotNull(\"no metadata in: \" + e.toString(), remoteErrMetadata);\n      Set<ToleratedUpdateError> actualKnownErrs\n        = new LinkedHashSet<ToleratedUpdateError>(remoteErrMetadata.size());\n      int actualKnownErrsCount = 0;\n      for (int i = 0; i < remoteErrMetadata.size(); i++) {\n        ToleratedUpdateError err =\n          ToleratedUpdateError.parseMetadataIfToleratedUpdateError(remoteErrMetadata.getName(i),\n                                                                   remoteErrMetadata.getVal(i));\n        if (null == err) {\n          // some metadata unrelated to this update processor\n          continue;\n        }\n        actualKnownErrsCount++;\n        actualKnownErrs.add(err);\n      }\n      assertEquals(\"wrong number of errors in metadata: \" + remoteErrMetadata.toString(),\n                   11, actualKnownErrsCount);\n      assertEquals(\"at least one dup error in metadata: \" + remoteErrMetadata.toString(),\n                   actualKnownErrsCount, actualKnownErrs.size());\n      for (ToleratedUpdateError err : actualKnownErrs) {\n        assertEquals(\"only expected type of error is ADD: \" + err,\n                     CmdType.ADD, err.getType());\n        assertTrue(\"failed id had unexpected prefix: \" + err,\n                   err.getId().startsWith(S_TWO_PRE));\n        assertTrue(\"failed err msg didn't match expected value: \" + err,\n                   err.getMessage().contains(\"bogus_val\"));\n      }\n           \n    }\n    assertEquals(0, client.commit().getStatus()); // need to force since update didn't finish\n    assertQueryDocIds(client, true\n                      , S_ONE_PRE + \"z\", S_ONE_PRE + \"y\", S_TWO_PRE + \"z\", S_TWO_PRE + \"y\" // first\n                      //\n                      , S_ONE_PRE + \"0\", S_ONE_PRE + \"1\", S_ONE_PRE + \"2\", S_ONE_PRE + \"3\", S_ONE_PRE + \"4\"\n                      , S_ONE_PRE + \"5\", S_ONE_PRE + \"6\", S_ONE_PRE + \"7\", S_ONE_PRE + \"8\", S_ONE_PRE + \"9\"\n                      );\n    assertQueryDocIds(client, false\n                      // explicitly failed\n                      , S_TWO_PRE + \"0\", S_TWO_PRE + \"1\", S_TWO_PRE + \"2\", S_TWO_PRE + \"3\", S_TWO_PRE + \"4\"\n                      , S_TWO_PRE + \"5\", S_TWO_PRE + \"6\", S_TWO_PRE + \"7\", S_TWO_PRE + \"8\", S_TWO_PRE + \"9\"\n                      //\n                      // // we can't assert for sure these docs were skipped\n                      // // depending on shard we hit, they may have been added async before errors were exceeded\n                      // , S_ONE_PRE + \"x\", S_TWO_PRE + \"x\", // skipped\n                      );\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n    \n    // many docs from diff shards, more then 10 don't have any uniqueKey specified\n\n    try {\n      ArrayList<SolrInputDocument> docs = new ArrayList<SolrInputDocument>(30);\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"z\")));\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"z\")));\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"y\")));\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"y\")));\n      for (int i = 0; i < 11; i++) {\n        // no \"id\" field\n        docs.add(doc(f(\"foo_i\", \"\" + i)));\n      }\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"x\"))); // may be skipped, more then 10 fails\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"x\"))); // may be skipped, more then 10 fails\n          \n      rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                          \"commit\", \"true\"),\n                   docs.toArray(new SolrInputDocument[docs.size()])).process(client);\n      \n      fail(\"did not get a top level exception when more then 10 docs mising uniqueKey: \" + rsp.toString());\n    } catch (SolrException e) {\n      // we can't make any reliable assertions about the error message, because\n      // it varies based on how the request was routed -- see SOLR-8830\n      assertEquals(\"not the type of error we were expecting (\"+e.code()+\"): \" + e.toString(),\n                   // NOTE: we always expect a 400 because we know that's what we would get from these types of errors\n                   // on a single node setup -- a 5xx type error isn't something we should have triggered\n                   400, e.code());\n\n      // verify that the Exceptions metadata can tell us what failed.\n      NamedList<String> remoteErrMetadata = e.getMetadata();\n      assertNotNull(\"no metadata in: \" + e.toString(), remoteErrMetadata);\n      int actualKnownErrsCount = 0;\n      for (int i = 0; i < remoteErrMetadata.size(); i++) {\n        ToleratedUpdateError err =\n          ToleratedUpdateError.parseMetadataIfToleratedUpdateError(remoteErrMetadata.getName(i),\n                                                                   remoteErrMetadata.getVal(i));\n        if (null == err) {\n          // some metadata unrelated to this update processor\n          continue;\n        }\n        actualKnownErrsCount++;\n        assertEquals(\"only expected type of error is ADD: \" + err,\n                     CmdType.ADD, err.getType());\n        assertTrue(\"failed id didn't match 'unknown': \" + err,\n                   err.getId().contains(\"unknown\"));\n      }\n      assertEquals(\"wrong number of errors in metadata: \" + remoteErrMetadata.toString(),\n                   11, actualKnownErrsCount);\n    }\n    assertEquals(0, client.commit().getStatus()); // need to force since update didn't finish\n    assertQueryDocIds(client, true\n                      , S_ONE_PRE + \"z\", S_ONE_PRE + \"y\", S_TWO_PRE + \"z\", S_TWO_PRE + \"y\" // first\n                      // // we can't assert for sure these docs were skipped or added\n                      // // depending on shard we hit, they may have been added async before errors were exceeded\n                      // , S_ONE_PRE + \"x\", S_TWO_PRE + \"x\" // skipped\n                      );\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n    \n    // many docs from diff shards, more then 10 from a single shard (two) should fail but\n    // request should still succeed because of maxErrors=-1 param\n\n    ArrayList<SolrInputDocument> docs = new ArrayList<SolrInputDocument>(30);\n    ArrayList<ExpectedErr> expectedErrs = new ArrayList<ExpectedErr>(30);\n    docs.add(doc(f(\"id\", S_ONE_PRE + \"z\")));\n    docs.add(doc(f(\"id\", S_TWO_PRE + \"z\")));\n    docs.add(doc(f(\"id\", S_ONE_PRE + \"y\")));\n    docs.add(doc(f(\"id\", S_TWO_PRE + \"y\")));\n    for (int i = 0; i < 11; i++) {\n      docs.add(doc(f(\"id\", S_ONE_PRE + i)));\n      docs.add(doc(f(\"id\", S_TWO_PRE + i), f(\"foo_i\", \"bogus_val\")));\n      expectedErrs.add(addErr(S_TWO_PRE + i));\n    }\n    docs.add(doc(f(\"id\", S_ONE_PRE + \"x\"))); \n    docs.add(doc(f(\"id\", S_TWO_PRE + \"x\"))); \n    \n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                        \"maxErrors\", \"-1\",\n                        \"commit\", \"true\"),\n                 docs.toArray(new SolrInputDocument[docs.size()])).process(client);\n    assertUpdateTolerantErrors(\"many docs from shard2 fail, but req should succeed\", rsp,\n                               expectedErrs.toArray(new ExpectedErr[expectedErrs.size()]));\n    assertQueryDocIds(client, true\n                      , S_ONE_PRE + \"z\", S_ONE_PRE + \"y\", S_TWO_PRE + \"z\", S_TWO_PRE + \"y\" // first\n                      , S_ONE_PRE + \"x\", S_TWO_PRE + \"x\" // later\n                      );\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92f789dbd1886e4b468e61b0def88b29a3f55228","date":1533844010,"type":3,"author":"Jason Gerlowski","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorCloud#testVariousAdds(SolrClient).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestTolerantUpdateProcessorCloud#testVariousAdds(SolrClient).mjava","sourceNew":"  protected static void testVariousAdds(SolrClient client) throws Exception {\n    assertNotNull(\"client not initialized\", client);\n    \n    UpdateResponse rsp = null;\n\n    // 2 docs that are both on shard1, the first one should fail\n    for (int maxErrors : new int[] { -1, 2, 47, 10 }) {\n      // regardless of which of these maxErrors values we use, behavior should be the same...\n      rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                          \"maxErrors\", \"\"+maxErrors,\n                          \"commit\", \"true\"),\n                   doc(f(\"id\", S_ONE_PRE + \"42\"), f(\"foo_i\", \"bogus_value\")),\n                   doc(f(\"id\", S_ONE_PRE + \"666\"), f(\"foo_i\", \"1976\"))).process(client);\n      \n      assertEquals(0, rsp.getStatus());\n      assertUpdateTolerantAddErrors(\"single shard, 1st doc should fail\", rsp, S_ONE_PRE + \"42\");\n      assertEquals(0, client.commit().getStatus());\n      assertQueryDocIds(client, false, S_ONE_PRE + \"42\");\n      assertQueryDocIds(client, true, S_ONE_PRE + \"666\");\n\n      // ...only diff should be that we get an accurate report of the effective maxErrors\n      assertEquals(maxErrors, rsp.getResponseHeader().get(\"maxErrors\"));\n    }\n    \n    // 2 docs that are both on shard1, the second one should fail\n    \n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-not-set\",\n                        \"commit\", \"true\"),\n                 doc(f(\"id\", S_ONE_PRE + \"55\"), f(\"foo_i\", \"1976\")),\n                 doc(f(\"id\", S_ONE_PRE + \"77\"), f(\"foo_i\", \"bogus_val\"))).process(client);\n    \n    assertEquals(0, rsp.getStatus());\n    assertUpdateTolerantAddErrors(\"single shard, 2nd doc should fail\", rsp, S_ONE_PRE + \"77\");\n    assertQueryDocIds(client, false, S_ONE_PRE + \"77\");\n    assertQueryDocIds(client, true, S_ONE_PRE + \"666\", S_ONE_PRE + \"55\");\n    // since maxErrors is unset, we should get an \"unlimited\" value back\n    assertEquals(-1, rsp.getResponseHeader().get(\"maxErrors\"));\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n\n    // 2 docs on 2 diff shards, first of which should fail\n    \n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                        \"commit\", \"true\"),\n                 doc(f(\"id\", S_ONE_PRE + \"42\"), f(\"foo_i\", \"bogus_value\")),\n                 doc(f(\"id\", S_TWO_PRE + \"666\"), f(\"foo_i\", \"1976\"))).process(client);\n    \n    assertEquals(0, rsp.getStatus());\n    assertUpdateTolerantAddErrors(\"two shards, 1st doc should fail\", rsp, S_ONE_PRE + \"42\");\n    assertEquals(0, client.commit().getStatus());\n    assertQueryDocIds(client, false, S_ONE_PRE + \"42\");\n    assertQueryDocIds(client, true, S_TWO_PRE + \"666\");\n    \n    // 2 docs on 2 diff shards, second of which should fail\n\n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                        \"commit\", \"true\"),\n                 doc(f(\"id\", S_ONE_PRE + \"55\"), f(\"foo_i\", \"1976\")),\n                 doc(f(\"id\", S_TWO_PRE + \"77\"), f(\"foo_i\", \"bogus_val\"))).process(client);\n    \n    assertEquals(0, rsp.getStatus());\n    assertUpdateTolerantAddErrors(\"two shards, 2nd doc should fail\", rsp, S_TWO_PRE + \"77\");\n    assertQueryDocIds(client, false, S_TWO_PRE + \"77\");\n    assertQueryDocIds(client, true, S_TWO_PRE + \"666\", S_ONE_PRE + \"55\");\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n\n    // many docs from diff shards, 1 from each shard should fail\n    \n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                        \"commit\", \"true\"),\n                 doc(f(\"id\", S_ONE_PRE + \"11\")),\n                 doc(f(\"id\", S_TWO_PRE + \"21\")),\n                 doc(f(\"id\", S_ONE_PRE + \"12\")),\n                 doc(f(\"id\", S_TWO_PRE + \"22\"), f(\"foo_i\", \"bogus_val\")),\n                 doc(f(\"id\", S_ONE_PRE + \"13\")),\n                 doc(f(\"id\", S_TWO_PRE + \"23\")),\n                 doc(f(\"id\", S_ONE_PRE + \"14\")),\n                 doc(f(\"id\", S_TWO_PRE + \"24\")),\n                 doc(f(\"id\", S_ONE_PRE + \"15\"), f(\"foo_i\", \"bogus_val\")),\n                 doc(f(\"id\", S_TWO_PRE + \"25\")),\n                 doc(f(\"id\", S_ONE_PRE + \"16\")),\n                 doc(f(\"id\", S_TWO_PRE + \"26\"))).process(client);\n    \n    assertEquals(0, rsp.getStatus());\n    assertUpdateTolerantAddErrors(\"many docs, 1 from each shard should fail\", rsp,\n                                  S_ONE_PRE + \"15\",\n                                  S_TWO_PRE + \"22\");\n    assertQueryDocIds(client, false, S_TWO_PRE + \"22\", S_ONE_PRE + \"15\");\n    assertQueryDocIds(client, true,\n                      S_ONE_PRE + \"11\", S_TWO_PRE + \"21\", S_ONE_PRE + \"12\",\n                      S_ONE_PRE + \"13\", S_TWO_PRE + \"23\", S_ONE_PRE + \"14\", S_TWO_PRE + \"24\",\n                      S_TWO_PRE + \"25\", S_ONE_PRE + \"16\", S_TWO_PRE + \"26\");\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n\n    // many docs from diff shards, 1 from each shard should fail and 1 w/o uniqueKey\n    \n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                        \"commit\", \"true\"),\n                 doc(f(\"id\", S_ONE_PRE + \"11\")),\n                 doc(f(\"id\", S_TWO_PRE + \"21\")),\n                 doc(f(\"id\", S_ONE_PRE + \"12\")),\n                 doc(f(\"id\", S_TWO_PRE + \"22\"), f(\"foo_i\", \"bogus_val\")),\n                 doc(f(\"id\", S_ONE_PRE + \"13\")),\n                 doc(f(\"id\", S_TWO_PRE + \"23\")),\n                 doc(f(\"foo_i\", \"42\")),          // no \"id\"\n                 doc(f(\"id\", S_ONE_PRE + \"14\")),\n                 doc(f(\"id\", S_TWO_PRE + \"24\")),\n                 doc(f(\"id\", S_ONE_PRE + \"15\"), f(\"foo_i\", \"bogus_val\")),\n                 doc(f(\"id\", S_TWO_PRE + \"25\")),\n                 doc(f(\"id\", S_ONE_PRE + \"16\")),\n                 doc(f(\"id\", S_TWO_PRE + \"26\"))).process(client);\n    \n    assertEquals(0, rsp.getStatus());\n    assertUpdateTolerantAddErrors(\"many docs, 1 from each shard (+ no id) should fail\", rsp,\n                                  S_ONE_PRE + \"15\",\n                                  \"(unknown)\",\n                                  S_TWO_PRE + \"22\");\n    assertQueryDocIds(client, false, S_TWO_PRE + \"22\", S_ONE_PRE + \"15\");\n    assertQueryDocIds(client, true,\n                      S_ONE_PRE + \"11\", S_TWO_PRE + \"21\", S_ONE_PRE + \"12\",\n                      S_ONE_PRE + \"13\", S_TWO_PRE + \"23\", S_ONE_PRE + \"14\", S_TWO_PRE + \"24\",\n                      S_TWO_PRE + \"25\", S_ONE_PRE + \"16\", S_TWO_PRE + \"26\");\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n    \n    // many docs from diff shards, more then 10 (total) should fail\n    SolrException e = expectThrows(SolrException.class,\n        \"did not get a top level exception when more then 10 docs failed\",\n        () -> update(params(\"update.chain\", \"tolerant-chain-max-errors-10\", \"commit\", \"true\"),\n            doc(f(\"id\", S_ONE_PRE + \"11\")),\n            doc(f(\"id\", S_TWO_PRE + \"21\"), f(\"foo_i\", \"bogus_val\")),\n            doc(f(\"id\", S_ONE_PRE + \"12\")),\n            doc(f(\"id\", S_TWO_PRE + \"22\"), f(\"foo_i\", \"bogus_val\")),\n            doc(f(\"id\", S_ONE_PRE + \"13\")),\n            doc(f(\"id\", S_TWO_PRE + \"23\"), f(\"foo_i\", \"bogus_val\")),\n            doc(f(\"id\", S_ONE_PRE + \"14\"), f(\"foo_i\", \"bogus_val\")),\n            doc(f(\"id\", S_TWO_PRE + \"24\")),\n            doc(f(\"id\", S_ONE_PRE + \"15\"), f(\"foo_i\", \"bogus_val\")),\n            doc(f(\"id\", S_TWO_PRE + \"25\")),\n            doc(f(\"id\", S_ONE_PRE + \"16\"), f(\"foo_i\", \"bogus_val\")),\n            doc(f(\"id\", S_TWO_PRE + \"26\"), f(\"foo_i\", \"bogus_val\")),\n            doc(f(\"id\", S_ONE_PRE + \"17\")),\n            doc(f(\"id\", S_TWO_PRE + \"27\")),\n            doc(f(\"id\", S_ONE_PRE + \"18\"), f(\"foo_i\", \"bogus_val\")),\n            doc(f(\"id\", S_TWO_PRE + \"28\"), f(\"foo_i\", \"bogus_val\")),\n            doc(f(\"id\", S_ONE_PRE + \"19\"), f(\"foo_i\", \"bogus_val\")),\n            doc(f(\"id\", S_TWO_PRE + \"29\"), f(\"foo_i\", \"bogus_val\")),\n            doc(f(\"id\", S_ONE_PRE + \"10\")), // may be skipped, more then 10 fails\n            doc(f(\"id\", S_TWO_PRE + \"20\"))  // may be skipped, more then 10 fails\n            ).process(client)\n    );\n    {\n      // we can't make any reliable assertions about the error message, because\n      // it varies based on how the request was routed -- see SOLR-8830\n      assertEquals(\"not the type of error we were expecting (\" + e.code() + \"): \" + e.toString(),\n          // NOTE: we always expect a 400 because we know that's what we would get from these types of errors\n          // on a single node setup -- a 5xx type error isn't something we should have triggered\n          400, e.code());\n\n      // verify that the Exceptions metadata can tell us what failed.\n      NamedList<String> remoteErrMetadata = e.getMetadata();\n      assertNotNull(\"no metadata in: \" + e.toString(), remoteErrMetadata);\n      Set<ToleratedUpdateError> actualKnownErrs\n          = new LinkedHashSet<ToleratedUpdateError>(remoteErrMetadata.size());\n      int actualKnownErrsCount = 0;\n      for (int i = 0; i < remoteErrMetadata.size(); i++) {\n        ToleratedUpdateError err =\n            ToleratedUpdateError.parseMetadataIfToleratedUpdateError(remoteErrMetadata.getName(i),\n                remoteErrMetadata.getVal(i));\n        if (null == err) {\n          // some metadata unrelated to this update processor\n          continue;\n        }\n        actualKnownErrsCount++;\n        actualKnownErrs.add(err);\n      }\n      assertEquals(\"wrong number of errors in metadata: \" + remoteErrMetadata.toString(),\n          11, actualKnownErrsCount);\n      assertEquals(\"at least one dup error in metadata: \" + remoteErrMetadata.toString(),\n          actualKnownErrsCount, actualKnownErrs.size());\n      for (ToleratedUpdateError err : actualKnownErrs) {\n        assertEquals(\"only expected type of error is ADD: \" + err,\n            CmdType.ADD, err.getType());\n        assertTrue(\"failed err msg didn't match expected value: \" + err,\n            err.getMessage().contains(\"bogus_val\"));\n      }\n    }\n\n    assertEquals(0, client.commit().getStatus()); // need to force since update didn't finish\n    assertQueryDocIds(client, false\n                      // explicitly failed\n                      , S_TWO_PRE + \"21\", S_TWO_PRE + \"22\", S_TWO_PRE + \"23\", S_ONE_PRE + \"14\"\n                      , S_ONE_PRE + \"15\", S_ONE_PRE + \"16\", S_TWO_PRE + \"26\", S_ONE_PRE + \"18\"\n                      , S_TWO_PRE + \"28\", S_ONE_PRE + \"19\", S_TWO_PRE + \"29\"\n                      //\n                      // // we can't assert for sure these docs were skipped\n                      // // depending on shard we hit, they may have been added async before errors were exceeded\n                      // , S_ONE_PRE + \"10\", S_TWO_PRE + \"20\" // skipped\n                      );\n    assertQueryDocIds(client, true,\n                      S_ONE_PRE + \"11\", S_ONE_PRE + \"12\", S_ONE_PRE + \"13\", S_TWO_PRE + \"24\",\n                      S_TWO_PRE + \"25\", S_ONE_PRE + \"17\", S_TWO_PRE + \"27\");\n    \n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n    \n    // many docs from diff shards, more then 10 from a single shard (two) should fail\n\n    e = expectThrows(SolrException.class, \"did not get a top level exception when more then 10 docs failed\",\n        () -> {\n      ArrayList<SolrInputDocument> docs = new ArrayList<SolrInputDocument>(30);\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"z\")));\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"z\")));\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"y\")));\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"y\")));\n      for (int i = 0; i < 11; i++) {\n        docs.add(doc(f(\"id\", S_ONE_PRE + i)));\n        docs.add(doc(f(\"id\", S_TWO_PRE + i), f(\"foo_i\", \"bogus_val\")));\n      }\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"x\"))); // may be skipped, more then 10 fails\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"x\"))); // may be skipped, more then 10 fails\n\n      update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n          \"commit\", \"true\"),\n          docs.toArray(new SolrInputDocument[docs.size()])).process(client);\n    });\n\n    {\n      // we can't make any reliable assertions about the error message, because\n      // it varies based on how the request was routed -- see SOLR-8830\n      assertEquals(\"not the type of error we were expecting (\"+e.code()+\"): \" + e.toString(),\n          // NOTE: we always expect a 400 because we know that's what we would get from these types of errors\n          // on a single node setup -- a 5xx type error isn't something we should have triggered\n          400, e.code());\n\n      // verify that the Exceptions metadata can tell us what failed.\n      NamedList<String> remoteErrMetadata = e.getMetadata();\n      assertNotNull(\"no metadata in: \" + e.toString(), remoteErrMetadata);\n      Set<ToleratedUpdateError> actualKnownErrs\n          = new LinkedHashSet<ToleratedUpdateError>(remoteErrMetadata.size());\n      int actualKnownErrsCount = 0;\n      for (int i = 0; i < remoteErrMetadata.size(); i++) {\n        ToleratedUpdateError err =\n            ToleratedUpdateError.parseMetadataIfToleratedUpdateError(remoteErrMetadata.getName(i),\n                remoteErrMetadata.getVal(i));\n        if (null == err) {\n          // some metadata unrelated to this update processor\n          continue;\n        }\n        actualKnownErrsCount++;\n        actualKnownErrs.add(err);\n      }\n      assertEquals(\"wrong number of errors in metadata: \" + remoteErrMetadata.toString(),\n          11, actualKnownErrsCount);\n      assertEquals(\"at least one dup error in metadata: \" + remoteErrMetadata.toString(),\n          actualKnownErrsCount, actualKnownErrs.size());\n      for (ToleratedUpdateError err : actualKnownErrs) {\n        assertEquals(\"only expected type of error is ADD: \" + err,\n            CmdType.ADD, err.getType());\n        assertTrue(\"failed id had unexpected prefix: \" + err,\n            err.getId().startsWith(S_TWO_PRE));\n        assertTrue(\"failed err msg didn't match expected value: \" + err,\n            err.getMessage().contains(\"bogus_val\"));\n      }\n    }\n\n    assertEquals(0, client.commit().getStatus()); // need to force since update didn't finish\n    assertQueryDocIds(client, true\n                      , S_ONE_PRE + \"z\", S_ONE_PRE + \"y\", S_TWO_PRE + \"z\", S_TWO_PRE + \"y\" // first\n                      //\n                      , S_ONE_PRE + \"0\", S_ONE_PRE + \"1\", S_ONE_PRE + \"2\", S_ONE_PRE + \"3\", S_ONE_PRE + \"4\"\n                      , S_ONE_PRE + \"5\", S_ONE_PRE + \"6\", S_ONE_PRE + \"7\", S_ONE_PRE + \"8\", S_ONE_PRE + \"9\"\n                      );\n    assertQueryDocIds(client, false\n                      // explicitly failed\n                      , S_TWO_PRE + \"0\", S_TWO_PRE + \"1\", S_TWO_PRE + \"2\", S_TWO_PRE + \"3\", S_TWO_PRE + \"4\"\n                      , S_TWO_PRE + \"5\", S_TWO_PRE + \"6\", S_TWO_PRE + \"7\", S_TWO_PRE + \"8\", S_TWO_PRE + \"9\"\n                      //\n                      // // we can't assert for sure these docs were skipped\n                      // // depending on shard we hit, they may have been added async before errors were exceeded\n                      // , S_ONE_PRE + \"x\", S_TWO_PRE + \"x\", // skipped\n                      );\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n    \n    // many docs from diff shards, more then 10 don't have any uniqueKey specified\n\n    e = expectThrows(SolrException.class,\n        \"did not get a top level exception when more then 10 docs mising uniqueKey\",\n        () -> {\n      ArrayList<SolrInputDocument> docs = new ArrayList<SolrInputDocument>(30);\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"z\")));\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"z\")));\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"y\")));\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"y\")));\n      for (int i = 0; i < 11; i++) {\n        // no \"id\" field\n        docs.add(doc(f(\"foo_i\", \"\" + i)));\n      }\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"x\"))); // may be skipped, more then 10 fails\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"x\"))); // may be skipped, more then 10 fails\n\n      update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n          \"commit\", \"true\"),\n          docs.toArray(new SolrInputDocument[docs.size()])).process(client);\n    });\n\n    {\n      // we can't make any reliable assertions about the error message, because\n      // it varies based on how the request was routed -- see SOLR-8830\n      assertEquals(\"not the type of error we were expecting (\"+e.code()+\"): \" + e.toString(),\n          // NOTE: we always expect a 400 because we know that's what we would get from these types of errors\n          // on a single node setup -- a 5xx type error isn't something we should have triggered\n          400, e.code());\n\n      // verify that the Exceptions metadata can tell us what failed.\n      NamedList<String> remoteErrMetadata = e.getMetadata();\n      assertNotNull(\"no metadata in: \" + e.toString(), remoteErrMetadata);\n      int actualKnownErrsCount = 0;\n      for (int i = 0; i < remoteErrMetadata.size(); i++) {\n        ToleratedUpdateError err =\n            ToleratedUpdateError.parseMetadataIfToleratedUpdateError(remoteErrMetadata.getName(i),\n                remoteErrMetadata.getVal(i));\n        if (null == err) {\n          // some metadata unrelated to this update processor\n          continue;\n        }\n        actualKnownErrsCount++;\n        assertEquals(\"only expected type of error is ADD: \" + err,\n            CmdType.ADD, err.getType());\n        assertTrue(\"failed id didn't match 'unknown': \" + err,\n            err.getId().contains(\"unknown\"));\n      }\n      assertEquals(\"wrong number of errors in metadata: \" + remoteErrMetadata.toString(),\n          11, actualKnownErrsCount);\n    }\n\n    assertEquals(0, client.commit().getStatus()); // need to force since update didn't finish\n    assertQueryDocIds(client, true\n                      , S_ONE_PRE + \"z\", S_ONE_PRE + \"y\", S_TWO_PRE + \"z\", S_TWO_PRE + \"y\" // first\n                      // // we can't assert for sure these docs were skipped or added\n                      // // depending on shard we hit, they may have been added async before errors were exceeded\n                      // , S_ONE_PRE + \"x\", S_TWO_PRE + \"x\" // skipped\n                      );\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n    \n    // many docs from diff shards, more then 10 from a single shard (two) should fail but\n    // request should still succeed because of maxErrors=-1 param\n\n    ArrayList<SolrInputDocument> docs = new ArrayList<SolrInputDocument>(30);\n    ArrayList<ExpectedErr> expectedErrs = new ArrayList<ExpectedErr>(30);\n    docs.add(doc(f(\"id\", S_ONE_PRE + \"z\")));\n    docs.add(doc(f(\"id\", S_TWO_PRE + \"z\")));\n    docs.add(doc(f(\"id\", S_ONE_PRE + \"y\")));\n    docs.add(doc(f(\"id\", S_TWO_PRE + \"y\")));\n    for (int i = 0; i < 11; i++) {\n      docs.add(doc(f(\"id\", S_ONE_PRE + i)));\n      docs.add(doc(f(\"id\", S_TWO_PRE + i), f(\"foo_i\", \"bogus_val\")));\n      expectedErrs.add(addErr(S_TWO_PRE + i));\n    }\n    docs.add(doc(f(\"id\", S_ONE_PRE + \"x\"))); \n    docs.add(doc(f(\"id\", S_TWO_PRE + \"x\"))); \n    \n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                        \"maxErrors\", \"-1\",\n                        \"commit\", \"true\"),\n                 docs.toArray(new SolrInputDocument[docs.size()])).process(client);\n    assertUpdateTolerantErrors(\"many docs from shard2 fail, but req should succeed\", rsp,\n                               expectedErrs.toArray(new ExpectedErr[expectedErrs.size()]));\n    assertQueryDocIds(client, true\n                      , S_ONE_PRE + \"z\", S_ONE_PRE + \"y\", S_TWO_PRE + \"z\", S_TWO_PRE + \"y\" // first\n                      , S_ONE_PRE + \"x\", S_TWO_PRE + \"x\" // later\n                      );\n\n  }\n\n","sourceOld":"  protected static void testVariousAdds(SolrClient client) throws Exception {\n    assertNotNull(\"client not initialized\", client);\n    \n    UpdateResponse rsp = null;\n\n    // 2 docs that are both on shard1, the first one should fail\n    for (int maxErrors : new int[] { -1, 2, 47, 10 }) {\n      // regardless of which of these maxErrors values we use, behavior should be the same...\n      rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                          \"maxErrors\", \"\"+maxErrors,\n                          \"commit\", \"true\"),\n                   doc(f(\"id\", S_ONE_PRE + \"42\"), f(\"foo_i\", \"bogus_value\")),\n                   doc(f(\"id\", S_ONE_PRE + \"666\"), f(\"foo_i\", \"1976\"))).process(client);\n      \n      assertEquals(0, rsp.getStatus());\n      assertUpdateTolerantAddErrors(\"single shard, 1st doc should fail\", rsp, S_ONE_PRE + \"42\");\n      assertEquals(0, client.commit().getStatus());\n      assertQueryDocIds(client, false, S_ONE_PRE + \"42\");\n      assertQueryDocIds(client, true, S_ONE_PRE + \"666\");\n\n      // ...only diff should be that we get an accurate report of the effective maxErrors\n      assertEquals(maxErrors, rsp.getResponseHeader().get(\"maxErrors\"));\n    }\n    \n    // 2 docs that are both on shard1, the second one should fail\n    \n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-not-set\",\n                        \"commit\", \"true\"),\n                 doc(f(\"id\", S_ONE_PRE + \"55\"), f(\"foo_i\", \"1976\")),\n                 doc(f(\"id\", S_ONE_PRE + \"77\"), f(\"foo_i\", \"bogus_val\"))).process(client);\n    \n    assertEquals(0, rsp.getStatus());\n    assertUpdateTolerantAddErrors(\"single shard, 2nd doc should fail\", rsp, S_ONE_PRE + \"77\");\n    assertQueryDocIds(client, false, S_ONE_PRE + \"77\");\n    assertQueryDocIds(client, true, S_ONE_PRE + \"666\", S_ONE_PRE + \"55\");\n    // since maxErrors is unset, we should get an \"unlimited\" value back\n    assertEquals(-1, rsp.getResponseHeader().get(\"maxErrors\"));\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n\n    // 2 docs on 2 diff shards, first of which should fail\n    \n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                        \"commit\", \"true\"),\n                 doc(f(\"id\", S_ONE_PRE + \"42\"), f(\"foo_i\", \"bogus_value\")),\n                 doc(f(\"id\", S_TWO_PRE + \"666\"), f(\"foo_i\", \"1976\"))).process(client);\n    \n    assertEquals(0, rsp.getStatus());\n    assertUpdateTolerantAddErrors(\"two shards, 1st doc should fail\", rsp, S_ONE_PRE + \"42\");\n    assertEquals(0, client.commit().getStatus());\n    assertQueryDocIds(client, false, S_ONE_PRE + \"42\");\n    assertQueryDocIds(client, true, S_TWO_PRE + \"666\");\n    \n    // 2 docs on 2 diff shards, second of which should fail\n\n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                        \"commit\", \"true\"),\n                 doc(f(\"id\", S_ONE_PRE + \"55\"), f(\"foo_i\", \"1976\")),\n                 doc(f(\"id\", S_TWO_PRE + \"77\"), f(\"foo_i\", \"bogus_val\"))).process(client);\n    \n    assertEquals(0, rsp.getStatus());\n    assertUpdateTolerantAddErrors(\"two shards, 2nd doc should fail\", rsp, S_TWO_PRE + \"77\");\n    assertQueryDocIds(client, false, S_TWO_PRE + \"77\");\n    assertQueryDocIds(client, true, S_TWO_PRE + \"666\", S_ONE_PRE + \"55\");\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n\n    // many docs from diff shards, 1 from each shard should fail\n    \n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                        \"commit\", \"true\"),\n                 doc(f(\"id\", S_ONE_PRE + \"11\")),\n                 doc(f(\"id\", S_TWO_PRE + \"21\")),\n                 doc(f(\"id\", S_ONE_PRE + \"12\")),\n                 doc(f(\"id\", S_TWO_PRE + \"22\"), f(\"foo_i\", \"bogus_val\")),\n                 doc(f(\"id\", S_ONE_PRE + \"13\")),\n                 doc(f(\"id\", S_TWO_PRE + \"23\")),\n                 doc(f(\"id\", S_ONE_PRE + \"14\")),\n                 doc(f(\"id\", S_TWO_PRE + \"24\")),\n                 doc(f(\"id\", S_ONE_PRE + \"15\"), f(\"foo_i\", \"bogus_val\")),\n                 doc(f(\"id\", S_TWO_PRE + \"25\")),\n                 doc(f(\"id\", S_ONE_PRE + \"16\")),\n                 doc(f(\"id\", S_TWO_PRE + \"26\"))).process(client);\n    \n    assertEquals(0, rsp.getStatus());\n    assertUpdateTolerantAddErrors(\"many docs, 1 from each shard should fail\", rsp,\n                                  S_ONE_PRE + \"15\",\n                                  S_TWO_PRE + \"22\");\n    assertQueryDocIds(client, false, S_TWO_PRE + \"22\", S_ONE_PRE + \"15\");\n    assertQueryDocIds(client, true,\n                      S_ONE_PRE + \"11\", S_TWO_PRE + \"21\", S_ONE_PRE + \"12\",\n                      S_ONE_PRE + \"13\", S_TWO_PRE + \"23\", S_ONE_PRE + \"14\", S_TWO_PRE + \"24\",\n                      S_TWO_PRE + \"25\", S_ONE_PRE + \"16\", S_TWO_PRE + \"26\");\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n\n    // many docs from diff shards, 1 from each shard should fail and 1 w/o uniqueKey\n    \n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                        \"commit\", \"true\"),\n                 doc(f(\"id\", S_ONE_PRE + \"11\")),\n                 doc(f(\"id\", S_TWO_PRE + \"21\")),\n                 doc(f(\"id\", S_ONE_PRE + \"12\")),\n                 doc(f(\"id\", S_TWO_PRE + \"22\"), f(\"foo_i\", \"bogus_val\")),\n                 doc(f(\"id\", S_ONE_PRE + \"13\")),\n                 doc(f(\"id\", S_TWO_PRE + \"23\")),\n                 doc(f(\"foo_i\", \"42\")),          // no \"id\"\n                 doc(f(\"id\", S_ONE_PRE + \"14\")),\n                 doc(f(\"id\", S_TWO_PRE + \"24\")),\n                 doc(f(\"id\", S_ONE_PRE + \"15\"), f(\"foo_i\", \"bogus_val\")),\n                 doc(f(\"id\", S_TWO_PRE + \"25\")),\n                 doc(f(\"id\", S_ONE_PRE + \"16\")),\n                 doc(f(\"id\", S_TWO_PRE + \"26\"))).process(client);\n    \n    assertEquals(0, rsp.getStatus());\n    assertUpdateTolerantAddErrors(\"many docs, 1 from each shard (+ no id) should fail\", rsp,\n                                  S_ONE_PRE + \"15\",\n                                  \"(unknown)\",\n                                  S_TWO_PRE + \"22\");\n    assertQueryDocIds(client, false, S_TWO_PRE + \"22\", S_ONE_PRE + \"15\");\n    assertQueryDocIds(client, true,\n                      S_ONE_PRE + \"11\", S_TWO_PRE + \"21\", S_ONE_PRE + \"12\",\n                      S_ONE_PRE + \"13\", S_TWO_PRE + \"23\", S_ONE_PRE + \"14\", S_TWO_PRE + \"24\",\n                      S_TWO_PRE + \"25\", S_ONE_PRE + \"16\", S_TWO_PRE + \"26\");\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n    \n    // many docs from diff shards, more then 10 (total) should fail\n\n    try {\n      rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                          \"commit\", \"true\"),\n                   doc(f(\"id\", S_ONE_PRE + \"11\")),\n                   doc(f(\"id\", S_TWO_PRE + \"21\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_ONE_PRE + \"12\")),\n                   doc(f(\"id\", S_TWO_PRE + \"22\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_ONE_PRE + \"13\")),\n                   doc(f(\"id\", S_TWO_PRE + \"23\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_ONE_PRE + \"14\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_TWO_PRE + \"24\")),\n                   doc(f(\"id\", S_ONE_PRE + \"15\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_TWO_PRE + \"25\")),\n                   doc(f(\"id\", S_ONE_PRE + \"16\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_TWO_PRE + \"26\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_ONE_PRE + \"17\")),\n                   doc(f(\"id\", S_TWO_PRE + \"27\")),\n                   doc(f(\"id\", S_ONE_PRE + \"18\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_TWO_PRE + \"28\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_ONE_PRE + \"19\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_TWO_PRE + \"29\"), f(\"foo_i\", \"bogus_val\")),\n                   doc(f(\"id\", S_ONE_PRE + \"10\")), // may be skipped, more then 10 fails\n                   doc(f(\"id\", S_TWO_PRE + \"20\"))  // may be skipped, more then 10 fails\n                   ).process(client);\n      \n      fail(\"did not get a top level exception when more then 10 docs failed: \" + rsp.toString());\n    } catch (SolrException e) {\n      // we can't make any reliable assertions about the error message, because\n      // it varies based on how the request was routed -- see SOLR-8830\n      assertEquals(\"not the type of error we were expecting (\"+e.code()+\"): \" + e.toString(),\n                   // NOTE: we always expect a 400 because we know that's what we would get from these types of errors\n                   // on a single node setup -- a 5xx type error isn't something we should have triggered\n                   400, e.code());\n\n      // verify that the Exceptions metadata can tell us what failed.\n      NamedList<String> remoteErrMetadata = e.getMetadata();\n      assertNotNull(\"no metadata in: \" + e.toString(), remoteErrMetadata);\n      Set<ToleratedUpdateError> actualKnownErrs\n        = new LinkedHashSet<ToleratedUpdateError>(remoteErrMetadata.size());\n      int actualKnownErrsCount = 0;\n      for (int i = 0; i < remoteErrMetadata.size(); i++) {\n        ToleratedUpdateError err =\n          ToleratedUpdateError.parseMetadataIfToleratedUpdateError(remoteErrMetadata.getName(i),\n                                                                   remoteErrMetadata.getVal(i));\n        if (null == err) {\n          // some metadata unrelated to this update processor\n          continue;\n        }\n        actualKnownErrsCount++;\n        actualKnownErrs.add(err);\n      }\n      assertEquals(\"wrong number of errors in metadata: \" + remoteErrMetadata.toString(),\n                   11, actualKnownErrsCount);\n      assertEquals(\"at least one dup error in metadata: \" + remoteErrMetadata.toString(),\n                   actualKnownErrsCount, actualKnownErrs.size());\n      for (ToleratedUpdateError err : actualKnownErrs) {\n        assertEquals(\"only expected type of error is ADD: \" + err,\n                     CmdType.ADD, err.getType());\n        assertTrue(\"failed err msg didn't match expected value: \" + err,\n                   err.getMessage().contains(\"bogus_val\"));\n      }\n    }\n    assertEquals(0, client.commit().getStatus()); // need to force since update didn't finish\n    assertQueryDocIds(client, false\n                      // explicitly failed\n                      , S_TWO_PRE + \"21\", S_TWO_PRE + \"22\", S_TWO_PRE + \"23\", S_ONE_PRE + \"14\"\n                      , S_ONE_PRE + \"15\", S_ONE_PRE + \"16\", S_TWO_PRE + \"26\", S_ONE_PRE + \"18\"\n                      , S_TWO_PRE + \"28\", S_ONE_PRE + \"19\", S_TWO_PRE + \"29\"\n                      //\n                      // // we can't assert for sure these docs were skipped\n                      // // depending on shard we hit, they may have been added async before errors were exceeded\n                      // , S_ONE_PRE + \"10\", S_TWO_PRE + \"20\" // skipped\n                      );\n    assertQueryDocIds(client, true,\n                      S_ONE_PRE + \"11\", S_ONE_PRE + \"12\", S_ONE_PRE + \"13\", S_TWO_PRE + \"24\",\n                      S_TWO_PRE + \"25\", S_ONE_PRE + \"17\", S_TWO_PRE + \"27\");\n    \n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n    \n    // many docs from diff shards, more then 10 from a single shard (two) should fail\n\n    try {\n      ArrayList<SolrInputDocument> docs = new ArrayList<SolrInputDocument>(30);\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"z\")));\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"z\")));\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"y\")));\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"y\")));\n      for (int i = 0; i < 11; i++) {\n        docs.add(doc(f(\"id\", S_ONE_PRE + i)));\n        docs.add(doc(f(\"id\", S_TWO_PRE + i), f(\"foo_i\", \"bogus_val\")));\n      }\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"x\"))); // may be skipped, more then 10 fails\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"x\"))); // may be skipped, more then 10 fails\n          \n      rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                          \"commit\", \"true\"),\n                   docs.toArray(new SolrInputDocument[docs.size()])).process(client);\n      \n      fail(\"did not get a top level exception when more then 10 docs failed: \" + rsp.toString());\n    } catch (SolrException e) {\n      // we can't make any reliable assertions about the error message, because\n      // it varies based on how the request was routed -- see SOLR-8830\n      assertEquals(\"not the type of error we were expecting (\"+e.code()+\"): \" + e.toString(),\n                   // NOTE: we always expect a 400 because we know that's what we would get from these types of errors\n                   // on a single node setup -- a 5xx type error isn't something we should have triggered\n                   400, e.code());\n\n      // verify that the Exceptions metadata can tell us what failed.\n      NamedList<String> remoteErrMetadata = e.getMetadata();\n      assertNotNull(\"no metadata in: \" + e.toString(), remoteErrMetadata);\n      Set<ToleratedUpdateError> actualKnownErrs\n        = new LinkedHashSet<ToleratedUpdateError>(remoteErrMetadata.size());\n      int actualKnownErrsCount = 0;\n      for (int i = 0; i < remoteErrMetadata.size(); i++) {\n        ToleratedUpdateError err =\n          ToleratedUpdateError.parseMetadataIfToleratedUpdateError(remoteErrMetadata.getName(i),\n                                                                   remoteErrMetadata.getVal(i));\n        if (null == err) {\n          // some metadata unrelated to this update processor\n          continue;\n        }\n        actualKnownErrsCount++;\n        actualKnownErrs.add(err);\n      }\n      assertEquals(\"wrong number of errors in metadata: \" + remoteErrMetadata.toString(),\n                   11, actualKnownErrsCount);\n      assertEquals(\"at least one dup error in metadata: \" + remoteErrMetadata.toString(),\n                   actualKnownErrsCount, actualKnownErrs.size());\n      for (ToleratedUpdateError err : actualKnownErrs) {\n        assertEquals(\"only expected type of error is ADD: \" + err,\n                     CmdType.ADD, err.getType());\n        assertTrue(\"failed id had unexpected prefix: \" + err,\n                   err.getId().startsWith(S_TWO_PRE));\n        assertTrue(\"failed err msg didn't match expected value: \" + err,\n                   err.getMessage().contains(\"bogus_val\"));\n      }\n           \n    }\n    assertEquals(0, client.commit().getStatus()); // need to force since update didn't finish\n    assertQueryDocIds(client, true\n                      , S_ONE_PRE + \"z\", S_ONE_PRE + \"y\", S_TWO_PRE + \"z\", S_TWO_PRE + \"y\" // first\n                      //\n                      , S_ONE_PRE + \"0\", S_ONE_PRE + \"1\", S_ONE_PRE + \"2\", S_ONE_PRE + \"3\", S_ONE_PRE + \"4\"\n                      , S_ONE_PRE + \"5\", S_ONE_PRE + \"6\", S_ONE_PRE + \"7\", S_ONE_PRE + \"8\", S_ONE_PRE + \"9\"\n                      );\n    assertQueryDocIds(client, false\n                      // explicitly failed\n                      , S_TWO_PRE + \"0\", S_TWO_PRE + \"1\", S_TWO_PRE + \"2\", S_TWO_PRE + \"3\", S_TWO_PRE + \"4\"\n                      , S_TWO_PRE + \"5\", S_TWO_PRE + \"6\", S_TWO_PRE + \"7\", S_TWO_PRE + \"8\", S_TWO_PRE + \"9\"\n                      //\n                      // // we can't assert for sure these docs were skipped\n                      // // depending on shard we hit, they may have been added async before errors were exceeded\n                      // , S_ONE_PRE + \"x\", S_TWO_PRE + \"x\", // skipped\n                      );\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n    \n    // many docs from diff shards, more then 10 don't have any uniqueKey specified\n\n    try {\n      ArrayList<SolrInputDocument> docs = new ArrayList<SolrInputDocument>(30);\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"z\")));\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"z\")));\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"y\")));\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"y\")));\n      for (int i = 0; i < 11; i++) {\n        // no \"id\" field\n        docs.add(doc(f(\"foo_i\", \"\" + i)));\n      }\n      docs.add(doc(f(\"id\", S_ONE_PRE + \"x\"))); // may be skipped, more then 10 fails\n      docs.add(doc(f(\"id\", S_TWO_PRE + \"x\"))); // may be skipped, more then 10 fails\n          \n      rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                          \"commit\", \"true\"),\n                   docs.toArray(new SolrInputDocument[docs.size()])).process(client);\n      \n      fail(\"did not get a top level exception when more then 10 docs mising uniqueKey: \" + rsp.toString());\n    } catch (SolrException e) {\n      // we can't make any reliable assertions about the error message, because\n      // it varies based on how the request was routed -- see SOLR-8830\n      assertEquals(\"not the type of error we were expecting (\"+e.code()+\"): \" + e.toString(),\n                   // NOTE: we always expect a 400 because we know that's what we would get from these types of errors\n                   // on a single node setup -- a 5xx type error isn't something we should have triggered\n                   400, e.code());\n\n      // verify that the Exceptions metadata can tell us what failed.\n      NamedList<String> remoteErrMetadata = e.getMetadata();\n      assertNotNull(\"no metadata in: \" + e.toString(), remoteErrMetadata);\n      int actualKnownErrsCount = 0;\n      for (int i = 0; i < remoteErrMetadata.size(); i++) {\n        ToleratedUpdateError err =\n          ToleratedUpdateError.parseMetadataIfToleratedUpdateError(remoteErrMetadata.getName(i),\n                                                                   remoteErrMetadata.getVal(i));\n        if (null == err) {\n          // some metadata unrelated to this update processor\n          continue;\n        }\n        actualKnownErrsCount++;\n        assertEquals(\"only expected type of error is ADD: \" + err,\n                     CmdType.ADD, err.getType());\n        assertTrue(\"failed id didn't match 'unknown': \" + err,\n                   err.getId().contains(\"unknown\"));\n      }\n      assertEquals(\"wrong number of errors in metadata: \" + remoteErrMetadata.toString(),\n                   11, actualKnownErrsCount);\n    }\n    assertEquals(0, client.commit().getStatus()); // need to force since update didn't finish\n    assertQueryDocIds(client, true\n                      , S_ONE_PRE + \"z\", S_ONE_PRE + \"y\", S_TWO_PRE + \"z\", S_TWO_PRE + \"y\" // first\n                      // // we can't assert for sure these docs were skipped or added\n                      // // depending on shard we hit, they may have been added async before errors were exceeded\n                      // , S_ONE_PRE + \"x\", S_TWO_PRE + \"x\" // skipped\n                      );\n\n    // clean slate\n    assertEquals(0, client.deleteByQuery(\"*:*\").getStatus());\n    \n    // many docs from diff shards, more then 10 from a single shard (two) should fail but\n    // request should still succeed because of maxErrors=-1 param\n\n    ArrayList<SolrInputDocument> docs = new ArrayList<SolrInputDocument>(30);\n    ArrayList<ExpectedErr> expectedErrs = new ArrayList<ExpectedErr>(30);\n    docs.add(doc(f(\"id\", S_ONE_PRE + \"z\")));\n    docs.add(doc(f(\"id\", S_TWO_PRE + \"z\")));\n    docs.add(doc(f(\"id\", S_ONE_PRE + \"y\")));\n    docs.add(doc(f(\"id\", S_TWO_PRE + \"y\")));\n    for (int i = 0; i < 11; i++) {\n      docs.add(doc(f(\"id\", S_ONE_PRE + i)));\n      docs.add(doc(f(\"id\", S_TWO_PRE + i), f(\"foo_i\", \"bogus_val\")));\n      expectedErrs.add(addErr(S_TWO_PRE + i));\n    }\n    docs.add(doc(f(\"id\", S_ONE_PRE + \"x\"))); \n    docs.add(doc(f(\"id\", S_TWO_PRE + \"x\"))); \n    \n    rsp = update(params(\"update.chain\", \"tolerant-chain-max-errors-10\",\n                        \"maxErrors\", \"-1\",\n                        \"commit\", \"true\"),\n                 docs.toArray(new SolrInputDocument[docs.size()])).process(client);\n    assertUpdateTolerantErrors(\"many docs from shard2 fail, but req should succeed\", rsp,\n                               expectedErrs.toArray(new ExpectedErr[expectedErrs.size()]));\n    assertQueryDocIds(client, true\n                      , S_ONE_PRE + \"z\", S_ONE_PRE + \"y\", S_TWO_PRE + \"z\", S_TWO_PRE + \"y\" // first\n                      , S_ONE_PRE + \"x\", S_TWO_PRE + \"x\" // later\n                      );\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"92f789dbd1886e4b468e61b0def88b29a3f55228":["f57cf082c4d2ee975c6a2034fcf3c13f9514e6ef"],"f57cf082c4d2ee975c6a2034fcf3c13f9514e6ef":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["92f789dbd1886e4b468e61b0def88b29a3f55228"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f57cf082c4d2ee975c6a2034fcf3c13f9514e6ef"],"92f789dbd1886e4b468e61b0def88b29a3f55228":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f57cf082c4d2ee975c6a2034fcf3c13f9514e6ef":["92f789dbd1886e4b468e61b0def88b29a3f55228"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}