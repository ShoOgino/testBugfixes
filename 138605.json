{"path":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","pathOld":"solr/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","sourceNew":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.reusableTokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start());\n            token.setEndOffset(matcher.end());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.reusableTokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start());\n            token.setEndOffset(matcher.end());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","pathOld":"solr/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","sourceNew":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.reusableTokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start());\n            token.setEndOffset(matcher.end());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.reusableTokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start());\n            token.setEndOffset(matcher.end());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","pathOld":"solr/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","sourceNew":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.reusableTokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start());\n            token.setEndOffset(matcher.end());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.reusableTokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start());\n            token.setEndOffset(matcher.end());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77d924c3b8deab5881ed0d996d597a4ea5bbc40a","date":1316977817,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","sourceNew":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.reusableTokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start());\n            token.setEndOffset(matcher.end());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n          stream.end();\n          stream.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.reusableTokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start());\n            token.setEndOffset(matcher.end());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"69e043c521d4e8db770cc140c63f5ef51f03426a","date":1317187614,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","sourceNew":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.tokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start());\n            token.setEndOffset(matcher.end());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n          stream.end();\n          stream.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.reusableTokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start());\n            token.setEndOffset(matcher.end());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n          stream.end();\n          stream.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4a1d67dfa126cb83a8dfeea520dbc2fae9ba823c","date":1323268936,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","sourceNew":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.tokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start() + offsetAtt.startOffset());\n            token.setEndOffset(matcher.start() + offsetAtt.endOffset());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n          stream.end();\n          stream.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.tokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start());\n            token.setEndOffset(matcher.end());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n          stream.end();\n          stream.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":["84b6c001c19319635b53dd80ee9fc1ba9a5b4574"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"69e6e5a85de57ea8b642c0b8c9e15a2d7d2d0054","date":1323283758,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","sourceNew":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.tokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start() + offsetAtt.startOffset());\n            token.setEndOffset(matcher.start() + offsetAtt.endOffset());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n          stream.end();\n          stream.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.tokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start());\n            token.setEndOffset(matcher.end());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n          stream.end();\n          stream.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","sourceNew":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.tokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start() + offsetAtt.startOffset());\n            token.setEndOffset(matcher.start() + offsetAtt.endOffset());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n          stream.end();\n          stream.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.tokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start());\n            token.setEndOffset(matcher.end());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n          stream.end();\n          stream.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dfe519e9d72e08fa9d4ffdec80b908a20c8c2b5e","date":1329752918,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","sourceNew":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          analyze(result, new StringReader(word), matcher.start());\n        } catch (IOException e) {\n          // TODO: shouldn't we log something?\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    TokenStream stream;\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          stream = analyzer.tokenStream(\"\", new StringReader(word));\n          // TODO: support custom attributes\n          CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);\n          FlagsAttribute flagsAtt = stream.addAttribute(FlagsAttribute.class);\n          TypeAttribute typeAtt = stream.addAttribute(TypeAttribute.class);\n          PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);\n          PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class);\n          OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);\n          stream.reset();\n          while (stream.incrementToken()) {\n            Token token = new Token();\n            token.copyBuffer(termAtt.buffer(), 0, termAtt.length());\n            token.setStartOffset(matcher.start() + offsetAtt.startOffset());\n            token.setEndOffset(matcher.start() + offsetAtt.endOffset());\n            token.setFlags(flagsAtt.getFlags());\n            token.setType(typeAtt.type());\n            token.setPayload(payloadAtt.getPayload());\n            token.setPositionIncrement(posIncAtt.getPositionIncrement());\n            result.add(token);\n          }\n          stream.end();\n          stream.close();\n        } catch (IOException e) {\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0ad9ec888e587ca9a3279368245cdf00aabdc108","date":1338832525,"type":3,"author":"James Dyer","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","sourceNew":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    String nextWord = null;\n    int nextStartIndex = 0;\n    String lastBooleanOp = null;\n    while (nextWord!=null || matcher.find()) {\n      String word = null;\n      int startIndex = 0;\n      if(nextWord != null) {\n        word = nextWord;\n        startIndex = nextStartIndex;\n        nextWord = null;\n      } else {\n        word = matcher.group(0);\n        startIndex = matcher.start();\n      }\n      if(matcher.find()) {\n        nextWord = matcher.group(0);\n        nextStartIndex = matcher.start();\n      }      \n      if(\"AND\".equals(word) || \"OR\".equals(word) || \"NOT\".equals(word)) {\n        lastBooleanOp = word;        \n        continue;\n      }\n      // treat \"AND NOT\" as \"NOT\"...\n      if (\"AND\".equals(nextWord)\n          && original.length() > nextStartIndex + 7\n          && original.substring(nextStartIndex, nextStartIndex + 7).equals(\n              \"AND NOT\")) {\n        nextWord = \"NOT\";\n      }\n      \n      int flagValue = 0;\n      if (word.charAt(0) == '-'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '-')) {\n        flagValue = PROHIBITED_TERM_FLAG;\n      } else if (word.charAt(0) == '+'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '+')) {\n        flagValue = REQUIRED_TERM_FLAG;\n      //we don't know the default operator so just assume the first operator isn't new.\n      } else if (nextWord != null\n          && lastBooleanOp != null \n          && !nextWord.equals(lastBooleanOp)\n          && (\"AND\".equals(nextWord) || \"OR\".equals(nextWord) || \"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      //...unless the 1st boolean operator is a NOT, because only AND/OR can be default.\n      } else if (nextWord != null\n          && lastBooleanOp == null\n          && !nextWord.equals(lastBooleanOp)\n          && (\"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      }\n      try {\n        analyze(result, new StringReader(word), startIndex, flagValue);\n      } catch (IOException e) {\n        // TODO: shouldn't we log something?\n      }   \n    }\n    if(lastBooleanOp != null) {\n      for(Token t : result) {\n        int f = t.getFlags();\n        t.setFlags(f |= QueryConverter.TERM_IN_BOOLEAN_QUERY_FLAG);\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    //TODO: Extract the words using a simple regex, but not query stuff, and then analyze them to produce the token stream\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    while (matcher.find()) {\n      String word = matcher.group(0);\n      if (word.equals(\"AND\") == false && word.equals(\"OR\") == false) {\n        try {\n          analyze(result, new StringReader(word), matcher.start());\n        } catch (IOException e) {\n          // TODO: shouldn't we log something?\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":["c83d6c4335f31cae14f625a222bc842f20073dcd","ef81e90e0ee5cb887cfea273fe414ae0c3b844ae"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c83d6c4335f31cae14f625a222bc842f20073dcd","date":1373306148,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","sourceNew":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    String nextWord = null;\n    int nextStartIndex = 0;\n    String lastBooleanOp = null;\n    while (nextWord!=null || matcher.find()) {\n      String word = null;\n      int startIndex = 0;\n      if(nextWord != null) {\n        word = nextWord;\n        startIndex = nextStartIndex;\n        nextWord = null;\n      } else {\n        word = matcher.group(0);\n        startIndex = matcher.start();\n      }\n      if(matcher.find()) {\n        nextWord = matcher.group(0);\n        nextStartIndex = matcher.start();\n      }      \n      if(\"AND\".equals(word) || \"OR\".equals(word) || \"NOT\".equals(word)) {\n        lastBooleanOp = word;        \n        continue;\n      }\n      // treat \"AND NOT\" as \"NOT\"...\n      if (\"AND\".equals(nextWord)\n          && original.length() > nextStartIndex + 7\n          && original.substring(nextStartIndex, nextStartIndex + 7).equals(\n              \"AND NOT\")) {\n        nextWord = \"NOT\";\n      }\n      \n      int flagValue = 0;\n      if (word.charAt(0) == '-'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '-')) {\n        flagValue = PROHIBITED_TERM_FLAG;\n      } else if (word.charAt(0) == '+'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '+')) {\n        flagValue = REQUIRED_TERM_FLAG;\n      //we don't know the default operator so just assume the first operator isn't new.\n      } else if (nextWord != null\n          && lastBooleanOp != null \n          && !nextWord.equals(lastBooleanOp)\n          && (\"AND\".equals(nextWord) || \"OR\".equals(nextWord) || \"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      //...unless the 1st boolean operator is a NOT, because only AND/OR can be default.\n      } else if (nextWord != null\n          && lastBooleanOp == null\n          && !nextWord.equals(lastBooleanOp)\n          && (\"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      }\n      try {\n        analyze(result, word, startIndex, flagValue);\n      } catch (IOException e) {\n        // TODO: shouldn't we log something?\n      }   \n    }\n    if(lastBooleanOp != null) {\n      for(Token t : result) {\n        int f = t.getFlags();\n        t.setFlags(f |= QueryConverter.TERM_IN_BOOLEAN_QUERY_FLAG);\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    String nextWord = null;\n    int nextStartIndex = 0;\n    String lastBooleanOp = null;\n    while (nextWord!=null || matcher.find()) {\n      String word = null;\n      int startIndex = 0;\n      if(nextWord != null) {\n        word = nextWord;\n        startIndex = nextStartIndex;\n        nextWord = null;\n      } else {\n        word = matcher.group(0);\n        startIndex = matcher.start();\n      }\n      if(matcher.find()) {\n        nextWord = matcher.group(0);\n        nextStartIndex = matcher.start();\n      }      \n      if(\"AND\".equals(word) || \"OR\".equals(word) || \"NOT\".equals(word)) {\n        lastBooleanOp = word;        \n        continue;\n      }\n      // treat \"AND NOT\" as \"NOT\"...\n      if (\"AND\".equals(nextWord)\n          && original.length() > nextStartIndex + 7\n          && original.substring(nextStartIndex, nextStartIndex + 7).equals(\n              \"AND NOT\")) {\n        nextWord = \"NOT\";\n      }\n      \n      int flagValue = 0;\n      if (word.charAt(0) == '-'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '-')) {\n        flagValue = PROHIBITED_TERM_FLAG;\n      } else if (word.charAt(0) == '+'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '+')) {\n        flagValue = REQUIRED_TERM_FLAG;\n      //we don't know the default operator so just assume the first operator isn't new.\n      } else if (nextWord != null\n          && lastBooleanOp != null \n          && !nextWord.equals(lastBooleanOp)\n          && (\"AND\".equals(nextWord) || \"OR\".equals(nextWord) || \"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      //...unless the 1st boolean operator is a NOT, because only AND/OR can be default.\n      } else if (nextWord != null\n          && lastBooleanOp == null\n          && !nextWord.equals(lastBooleanOp)\n          && (\"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      }\n      try {\n        analyze(result, new StringReader(word), startIndex, flagValue);\n      } catch (IOException e) {\n        // TODO: shouldn't we log something?\n      }   \n    }\n    if(lastBooleanOp != null) {\n      for(Token t : result) {\n        int f = t.getFlags();\n        t.setFlags(f |= QueryConverter.TERM_IN_BOOLEAN_QUERY_FLAG);\n      }\n    }\n    return result;\n  }\n\n","bugFix":["0ad9ec888e587ca9a3279368245cdf00aabdc108"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","sourceNew":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    String nextWord = null;\n    int nextStartIndex = 0;\n    String lastBooleanOp = null;\n    while (nextWord!=null || matcher.find()) {\n      String word = null;\n      int startIndex = 0;\n      if(nextWord != null) {\n        word = nextWord;\n        startIndex = nextStartIndex;\n        nextWord = null;\n      } else {\n        word = matcher.group(0);\n        startIndex = matcher.start();\n      }\n      if(matcher.find()) {\n        nextWord = matcher.group(0);\n        nextStartIndex = matcher.start();\n      }      \n      if(\"AND\".equals(word) || \"OR\".equals(word) || \"NOT\".equals(word)) {\n        lastBooleanOp = word;        \n        continue;\n      }\n      // treat \"AND NOT\" as \"NOT\"...\n      if (\"AND\".equals(nextWord)\n          && original.length() > nextStartIndex + 7\n          && original.substring(nextStartIndex, nextStartIndex + 7).equals(\n              \"AND NOT\")) {\n        nextWord = \"NOT\";\n      }\n      \n      int flagValue = 0;\n      if (word.charAt(0) == '-'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '-')) {\n        flagValue = PROHIBITED_TERM_FLAG;\n      } else if (word.charAt(0) == '+'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '+')) {\n        flagValue = REQUIRED_TERM_FLAG;\n      //we don't know the default operator so just assume the first operator isn't new.\n      } else if (nextWord != null\n          && lastBooleanOp != null \n          && !nextWord.equals(lastBooleanOp)\n          && (\"AND\".equals(nextWord) || \"OR\".equals(nextWord) || \"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      //...unless the 1st boolean operator is a NOT, because only AND/OR can be default.\n      } else if (nextWord != null\n          && lastBooleanOp == null\n          && !nextWord.equals(lastBooleanOp)\n          && (\"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      }\n      try {\n        analyze(result, word, startIndex, flagValue);\n      } catch (IOException e) {\n        // TODO: shouldn't we log something?\n      }   \n    }\n    if(lastBooleanOp != null) {\n      for(Token t : result) {\n        int f = t.getFlags();\n        t.setFlags(f |= QueryConverter.TERM_IN_BOOLEAN_QUERY_FLAG);\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    String nextWord = null;\n    int nextStartIndex = 0;\n    String lastBooleanOp = null;\n    while (nextWord!=null || matcher.find()) {\n      String word = null;\n      int startIndex = 0;\n      if(nextWord != null) {\n        word = nextWord;\n        startIndex = nextStartIndex;\n        nextWord = null;\n      } else {\n        word = matcher.group(0);\n        startIndex = matcher.start();\n      }\n      if(matcher.find()) {\n        nextWord = matcher.group(0);\n        nextStartIndex = matcher.start();\n      }      \n      if(\"AND\".equals(word) || \"OR\".equals(word) || \"NOT\".equals(word)) {\n        lastBooleanOp = word;        \n        continue;\n      }\n      // treat \"AND NOT\" as \"NOT\"...\n      if (\"AND\".equals(nextWord)\n          && original.length() > nextStartIndex + 7\n          && original.substring(nextStartIndex, nextStartIndex + 7).equals(\n              \"AND NOT\")) {\n        nextWord = \"NOT\";\n      }\n      \n      int flagValue = 0;\n      if (word.charAt(0) == '-'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '-')) {\n        flagValue = PROHIBITED_TERM_FLAG;\n      } else if (word.charAt(0) == '+'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '+')) {\n        flagValue = REQUIRED_TERM_FLAG;\n      //we don't know the default operator so just assume the first operator isn't new.\n      } else if (nextWord != null\n          && lastBooleanOp != null \n          && !nextWord.equals(lastBooleanOp)\n          && (\"AND\".equals(nextWord) || \"OR\".equals(nextWord) || \"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      //...unless the 1st boolean operator is a NOT, because only AND/OR can be default.\n      } else if (nextWord != null\n          && lastBooleanOp == null\n          && !nextWord.equals(lastBooleanOp)\n          && (\"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      }\n      try {\n        analyze(result, new StringReader(word), startIndex, flagValue);\n      } catch (IOException e) {\n        // TODO: shouldn't we log something?\n      }   \n    }\n    if(lastBooleanOp != null) {\n      for(Token t : result) {\n        int f = t.getFlags();\n        t.setFlags(f |= QueryConverter.TERM_IN_BOOLEAN_QUERY_FLAG);\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","sourceNew":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<>();\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    String nextWord = null;\n    int nextStartIndex = 0;\n    String lastBooleanOp = null;\n    while (nextWord!=null || matcher.find()) {\n      String word = null;\n      int startIndex = 0;\n      if(nextWord != null) {\n        word = nextWord;\n        startIndex = nextStartIndex;\n        nextWord = null;\n      } else {\n        word = matcher.group(0);\n        startIndex = matcher.start();\n      }\n      if(matcher.find()) {\n        nextWord = matcher.group(0);\n        nextStartIndex = matcher.start();\n      }      \n      if(\"AND\".equals(word) || \"OR\".equals(word) || \"NOT\".equals(word)) {\n        lastBooleanOp = word;        \n        continue;\n      }\n      // treat \"AND NOT\" as \"NOT\"...\n      if (\"AND\".equals(nextWord)\n          && original.length() > nextStartIndex + 7\n          && original.substring(nextStartIndex, nextStartIndex + 7).equals(\n              \"AND NOT\")) {\n        nextWord = \"NOT\";\n      }\n      \n      int flagValue = 0;\n      if (word.charAt(0) == '-'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '-')) {\n        flagValue = PROHIBITED_TERM_FLAG;\n      } else if (word.charAt(0) == '+'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '+')) {\n        flagValue = REQUIRED_TERM_FLAG;\n      //we don't know the default operator so just assume the first operator isn't new.\n      } else if (nextWord != null\n          && lastBooleanOp != null \n          && !nextWord.equals(lastBooleanOp)\n          && (\"AND\".equals(nextWord) || \"OR\".equals(nextWord) || \"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      //...unless the 1st boolean operator is a NOT, because only AND/OR can be default.\n      } else if (nextWord != null\n          && lastBooleanOp == null\n          && !nextWord.equals(lastBooleanOp)\n          && (\"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      }\n      try {\n        analyze(result, word, startIndex, flagValue);\n      } catch (IOException e) {\n        // TODO: shouldn't we log something?\n      }   \n    }\n    if(lastBooleanOp != null) {\n      for(Token t : result) {\n        int f = t.getFlags();\n        t.setFlags(f |= QueryConverter.TERM_IN_BOOLEAN_QUERY_FLAG);\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<Token>();\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    String nextWord = null;\n    int nextStartIndex = 0;\n    String lastBooleanOp = null;\n    while (nextWord!=null || matcher.find()) {\n      String word = null;\n      int startIndex = 0;\n      if(nextWord != null) {\n        word = nextWord;\n        startIndex = nextStartIndex;\n        nextWord = null;\n      } else {\n        word = matcher.group(0);\n        startIndex = matcher.start();\n      }\n      if(matcher.find()) {\n        nextWord = matcher.group(0);\n        nextStartIndex = matcher.start();\n      }      \n      if(\"AND\".equals(word) || \"OR\".equals(word) || \"NOT\".equals(word)) {\n        lastBooleanOp = word;        \n        continue;\n      }\n      // treat \"AND NOT\" as \"NOT\"...\n      if (\"AND\".equals(nextWord)\n          && original.length() > nextStartIndex + 7\n          && original.substring(nextStartIndex, nextStartIndex + 7).equals(\n              \"AND NOT\")) {\n        nextWord = \"NOT\";\n      }\n      \n      int flagValue = 0;\n      if (word.charAt(0) == '-'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '-')) {\n        flagValue = PROHIBITED_TERM_FLAG;\n      } else if (word.charAt(0) == '+'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '+')) {\n        flagValue = REQUIRED_TERM_FLAG;\n      //we don't know the default operator so just assume the first operator isn't new.\n      } else if (nextWord != null\n          && lastBooleanOp != null \n          && !nextWord.equals(lastBooleanOp)\n          && (\"AND\".equals(nextWord) || \"OR\".equals(nextWord) || \"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      //...unless the 1st boolean operator is a NOT, because only AND/OR can be default.\n      } else if (nextWord != null\n          && lastBooleanOp == null\n          && !nextWord.equals(lastBooleanOp)\n          && (\"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      }\n      try {\n        analyze(result, word, startIndex, flagValue);\n      } catch (IOException e) {\n        // TODO: shouldn't we log something?\n      }   \n    }\n    if(lastBooleanOp != null) {\n      for(Token t : result) {\n        int f = t.getFlags();\n        t.setFlags(f |= QueryConverter.TERM_IN_BOOLEAN_QUERY_FLAG);\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ef81e90e0ee5cb887cfea273fe414ae0c3b844ae","date":1449503740,"type":3,"author":"James Dyer","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/SpellingQueryConverter#convert(String).mjava","sourceNew":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    boolean mightContainRangeQuery = (original.indexOf('[') != -1 || original.indexOf('{') != -1)\n        && (original.indexOf(']') != -1 || original.indexOf('}') != -1);\n    Collection<Token> result = new ArrayList<>();\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    String nextWord = null;\n    int nextStartIndex = 0;\n    String lastBooleanOp = null;\n    while (nextWord!=null || matcher.find()) {\n      String word = null;\n      int startIndex = 0;\n      if(nextWord != null) {\n        word = nextWord;\n        startIndex = nextStartIndex;\n        nextWord = null;\n      } else {\n        word = matcher.group(0);\n        startIndex = matcher.start();\n      }\n      if(matcher.find()) {\n        nextWord = matcher.group(0);\n        nextStartIndex = matcher.start();\n      }  \n      if(mightContainRangeQuery && \"TO\".equals(word)) {\n        continue;\n      }\n      if(\"AND\".equals(word) || \"OR\".equals(word) || \"NOT\".equals(word)) {\n        lastBooleanOp = word;        \n        continue;\n      }\n      // treat \"AND NOT\" as \"NOT\"...\n      if (\"AND\".equals(nextWord)\n          && original.length() > nextStartIndex + 7\n          && original.substring(nextStartIndex, nextStartIndex + 7).equals(\n              \"AND NOT\")) {\n        nextWord = \"NOT\";\n      }\n      \n      int flagValue = 0;\n      if (word.charAt(0) == '-'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '-')) {\n        flagValue = PROHIBITED_TERM_FLAG;\n      } else if (word.charAt(0) == '+'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '+')) {\n        flagValue = REQUIRED_TERM_FLAG;\n      //we don't know the default operator so just assume the first operator isn't new.\n      } else if (nextWord != null\n          && lastBooleanOp != null \n          && !nextWord.equals(lastBooleanOp)\n          && (\"AND\".equals(nextWord) || \"OR\".equals(nextWord) || \"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      //...unless the 1st boolean operator is a NOT, because only AND/OR can be default.\n      } else if (nextWord != null\n          && lastBooleanOp == null\n          && !nextWord.equals(lastBooleanOp)\n          && (\"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      }\n      try {\n        analyze(result, word, startIndex, flagValue);\n      } catch (IOException e) {\n        // TODO: shouldn't we log something?\n      }   \n    }\n    if(lastBooleanOp != null) {\n      for(Token t : result) {\n        int f = t.getFlags();\n        t.setFlags(f |= QueryConverter.TERM_IN_BOOLEAN_QUERY_FLAG);\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  /**\n   * Converts the original query string to a collection of Lucene Tokens.\n   * @param original the original query string\n   * @return a Collection of Lucene Tokens\n   */\n  @Override\n  public Collection<Token> convert(String original) {\n    if (original == null) { // this can happen with q.alt = and no query\n      return Collections.emptyList();\n    }\n    Collection<Token> result = new ArrayList<>();\n    Matcher matcher = QUERY_REGEX.matcher(original);\n    String nextWord = null;\n    int nextStartIndex = 0;\n    String lastBooleanOp = null;\n    while (nextWord!=null || matcher.find()) {\n      String word = null;\n      int startIndex = 0;\n      if(nextWord != null) {\n        word = nextWord;\n        startIndex = nextStartIndex;\n        nextWord = null;\n      } else {\n        word = matcher.group(0);\n        startIndex = matcher.start();\n      }\n      if(matcher.find()) {\n        nextWord = matcher.group(0);\n        nextStartIndex = matcher.start();\n      }      \n      if(\"AND\".equals(word) || \"OR\".equals(word) || \"NOT\".equals(word)) {\n        lastBooleanOp = word;        \n        continue;\n      }\n      // treat \"AND NOT\" as \"NOT\"...\n      if (\"AND\".equals(nextWord)\n          && original.length() > nextStartIndex + 7\n          && original.substring(nextStartIndex, nextStartIndex + 7).equals(\n              \"AND NOT\")) {\n        nextWord = \"NOT\";\n      }\n      \n      int flagValue = 0;\n      if (word.charAt(0) == '-'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '-')) {\n        flagValue = PROHIBITED_TERM_FLAG;\n      } else if (word.charAt(0) == '+'\n          || (startIndex > 0 && original.charAt(startIndex - 1) == '+')) {\n        flagValue = REQUIRED_TERM_FLAG;\n      //we don't know the default operator so just assume the first operator isn't new.\n      } else if (nextWord != null\n          && lastBooleanOp != null \n          && !nextWord.equals(lastBooleanOp)\n          && (\"AND\".equals(nextWord) || \"OR\".equals(nextWord) || \"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      //...unless the 1st boolean operator is a NOT, because only AND/OR can be default.\n      } else if (nextWord != null\n          && lastBooleanOp == null\n          && !nextWord.equals(lastBooleanOp)\n          && (\"NOT\".equals(nextWord))) {\n        flagValue = TERM_PRECEDES_NEW_BOOLEAN_OPERATOR_FLAG;\n      }\n      try {\n        analyze(result, word, startIndex, flagValue);\n      } catch (IOException e) {\n        // TODO: shouldn't we log something?\n      }   \n    }\n    if(lastBooleanOp != null) {\n      for(Token t : result) {\n        int f = t.getFlags();\n        t.setFlags(f |= QueryConverter.TERM_IN_BOOLEAN_QUERY_FLAG);\n      }\n    }\n    return result;\n  }\n\n","bugFix":["0ad9ec888e587ca9a3279368245cdf00aabdc108"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"0ad9ec888e587ca9a3279368245cdf00aabdc108":["dfe519e9d72e08fa9d4ffdec80b908a20c8c2b5e"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["0ad9ec888e587ca9a3279368245cdf00aabdc108","c83d6c4335f31cae14f625a222bc842f20073dcd"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["69e043c521d4e8db770cc140c63f5ef51f03426a","4a1d67dfa126cb83a8dfeea520dbc2fae9ba823c"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"77d924c3b8deab5881ed0d996d597a4ea5bbc40a":["c26f00b574427b55127e869b935845554afde1fa"],"ef81e90e0ee5cb887cfea273fe414ae0c3b844ae":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"4a1d67dfa126cb83a8dfeea520dbc2fae9ba823c":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"dfe519e9d72e08fa9d4ffdec80b908a20c8c2b5e":["4a1d67dfa126cb83a8dfeea520dbc2fae9ba823c"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["0ad9ec888e587ca9a3279368245cdf00aabdc108"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"69e6e5a85de57ea8b642c0b8c9e15a2d7d2d0054":["69e043c521d4e8db770cc140c63f5ef51f03426a","4a1d67dfa126cb83a8dfeea520dbc2fae9ba823c"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["77d924c3b8deab5881ed0d996d597a4ea5bbc40a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ef81e90e0ee5cb887cfea273fe414ae0c3b844ae"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ef81e90e0ee5cb887cfea273fe414ae0c3b844ae"],"0ad9ec888e587ca9a3279368245cdf00aabdc108":["37a0f60745e53927c4c876cfe5b5a58170f0646c","c83d6c4335f31cae14f625a222bc842f20073dcd"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"c26f00b574427b55127e869b935845554afde1fa":["77d924c3b8deab5881ed0d996d597a4ea5bbc40a"],"77d924c3b8deab5881ed0d996d597a4ea5bbc40a":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"ef81e90e0ee5cb887cfea273fe414ae0c3b844ae":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4a1d67dfa126cb83a8dfeea520dbc2fae9ba823c":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","dfe519e9d72e08fa9d4ffdec80b908a20c8c2b5e","69e6e5a85de57ea8b642c0b8c9e15a2d7d2d0054"],"dfe519e9d72e08fa9d4ffdec80b908a20c8c2b5e":["0ad9ec888e587ca9a3279368245cdf00aabdc108"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","37a0f60745e53927c4c876cfe5b5a58170f0646c"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"69e6e5a85de57ea8b642c0b8c9e15a2d7d2d0054":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"69e043c521d4e8db770cc140c63f5ef51f03426a":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","4a1d67dfa126cb83a8dfeea520dbc2fae9ba823c","69e6e5a85de57ea8b642c0b8c9e15a2d7d2d0054"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","69e6e5a85de57ea8b642c0b8c9e15a2d7d2d0054","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}