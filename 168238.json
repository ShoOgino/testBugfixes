{"path":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testOneFuzzy().mjava","commits":[{"id":"dd81b1d062b9688a18721a1adfc489577479856a","date":1390711758,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testOneFuzzy().mjava","pathOld":"/dev/null","sourceNew":"  public void testOneFuzzy() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    Query query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // with prefix\n    query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1, 2);\n    topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // wrong field\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);\n    bq.add(new FuzzyQuery(new Term(\"bogus\", \"tets\"), 1), BooleanClause.Occur.SHOULD);\n    topDocs = searcher.search(bq, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", bq, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a test.\", snippets[0]);\n    assertEquals(\"Test a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testOneFuzzy().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testOneFuzzy().mjava","sourceNew":"  public void testOneFuzzy() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.shutdown();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    Query query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // with prefix\n    query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1, 2);\n    topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // wrong field\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);\n    bq.add(new FuzzyQuery(new Term(\"bogus\", \"tets\"), 1), BooleanClause.Occur.SHOULD);\n    topDocs = searcher.search(bq, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", bq, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a test.\", snippets[0]);\n    assertEquals(\"Test a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testOneFuzzy() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    Query query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // with prefix\n    query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1, 2);\n    topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // wrong field\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);\n    bq.add(new FuzzyQuery(new Term(\"bogus\", \"tets\"), 1), BooleanClause.Occur.SHOULD);\n    topDocs = searcher.search(bq, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", bq, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a test.\", snippets[0]);\n    assertEquals(\"Test a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testOneFuzzy().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testOneFuzzy().mjava","sourceNew":"  public void testOneFuzzy() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.shutdown();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    Query query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // with prefix\n    query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1, 2);\n    topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // wrong field\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);\n    bq.add(new FuzzyQuery(new Term(\"bogus\", \"tets\"), 1), BooleanClause.Occur.SHOULD);\n    topDocs = searcher.search(bq, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", bq, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a test.\", snippets[0]);\n    assertEquals(\"Test a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testOneFuzzy() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.shutdown();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    Query query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // with prefix\n    query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1, 2);\n    topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // wrong field\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);\n    bq.add(new FuzzyQuery(new Term(\"bogus\", \"tets\"), 1), BooleanClause.Occur.SHOULD);\n    topDocs = searcher.search(bq, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", bq, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a test.\", snippets[0]);\n    assertEquals(\"Test a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testOneFuzzy().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testOneFuzzy().mjava","sourceNew":"  public void testOneFuzzy() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    Query query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // with prefix\n    query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1, 2);\n    topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // wrong field\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);\n    bq.add(new FuzzyQuery(new Term(\"bogus\", \"tets\"), 1), BooleanClause.Occur.SHOULD);\n    topDocs = searcher.search(bq, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", bq, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a test.\", snippets[0]);\n    assertEquals(\"Test a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testOneFuzzy() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.shutdown();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    Query query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // with prefix\n    query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1, 2);\n    topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // wrong field\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);\n    bq.add(new FuzzyQuery(new Term(\"bogus\", \"tets\"), 1), BooleanClause.Occur.SHOULD);\n    topDocs = searcher.search(bq, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", bq, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a test.\", snippets[0]);\n    assertEquals(\"Test a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","date":1424799790,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testOneFuzzy().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testOneFuzzy().mjava","sourceNew":"  public void testOneFuzzy() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    Query query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1);\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // with prefix\n    query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1, 2);\n    topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // wrong field\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);\n    bq.add(new FuzzyQuery(new Term(\"bogus\", \"tets\"), 1), BooleanClause.Occur.SHOULD);\n    topDocs = searcher.search(bq, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", bq, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a test.\", snippets[0]);\n    assertEquals(\"Test a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testOneFuzzy() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    Query query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1);\n    TopDocs topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // with prefix\n    query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1, 2);\n    topDocs = searcher.search(query, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // wrong field\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);\n    bq.add(new FuzzyQuery(new Term(\"bogus\", \"tets\"), 1), BooleanClause.Occur.SHOULD);\n    topDocs = searcher.search(bq, null, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", bq, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a test.\", snippets[0]);\n    assertEquals(\"Test a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f68d01cf19df971dcdcb05e30247f4ad7ec9747","date":1434611645,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testOneFuzzy().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testOneFuzzy().mjava","sourceNew":"  public void testOneFuzzy() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    Query query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1);\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // with prefix\n    query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1, 2);\n    topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // wrong field\n    BooleanQuery.Builder bq = new BooleanQuery.Builder();\n    bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);\n    bq.add(new FuzzyQuery(new Term(\"bogus\", \"tets\"), 1), BooleanClause.Occur.SHOULD);\n    topDocs = searcher.search(bq.build(), 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", bq.build(), searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a test.\", snippets[0]);\n    assertEquals(\"Test a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testOneFuzzy() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    Query query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1);\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // with prefix\n    query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1, 2);\n    topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // wrong field\n    BooleanQuery bq = new BooleanQuery();\n    bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);\n    bq.add(new FuzzyQuery(new Term(\"bogus\", \"tets\"), 1), BooleanClause.Occur.SHOULD);\n    topDocs = searcher.search(bq, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", bq, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a test.\", snippets[0]);\n    assertEquals(\"Test a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"381618eac2691bb34ab9a3fca76ad55c6274517e","date":1495564791,"type":4,"author":"David Smiley","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testOneFuzzy().mjava","sourceNew":null,"sourceOld":"  public void testOneFuzzy() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    Query query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1);\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // with prefix\n    query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1, 2);\n    topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // wrong field\n    BooleanQuery.Builder bq = new BooleanQuery.Builder();\n    bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);\n    bq.add(new FuzzyQuery(new Term(\"bogus\", \"tets\"), 1), BooleanClause.Occur.SHOULD);\n    topDocs = searcher.search(bq.build(), 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", bq.build(), searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a test.\", snippets[0]);\n    assertEquals(\"Test a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":4,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/postingshighlight/TestMultiTermHighlighting#testOneFuzzy().mjava","sourceNew":null,"sourceOld":"  public void testOneFuzzy() throws Exception {\n    Directory dir = newDirectory();\n    // use simpleanalyzer for more natural tokenization (else \"test.\" is a token)\n    final Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    \n    FieldType offsetsType = new FieldType(TextField.TYPE_STORED);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field body = new Field(\"body\", \"\", offsetsType);\n    Document doc = new Document();\n    doc.add(body);\n    \n    body.setStringValue(\"This is a test.\");\n    iw.addDocument(doc);\n    body.setStringValue(\"Test a one sentence document.\");\n    iw.addDocument(doc);\n    \n    IndexReader ir = iw.getReader();\n    iw.close();\n    \n    IndexSearcher searcher = newSearcher(ir);\n    PostingsHighlighter highlighter = new PostingsHighlighter() {\n      @Override\n      protected Analyzer getIndexAnalyzer(String field) {\n        return analyzer;\n      }\n    };\n    Query query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1);\n    TopDocs topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    String snippets[] = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // with prefix\n    query = new FuzzyQuery(new Term(\"body\", \"tets\"), 1, 2);\n    topDocs = searcher.search(query, 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", query, searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a <b>test</b>.\", snippets[0]);\n    assertEquals(\"<b>Test</b> a one sentence document.\", snippets[1]);\n    \n    // wrong field\n    BooleanQuery.Builder bq = new BooleanQuery.Builder();\n    bq.add(new MatchAllDocsQuery(), BooleanClause.Occur.SHOULD);\n    bq.add(new FuzzyQuery(new Term(\"bogus\", \"tets\"), 1), BooleanClause.Occur.SHOULD);\n    topDocs = searcher.search(bq.build(), 10, Sort.INDEXORDER);\n    assertEquals(2, topDocs.totalHits);\n    snippets = highlighter.highlight(\"body\", bq.build(), searcher, topDocs);\n    assertEquals(2, snippets.length);\n    assertEquals(\"This is a test.\", snippets[0]);\n    assertEquals(\"Test a one sentence document.\", snippets[1]);\n    \n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"381618eac2691bb34ab9a3fca76ad55c6274517e":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"],"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747","381618eac2691bb34ab9a3fca76ad55c6274517e"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["dd81b1d062b9688a18721a1adfc489577479856a"],"dd81b1d062b9688a18721a1adfc489577479856a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["381618eac2691bb34ab9a3fca76ad55c6274517e"]},"commit2Childs":{"381618eac2691bb34ab9a3fca76ad55c6274517e":["e9017cf144952056066919f1ebc7897ff9bd71b1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["381618eac2691bb34ab9a3fca76ad55c6274517e","e9017cf144952056066919f1ebc7897ff9bd71b1"],"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["dd81b1d062b9688a18721a1adfc489577479856a"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"dd81b1d062b9688a18721a1adfc489577479856a":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["e9017cf144952056066919f1ebc7897ff9bd71b1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}