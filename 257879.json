{"path":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","commits":[{"id":"a9cc184ce59bfe09f739d9aaa34fdb28ddc738c3","date":1361894345,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final OpenBitSet termSet = new OpenBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public Comparator<BytesRef> getComparator() {\n          return BytesRef.getUTF8SortedAsUnicodeComparator();\n        }\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return new SortedSetDocValuesTermsEnum(docTermOrds);\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a OpenBitSet\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return DocIdSet.EMPTY_DOCIDSET;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["9274621789ce990dbfef455dabdf026bb3184821"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e129598ae448211d969dd7cdf2ad4558a0658a1","date":1362963550,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final OpenBitSet termSet = new OpenBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public Comparator<BytesRef> getComparator() {\n          return BytesRef.getUTF8SortedAsUnicodeComparator();\n        }\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a OpenBitSet\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return DocIdSet.EMPTY_DOCIDSET;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final OpenBitSet termSet = new OpenBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public Comparator<BytesRef> getComparator() {\n          return BytesRef.getUTF8SortedAsUnicodeComparator();\n        }\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return new SortedSetDocValuesTermsEnum(docTermOrds);\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a OpenBitSet\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return DocIdSet.EMPTY_DOCIDSET;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"64e6baad25b7155a116cb0126b4e2a06b945a5c5","date":1362976847,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final OpenBitSet termSet = new OpenBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public Comparator<BytesRef> getComparator() {\n          return BytesRef.getUTF8SortedAsUnicodeComparator();\n        }\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return new SortedSetDocValuesTermsEnum(docTermOrds);\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a OpenBitSet\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return DocIdSet.EMPTY_DOCIDSET;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final OpenBitSet termSet = new OpenBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public Comparator<BytesRef> getComparator() {\n          return BytesRef.getUTF8SortedAsUnicodeComparator();\n        }\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a OpenBitSet\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return DocIdSet.EMPTY_DOCIDSET;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5c2b6033d1fc841b41dbf56c765ce3dc053ecba6","date":1363054647,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final OpenBitSet termSet = new OpenBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public Comparator<BytesRef> getComparator() {\n          return BytesRef.getUTF8SortedAsUnicodeComparator();\n        }\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a OpenBitSet\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return DocIdSet.EMPTY_DOCIDSET;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final OpenBitSet termSet = new OpenBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public Comparator<BytesRef> getComparator() {\n          return BytesRef.getUTF8SortedAsUnicodeComparator();\n        }\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return new SortedSetDocValuesTermsEnum(docTermOrds);\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a OpenBitSet\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return DocIdSet.EMPTY_DOCIDSET;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"dc06632ede7e48a5ddc6917badec25c8336feedc","date":1366983006,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final OpenBitSet termSet = new OpenBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public Comparator<BytesRef> getComparator() {\n          return BytesRef.getUTF8SortedAsUnicodeComparator();\n        }\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a OpenBitSet\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final OpenBitSet termSet = new OpenBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public Comparator<BytesRef> getComparator() {\n          return BytesRef.getUTF8SortedAsUnicodeComparator();\n        }\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a OpenBitSet\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return DocIdSet.EMPTY_DOCIDSET;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5","date":1379624229,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final OpenBitSet termSet = new OpenBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a OpenBitSet\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final OpenBitSet termSet = new OpenBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public Comparator<BytesRef> getComparator() {\n          return BytesRef.getUTF8SortedAsUnicodeComparator();\n        }\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a OpenBitSet\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"34bbd0c9efc37fd35a3ffdb47172aaebf7ab06db","date":1381416174,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final OpenBitSet termSet = new OpenBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a OpenBitSet\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final OpenBitSet termSet = new OpenBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a OpenBitSet\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3995f83351082af8ae83bb017e63c56818fc1568","date":1392047063,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final OpenBitSet termSet = new OpenBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a OpenBitSet\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c","date":1399816179,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = DocValues.getSortedSet(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9274621789ce990dbfef455dabdf026bb3184821","date":1400046684,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = DocValues.getSortedSet(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new DocValuesDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = DocValues.getSortedSet(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","bugFix":["a9cc184ce59bfe09f739d9aaa34fdb28ddc738c3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93dd449115a9247533e44bab47e8429e5dccbc6d","date":1400258396,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = DocValues.getSortedSet(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new DocValuesDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"56572ec06f1407c066d6b7399413178b33176cd8","date":1400495675,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = DocValues.getSortedSet(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new DocValuesDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = FieldCache.DEFAULT.getDocTermOrds(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new FieldCacheDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":4,"author":"Ryan Ernst","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocTermOrdsRewriteMethod.MultiTermQueryDocTermOrdsWrapperFilter#getDocIdSet(AtomicReaderContext,Bits).mjava","sourceNew":null,"sourceOld":"    /**\n     * Returns a DocIdSet with documents that should be permitted in search\n     * results.\n     */\n    @Override\n    public DocIdSet getDocIdSet(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n      final SortedSetDocValues docTermOrds = DocValues.getSortedSet(context.reader(), query.field);\n      // Cannot use FixedBitSet because we require long index (ord):\n      final LongBitSet termSet = new LongBitSet(docTermOrds.getValueCount());\n      TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n        \n        @Override\n        public TermsEnum iterator(TermsEnum reuse) {\n          return docTermOrds.termsEnum();\n        }\n\n        @Override\n        public long getSumTotalTermFreq() {\n          return -1;\n        }\n\n        @Override\n        public long getSumDocFreq() {\n          return -1;\n        }\n\n        @Override\n        public int getDocCount() {\n          return -1;\n        }\n\n        @Override\n        public long size() {\n          return -1;\n        }\n\n        @Override\n        public boolean hasFreqs() {\n          return false;\n        }\n\n        @Override\n        public boolean hasOffsets() {\n          return false;\n        }\n\n        @Override\n        public boolean hasPositions() {\n          return false;\n        }\n        \n        @Override\n        public boolean hasPayloads() {\n          return false;\n        }\n      });\n      \n      assert termsEnum != null;\n      if (termsEnum.next() != null) {\n        // fill into a bitset\n        do {\n          termSet.set(termsEnum.ord());\n        } while (termsEnum.next() != null);\n      } else {\n        return null;\n      }\n      \n      return new DocValuesDocIdSet(context.reader().maxDoc(), acceptDocs) {\n        @Override\n        protected final boolean matchDoc(int doc) throws ArrayIndexOutOfBoundsException {\n          docTermOrds.setDocument(doc);\n          long ord;\n          // TODO: we could track max bit set and early terminate (since they come in sorted order)\n          while ((ord = docTermOrds.nextOrd()) != SortedSetDocValues.NO_MORE_ORDS) {\n            if (termSet.get(ord)) {\n              return true;\n            }\n          }\n          return false;\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"dc06632ede7e48a5ddc6917badec25c8336feedc":["5c2b6033d1fc841b41dbf56c765ce3dc053ecba6"],"a9cc184ce59bfe09f739d9aaa34fdb28ddc738c3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9274621789ce990dbfef455dabdf026bb3184821":["b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c"],"34bbd0c9efc37fd35a3ffdb47172aaebf7ab06db":["519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5"],"b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c":["3995f83351082af8ae83bb017e63c56818fc1568"],"56572ec06f1407c066d6b7399413178b33176cd8":["3995f83351082af8ae83bb017e63c56818fc1568","93dd449115a9247533e44bab47e8429e5dccbc6d"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["93dd449115a9247533e44bab47e8429e5dccbc6d"],"5c2b6033d1fc841b41dbf56c765ce3dc053ecba6":["64e6baad25b7155a116cb0126b4e2a06b945a5c5"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["3995f83351082af8ae83bb017e63c56818fc1568","9274621789ce990dbfef455dabdf026bb3184821"],"7e129598ae448211d969dd7cdf2ad4558a0658a1":["a9cc184ce59bfe09f739d9aaa34fdb28ddc738c3"],"519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5":["dc06632ede7e48a5ddc6917badec25c8336feedc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"64e6baad25b7155a116cb0126b4e2a06b945a5c5":["7e129598ae448211d969dd7cdf2ad4558a0658a1"],"3995f83351082af8ae83bb017e63c56818fc1568":["34bbd0c9efc37fd35a3ffdb47172aaebf7ab06db"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c9fb5f46e264daf5ba3860defe623a89d202dd87"]},"commit2Childs":{"dc06632ede7e48a5ddc6917badec25c8336feedc":["519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5"],"a9cc184ce59bfe09f739d9aaa34fdb28ddc738c3":["7e129598ae448211d969dd7cdf2ad4558a0658a1"],"9274621789ce990dbfef455dabdf026bb3184821":["93dd449115a9247533e44bab47e8429e5dccbc6d"],"34bbd0c9efc37fd35a3ffdb47172aaebf7ab06db":["3995f83351082af8ae83bb017e63c56818fc1568"],"b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c":["9274621789ce990dbfef455dabdf026bb3184821"],"56572ec06f1407c066d6b7399413178b33176cd8":[],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5c2b6033d1fc841b41dbf56c765ce3dc053ecba6":["dc06632ede7e48a5ddc6917badec25c8336feedc"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["56572ec06f1407c066d6b7399413178b33176cd8","c9fb5f46e264daf5ba3860defe623a89d202dd87"],"7e129598ae448211d969dd7cdf2ad4558a0658a1":["64e6baad25b7155a116cb0126b4e2a06b945a5c5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a9cc184ce59bfe09f739d9aaa34fdb28ddc738c3"],"519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5":["34bbd0c9efc37fd35a3ffdb47172aaebf7ab06db"],"64e6baad25b7155a116cb0126b4e2a06b945a5c5":["5c2b6033d1fc841b41dbf56c765ce3dc053ecba6"],"3995f83351082af8ae83bb017e63c56818fc1568":["b70a13d2b73512ad6b204e9ad8fe09ffeeda3c2c","56572ec06f1407c066d6b7399413178b33176cd8","93dd449115a9247533e44bab47e8429e5dccbc6d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["56572ec06f1407c066d6b7399413178b33176cd8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}