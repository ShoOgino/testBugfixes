{"path":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","commits":[{"id":"770281b8a8459cafcdd2354b6a06078fea2d83c9","date":1077308096,"type":0,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","pathOld":"/dev/null","sourceNew":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        Token next = null;\n        List terms = new ArrayList();\n        try {\n          while ((next = stream.next()) != null)\n          {\n            terms.add(next.termText());\n          }\n          processTerms((String[])terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e2cb543b41c145f33390f460ee743d6693c9c6c","date":1219243087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","sourceNew":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        List terms = new ArrayList();\n        try {\n          final Token reusableToken = new Token();\n          for (Token nextToken = stream.next(reusableToken); nextToken != null; nextToken = stream.next(reusableToken)) {\n            terms.add(nextToken.term());\n          }\n          processTerms((String[])terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","sourceOld":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        Token next = null;\n        List terms = new ArrayList();\n        try {\n          while ((next = stream.next()) != null)\n          {\n            terms.add(next.termText());\n          }\n          processTerms((String[])terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223","date":1227051709,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","sourceNew":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        List terms = new ArrayList();\n        try {\n          if (stream.useNewAPI()) {\n            stream.reset();\n            TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);\n            while (stream.incrementToken()) {\n              terms.add(termAtt.term());\n            }\n          } else {  \n            final Token reusableToken = new Token();\n            for (Token nextToken = stream.next(reusableToken); nextToken != null; nextToken = stream.next(reusableToken)) {\n              terms.add(nextToken.term());\n            }\n          }\n          processTerms((String[])terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","sourceOld":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        List terms = new ArrayList();\n        try {\n          final Token reusableToken = new Token();\n          for (Token nextToken = stream.next(reusableToken); nextToken != null; nextToken = stream.next(reusableToken)) {\n            terms.add(nextToken.term());\n          }\n          processTerms((String[])terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ec8b5a20a12931b8d7e616c79c5248ae06cc5568","date":1248471948,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","sourceNew":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        List terms = new ArrayList();\n        try {\n          boolean hasMoreTokens = false;\n          \n          stream.reset(); \n          TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);\n\n          hasMoreTokens = stream.incrementToken();\n          while (hasMoreTokens) {\n            terms.add(termAtt.term());\n            hasMoreTokens = stream.incrementToken();\n          }\n          processTerms((String[])terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","sourceOld":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        List terms = new ArrayList();\n        try {\n          if (stream.useNewAPI()) {\n            stream.reset();\n            TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);\n            while (stream.incrementToken()) {\n              terms.add(termAtt.term());\n            }\n          } else {  \n            final Token reusableToken = new Token();\n            for (Token nextToken = stream.next(reusableToken); nextToken != null; nextToken = stream.next(reusableToken)) {\n              terms.add(nextToken.term());\n            }\n          }\n          processTerms((String[])terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"efa6f2b2265151f8faaf69272253e065734ec9d4","date":1250942675,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","sourceNew":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        List terms = new ArrayList();\n        try {\n          boolean hasMoreTokens = false;\n          \n          stream.reset(); \n          TermAttribute termAtt = (TermAttribute) stream.addAttribute(TermAttribute.class);\n\n          hasMoreTokens = stream.incrementToken();\n          while (hasMoreTokens) {\n            terms.add(termAtt.term());\n            hasMoreTokens = stream.incrementToken();\n          }\n          processTerms((String[])terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","sourceOld":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        List terms = new ArrayList();\n        try {\n          boolean hasMoreTokens = false;\n          \n          stream.reset(); \n          TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);\n\n          hasMoreTokens = stream.incrementToken();\n          while (hasMoreTokens) {\n            terms.add(termAtt.term());\n            hasMoreTokens = stream.incrementToken();\n          }\n          processTerms((String[])terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8d78f014fded44fbde905f4f84cdc21907b371e8","date":1254383623,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","sourceNew":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        List terms = new ArrayList();\n        try {\n          boolean hasMoreTokens = false;\n          \n          stream.reset(); \n          TermAttribute termAtt = stream.addAttribute(TermAttribute.class);\n\n          hasMoreTokens = stream.incrementToken();\n          while (hasMoreTokens) {\n            terms.add(termAtt.term());\n            hasMoreTokens = stream.incrementToken();\n          }\n          processTerms((String[])terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","sourceOld":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        List terms = new ArrayList();\n        try {\n          boolean hasMoreTokens = false;\n          \n          stream.reset(); \n          TermAttribute termAtt = (TermAttribute) stream.addAttribute(TermAttribute.class);\n\n          hasMoreTokens = stream.incrementToken();\n          while (hasMoreTokens) {\n            terms.add(termAtt.term());\n            hasMoreTokens = stream.incrementToken();\n          }\n          processTerms((String[])terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ef82ff03e4016c705811b2658e81471a645c0e49","date":1255900293,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","sourceNew":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        List<String> terms = new ArrayList<String>();\n        try {\n          boolean hasMoreTokens = false;\n          \n          stream.reset(); \n          TermAttribute termAtt = stream.addAttribute(TermAttribute.class);\n\n          hasMoreTokens = stream.incrementToken();\n          while (hasMoreTokens) {\n            terms.add(termAtt.term());\n            hasMoreTokens = stream.incrementToken();\n          }\n          processTerms((String[])terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","sourceOld":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        List terms = new ArrayList();\n        try {\n          boolean hasMoreTokens = false;\n          \n          stream.reset(); \n          TermAttribute termAtt = stream.addAttribute(TermAttribute.class);\n\n          hasMoreTokens = stream.incrementToken();\n          while (hasMoreTokens) {\n            terms.add(termAtt.term());\n            hasMoreTokens = stream.incrementToken();\n          }\n          processTerms((String[])terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"20645c714ca2a7b7707c2707d58ee9fa384c7362","date":1256074979,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","sourceNew":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        List<String> terms = new ArrayList<String>();\n        try {\n          boolean hasMoreTokens = false;\n          \n          stream.reset(); \n          TermAttribute termAtt = stream.addAttribute(TermAttribute.class);\n\n          hasMoreTokens = stream.incrementToken();\n          while (hasMoreTokens) {\n            terms.add(termAtt.term());\n            hasMoreTokens = stream.incrementToken();\n          }\n          processTerms(terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","sourceOld":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        List<String> terms = new ArrayList<String>();\n        try {\n          boolean hasMoreTokens = false;\n          \n          stream.reset(); \n          TermAttribute termAtt = stream.addAttribute(TermAttribute.class);\n\n          hasMoreTokens = stream.incrementToken();\n          while (hasMoreTokens) {\n            terms.add(termAtt.term());\n            hasMoreTokens = stream.incrementToken();\n          }\n          processTerms((String[])terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","pathOld":"src/java/org/apache/lucene/search/QueryTermVector#QueryTermVector(String,Analyzer).mjava","sourceNew":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        List<String> terms = new ArrayList<String>();\n        try {\n          boolean hasMoreTokens = false;\n          \n          stream.reset(); \n          TermAttribute termAtt = stream.addAttribute(TermAttribute.class);\n\n          hasMoreTokens = stream.incrementToken();\n          while (hasMoreTokens) {\n            terms.add(termAtt.term());\n            hasMoreTokens = stream.incrementToken();\n          }\n          processTerms(terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","sourceOld":"  public QueryTermVector(String queryString, Analyzer analyzer) {    \n    if (analyzer != null)\n    {\n      TokenStream stream = analyzer.tokenStream(\"\", new StringReader(queryString));\n      if (stream != null)\n      {\n        List<String> terms = new ArrayList<String>();\n        try {\n          boolean hasMoreTokens = false;\n          \n          stream.reset(); \n          TermAttribute termAtt = stream.addAttribute(TermAttribute.class);\n\n          hasMoreTokens = stream.incrementToken();\n          while (hasMoreTokens) {\n            terms.add(termAtt.term());\n            hasMoreTokens = stream.incrementToken();\n          }\n          processTerms(terms.toArray(new String[terms.size()]));\n        } catch (IOException e) {\n        }\n      }\n    }                                                              \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["770281b8a8459cafcdd2354b6a06078fea2d83c9"],"770281b8a8459cafcdd2354b6a06078fea2d83c9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"ef82ff03e4016c705811b2658e81471a645c0e49":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"20645c714ca2a7b7707c2707d58ee9fa384c7362":["ef82ff03e4016c705811b2658e81471a645c0e49"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["efa6f2b2265151f8faaf69272253e065734ec9d4"],"efa6f2b2265151f8faaf69272253e065734ec9d4":["ec8b5a20a12931b8d7e616c79c5248ae06cc5568"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["20645c714ca2a7b7707c2707d58ee9fa384c7362"],"ec8b5a20a12931b8d7e616c79c5248ae06cc5568":["74a5e7f20b4a444da9df3b2c0f331fa7a1f64223"]},"commit2Childs":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["74a5e7f20b4a444da9df3b2c0f331fa7a1f64223"],"770281b8a8459cafcdd2354b6a06078fea2d83c9":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"74a5e7f20b4a444da9df3b2c0f331fa7a1f64223":["ec8b5a20a12931b8d7e616c79c5248ae06cc5568"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["770281b8a8459cafcdd2354b6a06078fea2d83c9"],"ef82ff03e4016c705811b2658e81471a645c0e49":["20645c714ca2a7b7707c2707d58ee9fa384c7362"],"20645c714ca2a7b7707c2707d58ee9fa384c7362":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["ef82ff03e4016c705811b2658e81471a645c0e49"],"efa6f2b2265151f8faaf69272253e065734ec9d4":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"ec8b5a20a12931b8d7e616c79c5248ae06cc5568":["efa6f2b2265151f8faaf69272253e065734ec9d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}