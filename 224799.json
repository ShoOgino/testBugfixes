{"path":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","commits":[{"id":"368714b5b6663ca71a0cba34a94e6032ccdff3f2","date":1329821210,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(SegmentReader).mjava","sourceNew":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      int computedFieldCount = 0;\n      final Fields fields = reader.fields();\n      if (fields == null) {\n        msg(\"OK [no fields/terms]\");\n        return status;\n      }\n     \n      DocsEnum docs = null;\n      DocsEnum docsAndFreqs = null;\n      DocsAndPositionsEnum postings = null;\n\n      String lastField = null;\n      final FieldsEnum fieldsEnum = fields.iterator();\n      while(true) {\n        final String field = fieldsEnum.next();\n        if (field == null) {\n          break;\n        }\n        // MultiFieldsEnum relies upon this order...\n        if (lastField != null && field.compareTo(lastField) <= 0) {\n          throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n        }\n        lastField = field;\n        \n        // check that the field is in fieldinfos, and is indexed.\n        // TODO: add a separate test to check this for different reader impls\n        FieldInfo fi = fieldInfos.fieldInfo(field);\n        if (fi == null) {\n          throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n        }\n        if (!fi.isIndexed) {\n          throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n        }\n\n        // TODO: really the codec should not return a field\n        // from FieldsEnum if it has no Terms... but we do\n        // this today:\n        // assert fields.terms(field) != null;\n        computedFieldCount++;\n        \n        final Terms terms = fieldsEnum.terms();\n        if (terms == null) {\n          continue;\n        }\n\n        final TermsEnum termsEnum = terms.iterator(null);\n\n        boolean hasOrd = true;\n        final long termCountStart = status.termCount;\n\n        BytesRef lastTerm = null;\n\n        Comparator<BytesRef> termComp = terms.getComparator();\n\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        FixedBitSet visitedDocs = new FixedBitSet(reader.maxDoc());\n        while(true) {\n\n          final BytesRef term = termsEnum.next();\n          if (term == null) {\n            break;\n          }\n\n          // make sure terms arrive in order according to\n          // the comp\n          if (lastTerm == null) {\n            lastTerm = BytesRef.deepCopyOf(term);\n          } else {\n            if (termComp.compare(lastTerm, term) >= 0) {\n              throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n            }\n            lastTerm.copyBytes(term);\n          }\n\n          final int docFreq = termsEnum.docFreq();\n          if (docFreq <= 0) {\n            throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n          }\n          status.totFreq += docFreq;\n          sumDocFreq += docFreq;\n\n          docs = termsEnum.docs(liveDocs, docs, false);\n          docsAndFreqs = termsEnum.docs(liveDocs, docsAndFreqs, true);\n          postings = termsEnum.docsAndPositions(liveDocs, postings, false);\n\n          if (hasOrd) {\n            long ord = -1;\n            try {\n              ord = termsEnum.ord();\n            } catch (UnsupportedOperationException uoe) {\n              hasOrd = false;\n            }\n\n            if (hasOrd) {\n              final long ordExpected = status.termCount - termCountStart;\n              if (ord != ordExpected) {\n                throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n              }\n            }\n          }\n\n          status.termCount++;\n\n          final DocsEnum docs2;\n          final DocsEnum docsAndFreqs2;\n          final boolean hasPositions;\n          final boolean hasFreqs;\n          if (postings != null) {\n            docs2 = postings;\n            docsAndFreqs2 = postings;\n            hasPositions = true;\n            hasFreqs = true;\n          } else if (docsAndFreqs != null) {\n            docs2 = docsAndFreqs;\n            docsAndFreqs2 = docsAndFreqs;\n            hasPositions = false;\n            hasFreqs = true;\n          } else {\n            docs2 = docs;\n            docsAndFreqs2 = null;\n            hasPositions = false;\n            hasFreqs = false;\n          }\n\n          int lastDoc = -1;\n          int docCount = 0;\n          long totalTermFreq = 0;\n          while(true) {\n            final int doc = docs2.nextDoc();\n            if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            }\n            visitedDocs.set(doc);\n            int freq = -1;\n            if (hasFreqs) {\n              freq = docsAndFreqs2.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n              }\n              status.totPos += freq;\n              totalTermFreq += freq;\n            }\n            docCount++;\n\n            if (doc <= lastDoc) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            }\n            if (doc >= maxDoc) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n            }\n\n            lastDoc = doc;\n            \n            int lastPos = -1;\n            if (hasPositions) {\n              for(int j=0;j<freq;j++) {\n                final int pos = postings.nextPosition();\n                if (pos < -1) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPos) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n                }\n                lastPos = pos;\n                if (postings.hasPayload()) {\n                  postings.getPayload();\n                }\n              }\n            }\n          }\n          \n          final long totalTermFreq2 = termsEnum.totalTermFreq();\n          final boolean hasTotalTermFreq = postings != null && totalTermFreq2 != -1;\n\n          // Re-count if there are deleted docs:\n          if (reader.hasDeletions()) {\n            if (hasFreqs) {\n              final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs, true);\n              docCount = 0;\n              totalTermFreq = 0;\n              while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                visitedDocs.set(docsNoDel.docID());\n                docCount++;\n                totalTermFreq += docsNoDel.freq();\n              }\n            } else {\n              final DocsEnum docsNoDel = termsEnum.docs(null, docs, false);\n              docCount = 0;\n              totalTermFreq = -1;\n              while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                visitedDocs.set(docsNoDel.docID());\n                docCount++;\n              }\n            }\n          }\n\n          if (docCount != docFreq) {\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n          }\n          if (hasTotalTermFreq) {\n            if (totalTermFreq2 <= 0) {\n              throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n            }\n            sumTotalTermFreq += totalTermFreq;\n            if (totalTermFreq != totalTermFreq2) {\n              throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n            }\n          }\n\n          // Test skipping\n          if (hasPositions) {\n            for(int idx=0;idx<7;idx++) {\n              final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n              postings = termsEnum.docsAndPositions(liveDocs, postings, false);\n              final int docID = postings.advance(skipDocID);\n              if (docID == DocsEnum.NO_MORE_DOCS) {\n                break;\n              } else {\n                if (docID < skipDocID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n                }\n                final int freq = postings.freq();\n                if (freq <= 0) {\n                  throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n                }\n                int lastPosition = -1;\n                for(int posUpto=0;posUpto<freq;posUpto++) {\n                  final int pos = postings.nextPosition();\n                  if (pos < 0) {\n                    throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                  }\n                  if (pos < lastPosition) {\n                    throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                  }\n                  lastPosition = pos;\n                } \n\n                final int nextDocID = postings.nextDoc();\n                if (nextDocID == DocsEnum.NO_MORE_DOCS) {\n                  break;\n                }\n                if (nextDocID <= docID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n                }\n              }\n            }\n          } else {\n            for(int idx=0;idx<7;idx++) {\n              final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n              docs = termsEnum.docs(liveDocs, docs, false);\n              final int docID = docs.advance(skipDocID);\n              if (docID == DocsEnum.NO_MORE_DOCS) {\n                break;\n              } else {\n                if (docID < skipDocID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n                }\n                final int nextDocID = docs.nextDoc();\n                if (nextDocID == DocsEnum.NO_MORE_DOCS) {\n                  break;\n                }\n                if (nextDocID <= docID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n                }\n              }\n            }\n          }\n        }\n        \n        final Terms fieldTerms = fields.terms(field);\n        if (fieldTerms == null) {\n          // Unusual: the FieldsEnum returned a field but\n          // the Terms for that field is null; this should\n          // only happen if it's a ghost field (field with\n          // no terms, eg there used to be terms but all\n          // docs got deleted and then merged away):\n          // make sure TermsEnum is empty:\n          final Terms fieldTerms2 = fieldsEnum.terms();\n          if (fieldTerms2 != null && fieldTerms2.iterator(null).next() != null) {\n            throw new RuntimeException(\"Fields.terms(field=\" + field + \") returned null yet the field appears to have terms\");\n          }\n        } else {\n          if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n            final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n            assert stats != null;\n            if (status.blockTreeStats == null) {\n              status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n            }\n            status.blockTreeStats.put(field, stats);\n          }\n\n          if (sumTotalTermFreq != 0) {\n            final long v = fields.terms(field).getSumTotalTermFreq();\n            if (v != -1 && sumTotalTermFreq != v) {\n              throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n            }\n          }\n        \n          if (sumDocFreq != 0) {\n            final long v = fields.terms(field).getSumDocFreq();\n            if (v != -1 && sumDocFreq != v) {\n              throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n            }\n          }\n        \n          if (fieldTerms != null) {\n            final int v = fieldTerms.getDocCount();\n            if (v != -1 && visitedDocs.cardinality() != v) {\n              throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n            }\n          }\n\n          // Test seek to last term:\n          if (lastTerm != null) {\n            if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n              throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n            }\n\n            is.search(new TermQuery(new Term(field, lastTerm)), 1);\n          }\n          \n          // check unique term count\n          long termCount = -1;\n          \n          if (status.termCount-termCountStart > 0) {\n            termCount = fields.terms(field).getUniqueTermCount();\n            \n            if (termCount != -1 && termCount != status.termCount - termCountStart) {\n              throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + (status.termCount - termCountStart));\n            }\n          }\n          \n          // Test seeking by ord\n          if (hasOrd && status.termCount-termCountStart > 0) {\n            int seekCount = (int) Math.min(10000L, termCount);\n            if (seekCount > 0) {\n              BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n              // Seek by ord\n              for(int i=seekCount-1;i>=0;i--) {\n                long ord = i*(termCount/seekCount);\n                termsEnum.seekExact(ord);\n                seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n              }\n\n              // Seek by term\n              long totDocCount = 0;\n              for(int i=seekCount-1;i>=0;i--) {\n                if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                  throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n                }\n              \n                docs = termsEnum.docs(liveDocs, docs, false);\n                if (docs == null) {\n                  throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n                }\n\n                while(docs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n                  totDocCount++;\n                }\n              }\n\n              // TermQuery\n              long totDocCount2 = 0;\n              for(int i=0;i<seekCount;i++) {\n                totDocCount2 += is.search(new TermQuery(new Term(field, seekTerms[i])), 1).totalHits;\n              }\n\n              if (totDocCount != totDocCount2) {\n                throw new RuntimeException(\"search to seek terms produced wrong number of hits: \" + totDocCount + \" vs \" + totDocCount2);\n              }\n            }\n          }\n        }\n      }\n      \n      int fieldCount = fields.getUniqueFieldCount();\n      \n      if (fieldCount != -1) {\n        if (fieldCount < 0) {\n          throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n        }\n        if (fieldCount != computedFieldCount) {\n          throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n        }\n      }\n\n      // for most implementations, this is boring (just the sum across all fields)\n      // but codecs that don't work per-field like preflex actually implement this,\n      // but don't implement it on Terms, so the check isn't redundant.\n      long uniqueTermCountAllFields = reader.getUniqueTermCount();\n      \n      // this means something is seriously screwed, e.g. we are somehow getting enclosed in PFCW!!!!!!\n      \n      if (uniqueTermCountAllFields == -1) {\n        throw new RuntimeException(\"invalid termCount: -1\");\n     }\n\n      if (status.termCount != uniqueTermCountAllFields) {\n        throw new RuntimeException(\"termCount mismatch \" + uniqueTermCountAllFields + \" vs \" + (status.termCount));\n      }\n\n      msg(\"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n\n      if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n        for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n          infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n          infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n        }\n      }\n\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      int computedFieldCount = 0;\n      final Fields fields = reader.fields();\n      if (fields == null) {\n        msg(\"OK [no fields/terms]\");\n        return status;\n      }\n     \n      DocsEnum docs = null;\n      DocsEnum docsAndFreqs = null;\n      DocsAndPositionsEnum postings = null;\n\n      final FieldsEnum fieldsEnum = fields.iterator();\n      while(true) {\n        final String field = fieldsEnum.next();\n        if (field == null) {\n          break;\n        }\n\n        // TODO: really the codec should not return a field\n        // from FieldsEnum if it has to Terms... but we do\n        // this today:\n        // assert fields.terms(field) != null;\n        computedFieldCount++;\n        \n        final Terms terms = fieldsEnum.terms();\n        if (terms == null) {\n          continue;\n        }\n\n        final TermsEnum termsEnum = terms.iterator(null);\n\n        boolean hasOrd = true;\n        final long termCountStart = status.termCount;\n\n        BytesRef lastTerm = null;\n\n        Comparator<BytesRef> termComp = terms.getComparator();\n\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        FixedBitSet visitedDocs = new FixedBitSet(reader.maxDoc());\n        while(true) {\n\n          final BytesRef term = termsEnum.next();\n          if (term == null) {\n            break;\n          }\n\n          // make sure terms arrive in order according to\n          // the comp\n          if (lastTerm == null) {\n            lastTerm = BytesRef.deepCopyOf(term);\n          } else {\n            if (termComp.compare(lastTerm, term) >= 0) {\n              throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n            }\n            lastTerm.copyBytes(term);\n          }\n\n          final int docFreq = termsEnum.docFreq();\n          if (docFreq <= 0) {\n            throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n          }\n          status.totFreq += docFreq;\n          sumDocFreq += docFreq;\n\n          docs = termsEnum.docs(liveDocs, docs, false);\n          docsAndFreqs = termsEnum.docs(liveDocs, docsAndFreqs, true);\n          postings = termsEnum.docsAndPositions(liveDocs, postings, false);\n\n          if (hasOrd) {\n            long ord = -1;\n            try {\n              ord = termsEnum.ord();\n            } catch (UnsupportedOperationException uoe) {\n              hasOrd = false;\n            }\n\n            if (hasOrd) {\n              final long ordExpected = status.termCount - termCountStart;\n              if (ord != ordExpected) {\n                throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n              }\n            }\n          }\n\n          status.termCount++;\n\n          final DocsEnum docs2;\n          final DocsEnum docsAndFreqs2;\n          final boolean hasPositions;\n          final boolean hasFreqs;\n          if (postings != null) {\n            docs2 = postings;\n            docsAndFreqs2 = postings;\n            hasPositions = true;\n            hasFreqs = true;\n          } else if (docsAndFreqs != null) {\n            docs2 = docsAndFreqs;\n            docsAndFreqs2 = docsAndFreqs;\n            hasPositions = false;\n            hasFreqs = true;\n          } else {\n            docs2 = docs;\n            docsAndFreqs2 = null;\n            hasPositions = false;\n            hasFreqs = false;\n          }\n\n          int lastDoc = -1;\n          int docCount = 0;\n          long totalTermFreq = 0;\n          while(true) {\n            final int doc = docs2.nextDoc();\n            if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            }\n            visitedDocs.set(doc);\n            int freq = -1;\n            if (hasFreqs) {\n              freq = docsAndFreqs2.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n              }\n              status.totPos += freq;\n              totalTermFreq += freq;\n            }\n            docCount++;\n\n            if (doc <= lastDoc) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            }\n            if (doc >= maxDoc) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n            }\n\n            lastDoc = doc;\n            \n            int lastPos = -1;\n            if (hasPositions) {\n              for(int j=0;j<freq;j++) {\n                final int pos = postings.nextPosition();\n                if (pos < -1) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPos) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n                }\n                lastPos = pos;\n                if (postings.hasPayload()) {\n                  postings.getPayload();\n                }\n              }\n            }\n          }\n          \n          final long totalTermFreq2 = termsEnum.totalTermFreq();\n          final boolean hasTotalTermFreq = postings != null && totalTermFreq2 != -1;\n\n          // Re-count if there are deleted docs:\n          if (reader.hasDeletions()) {\n            if (hasFreqs) {\n              final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs, true);\n              docCount = 0;\n              totalTermFreq = 0;\n              while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                visitedDocs.set(docsNoDel.docID());\n                docCount++;\n                totalTermFreq += docsNoDel.freq();\n              }\n            } else {\n              final DocsEnum docsNoDel = termsEnum.docs(null, docs, false);\n              docCount = 0;\n              totalTermFreq = -1;\n              while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                visitedDocs.set(docsNoDel.docID());\n                docCount++;\n              }\n            }\n          }\n\n          if (docCount != docFreq) {\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n          }\n          if (hasTotalTermFreq) {\n            if (totalTermFreq2 <= 0) {\n              throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n            }\n            sumTotalTermFreq += totalTermFreq;\n            if (totalTermFreq != totalTermFreq2) {\n              throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n            }\n          }\n\n          // Test skipping\n          if (hasPositions) {\n            for(int idx=0;idx<7;idx++) {\n              final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n              postings = termsEnum.docsAndPositions(liveDocs, postings, false);\n              final int docID = postings.advance(skipDocID);\n              if (docID == DocsEnum.NO_MORE_DOCS) {\n                break;\n              } else {\n                if (docID < skipDocID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n                }\n                final int freq = postings.freq();\n                if (freq <= 0) {\n                  throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n                }\n                int lastPosition = -1;\n                for(int posUpto=0;posUpto<freq;posUpto++) {\n                  final int pos = postings.nextPosition();\n                  if (pos < 0) {\n                    throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                  }\n                  if (pos < lastPosition) {\n                    throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                  }\n                  lastPosition = pos;\n                } \n\n                final int nextDocID = postings.nextDoc();\n                if (nextDocID == DocsEnum.NO_MORE_DOCS) {\n                  break;\n                }\n                if (nextDocID <= docID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n                }\n              }\n            }\n          } else {\n            for(int idx=0;idx<7;idx++) {\n              final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n              docs = termsEnum.docs(liveDocs, docs, false);\n              final int docID = docs.advance(skipDocID);\n              if (docID == DocsEnum.NO_MORE_DOCS) {\n                break;\n              } else {\n                if (docID < skipDocID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n                }\n                final int nextDocID = docs.nextDoc();\n                if (nextDocID == DocsEnum.NO_MORE_DOCS) {\n                  break;\n                }\n                if (nextDocID <= docID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n                }\n              }\n            }\n          }\n        }\n        \n        final Terms fieldTerms = fields.terms(field);\n        if (fieldTerms == null) {\n          // Unusual: the FieldsEnum returned a field but\n          // the Terms for that field is null; this should\n          // only happen if it's a ghost field (field with\n          // no terms, eg there used to be terms but all\n          // docs got deleted and then merged away):\n          // make sure TermsEnum is empty:\n          final Terms fieldTerms2 = fieldsEnum.terms();\n          if (fieldTerms2 != null && fieldTerms2.iterator(null).next() != null) {\n            throw new RuntimeException(\"Fields.terms(field=\" + field + \") returned null yet the field appears to have terms\");\n          }\n        } else {\n          if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n            final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n            assert stats != null;\n            if (status.blockTreeStats == null) {\n              status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n            }\n            status.blockTreeStats.put(field, stats);\n          }\n\n          if (sumTotalTermFreq != 0) {\n            final long v = fields.terms(field).getSumTotalTermFreq();\n            if (v != -1 && sumTotalTermFreq != v) {\n              throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n            }\n          }\n        \n          if (sumDocFreq != 0) {\n            final long v = fields.terms(field).getSumDocFreq();\n            if (v != -1 && sumDocFreq != v) {\n              throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n            }\n          }\n        \n          if (fieldTerms != null) {\n            final int v = fieldTerms.getDocCount();\n            if (v != -1 && visitedDocs.cardinality() != v) {\n              throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n            }\n          }\n\n          // Test seek to last term:\n          if (lastTerm != null) {\n            if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n              throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n            }\n\n            is.search(new TermQuery(new Term(field, lastTerm)), 1);\n          }\n          \n          // check unique term count\n          long termCount = -1;\n          \n          if (status.termCount-termCountStart > 0) {\n            termCount = fields.terms(field).getUniqueTermCount();\n            \n            if (termCount != -1 && termCount != status.termCount - termCountStart) {\n              throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + (status.termCount - termCountStart));\n            }\n          }\n          \n          // Test seeking by ord\n          if (hasOrd && status.termCount-termCountStart > 0) {\n            int seekCount = (int) Math.min(10000L, termCount);\n            if (seekCount > 0) {\n              BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n              // Seek by ord\n              for(int i=seekCount-1;i>=0;i--) {\n                long ord = i*(termCount/seekCount);\n                termsEnum.seekExact(ord);\n                seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n              }\n\n              // Seek by term\n              long totDocCount = 0;\n              for(int i=seekCount-1;i>=0;i--) {\n                if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                  throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n                }\n              \n                docs = termsEnum.docs(liveDocs, docs, false);\n                if (docs == null) {\n                  throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n                }\n\n                while(docs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n                  totDocCount++;\n                }\n              }\n\n              // TermQuery\n              long totDocCount2 = 0;\n              for(int i=0;i<seekCount;i++) {\n                totDocCount2 += is.search(new TermQuery(new Term(field, seekTerms[i])), 1).totalHits;\n              }\n\n              if (totDocCount != totDocCount2) {\n                throw new RuntimeException(\"search to seek terms produced wrong number of hits: \" + totDocCount + \" vs \" + totDocCount2);\n              }\n            }\n          }\n        }\n      }\n      \n      int fieldCount = fields.getUniqueFieldCount();\n      \n      if (fieldCount != -1) {\n        if (fieldCount < 0) {\n          throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n        }\n        if (fieldCount != computedFieldCount) {\n          throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n        }\n      }\n\n      // for most implementations, this is boring (just the sum across all fields)\n      // but codecs that don't work per-field like preflex actually implement this,\n      // but don't implement it on Terms, so the check isn't redundant.\n      long uniqueTermCountAllFields = reader.getUniqueTermCount();\n      \n      // this means something is seriously screwed, e.g. we are somehow getting enclosed in PFCW!!!!!!\n      \n      if (uniqueTermCountAllFields == -1) {\n        throw new RuntimeException(\"invalid termCount: -1\");\n     }\n\n      if (status.termCount != uniqueTermCountAllFields) {\n        throw new RuntimeException(\"termCount mismatch \" + uniqueTermCountAllFields + \" vs \" + (status.termCount));\n      }\n\n      msg(\"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n\n      if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n        for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n          infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n          infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n        }\n      }\n\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","sourceNew":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      int computedFieldCount = 0;\n      final Fields fields = reader.fields();\n      if (fields == null) {\n        msg(\"OK [no fields/terms]\");\n        return status;\n      }\n     \n      DocsEnum docs = null;\n      DocsEnum docsAndFreqs = null;\n      DocsAndPositionsEnum postings = null;\n\n      String lastField = null;\n      final FieldsEnum fieldsEnum = fields.iterator();\n      while(true) {\n        final String field = fieldsEnum.next();\n        if (field == null) {\n          break;\n        }\n        // MultiFieldsEnum relies upon this order...\n        if (lastField != null && field.compareTo(lastField) <= 0) {\n          throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n        }\n        lastField = field;\n        \n        // check that the field is in fieldinfos, and is indexed.\n        // TODO: add a separate test to check this for different reader impls\n        FieldInfo fi = fieldInfos.fieldInfo(field);\n        if (fi == null) {\n          throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n        }\n        if (!fi.isIndexed) {\n          throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n        }\n\n        // TODO: really the codec should not return a field\n        // from FieldsEnum if it has no Terms... but we do\n        // this today:\n        // assert fields.terms(field) != null;\n        computedFieldCount++;\n        \n        final Terms terms = fieldsEnum.terms();\n        if (terms == null) {\n          continue;\n        }\n\n        final TermsEnum termsEnum = terms.iterator(null);\n\n        boolean hasOrd = true;\n        final long termCountStart = status.termCount;\n\n        BytesRef lastTerm = null;\n\n        Comparator<BytesRef> termComp = terms.getComparator();\n\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        FixedBitSet visitedDocs = new FixedBitSet(reader.maxDoc());\n        while(true) {\n\n          final BytesRef term = termsEnum.next();\n          if (term == null) {\n            break;\n          }\n\n          // make sure terms arrive in order according to\n          // the comp\n          if (lastTerm == null) {\n            lastTerm = BytesRef.deepCopyOf(term);\n          } else {\n            if (termComp.compare(lastTerm, term) >= 0) {\n              throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n            }\n            lastTerm.copyBytes(term);\n          }\n\n          final int docFreq = termsEnum.docFreq();\n          if (docFreq <= 0) {\n            throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n          }\n          status.totFreq += docFreq;\n          sumDocFreq += docFreq;\n\n          docs = termsEnum.docs(liveDocs, docs, false);\n          docsAndFreqs = termsEnum.docs(liveDocs, docsAndFreqs, true);\n          postings = termsEnum.docsAndPositions(liveDocs, postings, false);\n\n          if (hasOrd) {\n            long ord = -1;\n            try {\n              ord = termsEnum.ord();\n            } catch (UnsupportedOperationException uoe) {\n              hasOrd = false;\n            }\n\n            if (hasOrd) {\n              final long ordExpected = status.termCount - termCountStart;\n              if (ord != ordExpected) {\n                throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n              }\n            }\n          }\n\n          status.termCount++;\n\n          final DocsEnum docs2;\n          final DocsEnum docsAndFreqs2;\n          final boolean hasPositions;\n          final boolean hasFreqs;\n          if (postings != null) {\n            docs2 = postings;\n            docsAndFreqs2 = postings;\n            hasPositions = true;\n            hasFreqs = true;\n          } else if (docsAndFreqs != null) {\n            docs2 = docsAndFreqs;\n            docsAndFreqs2 = docsAndFreqs;\n            hasPositions = false;\n            hasFreqs = true;\n          } else {\n            docs2 = docs;\n            docsAndFreqs2 = null;\n            hasPositions = false;\n            hasFreqs = false;\n          }\n\n          int lastDoc = -1;\n          int docCount = 0;\n          long totalTermFreq = 0;\n          while(true) {\n            final int doc = docs2.nextDoc();\n            if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            }\n            visitedDocs.set(doc);\n            int freq = -1;\n            if (hasFreqs) {\n              freq = docsAndFreqs2.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n              }\n              status.totPos += freq;\n              totalTermFreq += freq;\n            }\n            docCount++;\n\n            if (doc <= lastDoc) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            }\n            if (doc >= maxDoc) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n            }\n\n            lastDoc = doc;\n            \n            int lastPos = -1;\n            if (hasPositions) {\n              for(int j=0;j<freq;j++) {\n                final int pos = postings.nextPosition();\n                if (pos < -1) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPos) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n                }\n                lastPos = pos;\n                if (postings.hasPayload()) {\n                  postings.getPayload();\n                }\n              }\n            }\n          }\n          \n          final long totalTermFreq2 = termsEnum.totalTermFreq();\n          final boolean hasTotalTermFreq = postings != null && totalTermFreq2 != -1;\n\n          // Re-count if there are deleted docs:\n          if (reader.hasDeletions()) {\n            if (hasFreqs) {\n              final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs, true);\n              docCount = 0;\n              totalTermFreq = 0;\n              while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                visitedDocs.set(docsNoDel.docID());\n                docCount++;\n                totalTermFreq += docsNoDel.freq();\n              }\n            } else {\n              final DocsEnum docsNoDel = termsEnum.docs(null, docs, false);\n              docCount = 0;\n              totalTermFreq = -1;\n              while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                visitedDocs.set(docsNoDel.docID());\n                docCount++;\n              }\n            }\n          }\n\n          if (docCount != docFreq) {\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n          }\n          if (hasTotalTermFreq) {\n            if (totalTermFreq2 <= 0) {\n              throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n            }\n            sumTotalTermFreq += totalTermFreq;\n            if (totalTermFreq != totalTermFreq2) {\n              throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n            }\n          }\n\n          // Test skipping\n          if (hasPositions) {\n            for(int idx=0;idx<7;idx++) {\n              final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n              postings = termsEnum.docsAndPositions(liveDocs, postings, false);\n              final int docID = postings.advance(skipDocID);\n              if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              } else {\n                if (docID < skipDocID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n                }\n                final int freq = postings.freq();\n                if (freq <= 0) {\n                  throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n                }\n                int lastPosition = -1;\n                for(int posUpto=0;posUpto<freq;posUpto++) {\n                  final int pos = postings.nextPosition();\n                  if (pos < 0) {\n                    throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                  }\n                  if (pos < lastPosition) {\n                    throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                  }\n                  lastPosition = pos;\n                } \n\n                final int nextDocID = postings.nextDoc();\n                if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                  break;\n                }\n                if (nextDocID <= docID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n                }\n              }\n            }\n          } else {\n            for(int idx=0;idx<7;idx++) {\n              final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n              docs = termsEnum.docs(liveDocs, docs, false);\n              final int docID = docs.advance(skipDocID);\n              if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              } else {\n                if (docID < skipDocID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n                }\n                final int nextDocID = docs.nextDoc();\n                if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                  break;\n                }\n                if (nextDocID <= docID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n                }\n              }\n            }\n          }\n        }\n        \n        final Terms fieldTerms = fields.terms(field);\n        if (fieldTerms == null) {\n          // Unusual: the FieldsEnum returned a field but\n          // the Terms for that field is null; this should\n          // only happen if it's a ghost field (field with\n          // no terms, eg there used to be terms but all\n          // docs got deleted and then merged away):\n          // make sure TermsEnum is empty:\n          final Terms fieldTerms2 = fieldsEnum.terms();\n          if (fieldTerms2 != null && fieldTerms2.iterator(null).next() != null) {\n            throw new RuntimeException(\"Fields.terms(field=\" + field + \") returned null yet the field appears to have terms\");\n          }\n        } else {\n          if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n            final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n            assert stats != null;\n            if (status.blockTreeStats == null) {\n              status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n            }\n            status.blockTreeStats.put(field, stats);\n          }\n\n          if (sumTotalTermFreq != 0) {\n            final long v = fields.terms(field).getSumTotalTermFreq();\n            if (v != -1 && sumTotalTermFreq != v) {\n              throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n            }\n          }\n        \n          if (sumDocFreq != 0) {\n            final long v = fields.terms(field).getSumDocFreq();\n            if (v != -1 && sumDocFreq != v) {\n              throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n            }\n          }\n        \n          if (fieldTerms != null) {\n            final int v = fieldTerms.getDocCount();\n            if (v != -1 && visitedDocs.cardinality() != v) {\n              throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n            }\n          }\n\n          // Test seek to last term:\n          if (lastTerm != null) {\n            if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n              throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n            }\n\n            is.search(new TermQuery(new Term(field, lastTerm)), 1);\n          }\n          \n          // check unique term count\n          long termCount = -1;\n          \n          if (status.termCount-termCountStart > 0) {\n            termCount = fields.terms(field).getUniqueTermCount();\n            \n            if (termCount != -1 && termCount != status.termCount - termCountStart) {\n              throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + (status.termCount - termCountStart));\n            }\n          }\n          \n          // Test seeking by ord\n          if (hasOrd && status.termCount-termCountStart > 0) {\n            int seekCount = (int) Math.min(10000L, termCount);\n            if (seekCount > 0) {\n              BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n              // Seek by ord\n              for(int i=seekCount-1;i>=0;i--) {\n                long ord = i*(termCount/seekCount);\n                termsEnum.seekExact(ord);\n                seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n              }\n\n              // Seek by term\n              long totDocCount = 0;\n              for(int i=seekCount-1;i>=0;i--) {\n                if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                  throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n                }\n              \n                docs = termsEnum.docs(liveDocs, docs, false);\n                if (docs == null) {\n                  throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n                }\n\n                while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                  totDocCount++;\n                }\n              }\n\n              // TermQuery\n              long totDocCount2 = 0;\n              for(int i=0;i<seekCount;i++) {\n                totDocCount2 += is.search(new TermQuery(new Term(field, seekTerms[i])), 1).totalHits;\n              }\n\n              if (totDocCount != totDocCount2) {\n                throw new RuntimeException(\"search to seek terms produced wrong number of hits: \" + totDocCount + \" vs \" + totDocCount2);\n              }\n            }\n          }\n        }\n      }\n      \n      int fieldCount = fields.getUniqueFieldCount();\n      \n      if (fieldCount != -1) {\n        if (fieldCount < 0) {\n          throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n        }\n        if (fieldCount != computedFieldCount) {\n          throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n        }\n      }\n\n      // for most implementations, this is boring (just the sum across all fields)\n      // but codecs that don't work per-field like preflex actually implement this,\n      // but don't implement it on Terms, so the check isn't redundant.\n      long uniqueTermCountAllFields = reader.getUniqueTermCount();\n      \n      // this means something is seriously screwed, e.g. we are somehow getting enclosed in PFCW!!!!!!\n      \n      if (uniqueTermCountAllFields == -1) {\n        throw new RuntimeException(\"invalid termCount: -1\");\n     }\n\n      if (status.termCount != uniqueTermCountAllFields) {\n        throw new RuntimeException(\"termCount mismatch \" + uniqueTermCountAllFields + \" vs \" + (status.termCount));\n      }\n\n      msg(\"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n\n      if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n        for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n          infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n          infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n        }\n      }\n\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      int computedFieldCount = 0;\n      final Fields fields = reader.fields();\n      if (fields == null) {\n        msg(\"OK [no fields/terms]\");\n        return status;\n      }\n     \n      DocsEnum docs = null;\n      DocsEnum docsAndFreqs = null;\n      DocsAndPositionsEnum postings = null;\n\n      String lastField = null;\n      final FieldsEnum fieldsEnum = fields.iterator();\n      while(true) {\n        final String field = fieldsEnum.next();\n        if (field == null) {\n          break;\n        }\n        // MultiFieldsEnum relies upon this order...\n        if (lastField != null && field.compareTo(lastField) <= 0) {\n          throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n        }\n        lastField = field;\n        \n        // check that the field is in fieldinfos, and is indexed.\n        // TODO: add a separate test to check this for different reader impls\n        FieldInfo fi = fieldInfos.fieldInfo(field);\n        if (fi == null) {\n          throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n        }\n        if (!fi.isIndexed) {\n          throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n        }\n\n        // TODO: really the codec should not return a field\n        // from FieldsEnum if it has no Terms... but we do\n        // this today:\n        // assert fields.terms(field) != null;\n        computedFieldCount++;\n        \n        final Terms terms = fieldsEnum.terms();\n        if (terms == null) {\n          continue;\n        }\n\n        final TermsEnum termsEnum = terms.iterator(null);\n\n        boolean hasOrd = true;\n        final long termCountStart = status.termCount;\n\n        BytesRef lastTerm = null;\n\n        Comparator<BytesRef> termComp = terms.getComparator();\n\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        FixedBitSet visitedDocs = new FixedBitSet(reader.maxDoc());\n        while(true) {\n\n          final BytesRef term = termsEnum.next();\n          if (term == null) {\n            break;\n          }\n\n          // make sure terms arrive in order according to\n          // the comp\n          if (lastTerm == null) {\n            lastTerm = BytesRef.deepCopyOf(term);\n          } else {\n            if (termComp.compare(lastTerm, term) >= 0) {\n              throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n            }\n            lastTerm.copyBytes(term);\n          }\n\n          final int docFreq = termsEnum.docFreq();\n          if (docFreq <= 0) {\n            throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n          }\n          status.totFreq += docFreq;\n          sumDocFreq += docFreq;\n\n          docs = termsEnum.docs(liveDocs, docs, false);\n          docsAndFreqs = termsEnum.docs(liveDocs, docsAndFreqs, true);\n          postings = termsEnum.docsAndPositions(liveDocs, postings, false);\n\n          if (hasOrd) {\n            long ord = -1;\n            try {\n              ord = termsEnum.ord();\n            } catch (UnsupportedOperationException uoe) {\n              hasOrd = false;\n            }\n\n            if (hasOrd) {\n              final long ordExpected = status.termCount - termCountStart;\n              if (ord != ordExpected) {\n                throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n              }\n            }\n          }\n\n          status.termCount++;\n\n          final DocsEnum docs2;\n          final DocsEnum docsAndFreqs2;\n          final boolean hasPositions;\n          final boolean hasFreqs;\n          if (postings != null) {\n            docs2 = postings;\n            docsAndFreqs2 = postings;\n            hasPositions = true;\n            hasFreqs = true;\n          } else if (docsAndFreqs != null) {\n            docs2 = docsAndFreqs;\n            docsAndFreqs2 = docsAndFreqs;\n            hasPositions = false;\n            hasFreqs = true;\n          } else {\n            docs2 = docs;\n            docsAndFreqs2 = null;\n            hasPositions = false;\n            hasFreqs = false;\n          }\n\n          int lastDoc = -1;\n          int docCount = 0;\n          long totalTermFreq = 0;\n          while(true) {\n            final int doc = docs2.nextDoc();\n            if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            }\n            visitedDocs.set(doc);\n            int freq = -1;\n            if (hasFreqs) {\n              freq = docsAndFreqs2.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n              }\n              status.totPos += freq;\n              totalTermFreq += freq;\n            }\n            docCount++;\n\n            if (doc <= lastDoc) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            }\n            if (doc >= maxDoc) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n            }\n\n            lastDoc = doc;\n            \n            int lastPos = -1;\n            if (hasPositions) {\n              for(int j=0;j<freq;j++) {\n                final int pos = postings.nextPosition();\n                if (pos < -1) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPos) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n                }\n                lastPos = pos;\n                if (postings.hasPayload()) {\n                  postings.getPayload();\n                }\n              }\n            }\n          }\n          \n          final long totalTermFreq2 = termsEnum.totalTermFreq();\n          final boolean hasTotalTermFreq = postings != null && totalTermFreq2 != -1;\n\n          // Re-count if there are deleted docs:\n          if (reader.hasDeletions()) {\n            if (hasFreqs) {\n              final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs, true);\n              docCount = 0;\n              totalTermFreq = 0;\n              while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                visitedDocs.set(docsNoDel.docID());\n                docCount++;\n                totalTermFreq += docsNoDel.freq();\n              }\n            } else {\n              final DocsEnum docsNoDel = termsEnum.docs(null, docs, false);\n              docCount = 0;\n              totalTermFreq = -1;\n              while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                visitedDocs.set(docsNoDel.docID());\n                docCount++;\n              }\n            }\n          }\n\n          if (docCount != docFreq) {\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n          }\n          if (hasTotalTermFreq) {\n            if (totalTermFreq2 <= 0) {\n              throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n            }\n            sumTotalTermFreq += totalTermFreq;\n            if (totalTermFreq != totalTermFreq2) {\n              throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n            }\n          }\n\n          // Test skipping\n          if (hasPositions) {\n            for(int idx=0;idx<7;idx++) {\n              final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n              postings = termsEnum.docsAndPositions(liveDocs, postings, false);\n              final int docID = postings.advance(skipDocID);\n              if (docID == DocsEnum.NO_MORE_DOCS) {\n                break;\n              } else {\n                if (docID < skipDocID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n                }\n                final int freq = postings.freq();\n                if (freq <= 0) {\n                  throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n                }\n                int lastPosition = -1;\n                for(int posUpto=0;posUpto<freq;posUpto++) {\n                  final int pos = postings.nextPosition();\n                  if (pos < 0) {\n                    throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                  }\n                  if (pos < lastPosition) {\n                    throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                  }\n                  lastPosition = pos;\n                } \n\n                final int nextDocID = postings.nextDoc();\n                if (nextDocID == DocsEnum.NO_MORE_DOCS) {\n                  break;\n                }\n                if (nextDocID <= docID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n                }\n              }\n            }\n          } else {\n            for(int idx=0;idx<7;idx++) {\n              final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n              docs = termsEnum.docs(liveDocs, docs, false);\n              final int docID = docs.advance(skipDocID);\n              if (docID == DocsEnum.NO_MORE_DOCS) {\n                break;\n              } else {\n                if (docID < skipDocID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n                }\n                final int nextDocID = docs.nextDoc();\n                if (nextDocID == DocsEnum.NO_MORE_DOCS) {\n                  break;\n                }\n                if (nextDocID <= docID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n                }\n              }\n            }\n          }\n        }\n        \n        final Terms fieldTerms = fields.terms(field);\n        if (fieldTerms == null) {\n          // Unusual: the FieldsEnum returned a field but\n          // the Terms for that field is null; this should\n          // only happen if it's a ghost field (field with\n          // no terms, eg there used to be terms but all\n          // docs got deleted and then merged away):\n          // make sure TermsEnum is empty:\n          final Terms fieldTerms2 = fieldsEnum.terms();\n          if (fieldTerms2 != null && fieldTerms2.iterator(null).next() != null) {\n            throw new RuntimeException(\"Fields.terms(field=\" + field + \") returned null yet the field appears to have terms\");\n          }\n        } else {\n          if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n            final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n            assert stats != null;\n            if (status.blockTreeStats == null) {\n              status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n            }\n            status.blockTreeStats.put(field, stats);\n          }\n\n          if (sumTotalTermFreq != 0) {\n            final long v = fields.terms(field).getSumTotalTermFreq();\n            if (v != -1 && sumTotalTermFreq != v) {\n              throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n            }\n          }\n        \n          if (sumDocFreq != 0) {\n            final long v = fields.terms(field).getSumDocFreq();\n            if (v != -1 && sumDocFreq != v) {\n              throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n            }\n          }\n        \n          if (fieldTerms != null) {\n            final int v = fieldTerms.getDocCount();\n            if (v != -1 && visitedDocs.cardinality() != v) {\n              throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n            }\n          }\n\n          // Test seek to last term:\n          if (lastTerm != null) {\n            if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n              throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n            }\n\n            is.search(new TermQuery(new Term(field, lastTerm)), 1);\n          }\n          \n          // check unique term count\n          long termCount = -1;\n          \n          if (status.termCount-termCountStart > 0) {\n            termCount = fields.terms(field).getUniqueTermCount();\n            \n            if (termCount != -1 && termCount != status.termCount - termCountStart) {\n              throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + (status.termCount - termCountStart));\n            }\n          }\n          \n          // Test seeking by ord\n          if (hasOrd && status.termCount-termCountStart > 0) {\n            int seekCount = (int) Math.min(10000L, termCount);\n            if (seekCount > 0) {\n              BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n              // Seek by ord\n              for(int i=seekCount-1;i>=0;i--) {\n                long ord = i*(termCount/seekCount);\n                termsEnum.seekExact(ord);\n                seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n              }\n\n              // Seek by term\n              long totDocCount = 0;\n              for(int i=seekCount-1;i>=0;i--) {\n                if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                  throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n                }\n              \n                docs = termsEnum.docs(liveDocs, docs, false);\n                if (docs == null) {\n                  throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n                }\n\n                while(docs.nextDoc() != DocsEnum.NO_MORE_DOCS) {\n                  totDocCount++;\n                }\n              }\n\n              // TermQuery\n              long totDocCount2 = 0;\n              for(int i=0;i<seekCount;i++) {\n                totDocCount2 += is.search(new TermQuery(new Term(field, seekTerms[i])), 1).totalHits;\n              }\n\n              if (totDocCount != totDocCount2) {\n                throw new RuntimeException(\"search to seek terms produced wrong number of hits: \" + totDocCount + \" vs \" + totDocCount2);\n              }\n            }\n          }\n        }\n      }\n      \n      int fieldCount = fields.getUniqueFieldCount();\n      \n      if (fieldCount != -1) {\n        if (fieldCount < 0) {\n          throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n        }\n        if (fieldCount != computedFieldCount) {\n          throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n        }\n      }\n\n      // for most implementations, this is boring (just the sum across all fields)\n      // but codecs that don't work per-field like preflex actually implement this,\n      // but don't implement it on Terms, so the check isn't redundant.\n      long uniqueTermCountAllFields = reader.getUniqueTermCount();\n      \n      // this means something is seriously screwed, e.g. we are somehow getting enclosed in PFCW!!!!!!\n      \n      if (uniqueTermCountAllFields == -1) {\n        throw new RuntimeException(\"invalid termCount: -1\");\n     }\n\n      if (status.termCount != uniqueTermCountAllFields) {\n        throw new RuntimeException(\"termCount mismatch \" + uniqueTermCountAllFields + \" vs \" + (status.termCount));\n      }\n\n      msg(\"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n\n      if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n        for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n          infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n          infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n        }\n      }\n\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":0,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      int computedFieldCount = 0;\n      final Fields fields = reader.fields();\n      if (fields == null) {\n        msg(\"OK [no fields/terms]\");\n        return status;\n      }\n     \n      DocsEnum docs = null;\n      DocsEnum docsAndFreqs = null;\n      DocsAndPositionsEnum postings = null;\n\n      String lastField = null;\n      final FieldsEnum fieldsEnum = fields.iterator();\n      while(true) {\n        final String field = fieldsEnum.next();\n        if (field == null) {\n          break;\n        }\n        // MultiFieldsEnum relies upon this order...\n        if (lastField != null && field.compareTo(lastField) <= 0) {\n          throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n        }\n        lastField = field;\n        \n        // check that the field is in fieldinfos, and is indexed.\n        // TODO: add a separate test to check this for different reader impls\n        FieldInfo fi = fieldInfos.fieldInfo(field);\n        if (fi == null) {\n          throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n        }\n        if (!fi.isIndexed) {\n          throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n        }\n\n        // TODO: really the codec should not return a field\n        // from FieldsEnum if it has no Terms... but we do\n        // this today:\n        // assert fields.terms(field) != null;\n        computedFieldCount++;\n        \n        final Terms terms = fieldsEnum.terms();\n        if (terms == null) {\n          continue;\n        }\n\n        final TermsEnum termsEnum = terms.iterator(null);\n\n        boolean hasOrd = true;\n        final long termCountStart = status.termCount;\n\n        BytesRef lastTerm = null;\n\n        Comparator<BytesRef> termComp = terms.getComparator();\n\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        FixedBitSet visitedDocs = new FixedBitSet(reader.maxDoc());\n        while(true) {\n\n          final BytesRef term = termsEnum.next();\n          if (term == null) {\n            break;\n          }\n\n          // make sure terms arrive in order according to\n          // the comp\n          if (lastTerm == null) {\n            lastTerm = BytesRef.deepCopyOf(term);\n          } else {\n            if (termComp.compare(lastTerm, term) >= 0) {\n              throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n            }\n            lastTerm.copyBytes(term);\n          }\n\n          final int docFreq = termsEnum.docFreq();\n          if (docFreq <= 0) {\n            throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n          }\n          status.totFreq += docFreq;\n          sumDocFreq += docFreq;\n\n          docs = termsEnum.docs(liveDocs, docs, false);\n          docsAndFreqs = termsEnum.docs(liveDocs, docsAndFreqs, true);\n          postings = termsEnum.docsAndPositions(liveDocs, postings, false);\n\n          if (hasOrd) {\n            long ord = -1;\n            try {\n              ord = termsEnum.ord();\n            } catch (UnsupportedOperationException uoe) {\n              hasOrd = false;\n            }\n\n            if (hasOrd) {\n              final long ordExpected = status.termCount - termCountStart;\n              if (ord != ordExpected) {\n                throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n              }\n            }\n          }\n\n          status.termCount++;\n\n          final DocsEnum docs2;\n          final DocsEnum docsAndFreqs2;\n          final boolean hasPositions;\n          final boolean hasFreqs;\n          if (postings != null) {\n            docs2 = postings;\n            docsAndFreqs2 = postings;\n            hasPositions = true;\n            hasFreqs = true;\n          } else if (docsAndFreqs != null) {\n            docs2 = docsAndFreqs;\n            docsAndFreqs2 = docsAndFreqs;\n            hasPositions = false;\n            hasFreqs = true;\n          } else {\n            docs2 = docs;\n            docsAndFreqs2 = null;\n            hasPositions = false;\n            hasFreqs = false;\n          }\n\n          int lastDoc = -1;\n          int docCount = 0;\n          long totalTermFreq = 0;\n          while(true) {\n            final int doc = docs2.nextDoc();\n            if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            }\n            visitedDocs.set(doc);\n            int freq = -1;\n            if (hasFreqs) {\n              freq = docsAndFreqs2.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n              }\n              status.totPos += freq;\n              totalTermFreq += freq;\n            }\n            docCount++;\n\n            if (doc <= lastDoc) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            }\n            if (doc >= maxDoc) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n            }\n\n            lastDoc = doc;\n            \n            int lastPos = -1;\n            if (hasPositions) {\n              for(int j=0;j<freq;j++) {\n                final int pos = postings.nextPosition();\n                if (pos < -1) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPos) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n                }\n                lastPos = pos;\n                if (postings.hasPayload()) {\n                  postings.getPayload();\n                }\n              }\n            }\n          }\n          \n          final long totalTermFreq2 = termsEnum.totalTermFreq();\n          final boolean hasTotalTermFreq = postings != null && totalTermFreq2 != -1;\n\n          // Re-count if there are deleted docs:\n          if (reader.hasDeletions()) {\n            if (hasFreqs) {\n              final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs, true);\n              docCount = 0;\n              totalTermFreq = 0;\n              while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                visitedDocs.set(docsNoDel.docID());\n                docCount++;\n                totalTermFreq += docsNoDel.freq();\n              }\n            } else {\n              final DocsEnum docsNoDel = termsEnum.docs(null, docs, false);\n              docCount = 0;\n              totalTermFreq = -1;\n              while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                visitedDocs.set(docsNoDel.docID());\n                docCount++;\n              }\n            }\n          }\n\n          if (docCount != docFreq) {\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n          }\n          if (hasTotalTermFreq) {\n            if (totalTermFreq2 <= 0) {\n              throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n            }\n            sumTotalTermFreq += totalTermFreq;\n            if (totalTermFreq != totalTermFreq2) {\n              throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n            }\n          }\n\n          // Test skipping\n          if (hasPositions) {\n            for(int idx=0;idx<7;idx++) {\n              final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n              postings = termsEnum.docsAndPositions(liveDocs, postings, false);\n              final int docID = postings.advance(skipDocID);\n              if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              } else {\n                if (docID < skipDocID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n                }\n                final int freq = postings.freq();\n                if (freq <= 0) {\n                  throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n                }\n                int lastPosition = -1;\n                for(int posUpto=0;posUpto<freq;posUpto++) {\n                  final int pos = postings.nextPosition();\n                  if (pos < 0) {\n                    throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                  }\n                  if (pos < lastPosition) {\n                    throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                  }\n                  lastPosition = pos;\n                } \n\n                final int nextDocID = postings.nextDoc();\n                if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                  break;\n                }\n                if (nextDocID <= docID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n                }\n              }\n            }\n          } else {\n            for(int idx=0;idx<7;idx++) {\n              final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n              docs = termsEnum.docs(liveDocs, docs, false);\n              final int docID = docs.advance(skipDocID);\n              if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              } else {\n                if (docID < skipDocID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n                }\n                final int nextDocID = docs.nextDoc();\n                if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                  break;\n                }\n                if (nextDocID <= docID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n                }\n              }\n            }\n          }\n        }\n        \n        final Terms fieldTerms = fields.terms(field);\n        if (fieldTerms == null) {\n          // Unusual: the FieldsEnum returned a field but\n          // the Terms for that field is null; this should\n          // only happen if it's a ghost field (field with\n          // no terms, eg there used to be terms but all\n          // docs got deleted and then merged away):\n          // make sure TermsEnum is empty:\n          final Terms fieldTerms2 = fieldsEnum.terms();\n          if (fieldTerms2 != null && fieldTerms2.iterator(null).next() != null) {\n            throw new RuntimeException(\"Fields.terms(field=\" + field + \") returned null yet the field appears to have terms\");\n          }\n        } else {\n          if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n            final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n            assert stats != null;\n            if (status.blockTreeStats == null) {\n              status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n            }\n            status.blockTreeStats.put(field, stats);\n          }\n\n          if (sumTotalTermFreq != 0) {\n            final long v = fields.terms(field).getSumTotalTermFreq();\n            if (v != -1 && sumTotalTermFreq != v) {\n              throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n            }\n          }\n        \n          if (sumDocFreq != 0) {\n            final long v = fields.terms(field).getSumDocFreq();\n            if (v != -1 && sumDocFreq != v) {\n              throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n            }\n          }\n        \n          if (fieldTerms != null) {\n            final int v = fieldTerms.getDocCount();\n            if (v != -1 && visitedDocs.cardinality() != v) {\n              throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n            }\n          }\n\n          // Test seek to last term:\n          if (lastTerm != null) {\n            if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n              throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n            }\n\n            is.search(new TermQuery(new Term(field, lastTerm)), 1);\n          }\n          \n          // check unique term count\n          long termCount = -1;\n          \n          if (status.termCount-termCountStart > 0) {\n            termCount = fields.terms(field).getUniqueTermCount();\n            \n            if (termCount != -1 && termCount != status.termCount - termCountStart) {\n              throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + (status.termCount - termCountStart));\n            }\n          }\n          \n          // Test seeking by ord\n          if (hasOrd && status.termCount-termCountStart > 0) {\n            int seekCount = (int) Math.min(10000L, termCount);\n            if (seekCount > 0) {\n              BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n              // Seek by ord\n              for(int i=seekCount-1;i>=0;i--) {\n                long ord = i*(termCount/seekCount);\n                termsEnum.seekExact(ord);\n                seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n              }\n\n              // Seek by term\n              long totDocCount = 0;\n              for(int i=seekCount-1;i>=0;i--) {\n                if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                  throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n                }\n              \n                docs = termsEnum.docs(liveDocs, docs, false);\n                if (docs == null) {\n                  throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n                }\n\n                while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                  totDocCount++;\n                }\n              }\n\n              // TermQuery\n              long totDocCount2 = 0;\n              for(int i=0;i<seekCount;i++) {\n                totDocCount2 += is.search(new TermQuery(new Term(field, seekTerms[i])), 1).totalHits;\n              }\n\n              if (totDocCount != totDocCount2) {\n                throw new RuntimeException(\"search to seek terms produced wrong number of hits: \" + totDocCount + \" vs \" + totDocCount2);\n              }\n            }\n          }\n        }\n      }\n      \n      int fieldCount = fields.getUniqueFieldCount();\n      \n      if (fieldCount != -1) {\n        if (fieldCount < 0) {\n          throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n        }\n        if (fieldCount != computedFieldCount) {\n          throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n        }\n      }\n\n      // for most implementations, this is boring (just the sum across all fields)\n      // but codecs that don't work per-field like preflex actually implement this,\n      // but don't implement it on Terms, so the check isn't redundant.\n      long uniqueTermCountAllFields = reader.getUniqueTermCount();\n      \n      // this means something is seriously screwed, e.g. we are somehow getting enclosed in PFCW!!!!!!\n      \n      if (uniqueTermCountAllFields == -1) {\n        throw new RuntimeException(\"invalid termCount: -1\");\n     }\n\n      if (status.termCount != uniqueTermCountAllFields) {\n        throw new RuntimeException(\"termCount mismatch \" + uniqueTermCountAllFields + \" vs \" + (status.termCount));\n      }\n\n      msg(\"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n\n      if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n        for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n          infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n          infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n        }\n      }\n\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b13ebda0f2c83525d118f4859e46eb3bd87ced36","date":1331925435,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","sourceNew":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, is);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        // TODO: can we make a IS that ignores all deletes?\n        checkFields(fields, null, maxDoc, fieldInfos, null);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    final Status.TermIndexStatus status = new Status.TermIndexStatus();\n\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      int computedFieldCount = 0;\n      final Fields fields = reader.fields();\n      if (fields == null) {\n        msg(\"OK [no fields/terms]\");\n        return status;\n      }\n     \n      DocsEnum docs = null;\n      DocsEnum docsAndFreqs = null;\n      DocsAndPositionsEnum postings = null;\n\n      String lastField = null;\n      final FieldsEnum fieldsEnum = fields.iterator();\n      while(true) {\n        final String field = fieldsEnum.next();\n        if (field == null) {\n          break;\n        }\n        // MultiFieldsEnum relies upon this order...\n        if (lastField != null && field.compareTo(lastField) <= 0) {\n          throw new RuntimeException(\"fields out of order: lastField=\" + lastField + \" field=\" + field);\n        }\n        lastField = field;\n        \n        // check that the field is in fieldinfos, and is indexed.\n        // TODO: add a separate test to check this for different reader impls\n        FieldInfo fi = fieldInfos.fieldInfo(field);\n        if (fi == null) {\n          throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, no fieldInfos for: \" + field);\n        }\n        if (!fi.isIndexed) {\n          throw new RuntimeException(\"fieldsEnum inconsistent with fieldInfos, isIndexed == false for: \" + field);\n        }\n\n        // TODO: really the codec should not return a field\n        // from FieldsEnum if it has no Terms... but we do\n        // this today:\n        // assert fields.terms(field) != null;\n        computedFieldCount++;\n        \n        final Terms terms = fieldsEnum.terms();\n        if (terms == null) {\n          continue;\n        }\n\n        final TermsEnum termsEnum = terms.iterator(null);\n\n        boolean hasOrd = true;\n        final long termCountStart = status.termCount;\n\n        BytesRef lastTerm = null;\n\n        Comparator<BytesRef> termComp = terms.getComparator();\n\n        long sumTotalTermFreq = 0;\n        long sumDocFreq = 0;\n        FixedBitSet visitedDocs = new FixedBitSet(reader.maxDoc());\n        while(true) {\n\n          final BytesRef term = termsEnum.next();\n          if (term == null) {\n            break;\n          }\n\n          // make sure terms arrive in order according to\n          // the comp\n          if (lastTerm == null) {\n            lastTerm = BytesRef.deepCopyOf(term);\n          } else {\n            if (termComp.compare(lastTerm, term) >= 0) {\n              throw new RuntimeException(\"terms out of order: lastTerm=\" + lastTerm + \" term=\" + term);\n            }\n            lastTerm.copyBytes(term);\n          }\n\n          final int docFreq = termsEnum.docFreq();\n          if (docFreq <= 0) {\n            throw new RuntimeException(\"docfreq: \" + docFreq + \" is out of bounds\");\n          }\n          status.totFreq += docFreq;\n          sumDocFreq += docFreq;\n\n          docs = termsEnum.docs(liveDocs, docs, false);\n          docsAndFreqs = termsEnum.docs(liveDocs, docsAndFreqs, true);\n          postings = termsEnum.docsAndPositions(liveDocs, postings, false);\n\n          if (hasOrd) {\n            long ord = -1;\n            try {\n              ord = termsEnum.ord();\n            } catch (UnsupportedOperationException uoe) {\n              hasOrd = false;\n            }\n\n            if (hasOrd) {\n              final long ordExpected = status.termCount - termCountStart;\n              if (ord != ordExpected) {\n                throw new RuntimeException(\"ord mismatch: TermsEnum has ord=\" + ord + \" vs actual=\" + ordExpected);\n              }\n            }\n          }\n\n          status.termCount++;\n\n          final DocsEnum docs2;\n          final DocsEnum docsAndFreqs2;\n          final boolean hasPositions;\n          final boolean hasFreqs;\n          if (postings != null) {\n            docs2 = postings;\n            docsAndFreqs2 = postings;\n            hasPositions = true;\n            hasFreqs = true;\n          } else if (docsAndFreqs != null) {\n            docs2 = docsAndFreqs;\n            docsAndFreqs2 = docsAndFreqs;\n            hasPositions = false;\n            hasFreqs = true;\n          } else {\n            docs2 = docs;\n            docsAndFreqs2 = null;\n            hasPositions = false;\n            hasFreqs = false;\n          }\n\n          int lastDoc = -1;\n          int docCount = 0;\n          long totalTermFreq = 0;\n          while(true) {\n            final int doc = docs2.nextDoc();\n            if (doc == DocIdSetIterator.NO_MORE_DOCS) {\n              break;\n            }\n            visitedDocs.set(doc);\n            int freq = -1;\n            if (hasFreqs) {\n              freq = docsAndFreqs2.freq();\n              if (freq <= 0) {\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n              }\n              status.totPos += freq;\n              totalTermFreq += freq;\n            }\n            docCount++;\n\n            if (doc <= lastDoc) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            }\n            if (doc >= maxDoc) {\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" >= maxDoc \" + maxDoc);\n            }\n\n            lastDoc = doc;\n            \n            int lastPos = -1;\n            if (hasPositions) {\n              for(int j=0;j<freq;j++) {\n                final int pos = postings.nextPosition();\n                if (pos < -1) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n                }\n                if (pos < lastPos) {\n                  throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n                }\n                lastPos = pos;\n                if (postings.hasPayload()) {\n                  postings.getPayload();\n                }\n              }\n            }\n          }\n          \n          final long totalTermFreq2 = termsEnum.totalTermFreq();\n          final boolean hasTotalTermFreq = postings != null && totalTermFreq2 != -1;\n\n          // Re-count if there are deleted docs:\n          if (reader.hasDeletions()) {\n            if (hasFreqs) {\n              final DocsEnum docsNoDel = termsEnum.docs(null, docsAndFreqs, true);\n              docCount = 0;\n              totalTermFreq = 0;\n              while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                visitedDocs.set(docsNoDel.docID());\n                docCount++;\n                totalTermFreq += docsNoDel.freq();\n              }\n            } else {\n              final DocsEnum docsNoDel = termsEnum.docs(null, docs, false);\n              docCount = 0;\n              totalTermFreq = -1;\n              while(docsNoDel.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                visitedDocs.set(docsNoDel.docID());\n                docCount++;\n              }\n            }\n          }\n\n          if (docCount != docFreq) {\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != tot docs w/o deletions \" + docCount);\n          }\n          if (hasTotalTermFreq) {\n            if (totalTermFreq2 <= 0) {\n              throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq2 + \" is out of bounds\");\n            }\n            sumTotalTermFreq += totalTermFreq;\n            if (totalTermFreq != totalTermFreq2) {\n              throw new RuntimeException(\"term \" + term + \" totalTermFreq=\" + totalTermFreq2 + \" != recomputed totalTermFreq=\" + totalTermFreq);\n            }\n          }\n\n          // Test skipping\n          if (hasPositions) {\n            for(int idx=0;idx<7;idx++) {\n              final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n              postings = termsEnum.docsAndPositions(liveDocs, postings, false);\n              final int docID = postings.advance(skipDocID);\n              if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              } else {\n                if (docID < skipDocID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n                }\n                final int freq = postings.freq();\n                if (freq <= 0) {\n                  throw new RuntimeException(\"termFreq \" + freq + \" is out of bounds\");\n                }\n                int lastPosition = -1;\n                for(int posUpto=0;posUpto<freq;posUpto++) {\n                  final int pos = postings.nextPosition();\n                  if (pos < 0) {\n                    throw new RuntimeException(\"position \" + pos + \" is out of bounds\");\n                  }\n                  if (pos < lastPosition) {\n                    throw new RuntimeException(\"position \" + pos + \" is < lastPosition \" + lastPosition);\n                  }\n                  lastPosition = pos;\n                } \n\n                final int nextDocID = postings.nextDoc();\n                if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                  break;\n                }\n                if (nextDocID <= docID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n                }\n              }\n            }\n          } else {\n            for(int idx=0;idx<7;idx++) {\n              final int skipDocID = (int) (((idx+1)*(long) maxDoc)/8);\n              docs = termsEnum.docs(liveDocs, docs, false);\n              final int docID = docs.advance(skipDocID);\n              if (docID == DocIdSetIterator.NO_MORE_DOCS) {\n                break;\n              } else {\n                if (docID < skipDocID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \") returned docID=\" + docID);\n                }\n                final int nextDocID = docs.nextDoc();\n                if (nextDocID == DocIdSetIterator.NO_MORE_DOCS) {\n                  break;\n                }\n                if (nextDocID <= docID) {\n                  throw new RuntimeException(\"term \" + term + \": advance(docID=\" + skipDocID + \"), then .next() returned docID=\" + nextDocID + \" vs prev docID=\" + docID);\n                }\n              }\n            }\n          }\n        }\n        \n        final Terms fieldTerms = fields.terms(field);\n        if (fieldTerms == null) {\n          // Unusual: the FieldsEnum returned a field but\n          // the Terms for that field is null; this should\n          // only happen if it's a ghost field (field with\n          // no terms, eg there used to be terms but all\n          // docs got deleted and then merged away):\n          // make sure TermsEnum is empty:\n          final Terms fieldTerms2 = fieldsEnum.terms();\n          if (fieldTerms2 != null && fieldTerms2.iterator(null).next() != null) {\n            throw new RuntimeException(\"Fields.terms(field=\" + field + \") returned null yet the field appears to have terms\");\n          }\n        } else {\n          if (fieldTerms instanceof BlockTreeTermsReader.FieldReader) {\n            final BlockTreeTermsReader.Stats stats = ((BlockTreeTermsReader.FieldReader) fieldTerms).computeStats();\n            assert stats != null;\n            if (status.blockTreeStats == null) {\n              status.blockTreeStats = new HashMap<String,BlockTreeTermsReader.Stats>();\n            }\n            status.blockTreeStats.put(field, stats);\n          }\n\n          if (sumTotalTermFreq != 0) {\n            final long v = fields.terms(field).getSumTotalTermFreq();\n            if (v != -1 && sumTotalTermFreq != v) {\n              throw new RuntimeException(\"sumTotalTermFreq for field \" + field + \"=\" + v + \" != recomputed sumTotalTermFreq=\" + sumTotalTermFreq);\n            }\n          }\n        \n          if (sumDocFreq != 0) {\n            final long v = fields.terms(field).getSumDocFreq();\n            if (v != -1 && sumDocFreq != v) {\n              throw new RuntimeException(\"sumDocFreq for field \" + field + \"=\" + v + \" != recomputed sumDocFreq=\" + sumDocFreq);\n            }\n          }\n        \n          if (fieldTerms != null) {\n            final int v = fieldTerms.getDocCount();\n            if (v != -1 && visitedDocs.cardinality() != v) {\n              throw new RuntimeException(\"docCount for field \" + field + \"=\" + v + \" != recomputed docCount=\" + visitedDocs.cardinality());\n            }\n          }\n\n          // Test seek to last term:\n          if (lastTerm != null) {\n            if (termsEnum.seekCeil(lastTerm) != TermsEnum.SeekStatus.FOUND) { \n              throw new RuntimeException(\"seek to last term \" + lastTerm + \" failed\");\n            }\n\n            is.search(new TermQuery(new Term(field, lastTerm)), 1);\n          }\n          \n          // check unique term count\n          long termCount = -1;\n          \n          if (status.termCount-termCountStart > 0) {\n            termCount = fields.terms(field).getUniqueTermCount();\n            \n            if (termCount != -1 && termCount != status.termCount - termCountStart) {\n              throw new RuntimeException(\"termCount mismatch \" + termCount + \" vs \" + (status.termCount - termCountStart));\n            }\n          }\n          \n          // Test seeking by ord\n          if (hasOrd && status.termCount-termCountStart > 0) {\n            int seekCount = (int) Math.min(10000L, termCount);\n            if (seekCount > 0) {\n              BytesRef[] seekTerms = new BytesRef[seekCount];\n            \n              // Seek by ord\n              for(int i=seekCount-1;i>=0;i--) {\n                long ord = i*(termCount/seekCount);\n                termsEnum.seekExact(ord);\n                seekTerms[i] = BytesRef.deepCopyOf(termsEnum.term());\n              }\n\n              // Seek by term\n              long totDocCount = 0;\n              for(int i=seekCount-1;i>=0;i--) {\n                if (termsEnum.seekCeil(seekTerms[i]) != TermsEnum.SeekStatus.FOUND) {\n                  throw new RuntimeException(\"seek to existing term \" + seekTerms[i] + \" failed\");\n                }\n              \n                docs = termsEnum.docs(liveDocs, docs, false);\n                if (docs == null) {\n                  throw new RuntimeException(\"null DocsEnum from to existing term \" + seekTerms[i]);\n                }\n\n                while(docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                  totDocCount++;\n                }\n              }\n\n              // TermQuery\n              long totDocCount2 = 0;\n              for(int i=0;i<seekCount;i++) {\n                totDocCount2 += is.search(new TermQuery(new Term(field, seekTerms[i])), 1).totalHits;\n              }\n\n              if (totDocCount != totDocCount2) {\n                throw new RuntimeException(\"search to seek terms produced wrong number of hits: \" + totDocCount + \" vs \" + totDocCount2);\n              }\n            }\n          }\n        }\n      }\n      \n      int fieldCount = fields.getUniqueFieldCount();\n      \n      if (fieldCount != -1) {\n        if (fieldCount < 0) {\n          throw new RuntimeException(\"invalid fieldCount: \" + fieldCount);\n        }\n        if (fieldCount != computedFieldCount) {\n          throw new RuntimeException(\"fieldCount mismatch \" + fieldCount + \" vs recomputed field count \" + computedFieldCount);\n        }\n      }\n\n      // for most implementations, this is boring (just the sum across all fields)\n      // but codecs that don't work per-field like preflex actually implement this,\n      // but don't implement it on Terms, so the check isn't redundant.\n      long uniqueTermCountAllFields = reader.getUniqueTermCount();\n      \n      // this means something is seriously screwed, e.g. we are somehow getting enclosed in PFCW!!!!!!\n      \n      if (uniqueTermCountAllFields == -1) {\n        throw new RuntimeException(\"invalid termCount: -1\");\n     }\n\n      if (status.termCount != uniqueTermCountAllFields) {\n        throw new RuntimeException(\"termCount mismatch \" + uniqueTermCountAllFields + \" vs \" + (status.termCount));\n      }\n\n      msg(\"OK [\" + status.termCount + \" terms; \" + status.totFreq + \" terms/docs pairs; \" + status.totPos + \" tokens]\");\n\n      if (verbose && status.blockTreeStats != null && infoStream != null && status.termCount > 0) {\n        for(Map.Entry<String,BlockTreeTermsReader.Stats> ent : status.blockTreeStats.entrySet()) {\n          infoStream.println(\"      field \\\"\" + ent.getKey() + \"\\\":\");\n          infoStream.println(\"      \" + ent.getValue().toString().replace(\"\\n\", \"\\n      \"));\n        }\n      }\n\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d08eba3d52b63561ebf936481ce73e6b6a14aa03","date":1333879759,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","sourceNew":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final InvertedFields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, is);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        // TODO: can we make a IS that ignores all deletes?\n        checkFields(fields, null, maxDoc, fieldInfos, null);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, is);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        // TODO: can we make a IS that ignores all deletes?\n        checkFields(fields, null, maxDoc, fieldInfos, null);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","date":1333892281,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","sourceNew":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, is);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        // TODO: can we make a IS that ignores all deletes?\n        checkFields(fields, null, maxDoc, fieldInfos, null);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final InvertedFields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, is);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        // TODO: can we make a IS that ignores all deletes?\n        checkFields(fields, null, maxDoc, fieldInfos, null);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4a8b14bc4241c302311422d5c6f7627f8febb86e","date":1337291675,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","sourceNew":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, is, true);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        // TODO: can we make a IS that ignores all deletes?\n        checkFields(fields, null, maxDoc, fieldInfos, null, true);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, is);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        // TODO: can we make a IS that ignores all deletes?\n        checkFields(fields, null, maxDoc, fieldInfos, null);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","sourceNew":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, is, true);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        // TODO: can we make a IS that ignores all deletes?\n        checkFields(fields, null, maxDoc, fieldInfos, null, true);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, is);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        // TODO: can we make a IS that ignores all deletes?\n        checkFields(fields, null, maxDoc, fieldInfos, null);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f0b2a0f7efff91a413da6cc75c82ef07af7baba4","date":1338485531,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","sourceNew":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, true);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        checkFields(fields, null, maxDoc, fieldInfos, true);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n    final IndexSearcher is = new IndexSearcher(reader);\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, is, true);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        // TODO: can we make a IS that ignores all deletes?\n        checkFields(fields, null, maxDoc, fieldInfos, null, true);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","bugFix":null,"bugIntro":["138923418367b4cadabaadb48c45f03a96cfde8b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"138923418367b4cadabaadb48c45f03a96cfde8b","date":1342359927,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","sourceNew":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, true, false);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        checkFields(fields, null, maxDoc, fieldInfos, true, false);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, true);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        checkFields(fields, null, maxDoc, fieldInfos, true);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","bugFix":["f0b2a0f7efff91a413da6cc75c82ef07af7baba4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","sourceNew":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, true, false);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        checkFields(fields, null, maxDoc, fieldInfos, true, false);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, true);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        checkFields(fields, null, maxDoc, fieldInfos, true);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","sourceNew":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, true, false);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        checkFields(fields, null, maxDoc, fieldInfos, true, false);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, true);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        checkFields(fields, null, maxDoc, fieldInfos, true);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e99275efa2c9c9ae3bdba986218af82f2bf3dc30","date":1354658499,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(AtomicReader,PrintStream,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","sourceNew":"  /**\n   * Test the term index.\n   * @lucene.experimental\n   */\n  public static Status.TermIndexStatus testPostings(AtomicReader reader, PrintStream infoStream, boolean verbose) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      final FieldInfos fieldInfos = reader.getFieldInfos();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, true, false, infoStream, verbose);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        checkFields(fields, null, maxDoc, fieldInfos, true, false, infoStream, verbose);\n      }\n    } catch (Throwable e) {\n      msg(infoStream, \"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, true, false);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        checkFields(fields, null, maxDoc, fieldInfos, true, false);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testPostings(FieldInfos,SegmentReader).mjava","sourceNew":null,"sourceOld":"  /**\n   * Test the term index.\n   */\n  private Status.TermIndexStatus testPostings(FieldInfos fieldInfos, SegmentReader reader) {\n\n    // TODO: we should go and verify term vectors match, if\n    // crossCheckTermVectors is on...\n\n    Status.TermIndexStatus status;\n    final int maxDoc = reader.maxDoc();\n    final Bits liveDocs = reader.getLiveDocs();\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: terms, freq, prox...\");\n      }\n\n      final Fields fields = reader.fields();\n      status = checkFields(fields, liveDocs, maxDoc, fieldInfos, true, false);\n      if (liveDocs != null) {\n        if (infoStream != null) {\n          infoStream.print(\"    test (ignoring deletes): terms, freq, prox...\");\n        }\n        checkFields(fields, null, maxDoc, fieldInfos, true, false);\n      }\n    } catch (Throwable e) {\n      msg(\"ERROR: \" + e);\n      status = new Status.TermIndexStatus();\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n\n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4a8b14bc4241c302311422d5c6f7627f8febb86e":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"b13ebda0f2c83525d118f4859e46eb3bd87ced36":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["368714b5b6663ca71a0cba34a94e6032ccdff3f2"],"e99275efa2c9c9ae3bdba986218af82f2bf3dc30":["138923418367b4cadabaadb48c45f03a96cfde8b"],"368714b5b6663ca71a0cba34a94e6032ccdff3f2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["b13ebda0f2c83525d118f4859e46eb3bd87ced36"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","4a8b14bc4241c302311422d5c6f7627f8febb86e"],"aba371508186796cc6151d8223a5b4e16d02e26e":["f0b2a0f7efff91a413da6cc75c82ef07af7baba4","138923418367b4cadabaadb48c45f03a96cfde8b"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["138923418367b4cadabaadb48c45f03a96cfde8b","e99275efa2c9c9ae3bdba986218af82f2bf3dc30"],"138923418367b4cadabaadb48c45f03a96cfde8b":["f0b2a0f7efff91a413da6cc75c82ef07af7baba4"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["f0b2a0f7efff91a413da6cc75c82ef07af7baba4","138923418367b4cadabaadb48c45f03a96cfde8b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"f0b2a0f7efff91a413da6cc75c82ef07af7baba4":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d4d69c535930b5cce125cff868d40f6373dc27d4"]},"commit2Childs":{"4a8b14bc4241c302311422d5c6f7627f8febb86e":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"b13ebda0f2c83525d118f4859e46eb3bd87ced36":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["b13ebda0f2c83525d118f4859e46eb3bd87ced36","9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab"],"e99275efa2c9c9ae3bdba986218af82f2bf3dc30":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"368714b5b6663ca71a0cba34a94e6032ccdff3f2":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["f0b2a0f7efff91a413da6cc75c82ef07af7baba4"],"aba371508186796cc6151d8223a5b4e16d02e26e":[],"d4d69c535930b5cce125cff868d40f6373dc27d4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"138923418367b4cadabaadb48c45f03a96cfde8b":["e99275efa2c9c9ae3bdba986218af82f2bf3dc30","aba371508186796cc6151d8223a5b4e16d02e26e","d4d69c535930b5cce125cff868d40f6373dc27d4","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","368714b5b6663ca71a0cba34a94e6032ccdff3f2"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["4a8b14bc4241c302311422d5c6f7627f8febb86e","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"f0b2a0f7efff91a413da6cc75c82ef07af7baba4":["aba371508186796cc6151d8223a5b4e16d02e26e","138923418367b4cadabaadb48c45f03a96cfde8b","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","aba371508186796cc6151d8223a5b4e16d02e26e","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}