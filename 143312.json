{"path":"lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup#PerThreadPKLookup(IndexReader,String).mjava","commits":[{"id":"b7d615ef411046679022f6728bb2b876273d13ae","date":1400253450,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup#PerThreadPKLookup(IndexReader,String).mjava","pathOld":"/dev/null","sourceNew":"  public PerThreadPKLookup(IndexReader r, String idFieldName) throws IOException {\n\n    List<AtomicReaderContext> leaves = new ArrayList<>(r.leaves());\n\n    // Larger segments are more likely to have the id, so we sort largest to smallest by numDocs:\n    Collections.sort(leaves, new Comparator<AtomicReaderContext>() {\n        @Override\n        public int compare(AtomicReaderContext c1, AtomicReaderContext c2) {\n          return c2.reader().numDocs() - c1.reader().numDocs();\n        }\n      });\n\n    termsEnums = new TermsEnum[leaves.size()];\n    docsEnums = new DocsEnum[leaves.size()];\n    liveDocs = new Bits[leaves.size()];\n    docBases = new int[leaves.size()];\n    int numSegs = 0;\n    boolean hasDeletions = false;\n    for(int i=0;i<leaves.size();i++) {\n      Fields fields = leaves.get(i).reader().fields();\n      if (fields != null) {\n        Terms terms = fields.terms(idFieldName);\n        if (terms != null) {\n          termsEnums[numSegs] = terms.iterator(null);\n          assert termsEnums[numSegs] != null;\n          docBases[numSegs] = leaves.get(i).docBase;\n          liveDocs[numSegs] = leaves.get(i).reader().getLiveDocs();\n          hasDeletions |= leaves.get(i).reader().hasDeletions();\n          numSegs++;\n        }\n      }\n    }\n    this.numSegs = numSegs;\n    this.hasDeletions = hasDeletions;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4d637064d608752565d4f9f41b2497dfdfdde50e","date":1400798123,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup#PerThreadPKLookup(IndexReader,String).mjava","pathOld":"/dev/null","sourceNew":"  public PerThreadPKLookup(IndexReader r, String idFieldName) throws IOException {\n\n    List<AtomicReaderContext> leaves = new ArrayList<>(r.leaves());\n\n    // Larger segments are more likely to have the id, so we sort largest to smallest by numDocs:\n    Collections.sort(leaves, new Comparator<AtomicReaderContext>() {\n        @Override\n        public int compare(AtomicReaderContext c1, AtomicReaderContext c2) {\n          return c2.reader().numDocs() - c1.reader().numDocs();\n        }\n      });\n\n    termsEnums = new TermsEnum[leaves.size()];\n    docsEnums = new DocsEnum[leaves.size()];\n    liveDocs = new Bits[leaves.size()];\n    docBases = new int[leaves.size()];\n    int numSegs = 0;\n    boolean hasDeletions = false;\n    for(int i=0;i<leaves.size();i++) {\n      Fields fields = leaves.get(i).reader().fields();\n      if (fields != null) {\n        Terms terms = fields.terms(idFieldName);\n        if (terms != null) {\n          termsEnums[numSegs] = terms.iterator(null);\n          assert termsEnums[numSegs] != null;\n          docBases[numSegs] = leaves.get(i).docBase;\n          liveDocs[numSegs] = leaves.get(i).reader().getLiveDocs();\n          hasDeletions |= leaves.get(i).reader().hasDeletions();\n          numSegs++;\n        }\n      }\n    }\n    this.numSegs = numSegs;\n    this.hasDeletions = hasDeletions;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup#PerThreadPKLookup(IndexReader,String).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup#PerThreadPKLookup(IndexReader,String).mjava","sourceNew":"  public PerThreadPKLookup(IndexReader r, String idFieldName) throws IOException {\n\n    List<LeafReaderContext> leaves = new ArrayList<>(r.leaves());\n\n    // Larger segments are more likely to have the id, so we sort largest to smallest by numDocs:\n    Collections.sort(leaves, new Comparator<LeafReaderContext>() {\n        @Override\n        public int compare(LeafReaderContext c1, LeafReaderContext c2) {\n          return c2.reader().numDocs() - c1.reader().numDocs();\n        }\n      });\n\n    termsEnums = new TermsEnum[leaves.size()];\n    docsEnums = new DocsEnum[leaves.size()];\n    liveDocs = new Bits[leaves.size()];\n    docBases = new int[leaves.size()];\n    int numSegs = 0;\n    boolean hasDeletions = false;\n    for(int i=0;i<leaves.size();i++) {\n      Fields fields = leaves.get(i).reader().fields();\n      if (fields != null) {\n        Terms terms = fields.terms(idFieldName);\n        if (terms != null) {\n          termsEnums[numSegs] = terms.iterator(null);\n          assert termsEnums[numSegs] != null;\n          docBases[numSegs] = leaves.get(i).docBase;\n          liveDocs[numSegs] = leaves.get(i).reader().getLiveDocs();\n          hasDeletions |= leaves.get(i).reader().hasDeletions();\n          numSegs++;\n        }\n      }\n    }\n    this.numSegs = numSegs;\n    this.hasDeletions = hasDeletions;\n  }\n\n","sourceOld":"  public PerThreadPKLookup(IndexReader r, String idFieldName) throws IOException {\n\n    List<AtomicReaderContext> leaves = new ArrayList<>(r.leaves());\n\n    // Larger segments are more likely to have the id, so we sort largest to smallest by numDocs:\n    Collections.sort(leaves, new Comparator<AtomicReaderContext>() {\n        @Override\n        public int compare(AtomicReaderContext c1, AtomicReaderContext c2) {\n          return c2.reader().numDocs() - c1.reader().numDocs();\n        }\n      });\n\n    termsEnums = new TermsEnum[leaves.size()];\n    docsEnums = new DocsEnum[leaves.size()];\n    liveDocs = new Bits[leaves.size()];\n    docBases = new int[leaves.size()];\n    int numSegs = 0;\n    boolean hasDeletions = false;\n    for(int i=0;i<leaves.size();i++) {\n      Fields fields = leaves.get(i).reader().fields();\n      if (fields != null) {\n        Terms terms = fields.terms(idFieldName);\n        if (terms != null) {\n          termsEnums[numSegs] = terms.iterator(null);\n          assert termsEnums[numSegs] != null;\n          docBases[numSegs] = leaves.get(i).docBase;\n          liveDocs[numSegs] = leaves.get(i).reader().getLiveDocs();\n          hasDeletions |= leaves.get(i).reader().hasDeletions();\n          numSegs++;\n        }\n      }\n    }\n    this.numSegs = numSegs;\n    this.hasDeletions = hasDeletions;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8028ab7a24273833d53d35eb160dba5b57283cf5","date":1416767720,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup#PerThreadPKLookup(IndexReader,String).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup#PerThreadPKLookup(IndexReader,String).mjava","sourceNew":"  public PerThreadPKLookup(IndexReader r, String idFieldName) throws IOException {\n\n    List<LeafReaderContext> leaves = new ArrayList<>(r.leaves());\n\n    // Larger segments are more likely to have the id, so we sort largest to smallest by numDocs:\n    Collections.sort(leaves, new Comparator<LeafReaderContext>() {\n        @Override\n        public int compare(LeafReaderContext c1, LeafReaderContext c2) {\n          return c2.reader().numDocs() - c1.reader().numDocs();\n        }\n      });\n\n    termsEnums = new TermsEnum[leaves.size()];\n    docsEnums = new DocsEnum[leaves.size()];\n    liveDocs = new Bits[leaves.size()];\n    docBases = new int[leaves.size()];\n    int numSegs = 0;\n    boolean hasDeletions = false;\n    for(int i=0;i<leaves.size();i++) {\n      Terms terms = leaves.get(i).reader().terms(idFieldName);\n      if (terms != null) {\n        termsEnums[numSegs] = terms.iterator(null);\n        assert termsEnums[numSegs] != null;\n        docBases[numSegs] = leaves.get(i).docBase;\n        liveDocs[numSegs] = leaves.get(i).reader().getLiveDocs();\n        hasDeletions |= leaves.get(i).reader().hasDeletions();\n        numSegs++;\n      }\n    }\n    this.numSegs = numSegs;\n    this.hasDeletions = hasDeletions;\n  }\n\n","sourceOld":"  public PerThreadPKLookup(IndexReader r, String idFieldName) throws IOException {\n\n    List<LeafReaderContext> leaves = new ArrayList<>(r.leaves());\n\n    // Larger segments are more likely to have the id, so we sort largest to smallest by numDocs:\n    Collections.sort(leaves, new Comparator<LeafReaderContext>() {\n        @Override\n        public int compare(LeafReaderContext c1, LeafReaderContext c2) {\n          return c2.reader().numDocs() - c1.reader().numDocs();\n        }\n      });\n\n    termsEnums = new TermsEnum[leaves.size()];\n    docsEnums = new DocsEnum[leaves.size()];\n    liveDocs = new Bits[leaves.size()];\n    docBases = new int[leaves.size()];\n    int numSegs = 0;\n    boolean hasDeletions = false;\n    for(int i=0;i<leaves.size();i++) {\n      Fields fields = leaves.get(i).reader().fields();\n      if (fields != null) {\n        Terms terms = fields.terms(idFieldName);\n        if (terms != null) {\n          termsEnums[numSegs] = terms.iterator(null);\n          assert termsEnums[numSegs] != null;\n          docBases[numSegs] = leaves.get(i).docBase;\n          liveDocs[numSegs] = leaves.get(i).reader().getLiveDocs();\n          hasDeletions |= leaves.get(i).reader().hasDeletions();\n          numSegs++;\n        }\n      }\n    }\n    this.numSegs = numSegs;\n    this.hasDeletions = hasDeletions;\n  }\n\n","bugFix":["b7d615ef411046679022f6728bb2b876273d13ae"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup#PerThreadPKLookup(IndexReader,String).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup#PerThreadPKLookup(IndexReader,String).mjava","sourceNew":"  public PerThreadPKLookup(IndexReader r, String idFieldName) throws IOException {\n\n    List<LeafReaderContext> leaves = new ArrayList<>(r.leaves());\n\n    // Larger segments are more likely to have the id, so we sort largest to smallest by numDocs:\n    Collections.sort(leaves, new Comparator<LeafReaderContext>() {\n        @Override\n        public int compare(LeafReaderContext c1, LeafReaderContext c2) {\n          return c2.reader().numDocs() - c1.reader().numDocs();\n        }\n      });\n\n    termsEnums = new TermsEnum[leaves.size()];\n    postingsEnums = new PostingsEnum[leaves.size()];\n    liveDocs = new Bits[leaves.size()];\n    docBases = new int[leaves.size()];\n    int numSegs = 0;\n    boolean hasDeletions = false;\n    for(int i=0;i<leaves.size();i++) {\n      Terms terms = leaves.get(i).reader().terms(idFieldName);\n      if (terms != null) {\n        termsEnums[numSegs] = terms.iterator(null);\n        assert termsEnums[numSegs] != null;\n        docBases[numSegs] = leaves.get(i).docBase;\n        liveDocs[numSegs] = leaves.get(i).reader().getLiveDocs();\n        hasDeletions |= leaves.get(i).reader().hasDeletions();\n        numSegs++;\n      }\n    }\n    this.numSegs = numSegs;\n    this.hasDeletions = hasDeletions;\n  }\n\n","sourceOld":"  public PerThreadPKLookup(IndexReader r, String idFieldName) throws IOException {\n\n    List<LeafReaderContext> leaves = new ArrayList<>(r.leaves());\n\n    // Larger segments are more likely to have the id, so we sort largest to smallest by numDocs:\n    Collections.sort(leaves, new Comparator<LeafReaderContext>() {\n        @Override\n        public int compare(LeafReaderContext c1, LeafReaderContext c2) {\n          return c2.reader().numDocs() - c1.reader().numDocs();\n        }\n      });\n\n    termsEnums = new TermsEnum[leaves.size()];\n    docsEnums = new DocsEnum[leaves.size()];\n    liveDocs = new Bits[leaves.size()];\n    docBases = new int[leaves.size()];\n    int numSegs = 0;\n    boolean hasDeletions = false;\n    for(int i=0;i<leaves.size();i++) {\n      Terms terms = leaves.get(i).reader().terms(idFieldName);\n      if (terms != null) {\n        termsEnums[numSegs] = terms.iterator(null);\n        assert termsEnums[numSegs] != null;\n        docBases[numSegs] = leaves.get(i).docBase;\n        liveDocs[numSegs] = leaves.get(i).reader().getLiveDocs();\n        hasDeletions |= leaves.get(i).reader().hasDeletions();\n        numSegs++;\n      }\n    }\n    this.numSegs = numSegs;\n    this.hasDeletions = hasDeletions;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup#PerThreadPKLookup(IndexReader,String).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/PerThreadPKLookup#PerThreadPKLookup(IndexReader,String).mjava","sourceNew":"  public PerThreadPKLookup(IndexReader r, String idFieldName) throws IOException {\n\n    List<LeafReaderContext> leaves = new ArrayList<>(r.leaves());\n\n    // Larger segments are more likely to have the id, so we sort largest to smallest by numDocs:\n    Collections.sort(leaves, new Comparator<LeafReaderContext>() {\n        @Override\n        public int compare(LeafReaderContext c1, LeafReaderContext c2) {\n          return c2.reader().numDocs() - c1.reader().numDocs();\n        }\n      });\n\n    termsEnums = new TermsEnum[leaves.size()];\n    postingsEnums = new PostingsEnum[leaves.size()];\n    liveDocs = new Bits[leaves.size()];\n    docBases = new int[leaves.size()];\n    int numSegs = 0;\n    boolean hasDeletions = false;\n    for(int i=0;i<leaves.size();i++) {\n      Terms terms = leaves.get(i).reader().terms(idFieldName);\n      if (terms != null) {\n        termsEnums[numSegs] = terms.iterator();\n        assert termsEnums[numSegs] != null;\n        docBases[numSegs] = leaves.get(i).docBase;\n        liveDocs[numSegs] = leaves.get(i).reader().getLiveDocs();\n        hasDeletions |= leaves.get(i).reader().hasDeletions();\n        numSegs++;\n      }\n    }\n    this.numSegs = numSegs;\n    this.hasDeletions = hasDeletions;\n  }\n\n","sourceOld":"  public PerThreadPKLookup(IndexReader r, String idFieldName) throws IOException {\n\n    List<LeafReaderContext> leaves = new ArrayList<>(r.leaves());\n\n    // Larger segments are more likely to have the id, so we sort largest to smallest by numDocs:\n    Collections.sort(leaves, new Comparator<LeafReaderContext>() {\n        @Override\n        public int compare(LeafReaderContext c1, LeafReaderContext c2) {\n          return c2.reader().numDocs() - c1.reader().numDocs();\n        }\n      });\n\n    termsEnums = new TermsEnum[leaves.size()];\n    postingsEnums = new PostingsEnum[leaves.size()];\n    liveDocs = new Bits[leaves.size()];\n    docBases = new int[leaves.size()];\n    int numSegs = 0;\n    boolean hasDeletions = false;\n    for(int i=0;i<leaves.size();i++) {\n      Terms terms = leaves.get(i).reader().terms(idFieldName);\n      if (terms != null) {\n        termsEnums[numSegs] = terms.iterator(null);\n        assert termsEnums[numSegs] != null;\n        docBases[numSegs] = leaves.get(i).docBase;\n        liveDocs[numSegs] = leaves.get(i).reader().getLiveDocs();\n        hasDeletions |= leaves.get(i).reader().hasDeletions();\n        numSegs++;\n      }\n    }\n    this.numSegs = numSegs;\n    this.hasDeletions = hasDeletions;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["51f5280f31484820499077f41fcdfe92d527d9dc"],"4d637064d608752565d4f9f41b2497dfdfdde50e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b7d615ef411046679022f6728bb2b876273d13ae"],"8028ab7a24273833d53d35eb160dba5b57283cf5":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7d615ef411046679022f6728bb2b876273d13ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"51f5280f31484820499077f41fcdfe92d527d9dc":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["4d637064d608752565d4f9f41b2497dfdfdde50e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4d637064d608752565d4f9f41b2497dfdfdde50e":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"8028ab7a24273833d53d35eb160dba5b57283cf5":["51f5280f31484820499077f41fcdfe92d527d9dc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4d637064d608752565d4f9f41b2497dfdfdde50e","b7d615ef411046679022f6728bb2b876273d13ae"],"b7d615ef411046679022f6728bb2b876273d13ae":["4d637064d608752565d4f9f41b2497dfdfdde50e"],"51f5280f31484820499077f41fcdfe92d527d9dc":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}