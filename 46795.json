{"path":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","commits":[{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","pathOld":"/dev/null","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["b102459ba40f8bc6d609b2058019db7485f7ed67"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b102459ba40f8bc6d609b2058019db7485f7ed67","date":1291773722,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4bd5d0a5ac72666f0bcbd50b535d2cc70dbf584b","date":1291778725,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cdd3a20c3f7b8db3ed0313a58cb6304f9b5bc340","date":1295995357,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = Collections.synchronizedSet(new HashSet<ReaderFinishedListener>());\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ed47693b1e536083c1fa52f3c2994098f3154d3c","date":1296080277,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = Collections.synchronizedSet(new HashSet<ReaderFinishedListener>());\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eb378f8bdee16a26810e086303a4a86b4930ea12","date":1296410797,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(Directory,SegmentInfos,IndexDeletionPolicy,boolean,int,CodecProvider).mjava","sourceNew":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","sourceOld":"  /** Construct reading the named set of readers. */\n  DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, boolean readOnly, int termInfosIndexDivisor, CodecProvider codecs) throws IOException {\n    this.directory = directory;\n    this.readOnly = readOnly;\n    this.segmentInfos = sis;\n    this.deletionPolicy = deletionPolicy;\n    this.termInfosIndexDivisor = termInfosIndexDivisor;\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = new MapBackedSet<ReaderFinishedListener>(new ConcurrentHashMap<ReaderFinishedListener,Boolean>());\n    applyAllDeletes = false;\n\n    // To reduce the chance of hitting FileNotFound\n    // (and having to retry), we open segments in\n    // reverse because IndexWriter merges & deletes\n    // the newest segments first.\n\n    SegmentReader[] readers = new SegmentReader[sis.size()];\n    for (int i = sis.size()-1; i >= 0; i--) {\n      boolean success = false;\n      try {\n        readers[i] = SegmentReader.get(readOnly, sis.info(i), termInfosIndexDivisor, IOContext.READ);\n        readers[i].readerFinishedListeners = readerFinishedListeners;\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(i++;i<sis.size();i++) {\n            try {\n              readers[i].close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    initialize(readers);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b102459ba40f8bc6d609b2058019db7485f7ed67":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["eb378f8bdee16a26810e086303a4a86b4930ea12"],"ed47693b1e536083c1fa52f3c2994098f3154d3c":["cdd3a20c3f7b8db3ed0313a58cb6304f9b5bc340"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["955c32f886db6f6356c9fcdea6b1f1cb4effda24","b102459ba40f8bc6d609b2058019db7485f7ed67"],"eb378f8bdee16a26810e086303a4a86b4930ea12":["ed47693b1e536083c1fa52f3c2994098f3154d3c"],"7b91922b55d15444d554721b352861d028eb8278":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"cdd3a20c3f7b8db3ed0313a58cb6304f9b5bc340":["b102459ba40f8bc6d609b2058019db7485f7ed67"],"4bd5d0a5ac72666f0bcbd50b535d2cc70dbf584b":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["4bd5d0a5ac72666f0bcbd50b535d2cc70dbf584b","eb378f8bdee16a26810e086303a4a86b4930ea12"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["eb378f8bdee16a26810e086303a4a86b4930ea12","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["eb378f8bdee16a26810e086303a4a86b4930ea12","639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","eb378f8bdee16a26810e086303a4a86b4930ea12"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7b91922b55d15444d554721b352861d028eb8278"]},"commit2Childs":{"b102459ba40f8bc6d609b2058019db7485f7ed67":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cdd3a20c3f7b8db3ed0313a58cb6304f9b5bc340"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["b102459ba40f8bc6d609b2058019db7485f7ed67","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","4bd5d0a5ac72666f0bcbd50b535d2cc70dbf584b"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"ed47693b1e536083c1fa52f3c2994098f3154d3c":["eb378f8bdee16a26810e086303a4a86b4930ea12"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"eb378f8bdee16a26810e086303a4a86b4930ea12":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd","29ef99d61cda9641b6250bf9567329a6e65f901d","5d004d0e0b3f65bb40da76d476d659d7888270e8","ddc4c914be86e34b54f70023f45a60fa7f04e929","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"cdd3a20c3f7b8db3ed0313a58cb6304f9b5bc340":["ed47693b1e536083c1fa52f3c2994098f3154d3c"],"7b91922b55d15444d554721b352861d028eb8278":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4bd5d0a5ac72666f0bcbd50b535d2cc70dbf584b":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"29ef99d61cda9641b6250bf9567329a6e65f901d":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["7b91922b55d15444d554721b352861d028eb8278","5d004d0e0b3f65bb40da76d476d659d7888270e8"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["29ef99d61cda9641b6250bf9567329a6e65f901d","5d004d0e0b3f65bb40da76d476d659d7888270e8","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}