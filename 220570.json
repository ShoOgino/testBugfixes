{"path":"solr/src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"/dev/null","sourceNew":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req.getSchema());\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.UN_TOKENIZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      Hits hits = searcher.search(query, lfilter, sort);\n      test(hits.length() == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.id(i+results.offset()) );\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":null,"sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req.getSchema());\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.UN_TOKENIZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n      //\n      // test against hits\n      //\n      Hits hits = searcher.search(query, lfilter, sort);\n      test(hits.length() == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == hits.id(i+results.offset()) );\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req.getSchema());\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.NOT_ANALYZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n    \n      //\n      // test against hits\n      //\n      int numHits;\n      ScoreDoc[] scoreDocs;\n      if (sort != null) {\n        TopFieldDocs hits = searcher.search(query, lfilter, 1000, sort);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      } else {\n        TopDocs hits = searcher.search(query, lfilter, 1000);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      }\n      test(numHits == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == scoreDocs[i].doc);\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req.getSchema());\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.NOT_ANALYZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n    \n      //\n      // test against hits\n      //\n      int numHits;\n      ScoreDoc[] scoreDocs;\n      if (sort != null) {\n        TopFieldDocs hits = searcher.search(query, lfilter, 1000, sort);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      } else {\n        TopDocs hits = searcher.search(query, lfilter, 1000);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      }\n      test(numHits == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == scoreDocs[i].doc);\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"/dev/null","sourceNew":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req.getSchema());\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.NOT_ANALYZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n    \n      //\n      // test against hits\n      //\n      int numHits;\n      ScoreDoc[] scoreDocs;\n      if (sort != null) {\n        TopFieldDocs hits = searcher.search(query, lfilter, 1000, sort);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      } else {\n        TopDocs hits = searcher.search(query, lfilter, 1000);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      }\n      test(numHits == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == scoreDocs[i].doc);\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0883328ff2cc09b5c999d05c04e16530d819c627","date":1285860918,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"solr/src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req);\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.NOT_ANALYZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n    \n      //\n      // test against hits\n      //\n      int numHits;\n      ScoreDoc[] scoreDocs;\n      if (sort != null) {\n        TopFieldDocs hits = searcher.search(query, lfilter, 1000, sort);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      } else {\n        TopDocs hits = searcher.search(query, lfilter, 1000);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      }\n      test(numHits == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == scoreDocs[i].doc);\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req.getSchema());\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.NOT_ANALYZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n    \n      //\n      // test against hits\n      //\n      int numHits;\n      ScoreDoc[] scoreDocs;\n      if (sort != null) {\n        TopFieldDocs hits = searcher.search(query, lfilter, 1000, sort);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      } else {\n        TopDocs hits = searcher.search(query, lfilter, 1000);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      }\n      test(numHits == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == scoreDocs[i].doc);\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","pathOld":"solr/src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req);\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.NOT_ANALYZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n    \n      //\n      // test against hits\n      //\n      int numHits;\n      ScoreDoc[] scoreDocs;\n      if (sort != null) {\n        TopFieldDocs hits = searcher.search(query, lfilter, 1000, sort);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      } else {\n        TopDocs hits = searcher.search(query, lfilter, 1000);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      }\n      test(numHits == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == scoreDocs[i].doc);\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req.getSchema());\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.NOT_ANALYZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n    \n      //\n      // test against hits\n      //\n      int numHits;\n      ScoreDoc[] scoreDocs;\n      if (sort != null) {\n        TopFieldDocs hits = searcher.search(query, lfilter, 1000, sort);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      } else {\n        TopDocs hits = searcher.search(query, lfilter, 1000);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      }\n      test(numHits == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == scoreDocs[i].doc);\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c5b41c4c1cb769262a6793a8d940bc9ab7a7e9a","date":1293241159,"type":4,"author":"Yonik Seeley","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":null,"sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req);\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.NOT_ANALYZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n    \n      //\n      // test against hits\n      //\n      int numHits;\n      ScoreDoc[] scoreDocs;\n      if (sort != null) {\n        TopFieldDocs hits = searcher.search(query, lfilter, 1000, sort);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      } else {\n        TopDocs hits = searcher.search(query, lfilter, 1000);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      }\n      test(numHits == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == scoreDocs[i].doc);\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c","date":1294014627,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":null,"sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req);\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.NOT_ANALYZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n    \n      //\n      // test against hits\n      //\n      int numHits;\n      ScoreDoc[] scoreDocs;\n      if (sort != null) {\n        TopFieldDocs hits = searcher.search(query, lfilter, 1000, sort);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      } else {\n        TopDocs hits = searcher.search(query, lfilter, 1000);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      }\n      test(numHits == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == scoreDocs[i].doc);\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/tst/TestRequestHandler#handleRequest(SolrQueryRequest,SolrQueryResponse).mjava","sourceNew":null,"sourceOld":"  public void handleRequest(SolrQueryRequest req, SolrQueryResponse rsp) {\n    numRequests++;\n\n    // TODO: test if lucene will accept an escaped ';', otherwise\n    // we need to un-escape them before we pass to QueryParser\n    try {\n      String sreq = req.getQueryString();\n      if (sreq==null) throw new SolrException( SolrException.ErrorCode.BAD_REQUEST,\"Missing queryString\");\n      List<String> commands = StrUtils.splitSmart(sreq,';');\n\n      String qs = commands.size() >= 1 ? commands.get(0) : \"\";\n      Query query = QueryParsing.parseQuery(qs, req.getSchema());\n\n      // find fieldnames to return (fieldlist)\n      String fl = req.getParam(\"fl\");\n      int flags=0;\n      if (fl != null) {\n        // TODO - this could become more efficient if widely used.\n        // TODO - should field order be maintained?\n        String[] flst = splitList.split(fl,0);\n        if (flst.length > 0 && !(flst.length==1 && flst[0].length()==0)) {\n          Set<String> set = new HashSet<String>();\n          for (String fname : flst) {\n            if (\"score\".equals(fname)) flags |= SolrIndexSearcher.GET_SCORES;\n            set.add(fname);\n          }\n          rsp.setReturnFields(set);\n        }\n      }\n\n\n      // If the first non-query, non-filter command is a simple sort on an indexed field, then\n      // we can use the Lucene sort ability.\n      Sort sort = null;\n      if (commands.size() >= 2) {\n        sort = QueryParsing.parseSort(commands.get(1), req);\n      }\n\n      SolrIndexSearcher searcher = req.getSearcher();\n\n      /***\n      Object o = searcher.cacheLookup(\"dfllNode\", query);\n      if (o == null) {\n        searcher.cacheInsert(\"dfllNode\",query,\"Hello Bob\");\n      } else {\n        System.out.println(\"User Cache Hit On \" + o);\n      }\n      ***/\n\n      int start=req.getStart();\n      int limit=req.getLimit();\n\n      Query filterQuery=null;\n      DocSet filter=null;\n      Filter lfilter=null;\n\n      DocList results = req.getSearcher().getDocList(query, null, sort, req.getStart(), req.getLimit(), flags);\n      rsp.add(null, results);\n\n\n      if (qs.startsWith(\"values\")) {\n        rsp.add(\"testname1\",\"testval1\");\n\n        rsp.add(\"testarr1\",new String[]{\"my val 1\",\"my val 2\"});\n\n        NamedList nl = new NamedList();\n        nl.add(\"myInt\", 333);\n        nl.add(\"myNullVal\", null);\n        nl.add(\"myFloat\",1.414213562f);\n        nl.add(\"myDouble\", 1e100d);\n        nl.add(\"myBool\", false);\n        nl.add(\"myLong\",999999999999L);\n\n        Document doc = new Document();\n        doc.add(new Field(\"id\",\"55\",Field.Store.YES, Field.Index.NOT_ANALYZED));\n        nl.add(\"myDoc\",doc);\n\n        nl.add(\"myResult\",results);\n        nl.add(\"myStr\",\"&wow! test escaping: a&b<c&\");\n        nl.add(null, \"this value had a null name...\");\n        nl.add(\"myIntArray\", new Integer[] { 100, 5, -10, 42 });\n        nl.add(\"epoch\", new Date(0));\n        nl.add(\"currDate\", new Date(System.currentTimeMillis()));\n        rsp.add(\"myNamedList\", nl);\n      } else if (qs.startsWith(\"fields\")) {\n        NamedList nl = new NamedList();\n        Collection flst;\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.INDEXED);\n        nl.add(\"indexed\",flst);\n        flst = searcher.getReader().getFieldNames(IndexReader.FieldOption.UNINDEXED);\n        nl.add(\"unindexed\",flst);\n        rsp.add(\"fields\", nl);\n      }\n\n      test(results.size() <= limit);\n      test(results.size() <= results.matches());\n      // System.out.println(\"limit=\"+limit+\" results.size()=\"+results.size()+\" matches=\"+results.matches());\n      test((start==0 && limit>=results.matches()) ? results.size()==results.matches() : true );\n\n    \n      //\n      // test against hits\n      //\n      int numHits;\n      ScoreDoc[] scoreDocs;\n      if (sort != null) {\n        TopFieldDocs hits = searcher.search(query, lfilter, 1000, sort);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      } else {\n        TopDocs hits = searcher.search(query, lfilter, 1000);\n        numHits = hits.totalHits;\n        scoreDocs = hits.scoreDocs;\n      }\n      test(numHits == results.matches());\n\n\n      DocList rrr2 = results.subset(start,limit);\n      test(rrr2 == results);\n\n      DocIterator iter=results.iterator();\n\n\n      /***\n      for (int i=0; i<hits.length(); i++) {\n        System.out.println(\"doc=\"+hits.id(i) + \" score=\"+hits.score(i));\n      }\n      ***/\n\n      for (int i=0; i<results.size(); i++) {\n        test( iter.nextDoc() == scoreDocs[i].doc);\n\n        // Document doesn't implement equals()\n        // test( searcher.document(i).equals(hits.doc(i)));\n      }\n\n\n      DocList results2 = req.getSearcher().getDocList(query,query,sort,start,limit);\n      test(results2.size()==results.size() && results2.matches()==results.matches());\n      DocList results3 = req.getSearcher().getDocList(query,query,null,start,limit);\n      test(results3.size()==results.size() && results3.matches()==results.matches());\n\n      //\n      // getting both the list and set\n      //\n      DocListAndSet both = searcher.getDocListAndSet(query,filter,sort,start, limit);\n      test( both.docList.equals(results) );\n      test( both.docList.matches() == both.docSet.size() );\n      test( (start==0 && both.docSet.size() <= limit) ? both.docSet.equals(both.docList) : true);\n\n      // use the result set as a filter itself...\n      DocListAndSet both2 = searcher.getDocListAndSet(query,both.docSet,sort,start, limit);\n      test( both2.docList.equals(both.docList) );\n      test( both2.docSet.equals(both.docSet) );\n\n      // use the query as a filter itself...\n      DocListAndSet both3 = searcher.getDocListAndSet(query,query,sort,start, limit);\n      test( both3.docList.equals(both.docList) );\n      test( both3.docSet.equals(both.docSet) );\n\n      OpenBitSet bits = both.docSet.getBits();\n      OpenBitSet neg = ((OpenBitSet)bits.clone());\n      neg.flip(0, bits.capacity());\n\n      // use the negative as a filter (should result in 0 matches)\n      // todo - fix if filter is not null\n      both2 = searcher.getDocListAndSet(query,new BitDocSet(neg),sort, start, limit);\n      test( both2.docList.size() == 0 );\n      test( both2.docList.matches() == 0 );\n      test( both2.docSet.size() == 0 );\n\n      DocSet allResults=searcher.getDocSet(query,filter);\n      test ( allResults.equals(both.docSet) );\n\n      if (filter != null) {\n        DocSet res=searcher.getDocSet(query);\n        test( res.size() >= results.size() );\n        test( res.intersection(filter).equals(both.docSet));\n\n        test( res.intersectionSize(filter) == both.docSet.size() );\n        if (filterQuery != null) {\n          test( searcher.numDocs(filterQuery,res) == both.docSet.size() );\n        }\n      }\n\n\n    } catch (Exception e) {\n      rsp.setException(e);\n      numErrors++;\n      return;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0883328ff2cc09b5c999d05c04e16530d819c627":["1da8d55113b689b06716246649de6f62430f15c0"],"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"70ad682703b8585f5d0a637efec044d57ec05efb":["0883328ff2cc09b5c999d05c04e16530d819c627","2c5b41c4c1cb769262a6793a8d940bc9ab7a7e9a"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","2c5b41c4c1cb769262a6793a8d940bc9ab7a7e9a"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"2c5b41c4c1cb769262a6793a8d940bc9ab7a7e9a":["0883328ff2cc09b5c999d05c04e16530d819c627"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["1da8d55113b689b06716246649de6f62430f15c0","0883328ff2cc09b5c999d05c04e16530d819c627"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2c5b41c4c1cb769262a6793a8d940bc9ab7a7e9a"]},"commit2Childs":{"0883328ff2cc09b5c999d05c04e16530d819c627":["70ad682703b8585f5d0a637efec044d57ec05efb","2c5b41c4c1cb769262a6793a8d940bc9ab7a7e9a","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"1da8d55113b689b06716246649de6f62430f15c0":["0883328ff2cc09b5c999d05c04e16530d819c627","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"70ad682703b8585f5d0a637efec044d57ec05efb":[],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c":[],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"2c5b41c4c1cb769262a6793a8d940bc9ab7a7e9a":["70ad682703b8585f5d0a637efec044d57ec05efb","ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["70ad682703b8585f5d0a637efec044d57ec05efb","ff9cf7165d6cbafe4ef4431ecc2dc1af9cb2316c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}