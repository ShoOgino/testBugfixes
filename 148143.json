{"path":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","sourceNew":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n    TreeSet<Term> terms = new TreeSet<Term>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term, true));\n    }\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(context);\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      final Spans spans = query.getSpans(atomicReaderContext, atomicReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n    TreeSet<Term> terms = new TreeSet<Term>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term, true));\n    }\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(context);\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      final Spans spans = query.getSpans(atomicReaderContext, atomicReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8","date":1328775259,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","sourceNew":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n    TreeSet<Term> terms = new TreeSet<Term>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term, true));\n    }\n    final AtomicReaderContext[] leaves = context.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      final Spans spans = query.getSpans(atomicReaderContext, atomicReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n    TreeSet<Term> terms = new TreeSet<Term>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term, true));\n    }\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(context);\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      final Spans spans = query.getSpans(atomicReaderContext, atomicReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","date":1340090669,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","sourceNew":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n    TreeSet<Term> terms = new TreeSet<Term>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term, true));\n    }\n    for (AtomicReaderContext atomicReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(atomicReaderContext, atomicReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n    TreeSet<Term> terms = new TreeSet<Term>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term, true));\n    }\n    final AtomicReaderContext[] leaves = context.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      final Spans spans = query.getSpans(atomicReaderContext, atomicReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8","date":1373996650,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","sourceNew":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n    TreeSet<Term> terms = new TreeSet<Term>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term));\n    }\n    for (AtomicReaderContext atomicReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(atomicReaderContext, atomicReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n    TreeSet<Term> terms = new TreeSet<Term>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term, true));\n    }\n    for (AtomicReaderContext atomicReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(atomicReaderContext, atomicReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","sourceNew":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n    TreeSet<Term> terms = new TreeSet<Term>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term));\n    }\n    for (AtomicReaderContext atomicReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(atomicReaderContext, atomicReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n    TreeSet<Term> terms = new TreeSet<Term>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term, true));\n    }\n    for (AtomicReaderContext atomicReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(atomicReaderContext, atomicReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","sourceNew":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<>();\n    TreeSet<Term> terms = new TreeSet<>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term));\n    }\n    for (AtomicReaderContext atomicReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(atomicReaderContext, atomicReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n    TreeSet<Term> terms = new TreeSet<Term>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term));\n    }\n    for (AtomicReaderContext atomicReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(atomicReaderContext, atomicReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","sourceNew":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<>();\n    TreeSet<Term> terms = new TreeSet<>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term));\n    }\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<>();\n    TreeSet<Term> terms = new TreeSet<>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term));\n    }\n    for (AtomicReaderContext atomicReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(atomicReaderContext, atomicReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30de45e50bdc1a79a6797f34dca6271c8866cb6e","date":1427790465,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","sourceNew":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<>();\n    TreeSet<Term> terms = new TreeSet<>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term));\n    }\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), termContexts);\n      if (spans != null) {\n        while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n          while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n            if (spans.isPayloadAvailable()) {\n              Collection<byte[]> payload = spans.getPayload();\n              for (byte [] bytes : payload) {\n                payloads.add(bytes);\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<>();\n    TreeSet<Term> terms = new TreeSet<>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term));\n    }\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fab172655716b96f7e42376116235017a922de3a","date":1427850611,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","sourceNew":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<>();\n    TreeSet<Term> terms = new TreeSet<>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term));\n    }\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), termContexts);\n      if (spans != null) {\n        while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n          while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n            if (spans.isPayloadAvailable()) {\n              Collection<byte[]> payload = spans.getPayload();\n              for (byte [] bytes : payload) {\n                payloads.add(bytes);\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<>();\n    TreeSet<Term> terms = new TreeSet<>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term));\n    }\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), termContexts);\n      while (spans.next() == true) {\n        if (spans.isPayloadAvailable()) {\n          Collection<byte[]> payload = spans.getPayload();\n          for (byte [] bytes : payload) {\n            payloads.add(bytes);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05c52ac194342b760b830342ee8423fcf00e54d0","date":1429197275,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","sourceNew":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<>();\n    TreeSet<Term> terms = new TreeSet<>();\n    final IndexSearcher searcher = new IndexSearcher(context);\n    searcher.setQueryCache(null);\n    searcher.createNormalizedWeight(query, false).extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term));\n    }\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), termContexts);\n      if (spans != null) {\n        while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n          while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n            if (spans.isPayloadAvailable()) {\n              Collection<byte[]> payload = spans.getPayload();\n              for (byte [] bytes : payload) {\n                payloads.add(bytes);\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<>();\n    TreeSet<Term> terms = new TreeSet<>();\n    query.extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term));\n    }\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), termContexts);\n      if (spans != null) {\n        while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n          while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n            if (spans.isPayloadAvailable()) {\n              Collection<byte[]> payload = spans.getPayload();\n              for (byte [] bytes : payload) {\n                payloads.add(bytes);\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2d530e71ed32ab23b34ca3fc72b080a554a40404","date":1432026158,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","sourceNew":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<>();\n    TreeSet<Term> terms = new TreeSet<>();\n    final IndexSearcher searcher = new IndexSearcher(context);\n    searcher.setQueryCache(null);\n    searcher.createNormalizedWeight(query, false).extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term));\n    }\n\n    PayloadSpanCollector collector = new PayloadSpanCollector();\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), termContexts, collector);\n      if (spans != null) {\n        while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n          while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n            collector.reset();\n            spans.collect(collector);\n            payloads.addAll(collector.getPayloads());\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<>();\n    TreeSet<Term> terms = new TreeSet<>();\n    final IndexSearcher searcher = new IndexSearcher(context);\n    searcher.setQueryCache(null);\n    searcher.createNormalizedWeight(query, false).extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term));\n    }\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), termContexts);\n      if (spans != null) {\n        while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n          while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n            if (spans.isPayloadAvailable()) {\n              Collection<byte[]> payload = spans.getPayload();\n              for (byte [] bytes : payload) {\n                payloads.add(bytes);\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c257cd8ddb1ed5632a36c7488614a2ee21705d24","date":1432128550,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","sourceNew":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n\n    final IndexSearcher searcher = new IndexSearcher(context);\n    searcher.setQueryCache(null);\n\n    SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(query, false);\n\n    PayloadSpanCollector collector = new PayloadSpanCollector();\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = w.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), collector);\n      if (spans != null) {\n        while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n          while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n            collector.reset();\n            spans.collect(collector);\n            payloads.addAll(collector.getPayloads());\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n    Map<Term,TermContext> termContexts = new HashMap<>();\n    TreeSet<Term> terms = new TreeSet<>();\n    final IndexSearcher searcher = new IndexSearcher(context);\n    searcher.setQueryCache(null);\n    searcher.createNormalizedWeight(query, false).extractTerms(terms);\n    for (Term term : terms) {\n      termContexts.put(term, TermContext.build(context, term));\n    }\n\n    PayloadSpanCollector collector = new PayloadSpanCollector();\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = query.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), termContexts, collector);\n      if (spans != null) {\n        while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n          while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n            collector.reset();\n            spans.collect(collector);\n            payloads.addAll(collector.getPayloads());\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29aea3139c4326c0501d75d51059855463220279","date":1433952060,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","sourceNew":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n\n    final IndexSearcher searcher = new IndexSearcher(context);\n    searcher.setQueryCache(null);\n\n    SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(query, false);\n\n    PayloadSpanCollector collector = new PayloadSpanCollector();\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = w.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), SpanWeight.Postings.PAYLOADS);\n      if (spans != null) {\n        while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n          while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n            collector.reset();\n            spans.collect(collector);\n            payloads.addAll(collector.getPayloads());\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n\n    final IndexSearcher searcher = new IndexSearcher(context);\n    searcher.setQueryCache(null);\n\n    SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(query, false);\n\n    PayloadSpanCollector collector = new PayloadSpanCollector();\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = w.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), collector);\n      if (spans != null) {\n        while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n          while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n            collector.reset();\n            spans.collect(collector);\n            payloads.addAll(collector.getPayloads());\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","sourceNew":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n\n    final IndexSearcher searcher = new IndexSearcher(context);\n    searcher.setQueryCache(null);\n\n    SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(query, false);\n\n    PayloadSpanCollector collector = new PayloadSpanCollector();\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = w.getSpans(leafReaderContext, SpanWeight.Postings.PAYLOADS);\n      if (spans != null) {\n        while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n          while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n            collector.reset();\n            spans.collect(collector);\n            payloads.addAll(collector.getPayloads());\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n\n    final IndexSearcher searcher = new IndexSearcher(context);\n    searcher.setQueryCache(null);\n\n    SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(query, false);\n\n    PayloadSpanCollector collector = new PayloadSpanCollector();\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = w.getSpans(leafReaderContext, leafReaderContext.reader().getLiveDocs(), SpanWeight.Postings.PAYLOADS);\n      if (spans != null) {\n        while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n          while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n            collector.reset();\n            spans.collect(collector);\n            payloads.addAll(collector.getPayloads());\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eeab49258a6aca6c7e96aaf189f1794fe6ddebe4","date":1442407411,"type":5,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/sandbox/src/java/org/apache/lucene/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/payloads/PayloadSpanUtil#getPayloads(Collection[byte[]],SpanQuery).mjava","sourceNew":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n\n    final IndexSearcher searcher = new IndexSearcher(context);\n    searcher.setQueryCache(null);\n\n    SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(query, false);\n\n    PayloadSpanCollector collector = new PayloadSpanCollector();\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = w.getSpans(leafReaderContext, SpanWeight.Postings.PAYLOADS);\n      if (spans != null) {\n        while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n          while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n            collector.reset();\n            spans.collect(collector);\n            payloads.addAll(collector.getPayloads());\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void getPayloads(Collection<byte []> payloads, SpanQuery query)\n      throws IOException {\n\n    final IndexSearcher searcher = new IndexSearcher(context);\n    searcher.setQueryCache(null);\n\n    SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(query, false);\n\n    PayloadSpanCollector collector = new PayloadSpanCollector();\n    for (LeafReaderContext leafReaderContext : context.leaves()) {\n      final Spans spans = w.getSpans(leafReaderContext, SpanWeight.Postings.PAYLOADS);\n      if (spans != null) {\n        while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n          while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n            collector.reset();\n            spans.collect(collector);\n            payloads.addAll(collector.getPayloads());\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["eee5f2a24465d2c9a5f86ab84b7c35041a30fda8"],"29aea3139c4326c0501d75d51059855463220279":["c257cd8ddb1ed5632a36c7488614a2ee21705d24"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"c257cd8ddb1ed5632a36c7488614a2ee21705d24":["2d530e71ed32ab23b34ca3fc72b080a554a40404"],"05c52ac194342b760b830342ee8423fcf00e54d0":["30de45e50bdc1a79a6797f34dca6271c8866cb6e"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"eeab49258a6aca6c7e96aaf189f1794fe6ddebe4":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["29aea3139c4326c0501d75d51059855463220279"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"2d530e71ed32ab23b34ca3fc72b080a554a40404":["05c52ac194342b760b830342ee8423fcf00e54d0"],"30de45e50bdc1a79a6797f34dca6271c8866cb6e":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"fab172655716b96f7e42376116235017a922de3a":["c9fb5f46e264daf5ba3860defe623a89d202dd87","30de45e50bdc1a79a6797f34dca6271c8866cb6e"],"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["eeab49258a6aca6c7e96aaf189f1794fe6ddebe4"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"29aea3139c4326c0501d75d51059855463220279":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","eee5f2a24465d2c9a5f86ab84b7c35041a30fda8"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8"],"0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"c257cd8ddb1ed5632a36c7488614a2ee21705d24":["29aea3139c4326c0501d75d51059855463220279"],"05c52ac194342b760b830342ee8423fcf00e54d0":["2d530e71ed32ab23b34ca3fc72b080a554a40404"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["30de45e50bdc1a79a6797f34dca6271c8866cb6e","fab172655716b96f7e42376116235017a922de3a"],"eeab49258a6aca6c7e96aaf189f1794fe6ddebe4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["eeab49258a6aca6c7e96aaf189f1794fe6ddebe4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"2d530e71ed32ab23b34ca3fc72b080a554a40404":["c257cd8ddb1ed5632a36c7488614a2ee21705d24"],"30de45e50bdc1a79a6797f34dca6271c8866cb6e":["05c52ac194342b760b830342ee8423fcf00e54d0","fab172655716b96f7e42376116235017a922de3a"],"fab172655716b96f7e42376116235017a922de3a":[],"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","fab172655716b96f7e42376116235017a922de3a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}