{"path":"src/java/org/apache/solr/handler/component/SpellCheckComponent#finishStage(ResponseBuilder).mjava","commits":[{"id":"9079aceb3d611cfeb6922ebdf91003c30a08b745","date":1260364972,"type":0,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/component/SpellCheckComponent#finishStage(ResponseBuilder).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\", \"deprecation\"})\n  public void finishStage(ResponseBuilder rb) {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false) || rb.stage != ResponseBuilder.STAGE_GET_FIELDS)\n      return;\n\n    boolean extendedResults = params.getBool(SPELLCHECK_EXTENDED_RESULTS, false);\n    boolean collate = params.getBool(SPELLCHECK_COLLATE, false);\n\n    String origQuery = params.get(SPELLCHECK_Q);\n    if (origQuery == null) {\n      origQuery = rb.getQueryString();\n      if (origQuery == null) {\n        origQuery = params.get(CommonParams.Q);\n      }\n    }\n\n    int count = rb.req.getParams().getInt(SPELLCHECK_COUNT, 1);\n    float min = 0.5f;\n    StringDistance sd = null;\n    int numSug = Math.max(count, AbstractLuceneSpellChecker.DEFAULT_SUGGESTION_COUNT);\n    SolrSpellChecker checker = getSpellChecker(rb.req.getParams());\n    if (checker instanceof AbstractLuceneSpellChecker) {\n      AbstractLuceneSpellChecker spellChecker = (AbstractLuceneSpellChecker) checker;\n      min = spellChecker.getAccuracy();\n      sd = spellChecker.getStringDistance();\n    }\n    if (sd == null)\n      sd = new LevensteinDistance();\n\n    Collection<Token> tokens = null;\n    try {\n      tokens = getTokens(origQuery, checker.getQueryAnalyzer());\n    } catch (IOException e) {\n      LOG.error(\"Could not get tokens (this should never happen)\", e);\n    }\n\n    // original token -> corresponding Suggestion object (keep track of start,end)\n    Map<String, SpellCheckResponse.Suggestion> origVsSuggestion = new HashMap<String, SpellCheckResponse.Suggestion>();\n    // original token string -> summed up frequency\n    Map<String, Integer> origVsFreq = new HashMap<String, Integer>();\n    // original token string -> set of alternatives\n    // must preserve order because collation algorithm can only work in-order\n    Map<String, HashSet<String>> origVsSuggested = new LinkedHashMap<String, HashSet<String>>();\n    // alternative string -> corresponding SuggestWord object\n    Map<String, SuggestWord> suggestedVsWord = new HashMap<String, SuggestWord>();\n\n    for (ShardRequest sreq : rb.finished) {\n      for (ShardResponse srsp : sreq.responses) {\n        NamedList nl = (NamedList) srsp.getSolrResponse().getResponse().get(\"spellcheck\");\n        LOG.info(srsp.getShard() + \" \" + nl);\n        if (nl != null) {\n          SpellCheckResponse spellCheckResp = new SpellCheckResponse(nl);\n          for (SpellCheckResponse.Suggestion suggestion : spellCheckResp.getSuggestions()) {\n            origVsSuggestion.put(suggestion.getToken(), suggestion);\n            HashSet<String> suggested = origVsSuggested.get(suggestion.getToken());\n            if (suggested == null) {\n              suggested = new HashSet<String>();\n              origVsSuggested.put(suggestion.getToken(), suggested);\n            }\n\n            // sum up original frequency          \n            int origFreq = 0;\n            Integer o = origVsFreq.get(suggestion.getToken());\n            if (o != null)  origFreq += o;\n            origFreq += suggestion.getOriginalFrequency();\n            origVsFreq.put(suggestion.getToken(), origFreq);\n\n            // find best suggestions\n            for (int i = 0; i < suggestion.getNumFound(); i++) {\n              String alternative = suggestion.getAlternatives().get(i);\n              suggested.add(alternative);\n              SuggestWord sug = suggestedVsWord.get(alternative);\n              if (sug == null)  {\n                sug = new SuggestWord();\n                suggestedVsWord.put(alternative, sug);\n              }\n              sug.string = alternative;\n              // alternative frequency is present only for extendedResults=true\n              if (suggestion.getAlternativeFrequencies() != null && suggestion.getAlternativeFrequencies().size() > 0) {\n                Integer freq = suggestion.getAlternativeFrequencies().get(i);\n                if (freq != null) sug.freq += freq;\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // all shard responses have been collected\n    // create token and get top suggestions\n    SpellingResult result = new SpellingResult(tokens); //todo: investigate, why does it need tokens beforehand?\n    for (Map.Entry<String, HashSet<String>> entry : origVsSuggested.entrySet()) {\n      String original = entry.getKey();\n      HashSet<String> suggested = entry.getValue();\n      SuggestWordQueue sugQueue = new SuggestWordQueue(numSug);\n      for (String suggestion : suggested) {\n        SuggestWord sug = suggestedVsWord.get(suggestion);\n        sug.score = sd.getDistance(original, sug.string);\n        if (sug.score < min) continue;\n        sugQueue.insertWithOverflow(sug);\n        if (sugQueue.size() == numSug) {\n          // if queue full, maintain the minScore score\n          min = ((SuggestWord) sugQueue.top()).score;\n        }\n      }\n\n      // create token\n      SpellCheckResponse.Suggestion suggestion = origVsSuggestion.get(original);\n      Token token = new Token();\n      token.setTermText(original);\n      token.setStartOffset(suggestion.getStartOffset());\n      token.setEndOffset(suggestion.getEndOffset());\n\n      // get top 'count' suggestions out of 'sugQueue.size()' candidates\n      SuggestWord[] suggestions = new SuggestWord[Math.min(count, sugQueue.size())];\n      // skip the first sugQueue.size() - count elements\n      for (int k=0; k < sugQueue.size() - count; k++) sugQueue.pop();\n      // now collect the top 'count' responses\n      for (int k = Math.min(count, sugQueue.size()) - 1; k >= 0; k--)  {\n        suggestions[k] = ((SuggestWord) sugQueue.pop());\n      }\n\n      if (extendedResults) {\n        Integer o = origVsFreq.get(original);\n        if (o != null) result.add(token, o);\n        for (SuggestWord word : suggestions)\n          result.add(token, word.string, word.freq);\n      } else {\n        List<String> words = new ArrayList<String>(sugQueue.size());\n        for (SuggestWord word : suggestions) words.add(word.string);\n        result.add(token, words);\n      }\n    }\n    \n    NamedList response = new SimpleOrderedMap();\n    response.add(\"suggestions\", toNamedList(result, origQuery, extendedResults, collate));\n    rb.rsp.add(\"spellcheck\", response);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["d6aab5206b894bf0ea232b059a45cf2de460726f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ef28ac95f5f85bbf872801277448c0924b0a6827","date":1268600312,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/component/SpellCheckComponent#finishStage(ResponseBuilder).mjava","pathOld":"src/java/org/apache/solr/handler/component/SpellCheckComponent#finishStage(ResponseBuilder).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\", \"deprecation\"})\n  public void finishStage(ResponseBuilder rb) {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false) || rb.stage != ResponseBuilder.STAGE_GET_FIELDS)\n      return;\n\n    boolean extendedResults = params.getBool(SPELLCHECK_EXTENDED_RESULTS, false);\n    boolean collate = params.getBool(SPELLCHECK_COLLATE, false);\n\n    String origQuery = params.get(SPELLCHECK_Q);\n    if (origQuery == null) {\n      origQuery = rb.getQueryString();\n      if (origQuery == null) {\n        origQuery = params.get(CommonParams.Q);\n      }\n    }\n\n    int count = rb.req.getParams().getInt(SPELLCHECK_COUNT, 1);\n    float min = 0.5f;\n    StringDistance sd = null;\n    int numSug = Math.max(count, AbstractLuceneSpellChecker.DEFAULT_SUGGESTION_COUNT);\n    SolrSpellChecker checker = getSpellChecker(rb.req.getParams());\n    if (checker instanceof AbstractLuceneSpellChecker) {\n      AbstractLuceneSpellChecker spellChecker = (AbstractLuceneSpellChecker) checker;\n      min = spellChecker.getAccuracy();\n      sd = spellChecker.getStringDistance();\n    }\n    if (sd == null)\n      sd = new LevensteinDistance();\n\n    Collection<Token> tokens = null;\n    try {\n      tokens = getTokens(origQuery, checker.getQueryAnalyzer());\n    } catch (IOException e) {\n      LOG.error(\"Could not get tokens (this should never happen)\", e);\n    }\n\n    // original token -> corresponding Suggestion object (keep track of start,end)\n    Map<String, SpellCheckResponse.Suggestion> origVsSuggestion = new HashMap<String, SpellCheckResponse.Suggestion>();\n    // original token string -> summed up frequency\n    Map<String, Integer> origVsFreq = new HashMap<String, Integer>();\n    // original token string -> set of alternatives\n    // must preserve order because collation algorithm can only work in-order\n    Map<String, HashSet<String>> origVsSuggested = new LinkedHashMap<String, HashSet<String>>();\n    // alternative string -> corresponding SuggestWord object\n    Map<String, SuggestWord> suggestedVsWord = new HashMap<String, SuggestWord>();\n\n    for (ShardRequest sreq : rb.finished) {\n      for (ShardResponse srsp : sreq.responses) {\n        NamedList nl = (NamedList) srsp.getSolrResponse().getResponse().get(\"spellcheck\");\n        LOG.info(srsp.getShard() + \" \" + nl);\n        if (nl != null) {\n          SpellCheckResponse spellCheckResp = new SpellCheckResponse(nl);\n          for (SpellCheckResponse.Suggestion suggestion : spellCheckResp.getSuggestions()) {\n            origVsSuggestion.put(suggestion.getToken(), suggestion);\n            HashSet<String> suggested = origVsSuggested.get(suggestion.getToken());\n            if (suggested == null) {\n              suggested = new HashSet<String>();\n              origVsSuggested.put(suggestion.getToken(), suggested);\n            }\n\n            // sum up original frequency          \n            int origFreq = 0;\n            Integer o = origVsFreq.get(suggestion.getToken());\n            if (o != null)  origFreq += o;\n            origFreq += suggestion.getOriginalFrequency();\n            origVsFreq.put(suggestion.getToken(), origFreq);\n\n            // find best suggestions\n            for (int i = 0; i < suggestion.getNumFound(); i++) {\n              String alternative = suggestion.getAlternatives().get(i);\n              suggested.add(alternative);\n              SuggestWord sug = suggestedVsWord.get(alternative);\n              if (sug == null)  {\n                sug = new SuggestWord();\n                suggestedVsWord.put(alternative, sug);\n              }\n              sug.string = alternative;\n              // alternative frequency is present only for extendedResults=true\n              if (suggestion.getAlternativeFrequencies() != null && suggestion.getAlternativeFrequencies().size() > 0) {\n                Integer freq = suggestion.getAlternativeFrequencies().get(i);\n                if (freq != null) sug.freq += freq;\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // all shard responses have been collected\n    // create token and get top suggestions\n    SpellingResult result = new SpellingResult(tokens); //todo: investigate, why does it need tokens beforehand?\n    for (Map.Entry<String, HashSet<String>> entry : origVsSuggested.entrySet()) {\n      String original = entry.getKey();\n      HashSet<String> suggested = entry.getValue();\n      SuggestWordQueue sugQueue = new SuggestWordQueue(numSug);\n      for (String suggestion : suggested) {\n        SuggestWord sug = suggestedVsWord.get(suggestion);\n        sug.score = sd.getDistance(original, sug.string);\n        if (sug.score < min) continue;\n        sugQueue.insertWithOverflow(sug);\n        if (sugQueue.size() == numSug) {\n          // if queue full, maintain the minScore score\n          min = ((SuggestWord) sugQueue.top()).score;\n        }\n      }\n\n      // create token\n      SpellCheckResponse.Suggestion suggestion = origVsSuggestion.get(original);\n      Token token = new Token();\n      token.setTermBuffer(original);\n      token.setStartOffset(suggestion.getStartOffset());\n      token.setEndOffset(suggestion.getEndOffset());\n\n      // get top 'count' suggestions out of 'sugQueue.size()' candidates\n      SuggestWord[] suggestions = new SuggestWord[Math.min(count, sugQueue.size())];\n      // skip the first sugQueue.size() - count elements\n      for (int k=0; k < sugQueue.size() - count; k++) sugQueue.pop();\n      // now collect the top 'count' responses\n      for (int k = Math.min(count, sugQueue.size()) - 1; k >= 0; k--)  {\n        suggestions[k] = ((SuggestWord) sugQueue.pop());\n      }\n\n      if (extendedResults) {\n        Integer o = origVsFreq.get(original);\n        if (o != null) result.add(token, o);\n        for (SuggestWord word : suggestions)\n          result.add(token, word.string, word.freq);\n      } else {\n        List<String> words = new ArrayList<String>(sugQueue.size());\n        for (SuggestWord word : suggestions) words.add(word.string);\n        result.add(token, words);\n      }\n    }\n    \n    NamedList response = new SimpleOrderedMap();\n    response.add(\"suggestions\", toNamedList(result, origQuery, extendedResults, collate));\n    rb.rsp.add(\"spellcheck\", response);\n  }\n\n","sourceOld":"  @Override\n  @SuppressWarnings({\"unchecked\", \"deprecation\"})\n  public void finishStage(ResponseBuilder rb) {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false) || rb.stage != ResponseBuilder.STAGE_GET_FIELDS)\n      return;\n\n    boolean extendedResults = params.getBool(SPELLCHECK_EXTENDED_RESULTS, false);\n    boolean collate = params.getBool(SPELLCHECK_COLLATE, false);\n\n    String origQuery = params.get(SPELLCHECK_Q);\n    if (origQuery == null) {\n      origQuery = rb.getQueryString();\n      if (origQuery == null) {\n        origQuery = params.get(CommonParams.Q);\n      }\n    }\n\n    int count = rb.req.getParams().getInt(SPELLCHECK_COUNT, 1);\n    float min = 0.5f;\n    StringDistance sd = null;\n    int numSug = Math.max(count, AbstractLuceneSpellChecker.DEFAULT_SUGGESTION_COUNT);\n    SolrSpellChecker checker = getSpellChecker(rb.req.getParams());\n    if (checker instanceof AbstractLuceneSpellChecker) {\n      AbstractLuceneSpellChecker spellChecker = (AbstractLuceneSpellChecker) checker;\n      min = spellChecker.getAccuracy();\n      sd = spellChecker.getStringDistance();\n    }\n    if (sd == null)\n      sd = new LevensteinDistance();\n\n    Collection<Token> tokens = null;\n    try {\n      tokens = getTokens(origQuery, checker.getQueryAnalyzer());\n    } catch (IOException e) {\n      LOG.error(\"Could not get tokens (this should never happen)\", e);\n    }\n\n    // original token -> corresponding Suggestion object (keep track of start,end)\n    Map<String, SpellCheckResponse.Suggestion> origVsSuggestion = new HashMap<String, SpellCheckResponse.Suggestion>();\n    // original token string -> summed up frequency\n    Map<String, Integer> origVsFreq = new HashMap<String, Integer>();\n    // original token string -> set of alternatives\n    // must preserve order because collation algorithm can only work in-order\n    Map<String, HashSet<String>> origVsSuggested = new LinkedHashMap<String, HashSet<String>>();\n    // alternative string -> corresponding SuggestWord object\n    Map<String, SuggestWord> suggestedVsWord = new HashMap<String, SuggestWord>();\n\n    for (ShardRequest sreq : rb.finished) {\n      for (ShardResponse srsp : sreq.responses) {\n        NamedList nl = (NamedList) srsp.getSolrResponse().getResponse().get(\"spellcheck\");\n        LOG.info(srsp.getShard() + \" \" + nl);\n        if (nl != null) {\n          SpellCheckResponse spellCheckResp = new SpellCheckResponse(nl);\n          for (SpellCheckResponse.Suggestion suggestion : spellCheckResp.getSuggestions()) {\n            origVsSuggestion.put(suggestion.getToken(), suggestion);\n            HashSet<String> suggested = origVsSuggested.get(suggestion.getToken());\n            if (suggested == null) {\n              suggested = new HashSet<String>();\n              origVsSuggested.put(suggestion.getToken(), suggested);\n            }\n\n            // sum up original frequency          \n            int origFreq = 0;\n            Integer o = origVsFreq.get(suggestion.getToken());\n            if (o != null)  origFreq += o;\n            origFreq += suggestion.getOriginalFrequency();\n            origVsFreq.put(suggestion.getToken(), origFreq);\n\n            // find best suggestions\n            for (int i = 0; i < suggestion.getNumFound(); i++) {\n              String alternative = suggestion.getAlternatives().get(i);\n              suggested.add(alternative);\n              SuggestWord sug = suggestedVsWord.get(alternative);\n              if (sug == null)  {\n                sug = new SuggestWord();\n                suggestedVsWord.put(alternative, sug);\n              }\n              sug.string = alternative;\n              // alternative frequency is present only for extendedResults=true\n              if (suggestion.getAlternativeFrequencies() != null && suggestion.getAlternativeFrequencies().size() > 0) {\n                Integer freq = suggestion.getAlternativeFrequencies().get(i);\n                if (freq != null) sug.freq += freq;\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // all shard responses have been collected\n    // create token and get top suggestions\n    SpellingResult result = new SpellingResult(tokens); //todo: investigate, why does it need tokens beforehand?\n    for (Map.Entry<String, HashSet<String>> entry : origVsSuggested.entrySet()) {\n      String original = entry.getKey();\n      HashSet<String> suggested = entry.getValue();\n      SuggestWordQueue sugQueue = new SuggestWordQueue(numSug);\n      for (String suggestion : suggested) {\n        SuggestWord sug = suggestedVsWord.get(suggestion);\n        sug.score = sd.getDistance(original, sug.string);\n        if (sug.score < min) continue;\n        sugQueue.insertWithOverflow(sug);\n        if (sugQueue.size() == numSug) {\n          // if queue full, maintain the minScore score\n          min = ((SuggestWord) sugQueue.top()).score;\n        }\n      }\n\n      // create token\n      SpellCheckResponse.Suggestion suggestion = origVsSuggestion.get(original);\n      Token token = new Token();\n      token.setTermText(original);\n      token.setStartOffset(suggestion.getStartOffset());\n      token.setEndOffset(suggestion.getEndOffset());\n\n      // get top 'count' suggestions out of 'sugQueue.size()' candidates\n      SuggestWord[] suggestions = new SuggestWord[Math.min(count, sugQueue.size())];\n      // skip the first sugQueue.size() - count elements\n      for (int k=0; k < sugQueue.size() - count; k++) sugQueue.pop();\n      // now collect the top 'count' responses\n      for (int k = Math.min(count, sugQueue.size()) - 1; k >= 0; k--)  {\n        suggestions[k] = ((SuggestWord) sugQueue.pop());\n      }\n\n      if (extendedResults) {\n        Integer o = origVsFreq.get(original);\n        if (o != null) result.add(token, o);\n        for (SuggestWord word : suggestions)\n          result.add(token, word.string, word.freq);\n      } else {\n        List<String> words = new ArrayList<String>(sugQueue.size());\n        for (SuggestWord word : suggestions) words.add(word.string);\n        result.add(token, words);\n      }\n    }\n    \n    NamedList response = new SimpleOrderedMap();\n    response.add(\"suggestions\", toNamedList(result, origQuery, extendedResults, collate));\n    rb.rsp.add(\"spellcheck\", response);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/SpellCheckComponent#finishStage(ResponseBuilder).mjava","pathOld":"src/java/org/apache/solr/handler/component/SpellCheckComponent#finishStage(ResponseBuilder).mjava","sourceNew":"  @Override\n  @SuppressWarnings({\"unchecked\", \"deprecation\"})\n  public void finishStage(ResponseBuilder rb) {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false) || rb.stage != ResponseBuilder.STAGE_GET_FIELDS)\n      return;\n\n    boolean extendedResults = params.getBool(SPELLCHECK_EXTENDED_RESULTS, false);\n    boolean collate = params.getBool(SPELLCHECK_COLLATE, false);\n\n    String origQuery = params.get(SPELLCHECK_Q);\n    if (origQuery == null) {\n      origQuery = rb.getQueryString();\n      if (origQuery == null) {\n        origQuery = params.get(CommonParams.Q);\n      }\n    }\n\n    int count = rb.req.getParams().getInt(SPELLCHECK_COUNT, 1);\n    float min = 0.5f;\n    StringDistance sd = null;\n    int numSug = Math.max(count, AbstractLuceneSpellChecker.DEFAULT_SUGGESTION_COUNT);\n    SolrSpellChecker checker = getSpellChecker(rb.req.getParams());\n    if (checker instanceof AbstractLuceneSpellChecker) {\n      AbstractLuceneSpellChecker spellChecker = (AbstractLuceneSpellChecker) checker;\n      min = spellChecker.getAccuracy();\n      sd = spellChecker.getStringDistance();\n    }\n    if (sd == null)\n      sd = new LevensteinDistance();\n\n    Collection<Token> tokens = null;\n    try {\n      tokens = getTokens(origQuery, checker.getQueryAnalyzer());\n    } catch (IOException e) {\n      LOG.error(\"Could not get tokens (this should never happen)\", e);\n    }\n\n    // original token -> corresponding Suggestion object (keep track of start,end)\n    Map<String, SpellCheckResponse.Suggestion> origVsSuggestion = new HashMap<String, SpellCheckResponse.Suggestion>();\n    // original token string -> summed up frequency\n    Map<String, Integer> origVsFreq = new HashMap<String, Integer>();\n    // original token string -> set of alternatives\n    // must preserve order because collation algorithm can only work in-order\n    Map<String, HashSet<String>> origVsSuggested = new LinkedHashMap<String, HashSet<String>>();\n    // alternative string -> corresponding SuggestWord object\n    Map<String, SuggestWord> suggestedVsWord = new HashMap<String, SuggestWord>();\n\n    for (ShardRequest sreq : rb.finished) {\n      for (ShardResponse srsp : sreq.responses) {\n        NamedList nl = (NamedList) srsp.getSolrResponse().getResponse().get(\"spellcheck\");\n        LOG.info(srsp.getShard() + \" \" + nl);\n        if (nl != null) {\n          SpellCheckResponse spellCheckResp = new SpellCheckResponse(nl);\n          for (SpellCheckResponse.Suggestion suggestion : spellCheckResp.getSuggestions()) {\n            origVsSuggestion.put(suggestion.getToken(), suggestion);\n            HashSet<String> suggested = origVsSuggested.get(suggestion.getToken());\n            if (suggested == null) {\n              suggested = new HashSet<String>();\n              origVsSuggested.put(suggestion.getToken(), suggested);\n            }\n\n            // sum up original frequency          \n            int origFreq = 0;\n            Integer o = origVsFreq.get(suggestion.getToken());\n            if (o != null)  origFreq += o;\n            origFreq += suggestion.getOriginalFrequency();\n            origVsFreq.put(suggestion.getToken(), origFreq);\n\n            // find best suggestions\n            for (int i = 0; i < suggestion.getNumFound(); i++) {\n              String alternative = suggestion.getAlternatives().get(i);\n              suggested.add(alternative);\n              SuggestWord sug = suggestedVsWord.get(alternative);\n              if (sug == null)  {\n                sug = new SuggestWord();\n                suggestedVsWord.put(alternative, sug);\n              }\n              sug.string = alternative;\n              // alternative frequency is present only for extendedResults=true\n              if (suggestion.getAlternativeFrequencies() != null && suggestion.getAlternativeFrequencies().size() > 0) {\n                Integer freq = suggestion.getAlternativeFrequencies().get(i);\n                if (freq != null) sug.freq += freq;\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // all shard responses have been collected\n    // create token and get top suggestions\n    SpellingResult result = new SpellingResult(tokens); //todo: investigate, why does it need tokens beforehand?\n    for (Map.Entry<String, HashSet<String>> entry : origVsSuggested.entrySet()) {\n      String original = entry.getKey();\n      HashSet<String> suggested = entry.getValue();\n      SuggestWordQueue sugQueue = new SuggestWordQueue(numSug);\n      for (String suggestion : suggested) {\n        SuggestWord sug = suggestedVsWord.get(suggestion);\n        sug.score = sd.getDistance(original, sug.string);\n        if (sug.score < min) continue;\n        sugQueue.insertWithOverflow(sug);\n        if (sugQueue.size() == numSug) {\n          // if queue full, maintain the minScore score\n          min = ((SuggestWord) sugQueue.top()).score;\n        }\n      }\n\n      // create token\n      SpellCheckResponse.Suggestion suggestion = origVsSuggestion.get(original);\n      Token token = new Token();\n      token.setTermBuffer(original);\n      token.setStartOffset(suggestion.getStartOffset());\n      token.setEndOffset(suggestion.getEndOffset());\n\n      // get top 'count' suggestions out of 'sugQueue.size()' candidates\n      SuggestWord[] suggestions = new SuggestWord[Math.min(count, sugQueue.size())];\n      // skip the first sugQueue.size() - count elements\n      for (int k=0; k < sugQueue.size() - count; k++) sugQueue.pop();\n      // now collect the top 'count' responses\n      for (int k = Math.min(count, sugQueue.size()) - 1; k >= 0; k--)  {\n        suggestions[k] = ((SuggestWord) sugQueue.pop());\n      }\n\n      if (extendedResults) {\n        Integer o = origVsFreq.get(original);\n        if (o != null) result.add(token, o);\n        for (SuggestWord word : suggestions)\n          result.add(token, word.string, word.freq);\n      } else {\n        List<String> words = new ArrayList<String>(sugQueue.size());\n        for (SuggestWord word : suggestions) words.add(word.string);\n        result.add(token, words);\n      }\n    }\n    \n    NamedList response = new SimpleOrderedMap();\n    response.add(\"suggestions\", toNamedList(result, origQuery, extendedResults, collate));\n    rb.rsp.add(\"spellcheck\", response);\n  }\n\n","sourceOld":"  @Override\n  @SuppressWarnings({\"unchecked\", \"deprecation\"})\n  public void finishStage(ResponseBuilder rb) {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false) || rb.stage != ResponseBuilder.STAGE_GET_FIELDS)\n      return;\n\n    boolean extendedResults = params.getBool(SPELLCHECK_EXTENDED_RESULTS, false);\n    boolean collate = params.getBool(SPELLCHECK_COLLATE, false);\n\n    String origQuery = params.get(SPELLCHECK_Q);\n    if (origQuery == null) {\n      origQuery = rb.getQueryString();\n      if (origQuery == null) {\n        origQuery = params.get(CommonParams.Q);\n      }\n    }\n\n    int count = rb.req.getParams().getInt(SPELLCHECK_COUNT, 1);\n    float min = 0.5f;\n    StringDistance sd = null;\n    int numSug = Math.max(count, AbstractLuceneSpellChecker.DEFAULT_SUGGESTION_COUNT);\n    SolrSpellChecker checker = getSpellChecker(rb.req.getParams());\n    if (checker instanceof AbstractLuceneSpellChecker) {\n      AbstractLuceneSpellChecker spellChecker = (AbstractLuceneSpellChecker) checker;\n      min = spellChecker.getAccuracy();\n      sd = spellChecker.getStringDistance();\n    }\n    if (sd == null)\n      sd = new LevensteinDistance();\n\n    Collection<Token> tokens = null;\n    try {\n      tokens = getTokens(origQuery, checker.getQueryAnalyzer());\n    } catch (IOException e) {\n      LOG.error(\"Could not get tokens (this should never happen)\", e);\n    }\n\n    // original token -> corresponding Suggestion object (keep track of start,end)\n    Map<String, SpellCheckResponse.Suggestion> origVsSuggestion = new HashMap<String, SpellCheckResponse.Suggestion>();\n    // original token string -> summed up frequency\n    Map<String, Integer> origVsFreq = new HashMap<String, Integer>();\n    // original token string -> set of alternatives\n    // must preserve order because collation algorithm can only work in-order\n    Map<String, HashSet<String>> origVsSuggested = new LinkedHashMap<String, HashSet<String>>();\n    // alternative string -> corresponding SuggestWord object\n    Map<String, SuggestWord> suggestedVsWord = new HashMap<String, SuggestWord>();\n\n    for (ShardRequest sreq : rb.finished) {\n      for (ShardResponse srsp : sreq.responses) {\n        NamedList nl = (NamedList) srsp.getSolrResponse().getResponse().get(\"spellcheck\");\n        LOG.info(srsp.getShard() + \" \" + nl);\n        if (nl != null) {\n          SpellCheckResponse spellCheckResp = new SpellCheckResponse(nl);\n          for (SpellCheckResponse.Suggestion suggestion : spellCheckResp.getSuggestions()) {\n            origVsSuggestion.put(suggestion.getToken(), suggestion);\n            HashSet<String> suggested = origVsSuggested.get(suggestion.getToken());\n            if (suggested == null) {\n              suggested = new HashSet<String>();\n              origVsSuggested.put(suggestion.getToken(), suggested);\n            }\n\n            // sum up original frequency          \n            int origFreq = 0;\n            Integer o = origVsFreq.get(suggestion.getToken());\n            if (o != null)  origFreq += o;\n            origFreq += suggestion.getOriginalFrequency();\n            origVsFreq.put(suggestion.getToken(), origFreq);\n\n            // find best suggestions\n            for (int i = 0; i < suggestion.getNumFound(); i++) {\n              String alternative = suggestion.getAlternatives().get(i);\n              suggested.add(alternative);\n              SuggestWord sug = suggestedVsWord.get(alternative);\n              if (sug == null)  {\n                sug = new SuggestWord();\n                suggestedVsWord.put(alternative, sug);\n              }\n              sug.string = alternative;\n              // alternative frequency is present only for extendedResults=true\n              if (suggestion.getAlternativeFrequencies() != null && suggestion.getAlternativeFrequencies().size() > 0) {\n                Integer freq = suggestion.getAlternativeFrequencies().get(i);\n                if (freq != null) sug.freq += freq;\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // all shard responses have been collected\n    // create token and get top suggestions\n    SpellingResult result = new SpellingResult(tokens); //todo: investigate, why does it need tokens beforehand?\n    for (Map.Entry<String, HashSet<String>> entry : origVsSuggested.entrySet()) {\n      String original = entry.getKey();\n      HashSet<String> suggested = entry.getValue();\n      SuggestWordQueue sugQueue = new SuggestWordQueue(numSug);\n      for (String suggestion : suggested) {\n        SuggestWord sug = suggestedVsWord.get(suggestion);\n        sug.score = sd.getDistance(original, sug.string);\n        if (sug.score < min) continue;\n        sugQueue.insertWithOverflow(sug);\n        if (sugQueue.size() == numSug) {\n          // if queue full, maintain the minScore score\n          min = ((SuggestWord) sugQueue.top()).score;\n        }\n      }\n\n      // create token\n      SpellCheckResponse.Suggestion suggestion = origVsSuggestion.get(original);\n      Token token = new Token();\n      token.setTermBuffer(original);\n      token.setStartOffset(suggestion.getStartOffset());\n      token.setEndOffset(suggestion.getEndOffset());\n\n      // get top 'count' suggestions out of 'sugQueue.size()' candidates\n      SuggestWord[] suggestions = new SuggestWord[Math.min(count, sugQueue.size())];\n      // skip the first sugQueue.size() - count elements\n      for (int k=0; k < sugQueue.size() - count; k++) sugQueue.pop();\n      // now collect the top 'count' responses\n      for (int k = Math.min(count, sugQueue.size()) - 1; k >= 0; k--)  {\n        suggestions[k] = ((SuggestWord) sugQueue.pop());\n      }\n\n      if (extendedResults) {\n        Integer o = origVsFreq.get(original);\n        if (o != null) result.add(token, o);\n        for (SuggestWord word : suggestions)\n          result.add(token, word.string, word.freq);\n      } else {\n        List<String> words = new ArrayList<String>(sugQueue.size());\n        for (SuggestWord word : suggestions) words.add(word.string);\n        result.add(token, words);\n      }\n    }\n    \n    NamedList response = new SimpleOrderedMap();\n    response.add(\"suggestions\", toNamedList(result, origQuery, extendedResults, collate));\n    rb.rsp.add(\"spellcheck\", response);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"ef28ac95f5f85bbf872801277448c0924b0a6827":["9079aceb3d611cfeb6922ebdf91003c30a08b745"],"9079aceb3d611cfeb6922ebdf91003c30a08b745":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"ad94625fb8d088209f46650c8097196fec67f00c":["ef28ac95f5f85bbf872801277448c0924b0a6827"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["9079aceb3d611cfeb6922ebdf91003c30a08b745"],"ef28ac95f5f85bbf872801277448c0924b0a6827":["ad94625fb8d088209f46650c8097196fec67f00c"],"9079aceb3d611cfeb6922ebdf91003c30a08b745":["ef28ac95f5f85bbf872801277448c0924b0a6827"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}