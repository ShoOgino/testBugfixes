{"path":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","commits":[{"id":"1ed947d41796fd2096684c439e8a9b69aac940cf","date":1321538339,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"/dev/null","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = r.termDocsEnum(null, \"foo\", new BytesRef(\"bar\"));\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    disi = r.terms(\"foo\").docs(null, new BytesRef(\"bar\"), disi);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e2297162a22c55456e200caef2cbcb00fe381120","date":1321551342,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = r.termDocsEnum(null, \"foo\", new BytesRef(\"bar\"));\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = r.termDocsEnum(null, \"foo\", new BytesRef(\"bar\"));\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    disi = r.terms(\"foo\").docs(null, new BytesRef(\"bar\"), disi);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"872cff1d3a554e0cd64014cd97f88d3002b0f491","date":1323024658,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random, r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random, te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = r.termDocsEnum(null, \"foo\", new BytesRef(\"bar\"));\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b65b350ca9588f9fc76ce7d6804160d06c45ff42","date":1323026297,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random, r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random, te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = r.termDocsEnum(null, \"foo\", new BytesRef(\"bar\"));\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868186558eb3a854ce7e720a52bb445795d54910","date":1327853682,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicIndexReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random, r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random, te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random, r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random, te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"da6d5ac19a80d65b1e864251f155d30960353b7e","date":1327881054,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random, r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random, te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicIndexReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random, r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random, te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random, r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random, te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    IndexReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random, r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random, te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random, r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random, te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir);\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    writer.addDocument(doc);\n    DirectoryReader reader = writer.getReader();\n    AtomicReader r = getOnlySegmentReader(reader);\n    DocsEnum disi = _TestUtil.docs(random, r, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = r.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = _TestUtil.docs(random, te, null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    writer.close();\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"1ed947d41796fd2096684c439e8a9b69aac940cf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"da6d5ac19a80d65b1e864251f155d30960353b7e":["868186558eb3a854ce7e720a52bb445795d54910"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":["e2297162a22c55456e200caef2cbcb00fe381120","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e2297162a22c55456e200caef2cbcb00fe381120":["1ed947d41796fd2096684c439e8a9b69aac940cf"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["e2297162a22c55456e200caef2cbcb00fe381120"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["872cff1d3a554e0cd64014cd97f88d3002b0f491","da6d5ac19a80d65b1e864251f155d30960353b7e"],"868186558eb3a854ce7e720a52bb445795d54910":["872cff1d3a554e0cd64014cd97f88d3002b0f491"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"1ed947d41796fd2096684c439e8a9b69aac940cf":["e2297162a22c55456e200caef2cbcb00fe381120"],"da6d5ac19a80d65b1e864251f155d30960353b7e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1ed947d41796fd2096684c439e8a9b69aac940cf"],"e2297162a22c55456e200caef2cbcb00fe381120":["b65b350ca9588f9fc76ce7d6804160d06c45ff42","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["b65b350ca9588f9fc76ce7d6804160d06c45ff42","5cab9a86bd67202d20b6adc463008c8e982b070a","868186558eb3a854ce7e720a52bb445795d54910"],"868186558eb3a854ce7e720a52bb445795d54910":["da6d5ac19a80d65b1e864251f155d30960353b7e"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b65b350ca9588f9fc76ce7d6804160d06c45ff42","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}