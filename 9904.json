{"path":"modules/facet/src/java/org/apache/lucene/facet/util/RandomSample#main(String[]).mjava","commits":[{"id":"89f15687f60bd49cd3d9de427e85c17fd9397d61","date":1309381327,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"modules/facet/src/java/org/apache/lucene/facet/util/RandomSample#main(String[]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Self-test.\n   */\n  public static void main(String[] args) throws Exception {\n    RandomSample.returnTimings = true;\n    /*\n     * Create an array of sequential integers, from which samples will be taken.\n     */\n    final int COLLECTION_SIZE = 10 * 1000 * 1000;\n    ScoredDocIDs collection = createAllScoredDocs(COLLECTION_SIZE);\n\n    /*\n     * Factor PHI.\n     *\n        int[] factors = RandomSample.factor(PHI_32);\n        System.out.print(\"Factors of PHI_32: \");\n        for (int k : factors) {\n          System.out.print(k+\", \");\n        }\n        System.out.println(\"\");\n\n     * Verify inverse relationship of PHI & phi.\n     *\n        boolean inverseValid = true;\n        for (int j = 0; j < Integer.MAX_VALUE; j++) {\n          int k = (int)(j * PHI_32) & 0x7FFFFFFF;\n          int m = (int)(k * PHI_32I) & 0X7FFFFFFF;\n          if (j != m) {\n            System.out.println(\"Inverse not valid for \"+j);\n            inverseValid = false;\n          }\n        }\n        System.out.println(\"Inverse valid? \"+inverseValid);\n     */\n    /*\n     * Take samples of various sizes from the full set, verify no duplicates,\n     * check flatness.\n     */\n    int[] sampleSizes = {\n        10, 57, 100, 333, 1000, 2154, 10000\n    };\n    Algorithm[] algorithms = { Algorithm.HASHING, Algorithm.TRAVERSAL };\n    for (int sampleSize : sampleSizes) {\n      for (Algorithm algorithm : algorithms) {\n        System.out.println(\"Sample size \" + sampleSize\n            + \", algorithm \" + algorithm + \"...\");\n        /*\n         * Take the sample.\n         */\n        int[] sample = RandomSample.repeatableSample(\n            collection, COLLECTION_SIZE, sampleSize, algorithm, Sorted.YES);\n        /*\n         * Check for duplicates.\n         */\n        boolean noDups = true;\n        for (int j = 0; j < sampleSize - 1; j++) {\n          if (sample[j] == sample[j + 1]) {\n            System.out.println(\"Duplicate value \"\n                + sample[j] + \" at \" + j + \", \"\n                + (j + 1));\n            noDups = false;\n            break;\n          }\n        }\n        if (noDups) {\n          System.out.println(\"No duplicates.\");\n        }\n        if (algorithm == Algorithm.HASHING) {\n          System.out.print(\"Hashed sample, up to 100 of \"+sampleSize+\": \");\n          int lim = Math.min(100, sampleSize);\n          for (int k = 0; k < lim; k++) {\n            System.out.print(sample[k]+\", \");\n          }\n          System.out.println(\"\");\n        }\n        /*\n         * Check flatness of distribution in sample.\n         */\n        final int N_INTERVALS = 100;\n        int[] counts = RandomSample.countsBySubrange(sample, COLLECTION_SIZE, N_INTERVALS);\n        int minCount = Integer.MAX_VALUE;\n        int maxCount = Integer.MIN_VALUE;\n        int avgCount = 0;\n        for (int j = 0; j < N_INTERVALS; j++) {\n          int count = counts[j];\n          if (count < minCount) {\n            minCount = count;\n          }\n          if (count > maxCount) {\n            maxCount = count;\n          }\n          avgCount += count;\n        }\n        avgCount /= N_INTERVALS;\n        System.out.println(\"Min, max, avg: \"+minCount+\", \"+maxCount+\", \"+avgCount);\n\n        if (((double)minCount - avgCount)/avgCount < -0.05 && (minCount - avgCount) < -5) {\n          System.out.println(\"Not flat enough.\");\n        } else if (((double)maxCount - avgCount)/avgCount > 0.05 && (maxCount - avgCount) > 5) {\n          System.out.println(\"Not flat enough.\");\n        } else {\n          System.out.println(\"Flat enough.\");\n        }\n        if (sampleSize == 10544 && algorithm == Algorithm.TRAVERSAL) {\n          System.out.print(\"Counts of interest: \");\n          for (int j = 0; j < N_INTERVALS; j++) {\n            System.out.print(counts[j]+\", \");\n          }\n          System.out.println(\"\");\n        }\n      }\n    }\n    System.out.println(\"Last prime is \"\n        + RandomSample.primes[RandomSample.N_PRIMES - 1]);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/facet/src/java/org/apache/lucene/facet/util/RandomSample#main(String[]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Self-test.\n   */\n  public static void main(String[] args) throws Exception {\n    RandomSample.returnTimings = true;\n    /*\n     * Create an array of sequential integers, from which samples will be taken.\n     */\n    final int COLLECTION_SIZE = 10 * 1000 * 1000;\n    ScoredDocIDs collection = createAllScoredDocs(COLLECTION_SIZE);\n\n    /*\n     * Factor PHI.\n     *\n        int[] factors = RandomSample.factor(PHI_32);\n        System.out.print(\"Factors of PHI_32: \");\n        for (int k : factors) {\n          System.out.print(k+\", \");\n        }\n        System.out.println(\"\");\n\n     * Verify inverse relationship of PHI & phi.\n     *\n        boolean inverseValid = true;\n        for (int j = 0; j < Integer.MAX_VALUE; j++) {\n          int k = (int)(j * PHI_32) & 0x7FFFFFFF;\n          int m = (int)(k * PHI_32I) & 0X7FFFFFFF;\n          if (j != m) {\n            System.out.println(\"Inverse not valid for \"+j);\n            inverseValid = false;\n          }\n        }\n        System.out.println(\"Inverse valid? \"+inverseValid);\n     */\n    /*\n     * Take samples of various sizes from the full set, verify no duplicates,\n     * check flatness.\n     */\n    int[] sampleSizes = {\n        10, 57, 100, 333, 1000, 2154, 10000\n    };\n    Algorithm[] algorithms = { Algorithm.HASHING, Algorithm.TRAVERSAL };\n    for (int sampleSize : sampleSizes) {\n      for (Algorithm algorithm : algorithms) {\n        System.out.println(\"Sample size \" + sampleSize\n            + \", algorithm \" + algorithm + \"...\");\n        /*\n         * Take the sample.\n         */\n        int[] sample = RandomSample.repeatableSample(\n            collection, COLLECTION_SIZE, sampleSize, algorithm, Sorted.YES);\n        /*\n         * Check for duplicates.\n         */\n        boolean noDups = true;\n        for (int j = 0; j < sampleSize - 1; j++) {\n          if (sample[j] == sample[j + 1]) {\n            System.out.println(\"Duplicate value \"\n                + sample[j] + \" at \" + j + \", \"\n                + (j + 1));\n            noDups = false;\n            break;\n          }\n        }\n        if (noDups) {\n          System.out.println(\"No duplicates.\");\n        }\n        if (algorithm == Algorithm.HASHING) {\n          System.out.print(\"Hashed sample, up to 100 of \"+sampleSize+\": \");\n          int lim = Math.min(100, sampleSize);\n          for (int k = 0; k < lim; k++) {\n            System.out.print(sample[k]+\", \");\n          }\n          System.out.println(\"\");\n        }\n        /*\n         * Check flatness of distribution in sample.\n         */\n        final int N_INTERVALS = 100;\n        int[] counts = RandomSample.countsBySubrange(sample, COLLECTION_SIZE, N_INTERVALS);\n        int minCount = Integer.MAX_VALUE;\n        int maxCount = Integer.MIN_VALUE;\n        int avgCount = 0;\n        for (int j = 0; j < N_INTERVALS; j++) {\n          int count = counts[j];\n          if (count < minCount) {\n            minCount = count;\n          }\n          if (count > maxCount) {\n            maxCount = count;\n          }\n          avgCount += count;\n        }\n        avgCount /= N_INTERVALS;\n        System.out.println(\"Min, max, avg: \"+minCount+\", \"+maxCount+\", \"+avgCount);\n\n        if (((double)minCount - avgCount)/avgCount < -0.05 && (minCount - avgCount) < -5) {\n          System.out.println(\"Not flat enough.\");\n        } else if (((double)maxCount - avgCount)/avgCount > 0.05 && (maxCount - avgCount) > 5) {\n          System.out.println(\"Not flat enough.\");\n        } else {\n          System.out.println(\"Flat enough.\");\n        }\n        if (sampleSize == 10544 && algorithm == Algorithm.TRAVERSAL) {\n          System.out.print(\"Counts of interest: \");\n          for (int j = 0; j < N_INTERVALS; j++) {\n            System.out.print(counts[j]+\", \");\n          }\n          System.out.println(\"\");\n        }\n      }\n    }\n    System.out.println(\"Last prime is \"\n        + RandomSample.primes[RandomSample.N_PRIMES - 1]);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/facet/src/java/org/apache/lucene/facet/util/RandomSample#main(String[]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Self-test.\n   */\n  public static void main(String[] args) throws Exception {\n    RandomSample.returnTimings = true;\n    /*\n     * Create an array of sequential integers, from which samples will be taken.\n     */\n    final int COLLECTION_SIZE = 10 * 1000 * 1000;\n    ScoredDocIDs collection = createAllScoredDocs(COLLECTION_SIZE);\n\n    /*\n     * Factor PHI.\n     *\n        int[] factors = RandomSample.factor(PHI_32);\n        System.out.print(\"Factors of PHI_32: \");\n        for (int k : factors) {\n          System.out.print(k+\", \");\n        }\n        System.out.println(\"\");\n\n     * Verify inverse relationship of PHI & phi.\n     *\n        boolean inverseValid = true;\n        for (int j = 0; j < Integer.MAX_VALUE; j++) {\n          int k = (int)(j * PHI_32) & 0x7FFFFFFF;\n          int m = (int)(k * PHI_32I) & 0X7FFFFFFF;\n          if (j != m) {\n            System.out.println(\"Inverse not valid for \"+j);\n            inverseValid = false;\n          }\n        }\n        System.out.println(\"Inverse valid? \"+inverseValid);\n     */\n    /*\n     * Take samples of various sizes from the full set, verify no duplicates,\n     * check flatness.\n     */\n    int[] sampleSizes = {\n        10, 57, 100, 333, 1000, 2154, 10000\n    };\n    Algorithm[] algorithms = { Algorithm.HASHING, Algorithm.TRAVERSAL };\n    for (int sampleSize : sampleSizes) {\n      for (Algorithm algorithm : algorithms) {\n        System.out.println(\"Sample size \" + sampleSize\n            + \", algorithm \" + algorithm + \"...\");\n        /*\n         * Take the sample.\n         */\n        int[] sample = RandomSample.repeatableSample(\n            collection, COLLECTION_SIZE, sampleSize, algorithm, Sorted.YES);\n        /*\n         * Check for duplicates.\n         */\n        boolean noDups = true;\n        for (int j = 0; j < sampleSize - 1; j++) {\n          if (sample[j] == sample[j + 1]) {\n            System.out.println(\"Duplicate value \"\n                + sample[j] + \" at \" + j + \", \"\n                + (j + 1));\n            noDups = false;\n            break;\n          }\n        }\n        if (noDups) {\n          System.out.println(\"No duplicates.\");\n        }\n        if (algorithm == Algorithm.HASHING) {\n          System.out.print(\"Hashed sample, up to 100 of \"+sampleSize+\": \");\n          int lim = Math.min(100, sampleSize);\n          for (int k = 0; k < lim; k++) {\n            System.out.print(sample[k]+\", \");\n          }\n          System.out.println(\"\");\n        }\n        /*\n         * Check flatness of distribution in sample.\n         */\n        final int N_INTERVALS = 100;\n        int[] counts = RandomSample.countsBySubrange(sample, COLLECTION_SIZE, N_INTERVALS);\n        int minCount = Integer.MAX_VALUE;\n        int maxCount = Integer.MIN_VALUE;\n        int avgCount = 0;\n        for (int j = 0; j < N_INTERVALS; j++) {\n          int count = counts[j];\n          if (count < minCount) {\n            minCount = count;\n          }\n          if (count > maxCount) {\n            maxCount = count;\n          }\n          avgCount += count;\n        }\n        avgCount /= N_INTERVALS;\n        System.out.println(\"Min, max, avg: \"+minCount+\", \"+maxCount+\", \"+avgCount);\n\n        if (((double)minCount - avgCount)/avgCount < -0.05 && (minCount - avgCount) < -5) {\n          System.out.println(\"Not flat enough.\");\n        } else if (((double)maxCount - avgCount)/avgCount > 0.05 && (maxCount - avgCount) > 5) {\n          System.out.println(\"Not flat enough.\");\n        } else {\n          System.out.println(\"Flat enough.\");\n        }\n        if (sampleSize == 10544 && algorithm == Algorithm.TRAVERSAL) {\n          System.out.print(\"Counts of interest: \");\n          for (int j = 0; j < N_INTERVALS; j++) {\n            System.out.print(counts[j]+\", \");\n          }\n          System.out.println(\"\");\n        }\n      }\n    }\n    System.out.println(\"Last prime is \"\n        + RandomSample.primes[RandomSample.N_PRIMES - 1]);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"99b17503f4e360f8140fe80a593268486cd718b4","date":1318337685,"type":4,"author":"Doron Cohen","isMerge":false,"pathNew":"/dev/null","pathOld":"modules/facet/src/java/org/apache/lucene/facet/util/RandomSample#main(String[]).mjava","sourceNew":null,"sourceOld":"  /**\n   * Self-test.\n   */\n  public static void main(String[] args) throws Exception {\n    RandomSample.returnTimings = true;\n    /*\n     * Create an array of sequential integers, from which samples will be taken.\n     */\n    final int COLLECTION_SIZE = 10 * 1000 * 1000;\n    ScoredDocIDs collection = createAllScoredDocs(COLLECTION_SIZE);\n\n    /*\n     * Factor PHI.\n     *\n        int[] factors = RandomSample.factor(PHI_32);\n        System.out.print(\"Factors of PHI_32: \");\n        for (int k : factors) {\n          System.out.print(k+\", \");\n        }\n        System.out.println(\"\");\n\n     * Verify inverse relationship of PHI & phi.\n     *\n        boolean inverseValid = true;\n        for (int j = 0; j < Integer.MAX_VALUE; j++) {\n          int k = (int)(j * PHI_32) & 0x7FFFFFFF;\n          int m = (int)(k * PHI_32I) & 0X7FFFFFFF;\n          if (j != m) {\n            System.out.println(\"Inverse not valid for \"+j);\n            inverseValid = false;\n          }\n        }\n        System.out.println(\"Inverse valid? \"+inverseValid);\n     */\n    /*\n     * Take samples of various sizes from the full set, verify no duplicates,\n     * check flatness.\n     */\n    int[] sampleSizes = {\n        10, 57, 100, 333, 1000, 2154, 10000\n    };\n    Algorithm[] algorithms = { Algorithm.HASHING, Algorithm.TRAVERSAL };\n    for (int sampleSize : sampleSizes) {\n      for (Algorithm algorithm : algorithms) {\n        System.out.println(\"Sample size \" + sampleSize\n            + \", algorithm \" + algorithm + \"...\");\n        /*\n         * Take the sample.\n         */\n        int[] sample = RandomSample.repeatableSample(\n            collection, COLLECTION_SIZE, sampleSize, algorithm, Sorted.YES);\n        /*\n         * Check for duplicates.\n         */\n        boolean noDups = true;\n        for (int j = 0; j < sampleSize - 1; j++) {\n          if (sample[j] == sample[j + 1]) {\n            System.out.println(\"Duplicate value \"\n                + sample[j] + \" at \" + j + \", \"\n                + (j + 1));\n            noDups = false;\n            break;\n          }\n        }\n        if (noDups) {\n          System.out.println(\"No duplicates.\");\n        }\n        if (algorithm == Algorithm.HASHING) {\n          System.out.print(\"Hashed sample, up to 100 of \"+sampleSize+\": \");\n          int lim = Math.min(100, sampleSize);\n          for (int k = 0; k < lim; k++) {\n            System.out.print(sample[k]+\", \");\n          }\n          System.out.println(\"\");\n        }\n        /*\n         * Check flatness of distribution in sample.\n         */\n        final int N_INTERVALS = 100;\n        int[] counts = RandomSample.countsBySubrange(sample, COLLECTION_SIZE, N_INTERVALS);\n        int minCount = Integer.MAX_VALUE;\n        int maxCount = Integer.MIN_VALUE;\n        int avgCount = 0;\n        for (int j = 0; j < N_INTERVALS; j++) {\n          int count = counts[j];\n          if (count < minCount) {\n            minCount = count;\n          }\n          if (count > maxCount) {\n            maxCount = count;\n          }\n          avgCount += count;\n        }\n        avgCount /= N_INTERVALS;\n        System.out.println(\"Min, max, avg: \"+minCount+\", \"+maxCount+\", \"+avgCount);\n\n        if (((double)minCount - avgCount)/avgCount < -0.05 && (minCount - avgCount) < -5) {\n          System.out.println(\"Not flat enough.\");\n        } else if (((double)maxCount - avgCount)/avgCount > 0.05 && (maxCount - avgCount) > 5) {\n          System.out.println(\"Not flat enough.\");\n        } else {\n          System.out.println(\"Flat enough.\");\n        }\n        if (sampleSize == 10544 && algorithm == Algorithm.TRAVERSAL) {\n          System.out.print(\"Counts of interest: \");\n          for (int j = 0; j < N_INTERVALS; j++) {\n            System.out.print(counts[j]+\", \");\n          }\n          System.out.println(\"\");\n        }\n      }\n    }\n    System.out.println(\"Last prime is \"\n        + RandomSample.primes[RandomSample.N_PRIMES - 1]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"99b17503f4e360f8140fe80a593268486cd718b4":["89f15687f60bd49cd3d9de427e85c17fd9397d61"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","89f15687f60bd49cd3d9de427e85c17fd9397d61"],"89f15687f60bd49cd3d9de427e85c17fd9397d61":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","89f15687f60bd49cd3d9de427e85c17fd9397d61"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["99b17503f4e360f8140fe80a593268486cd718b4"]},"commit2Childs":{"99b17503f4e360f8140fe80a593268486cd718b4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d083e83f225b11e5fdd900e83d26ddb385b6955c","89f15687f60bd49cd3d9de427e85c17fd9397d61","817d8435e9135b756f08ce6710ab0baac51bdf88"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"89f15687f60bd49cd3d9de427e85c17fd9397d61":["99b17503f4e360f8140fe80a593268486cd718b4","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}