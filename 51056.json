{"path":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#searchAfter(ScoreDoc,Query,int).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#searchAfter(ScoreDoc,Query,int).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#searchAfter(ScoreDoc,Query,int).mjava","sourceNew":"      @Override\n      public TopDocs searchAfter(ScoreDoc after, Query query, int numHits) throws IOException {\n        final TopDocs[] shardHits = new TopDocs[nodeVersions.length];\n        ScoreDoc shardAfter = new ScoreDoc(after.doc, after.score);\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          if (nodeID < after.shardIndex) {\n            // If score is tied then no docs in this shard\n            // should be collected:\n            shardAfter.doc = Integer.MAX_VALUE;\n          } else if (nodeID == after.shardIndex) {\n            // If score is tied then we break according to\n            // docID (like normal):  \n            shardAfter.doc = after.doc;\n          } else {\n            // If score is tied then all docs in this shard\n            // should be collected, because they come after\n            // the previous bottom:\n            shardAfter.doc = -1;\n          }\n          if (nodeID == myNodeID) {\n            // My node; run using local shard searcher we\n            // already aquired:\n            shardHits[nodeID] = localSearchAfter(shardAfter, query, numHits);\n          } else {\n            shardHits[nodeID] = searchNode(nodeID, nodeVersions, query, null, numHits, shardAfter);\n          }\n          //System.out.println(\"  node=\" + nodeID + \" totHits=\" + shardHits[nodeID].totalHits);\n        }\n\n        // Merge:\n        return TopDocs.merge(null, numHits, shardHits);\n      }\n\n","sourceOld":"      @Override\n      public TopDocs searchAfter(ScoreDoc after, Query query, int numHits) throws IOException {\n        final TopDocs[] shardHits = new TopDocs[nodeVersions.length];\n        ScoreDoc shardAfter = new ScoreDoc(after.doc, after.score);\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          if (nodeID < after.shardIndex) {\n            // If score is tied then no docs in this shard\n            // should be collected:\n            shardAfter.doc = Integer.MAX_VALUE;\n          } else if (nodeID == after.shardIndex) {\n            // If score is tied then we break according to\n            // docID (like normal):  \n            shardAfter.doc = after.doc;\n          } else {\n            // If score is tied then all docs in this shard\n            // should be collected, because they come after\n            // the previous bottom:\n            shardAfter.doc = -1;\n          }\n          if (nodeID == myNodeID) {\n            // My node; run using local shard searcher we\n            // already aquired:\n            shardHits[nodeID] = localSearchAfter(shardAfter, query, numHits);\n          } else {\n            shardHits[nodeID] = searchNode(nodeID, nodeVersions, query, null, numHits, shardAfter);\n          }\n          //System.out.println(\"  node=\" + nodeID + \" totHits=\" + shardHits[nodeID].totalHits);\n        }\n\n        // Merge:\n        return TopDocs.merge(null, numHits, shardHits);\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e87ea9fb673e8638747af83477322f07ed5a8b95","date":1374560737,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#searchAfter(ScoreDoc,Query,int).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#searchAfter(ScoreDoc,Query,int).mjava","sourceNew":"      @Override\n      public TopDocs searchAfter(ScoreDoc after, Query query, int numHits) throws IOException {\n        final TopDocs[] shardHits = new TopDocs[nodeVersions.length];\n        // results are merged in that order: score, shardIndex, doc. therefore we set\n        // after to after.score and depending on the nodeID we set doc to either:\n        // - not collect any more documents with that score (only with worse score)\n        // - collect more documents with that score (and worse) following the last collected document\n        // - collect all documents with that score (and worse)\n        ScoreDoc shardAfter = new ScoreDoc(after.doc, after.score);\n        for (int nodeID = 0; nodeID < nodeVersions.length; nodeID++) {\n          if (nodeID < after.shardIndex) {\n            // all documents with after.score were already collected, so collect\n            // only documents with worse scores.\n            final NodeState.ShardIndexSearcher s = nodes[nodeID].acquire(nodeVersions);\n            try {\n              // Setting after.doc to reader.maxDoc-1 is a way to tell\n              // TopScoreDocCollector that no more docs with that score should\n              // be collected. note that in practice the shard which sends the\n              // request to a remote shard won't have reader.maxDoc at hand, so\n              // it will send some arbitrary value which will be fixed on the\n              // other end.\n              shardAfter.doc = s.getIndexReader().maxDoc() - 1;\n            } finally {\n              nodes[nodeID].release(s);\n            }\n          } else if (nodeID == after.shardIndex) {\n            // collect all documents following the last collected doc with\n            // after.score + documents with worse scores.  \n            shardAfter.doc = after.doc;\n          } else {\n            // all documents with after.score (and worse) should be collected\n            // because they didn't make it to top-N in the previous round.\n            shardAfter.doc = -1;\n          }\n          if (nodeID == myNodeID) {\n            // My node; run using local shard searcher we\n            // already aquired:\n            shardHits[nodeID] = localSearchAfter(shardAfter, query, numHits);\n          } else {\n            shardHits[nodeID] = searchNode(nodeID, nodeVersions, query, null, numHits, shardAfter);\n          }\n          //System.out.println(\"  node=\" + nodeID + \" totHits=\" + shardHits[nodeID].totalHits);\n        }\n\n        // Merge:\n        return TopDocs.merge(null, numHits, shardHits);\n      }\n\n","sourceOld":"      @Override\n      public TopDocs searchAfter(ScoreDoc after, Query query, int numHits) throws IOException {\n        final TopDocs[] shardHits = new TopDocs[nodeVersions.length];\n        ScoreDoc shardAfter = new ScoreDoc(after.doc, after.score);\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          if (nodeID < after.shardIndex) {\n            // If score is tied then no docs in this shard\n            // should be collected:\n            shardAfter.doc = Integer.MAX_VALUE;\n          } else if (nodeID == after.shardIndex) {\n            // If score is tied then we break according to\n            // docID (like normal):  \n            shardAfter.doc = after.doc;\n          } else {\n            // If score is tied then all docs in this shard\n            // should be collected, because they come after\n            // the previous bottom:\n            shardAfter.doc = -1;\n          }\n          if (nodeID == myNodeID) {\n            // My node; run using local shard searcher we\n            // already aquired:\n            shardHits[nodeID] = localSearchAfter(shardAfter, query, numHits);\n          } else {\n            shardHits[nodeID] = searchNode(nodeID, nodeVersions, query, null, numHits, shardAfter);\n          }\n          //System.out.println(\"  node=\" + nodeID + \" totHits=\" + shardHits[nodeID].totalHits);\n        }\n\n        // Merge:\n        return TopDocs.merge(null, numHits, shardHits);\n      }\n\n","bugFix":["226aae72c0326f4299c16280195bade4530de537"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#searchAfter(ScoreDoc,Query,int).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#searchAfter(ScoreDoc,Query,int).mjava","sourceNew":"      @Override\n      public TopDocs searchAfter(ScoreDoc after, Query query, int numHits) throws IOException {\n        final TopDocs[] shardHits = new TopDocs[nodeVersions.length];\n        // results are merged in that order: score, shardIndex, doc. therefore we set\n        // after to after.score and depending on the nodeID we set doc to either:\n        // - not collect any more documents with that score (only with worse score)\n        // - collect more documents with that score (and worse) following the last collected document\n        // - collect all documents with that score (and worse)\n        ScoreDoc shardAfter = new ScoreDoc(after.doc, after.score);\n        for (int nodeID = 0; nodeID < nodeVersions.length; nodeID++) {\n          if (nodeID < after.shardIndex) {\n            // all documents with after.score were already collected, so collect\n            // only documents with worse scores.\n            final NodeState.ShardIndexSearcher s = nodes[nodeID].acquire(nodeVersions);\n            try {\n              // Setting after.doc to reader.maxDoc-1 is a way to tell\n              // TopScoreDocCollector that no more docs with that score should\n              // be collected. note that in practice the shard which sends the\n              // request to a remote shard won't have reader.maxDoc at hand, so\n              // it will send some arbitrary value which will be fixed on the\n              // other end.\n              shardAfter.doc = s.getIndexReader().maxDoc() - 1;\n            } finally {\n              nodes[nodeID].release(s);\n            }\n          } else if (nodeID == after.shardIndex) {\n            // collect all documents following the last collected doc with\n            // after.score + documents with worse scores.  \n            shardAfter.doc = after.doc;\n          } else {\n            // all documents with after.score (and worse) should be collected\n            // because they didn't make it to top-N in the previous round.\n            shardAfter.doc = -1;\n          }\n          if (nodeID == myNodeID) {\n            // My node; run using local shard searcher we\n            // already aquired:\n            shardHits[nodeID] = localSearchAfter(shardAfter, query, numHits);\n          } else {\n            shardHits[nodeID] = searchNode(nodeID, nodeVersions, query, null, numHits, shardAfter);\n          }\n          //System.out.println(\"  node=\" + nodeID + \" totHits=\" + shardHits[nodeID].totalHits);\n        }\n\n        // Merge:\n        return TopDocs.merge(null, numHits, shardHits);\n      }\n\n","sourceOld":"      @Override\n      public TopDocs searchAfter(ScoreDoc after, Query query, int numHits) throws IOException {\n        final TopDocs[] shardHits = new TopDocs[nodeVersions.length];\n        ScoreDoc shardAfter = new ScoreDoc(after.doc, after.score);\n        for(int nodeID=0;nodeID<nodeVersions.length;nodeID++) {\n          if (nodeID < after.shardIndex) {\n            // If score is tied then no docs in this shard\n            // should be collected:\n            shardAfter.doc = Integer.MAX_VALUE;\n          } else if (nodeID == after.shardIndex) {\n            // If score is tied then we break according to\n            // docID (like normal):  \n            shardAfter.doc = after.doc;\n          } else {\n            // If score is tied then all docs in this shard\n            // should be collected, because they come after\n            // the previous bottom:\n            shardAfter.doc = -1;\n          }\n          if (nodeID == myNodeID) {\n            // My node; run using local shard searcher we\n            // already aquired:\n            shardHits[nodeID] = localSearchAfter(shardAfter, query, numHits);\n          } else {\n            shardHits[nodeID] = searchNode(nodeID, nodeVersions, query, null, numHits, shardAfter);\n          }\n          //System.out.println(\"  node=\" + nodeID + \" totHits=\" + shardHits[nodeID].totalHits);\n        }\n\n        // Merge:\n        return TopDocs.merge(null, numHits, shardHits);\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb17639909a369c1e64866842e5c213440acc17e","date":1423238093,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#searchAfter(ScoreDoc,Query,int).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#searchAfter(ScoreDoc,Query,int).mjava","sourceNew":"      @Override\n      public TopDocs searchAfter(ScoreDoc after, Query query, int numHits) throws IOException {\n        if (after == null) {\n          return super.searchAfter(after, query, numHits);\n        }\n        final TopDocs[] shardHits = new TopDocs[nodeVersions.length];\n        // results are merged in that order: score, shardIndex, doc. therefore we set\n        // after to after.score and depending on the nodeID we set doc to either:\n        // - not collect any more documents with that score (only with worse score)\n        // - collect more documents with that score (and worse) following the last collected document\n        // - collect all documents with that score (and worse)\n        ScoreDoc shardAfter = new ScoreDoc(after.doc, after.score);\n        for (int nodeID = 0; nodeID < nodeVersions.length; nodeID++) {\n          if (nodeID < after.shardIndex) {\n            // all documents with after.score were already collected, so collect\n            // only documents with worse scores.\n            final NodeState.ShardIndexSearcher s = nodes[nodeID].acquire(nodeVersions);\n            try {\n              // Setting after.doc to reader.maxDoc-1 is a way to tell\n              // TopScoreDocCollector that no more docs with that score should\n              // be collected. note that in practice the shard which sends the\n              // request to a remote shard won't have reader.maxDoc at hand, so\n              // it will send some arbitrary value which will be fixed on the\n              // other end.\n              shardAfter.doc = s.getIndexReader().maxDoc() - 1;\n            } finally {\n              nodes[nodeID].release(s);\n            }\n          } else if (nodeID == after.shardIndex) {\n            // collect all documents following the last collected doc with\n            // after.score + documents with worse scores.  \n            shardAfter.doc = after.doc;\n          } else {\n            // all documents with after.score (and worse) should be collected\n            // because they didn't make it to top-N in the previous round.\n            shardAfter.doc = -1;\n          }\n          if (nodeID == myNodeID) {\n            // My node; run using local shard searcher we\n            // already aquired:\n            shardHits[nodeID] = localSearchAfter(shardAfter, query, numHits);\n          } else {\n            shardHits[nodeID] = searchNode(nodeID, nodeVersions, query, null, numHits, shardAfter);\n          }\n          //System.out.println(\"  node=\" + nodeID + \" totHits=\" + shardHits[nodeID].totalHits);\n        }\n\n        // Merge:\n        return TopDocs.merge(numHits, shardHits);\n      }\n\n","sourceOld":"      @Override\n      public TopDocs searchAfter(ScoreDoc after, Query query, int numHits) throws IOException {\n        final TopDocs[] shardHits = new TopDocs[nodeVersions.length];\n        // results are merged in that order: score, shardIndex, doc. therefore we set\n        // after to after.score and depending on the nodeID we set doc to either:\n        // - not collect any more documents with that score (only with worse score)\n        // - collect more documents with that score (and worse) following the last collected document\n        // - collect all documents with that score (and worse)\n        ScoreDoc shardAfter = new ScoreDoc(after.doc, after.score);\n        for (int nodeID = 0; nodeID < nodeVersions.length; nodeID++) {\n          if (nodeID < after.shardIndex) {\n            // all documents with after.score were already collected, so collect\n            // only documents with worse scores.\n            final NodeState.ShardIndexSearcher s = nodes[nodeID].acquire(nodeVersions);\n            try {\n              // Setting after.doc to reader.maxDoc-1 is a way to tell\n              // TopScoreDocCollector that no more docs with that score should\n              // be collected. note that in practice the shard which sends the\n              // request to a remote shard won't have reader.maxDoc at hand, so\n              // it will send some arbitrary value which will be fixed on the\n              // other end.\n              shardAfter.doc = s.getIndexReader().maxDoc() - 1;\n            } finally {\n              nodes[nodeID].release(s);\n            }\n          } else if (nodeID == after.shardIndex) {\n            // collect all documents following the last collected doc with\n            // after.score + documents with worse scores.  \n            shardAfter.doc = after.doc;\n          } else {\n            // all documents with after.score (and worse) should be collected\n            // because they didn't make it to top-N in the previous round.\n            shardAfter.doc = -1;\n          }\n          if (nodeID == myNodeID) {\n            // My node; run using local shard searcher we\n            // already aquired:\n            shardHits[nodeID] = localSearchAfter(shardAfter, query, numHits);\n          } else {\n            shardHits[nodeID] = searchNode(nodeID, nodeVersions, query, null, numHits, shardAfter);\n          }\n          //System.out.println(\"  node=\" + nodeID + \" totHits=\" + shardHits[nodeID].totalHits);\n        }\n\n        // Merge:\n        return TopDocs.merge(null, numHits, shardHits);\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"36510a8e3c1ec60d366b45f8f716e9dc47589661","date":1561989412,"type":3,"author":"Atri Sharma","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#searchAfter(ScoreDoc,Query,int).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#searchAfter(ScoreDoc,Query,int).mjava","sourceNew":"      @Override\n      public TopDocs searchAfter(ScoreDoc after, Query query, int numHits) throws IOException {\n        if (after == null) {\n          return super.searchAfter(after, query, numHits);\n        }\n        final TopDocs[] shardHits = new TopDocs[nodeVersions.length];\n        // results are merged in that order: score, shardIndex, doc. therefore we set\n        // after to after.score and depending on the nodeID we set doc to either:\n        // - not collect any more documents with that score (only with worse score)\n        // - collect more documents with that score (and worse) following the last collected document\n        // - collect all documents with that score (and worse)\n        ScoreDoc shardAfter = new ScoreDoc(after.doc, after.score);\n        for (int nodeID = 0; nodeID < nodeVersions.length; nodeID++) {\n          if (nodeID < after.shardIndex) {\n            // all documents with after.score were already collected, so collect\n            // only documents with worse scores.\n            final NodeState.ShardIndexSearcher s = nodes[nodeID].acquire(nodeVersions);\n            try {\n              // Setting after.doc to reader.maxDoc-1 is a way to tell\n              // TopScoreDocCollector that no more docs with that score should\n              // be collected. note that in practice the shard which sends the\n              // request to a remote shard won't have reader.maxDoc at hand, so\n              // it will send some arbitrary value which will be fixed on the\n              // other end.\n              shardAfter.doc = s.getIndexReader().maxDoc() - 1;\n            } finally {\n              nodes[nodeID].release(s);\n            }\n          } else if (nodeID == after.shardIndex) {\n            // collect all documents following the last collected doc with\n            // after.score + documents with worse scores.  \n            shardAfter.doc = after.doc;\n          } else {\n            // all documents with after.score (and worse) should be collected\n            // because they didn't make it to top-N in the previous round.\n            shardAfter.doc = -1;\n          }\n          if (nodeID == myNodeID) {\n            // My node; run using local shard searcher we\n            // already aquired:\n            shardHits[nodeID] = localSearchAfter(shardAfter, query, numHits);\n          } else {\n            shardHits[nodeID] = searchNode(nodeID, nodeVersions, query, null, numHits, shardAfter);\n          }\n\n          for (int i = 0; i < shardHits[nodeID].scoreDocs.length; i++) {\n            shardHits[nodeID].scoreDocs[i].shardIndex = nodeID;\n          }\n          //System.out.println(\"  node=\" + nodeID + \" totHits=\" + shardHits[nodeID].totalHits);\n        }\n\n        // Merge:\n        return TopDocs.merge(numHits, shardHits);\n      }\n\n","sourceOld":"      @Override\n      public TopDocs searchAfter(ScoreDoc after, Query query, int numHits) throws IOException {\n        if (after == null) {\n          return super.searchAfter(after, query, numHits);\n        }\n        final TopDocs[] shardHits = new TopDocs[nodeVersions.length];\n        // results are merged in that order: score, shardIndex, doc. therefore we set\n        // after to after.score and depending on the nodeID we set doc to either:\n        // - not collect any more documents with that score (only with worse score)\n        // - collect more documents with that score (and worse) following the last collected document\n        // - collect all documents with that score (and worse)\n        ScoreDoc shardAfter = new ScoreDoc(after.doc, after.score);\n        for (int nodeID = 0; nodeID < nodeVersions.length; nodeID++) {\n          if (nodeID < after.shardIndex) {\n            // all documents with after.score were already collected, so collect\n            // only documents with worse scores.\n            final NodeState.ShardIndexSearcher s = nodes[nodeID].acquire(nodeVersions);\n            try {\n              // Setting after.doc to reader.maxDoc-1 is a way to tell\n              // TopScoreDocCollector that no more docs with that score should\n              // be collected. note that in practice the shard which sends the\n              // request to a remote shard won't have reader.maxDoc at hand, so\n              // it will send some arbitrary value which will be fixed on the\n              // other end.\n              shardAfter.doc = s.getIndexReader().maxDoc() - 1;\n            } finally {\n              nodes[nodeID].release(s);\n            }\n          } else if (nodeID == after.shardIndex) {\n            // collect all documents following the last collected doc with\n            // after.score + documents with worse scores.  \n            shardAfter.doc = after.doc;\n          } else {\n            // all documents with after.score (and worse) should be collected\n            // because they didn't make it to top-N in the previous round.\n            shardAfter.doc = -1;\n          }\n          if (nodeID == myNodeID) {\n            // My node; run using local shard searcher we\n            // already aquired:\n            shardHits[nodeID] = localSearchAfter(shardAfter, query, numHits);\n          } else {\n            shardHits[nodeID] = searchNode(nodeID, nodeVersions, query, null, numHits, shardAfter);\n          }\n          //System.out.println(\"  node=\" + nodeID + \" totHits=\" + shardHits[nodeID].totalHits);\n        }\n\n        // Merge:\n        return TopDocs.merge(numHits, shardHits);\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4f6b0fb6f08ac48f438f03002a283a63cb9992","date":1561992803,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#searchAfter(ScoreDoc,Query,int).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#searchAfter(ScoreDoc,Query,int).mjava","sourceNew":"      @Override\n      public TopDocs searchAfter(ScoreDoc after, Query query, int numHits) throws IOException {\n        if (after == null) {\n          return super.searchAfter(after, query, numHits);\n        }\n        final TopDocs[] shardHits = new TopDocs[nodeVersions.length];\n        // results are merged in that order: score, shardIndex, doc. therefore we set\n        // after to after.score and depending on the nodeID we set doc to either:\n        // - not collect any more documents with that score (only with worse score)\n        // - collect more documents with that score (and worse) following the last collected document\n        // - collect all documents with that score (and worse)\n        ScoreDoc shardAfter = new ScoreDoc(after.doc, after.score);\n        for (int nodeID = 0; nodeID < nodeVersions.length; nodeID++) {\n          if (nodeID < after.shardIndex) {\n            // all documents with after.score were already collected, so collect\n            // only documents with worse scores.\n            final NodeState.ShardIndexSearcher s = nodes[nodeID].acquire(nodeVersions);\n            try {\n              // Setting after.doc to reader.maxDoc-1 is a way to tell\n              // TopScoreDocCollector that no more docs with that score should\n              // be collected. note that in practice the shard which sends the\n              // request to a remote shard won't have reader.maxDoc at hand, so\n              // it will send some arbitrary value which will be fixed on the\n              // other end.\n              shardAfter.doc = s.getIndexReader().maxDoc() - 1;\n            } finally {\n              nodes[nodeID].release(s);\n            }\n          } else if (nodeID == after.shardIndex) {\n            // collect all documents following the last collected doc with\n            // after.score + documents with worse scores.  \n            shardAfter.doc = after.doc;\n          } else {\n            // all documents with after.score (and worse) should be collected\n            // because they didn't make it to top-N in the previous round.\n            shardAfter.doc = -1;\n          }\n          if (nodeID == myNodeID) {\n            // My node; run using local shard searcher we\n            // already aquired:\n            shardHits[nodeID] = localSearchAfter(shardAfter, query, numHits);\n          } else {\n            shardHits[nodeID] = searchNode(nodeID, nodeVersions, query, null, numHits, shardAfter);\n          }\n          //System.out.println(\"  node=\" + nodeID + \" totHits=\" + shardHits[nodeID].totalHits);\n        }\n\n        // Merge:\n        return TopDocs.merge(numHits, shardHits);\n      }\n\n","sourceOld":"      @Override\n      public TopDocs searchAfter(ScoreDoc after, Query query, int numHits) throws IOException {\n        if (after == null) {\n          return super.searchAfter(after, query, numHits);\n        }\n        final TopDocs[] shardHits = new TopDocs[nodeVersions.length];\n        // results are merged in that order: score, shardIndex, doc. therefore we set\n        // after to after.score and depending on the nodeID we set doc to either:\n        // - not collect any more documents with that score (only with worse score)\n        // - collect more documents with that score (and worse) following the last collected document\n        // - collect all documents with that score (and worse)\n        ScoreDoc shardAfter = new ScoreDoc(after.doc, after.score);\n        for (int nodeID = 0; nodeID < nodeVersions.length; nodeID++) {\n          if (nodeID < after.shardIndex) {\n            // all documents with after.score were already collected, so collect\n            // only documents with worse scores.\n            final NodeState.ShardIndexSearcher s = nodes[nodeID].acquire(nodeVersions);\n            try {\n              // Setting after.doc to reader.maxDoc-1 is a way to tell\n              // TopScoreDocCollector that no more docs with that score should\n              // be collected. note that in practice the shard which sends the\n              // request to a remote shard won't have reader.maxDoc at hand, so\n              // it will send some arbitrary value which will be fixed on the\n              // other end.\n              shardAfter.doc = s.getIndexReader().maxDoc() - 1;\n            } finally {\n              nodes[nodeID].release(s);\n            }\n          } else if (nodeID == after.shardIndex) {\n            // collect all documents following the last collected doc with\n            // after.score + documents with worse scores.  \n            shardAfter.doc = after.doc;\n          } else {\n            // all documents with after.score (and worse) should be collected\n            // because they didn't make it to top-N in the previous round.\n            shardAfter.doc = -1;\n          }\n          if (nodeID == myNodeID) {\n            // My node; run using local shard searcher we\n            // already aquired:\n            shardHits[nodeID] = localSearchAfter(shardAfter, query, numHits);\n          } else {\n            shardHits[nodeID] = searchNode(nodeID, nodeVersions, query, null, numHits, shardAfter);\n          }\n\n          for (int i = 0; i < shardHits[nodeID].scoreDocs.length; i++) {\n            shardHits[nodeID].scoreDocs[i].shardIndex = nodeID;\n          }\n          //System.out.println(\"  node=\" + nodeID + \" totHits=\" + shardHits[nodeID].totalHits);\n        }\n\n        // Merge:\n        return TopDocs.merge(numHits, shardHits);\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fccd4a691aac1aff06ab8110d8693514a34160c3","date":1562092518,"type":3,"author":"Atri Sharma","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#searchAfter(ScoreDoc,Query,int).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/ShardSearchingTestBase.NodeState.ShardIndexSearcher#searchAfter(ScoreDoc,Query,int).mjava","sourceNew":"      @Override\n      public TopDocs searchAfter(ScoreDoc after, Query query, int numHits) throws IOException {\n        if (after == null) {\n          return super.searchAfter(after, query, numHits);\n        }\n        final TopDocs[] shardHits = new TopDocs[nodeVersions.length];\n        // results are merged in that order: score, shardIndex, doc. therefore we set\n        // after to after.score and depending on the nodeID we set doc to either:\n        // - not collect any more documents with that score (only with worse score)\n        // - collect more documents with that score (and worse) following the last collected document\n        // - collect all documents with that score (and worse)\n        ScoreDoc shardAfter = new ScoreDoc(after.doc, after.score);\n        for (int nodeID = 0; nodeID < nodeVersions.length; nodeID++) {\n          if (nodeID < after.shardIndex) {\n            // all documents with after.score were already collected, so collect\n            // only documents with worse scores.\n            final NodeState.ShardIndexSearcher s = nodes[nodeID].acquire(nodeVersions);\n            try {\n              // Setting after.doc to reader.maxDoc-1 is a way to tell\n              // TopScoreDocCollector that no more docs with that score should\n              // be collected. note that in practice the shard which sends the\n              // request to a remote shard won't have reader.maxDoc at hand, so\n              // it will send some arbitrary value which will be fixed on the\n              // other end.\n              shardAfter.doc = s.getIndexReader().maxDoc() - 1;\n            } finally {\n              nodes[nodeID].release(s);\n            }\n          } else if (nodeID == after.shardIndex) {\n            // collect all documents following the last collected doc with\n            // after.score + documents with worse scores.  \n            shardAfter.doc = after.doc;\n          } else {\n            // all documents with after.score (and worse) should be collected\n            // because they didn't make it to top-N in the previous round.\n            shardAfter.doc = -1;\n          }\n          if (nodeID == myNodeID) {\n            // My node; run using local shard searcher we\n            // already aquired:\n            shardHits[nodeID] = localSearchAfter(shardAfter, query, numHits);\n          } else {\n            shardHits[nodeID] = searchNode(nodeID, nodeVersions, query, null, numHits, shardAfter);\n          }\n\n          for (int i = 0; i < shardHits[nodeID].scoreDocs.length; i++) {\n            shardHits[nodeID].scoreDocs[i].shardIndex = nodeID;\n          }\n          //System.out.println(\"  node=\" + nodeID + \" totHits=\" + shardHits[nodeID].totalHits);\n        }\n\n        // Merge:\n        return TopDocs.merge(numHits, shardHits);\n      }\n\n","sourceOld":"      @Override\n      public TopDocs searchAfter(ScoreDoc after, Query query, int numHits) throws IOException {\n        if (after == null) {\n          return super.searchAfter(after, query, numHits);\n        }\n        final TopDocs[] shardHits = new TopDocs[nodeVersions.length];\n        // results are merged in that order: score, shardIndex, doc. therefore we set\n        // after to after.score and depending on the nodeID we set doc to either:\n        // - not collect any more documents with that score (only with worse score)\n        // - collect more documents with that score (and worse) following the last collected document\n        // - collect all documents with that score (and worse)\n        ScoreDoc shardAfter = new ScoreDoc(after.doc, after.score);\n        for (int nodeID = 0; nodeID < nodeVersions.length; nodeID++) {\n          if (nodeID < after.shardIndex) {\n            // all documents with after.score were already collected, so collect\n            // only documents with worse scores.\n            final NodeState.ShardIndexSearcher s = nodes[nodeID].acquire(nodeVersions);\n            try {\n              // Setting after.doc to reader.maxDoc-1 is a way to tell\n              // TopScoreDocCollector that no more docs with that score should\n              // be collected. note that in practice the shard which sends the\n              // request to a remote shard won't have reader.maxDoc at hand, so\n              // it will send some arbitrary value which will be fixed on the\n              // other end.\n              shardAfter.doc = s.getIndexReader().maxDoc() - 1;\n            } finally {\n              nodes[nodeID].release(s);\n            }\n          } else if (nodeID == after.shardIndex) {\n            // collect all documents following the last collected doc with\n            // after.score + documents with worse scores.  \n            shardAfter.doc = after.doc;\n          } else {\n            // all documents with after.score (and worse) should be collected\n            // because they didn't make it to top-N in the previous round.\n            shardAfter.doc = -1;\n          }\n          if (nodeID == myNodeID) {\n            // My node; run using local shard searcher we\n            // already aquired:\n            shardHits[nodeID] = localSearchAfter(shardAfter, query, numHits);\n          } else {\n            shardHits[nodeID] = searchNode(nodeID, nodeVersions, query, null, numHits, shardAfter);\n          }\n          //System.out.println(\"  node=\" + nodeID + \" totHits=\" + shardHits[nodeID].totalHits);\n        }\n\n        // Merge:\n        return TopDocs.merge(numHits, shardHits);\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"36510a8e3c1ec60d366b45f8f716e9dc47589661":["fb17639909a369c1e64866842e5c213440acc17e"],"fb17639909a369c1e64866842e5c213440acc17e":["e87ea9fb673e8638747af83477322f07ed5a8b95"],"fccd4a691aac1aff06ab8110d8693514a34160c3":["5f4f6b0fb6f08ac48f438f03002a283a63cb9992"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"e87ea9fb673e8638747af83477322f07ed5a8b95":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fccd4a691aac1aff06ab8110d8693514a34160c3"],"5f4f6b0fb6f08ac48f438f03002a283a63cb9992":["36510a8e3c1ec60d366b45f8f716e9dc47589661"]},"commit2Childs":{"36510a8e3c1ec60d366b45f8f716e9dc47589661":["5f4f6b0fb6f08ac48f438f03002a283a63cb9992"],"fb17639909a369c1e64866842e5c213440acc17e":["36510a8e3c1ec60d366b45f8f716e9dc47589661"],"fccd4a691aac1aff06ab8110d8693514a34160c3":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","e87ea9fb673e8638747af83477322f07ed5a8b95"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"e87ea9fb673e8638747af83477322f07ed5a8b95":["fb17639909a369c1e64866842e5c213440acc17e"],"5f4f6b0fb6f08ac48f438f03002a283a63cb9992":["fccd4a691aac1aff06ab8110d8693514a34160c3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}