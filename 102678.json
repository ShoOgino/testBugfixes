{"path":"lucene/core/src/java/org/apache/lucene/index/StandardDirectoryReader#open(IndexWriter,SegmentInfos,boolean,boolean,Map[String,String]).mjava","commits":[{"id":"763da4a9605e47013078edc323b9d4b608f0f9e0","date":1555353576,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/StandardDirectoryReader#open(IndexWriter,SegmentInfos,boolean,boolean,Map[String,String]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/StandardDirectoryReader#open(IndexWriter,SegmentInfos,boolean,boolean).mjava","sourceNew":"  /** Used by near real-time search */\n  static DirectoryReader open(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes, boolean writeAllDeletes, Map<String, String> readerAttributes) throws IOException {\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    final List<SegmentReader> readers = new ArrayList<>(numSegments);\n    final Directory dir = writer.getDirectory();\n\n    final SegmentInfos segmentInfos = infos.clone();\n    int infosUpto = 0;\n    try {\n      for (int i = 0; i < numSegments; i++) {\n        // NOTE: important that we use infos not\n        // segmentInfos here, so that we are passing the\n        // actual instance of SegmentInfoPerCommit in\n        // IndexWriter's segmentInfos:\n        final SegmentCommitInfo info = infos.info(i);\n        assert info.info.dir == dir;\n        final ReadersAndUpdates rld = writer.getPooledInstance(info, true);\n        try {\n          final SegmentReader reader = rld.getReadOnlyClone(IOContext.READ);\n          if (reader.numDocs() > 0 || writer.getConfig().mergePolicy.keepFullyDeletedSegment(() -> reader)) {\n            // Steal the ref:\n            readers.add(reader);\n            infosUpto++;\n          } else {\n            reader.decRef();\n            segmentInfos.remove(infosUpto);\n          }\n        } finally {\n          writer.release(rld);\n        }\n      }\n\n      writer.incRefDeleter(segmentInfos);\n\n      StandardDirectoryReader result = new StandardDirectoryReader(dir,\n          readers.toArray(new SegmentReader[readers.size()]), writer,\n          segmentInfos, applyAllDeletes, writeAllDeletes, readerAttributes);\n      return result;\n    } catch (Throwable t) {\n      try {\n        IOUtils.applyToAll(readers, SegmentReader::decRef);\n      } catch (Throwable t1) {\n        t.addSuppressed(t1);\n      }\n      throw t;\n    }\n  }\n\n","sourceOld":"  /** Used by near real-time search */\n  static DirectoryReader open(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes, boolean writeAllDeletes) throws IOException {\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    final List<SegmentReader> readers = new ArrayList<>(numSegments);\n    final Directory dir = writer.getDirectory();\n\n    final SegmentInfos segmentInfos = infos.clone();\n    int infosUpto = 0;\n    try {\n      for (int i = 0; i < numSegments; i++) {\n        // NOTE: important that we use infos not\n        // segmentInfos here, so that we are passing the\n        // actual instance of SegmentInfoPerCommit in\n        // IndexWriter's segmentInfos:\n        final SegmentCommitInfo info = infos.info(i);\n        assert info.info.dir == dir;\n        final ReadersAndUpdates rld = writer.getPooledInstance(info, true);\n        try {\n          final SegmentReader reader = rld.getReadOnlyClone(IOContext.READ);\n          if (reader.numDocs() > 0 || writer.getConfig().mergePolicy.keepFullyDeletedSegment(() -> reader)) {\n            // Steal the ref:\n            readers.add(reader);\n            infosUpto++;\n          } else {\n            reader.decRef();\n            segmentInfos.remove(infosUpto);\n          }\n        } finally {\n          writer.release(rld);\n        }\n      }\n\n      writer.incRefDeleter(segmentInfos);\n\n      StandardDirectoryReader result = new StandardDirectoryReader(dir,\n          readers.toArray(new SegmentReader[readers.size()]), writer,\n          segmentInfos, applyAllDeletes, writeAllDeletes);\n      return result;\n    } catch (Throwable t) {\n      try {\n        IOUtils.applyToAll(readers, SegmentReader::decRef);\n      } catch (Throwable t1) {\n        t.addSuppressed(t1);\n      }\n      throw t;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a4e83191a3e02851a0b67e5335e6922f3e9ea86d","date":1583489709,"type":5,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/StandardDirectoryReader#open(IndexWriter,SegmentInfos,boolean,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/StandardDirectoryReader#open(IndexWriter,SegmentInfos,boolean,boolean,Map[String,String]).mjava","sourceNew":"  /** Used by near real-time search */\n  static DirectoryReader open(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes, boolean writeAllDeletes) throws IOException {\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    final List<SegmentReader> readers = new ArrayList<>(numSegments);\n    final Directory dir = writer.getDirectory();\n\n    final SegmentInfos segmentInfos = infos.clone();\n    int infosUpto = 0;\n    try {\n      for (int i = 0; i < numSegments; i++) {\n        // NOTE: important that we use infos not\n        // segmentInfos here, so that we are passing the\n        // actual instance of SegmentInfoPerCommit in\n        // IndexWriter's segmentInfos:\n        final SegmentCommitInfo info = infos.info(i);\n        assert info.info.dir == dir;\n        final ReadersAndUpdates rld = writer.getPooledInstance(info, true);\n        try {\n          final SegmentReader reader = rld.getReadOnlyClone(IOContext.READ);\n          if (reader.numDocs() > 0 || writer.getConfig().mergePolicy.keepFullyDeletedSegment(() -> reader)) {\n            // Steal the ref:\n            readers.add(reader);\n            infosUpto++;\n          } else {\n            reader.decRef();\n            segmentInfos.remove(infosUpto);\n          }\n        } finally {\n          writer.release(rld);\n        }\n      }\n\n      writer.incRefDeleter(segmentInfos);\n\n      StandardDirectoryReader result = new StandardDirectoryReader(dir,\n          readers.toArray(new SegmentReader[readers.size()]), writer,\n          segmentInfos, applyAllDeletes, writeAllDeletes);\n      return result;\n    } catch (Throwable t) {\n      try {\n        IOUtils.applyToAll(readers, SegmentReader::decRef);\n      } catch (Throwable t1) {\n        t.addSuppressed(t1);\n      }\n      throw t;\n    }\n  }\n\n","sourceOld":"  /** Used by near real-time search */\n  static DirectoryReader open(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes, boolean writeAllDeletes, Map<String, String> readerAttributes) throws IOException {\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    final List<SegmentReader> readers = new ArrayList<>(numSegments);\n    final Directory dir = writer.getDirectory();\n\n    final SegmentInfos segmentInfos = infos.clone();\n    int infosUpto = 0;\n    try {\n      for (int i = 0; i < numSegments; i++) {\n        // NOTE: important that we use infos not\n        // segmentInfos here, so that we are passing the\n        // actual instance of SegmentInfoPerCommit in\n        // IndexWriter's segmentInfos:\n        final SegmentCommitInfo info = infos.info(i);\n        assert info.info.dir == dir;\n        final ReadersAndUpdates rld = writer.getPooledInstance(info, true);\n        try {\n          final SegmentReader reader = rld.getReadOnlyClone(IOContext.READ);\n          if (reader.numDocs() > 0 || writer.getConfig().mergePolicy.keepFullyDeletedSegment(() -> reader)) {\n            // Steal the ref:\n            readers.add(reader);\n            infosUpto++;\n          } else {\n            reader.decRef();\n            segmentInfos.remove(infosUpto);\n          }\n        } finally {\n          writer.release(rld);\n        }\n      }\n\n      writer.incRefDeleter(segmentInfos);\n\n      StandardDirectoryReader result = new StandardDirectoryReader(dir,\n          readers.toArray(new SegmentReader[readers.size()]), writer,\n          segmentInfos, applyAllDeletes, writeAllDeletes, readerAttributes);\n      return result;\n    } catch (Throwable t) {\n      try {\n        IOUtils.applyToAll(readers, SegmentReader::decRef);\n      } catch (Throwable t1) {\n        t.addSuppressed(t1);\n      }\n      throw t;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"763da4a9605e47013078edc323b9d4b608f0f9e0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["763da4a9605e47013078edc323b9d4b608f0f9e0"]},"commit2Childs":{"763da4a9605e47013078edc323b9d4b608f0f9e0":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["763da4a9605e47013078edc323b9d4b608f0f9e0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}