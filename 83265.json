{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/pulsing/PulsingPostingsWriter#writeTerm(BytesRef,TermsEnum,FixedBitSet).mjava","commits":[{"id":"fa80a35d7c4b2b1e83082b275e3e8328ab93db52","date":1381766157,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/pulsing/PulsingPostingsWriter#writeTerm(BytesRef,TermsEnum,FixedBitSet).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public BlockTermState writeTerm(BytesRef term, TermsEnum termsEnum, FixedBitSet docsSeen) throws IOException {\n\n    // First pass: figure out whether we should pulse this term\n    long posCount = 0;\n\n    if (fieldHasPositions == false) {\n      // No positions:\n      docsEnum = termsEnum.docs(null, docsEnum, enumFlags);\n      assert docsEnum != null;\n      while (posCount <= maxPositions) {\n        if (docsEnum.nextDoc() == DocsEnum.NO_MORE_DOCS) {\n          break;\n        }\n        posCount++;\n      }\n    } else {\n      posEnum = termsEnum.docsAndPositions(null, posEnum, enumFlags);\n      assert posEnum != null;\n      while (posCount <= maxPositions) {\n        if (posEnum.nextDoc() == DocsEnum.NO_MORE_DOCS) {\n          break;\n        }\n        posCount += posEnum.freq();\n      }\n    }\n\n    if (posCount == 0) {\n      // All docs were deleted\n      return null;\n    }\n\n    // Second pass: write postings\n    if (posCount > maxPositions) {\n      // Too many positions; do not pulse.  Just lset\n      // wrapped postingsWriter encode the postings:\n\n      PulsingTermState state = new PulsingTermState();\n      state.wrappedState = wrappedPostingsWriter.writeTerm(term, termsEnum, docsSeen);\n      state.docFreq = state.wrappedState.docFreq;\n      state.totalTermFreq = state.wrappedState.totalTermFreq;\n      return state;\n    } else {\n      // Pulsed:\n      if (fieldHasPositions == false) {\n        docsEnum = termsEnum.docs(null, docsEnum, enumFlags);\n      } else {\n        posEnum = termsEnum.docsAndPositions(null, posEnum, enumFlags);\n        docsEnum = posEnum;\n      }\n      assert docsEnum != null;\n\n      // There were few enough total occurrences for this\n      // term, so we fully inline our postings data into\n      // terms dict, now:\n\n      // TODO: it'd be better to share this encoding logic\n      // in some inner codec that knows how to write a\n      // single doc / single position, etc.  This way if a\n      // given codec wants to store other interesting\n      // stuff, it could use this pulsing codec to do so\n\n      int lastDocID = 0;\n      int lastPayloadLength = -1;\n      int lastOffsetLength = -1;\n\n      int docFreq = 0;\n      long totalTermFreq = 0;\n      while (true) {\n        int docID = docsEnum.nextDoc();\n        if (docID == DocsEnum.NO_MORE_DOCS) {\n          break;\n        }\n        docsSeen.set(docID);\n\n        int delta = docID - lastDocID;\n        lastDocID = docID;\n\n        docFreq++;\n\n        if (fieldHasFreqs) {\n          int freq = docsEnum.freq();\n          totalTermFreq += freq;\n\n          if (freq == 1) {\n            buffer.writeVInt((delta << 1) | 1);\n          } else {\n            buffer.writeVInt(delta << 1);\n            buffer.writeVInt(freq);\n          }\n\n          if (fieldHasPositions) {\n            int lastPos = 0;\n            int lastOffset = 0;\n            for(int posIDX=0;posIDX<freq;posIDX++) {\n              int pos = posEnum.nextPosition();\n              int posDelta = pos - lastPos;\n              lastPos = pos;\n              int payloadLength;\n              BytesRef payload;\n              if (fieldHasPayloads) {\n                payload = posEnum.getPayload();\n                payloadLength = payload == null ? 0 : payload.length;\n                if (payloadLength != lastPayloadLength) {\n                  buffer.writeVInt((posDelta << 1)|1);\n                  buffer.writeVInt(payloadLength);\n                  lastPayloadLength = payloadLength;\n                } else {\n                  buffer.writeVInt(posDelta << 1);\n                }\n              } else {\n                payloadLength = 0;\n                payload = null;\n                buffer.writeVInt(posDelta);\n              }\n\n              if (fieldHasOffsets) {\n                int startOffset = posEnum.startOffset();\n                int endOffset = posEnum.endOffset();\n                int offsetDelta = startOffset - lastOffset;\n                int offsetLength = endOffset - startOffset;\n                if (offsetLength != lastOffsetLength) {\n                  buffer.writeVInt(offsetDelta << 1 | 1);\n                  buffer.writeVInt(offsetLength);\n                } else {\n                  buffer.writeVInt(offsetDelta << 1);\n                }\n                lastOffset = startOffset;\n                lastOffsetLength = offsetLength;             \n              }\n            \n              if (payloadLength > 0) {\n                assert fieldHasPayloads;\n                assert payload != null;\n                buffer.writeBytes(payload.bytes, payload.offset, payload.length);\n              }\n            }\n          }\n        } else {\n          buffer.writeVInt(delta);\n        }\n      }\n      \n      PulsingTermState state = new PulsingTermState();\n      state.bytes = new byte[(int) buffer.getFilePointer()];\n      state.docFreq = docFreq;\n      state.totalTermFreq = fieldHasFreqs ? totalTermFreq : -1;\n      buffer.writeTo(state.bytes, 0);\n      buffer.reset();\n      return state;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fbaae1c00d39df2c872bbe043af26d02d3818313","date":1409657064,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/pulsing/PulsingPostingsWriter#writeTerm(BytesRef,TermsEnum,FixedBitSet).mjava","sourceNew":null,"sourceOld":"  @Override\n  public BlockTermState writeTerm(BytesRef term, TermsEnum termsEnum, FixedBitSet docsSeen) throws IOException {\n\n    // First pass: figure out whether we should pulse this term\n    long posCount = 0;\n\n    if (fieldHasPositions == false) {\n      // No positions:\n      docsEnum = termsEnum.docs(null, docsEnum, enumFlags);\n      assert docsEnum != null;\n      while (posCount <= maxPositions) {\n        if (docsEnum.nextDoc() == DocsEnum.NO_MORE_DOCS) {\n          break;\n        }\n        posCount++;\n      }\n    } else {\n      posEnum = termsEnum.docsAndPositions(null, posEnum, enumFlags);\n      assert posEnum != null;\n      while (posCount <= maxPositions) {\n        if (posEnum.nextDoc() == DocsEnum.NO_MORE_DOCS) {\n          break;\n        }\n        posCount += posEnum.freq();\n      }\n    }\n\n    if (posCount == 0) {\n      // All docs were deleted\n      return null;\n    }\n\n    // Second pass: write postings\n    if (posCount > maxPositions) {\n      // Too many positions; do not pulse.  Just lset\n      // wrapped postingsWriter encode the postings:\n\n      PulsingTermState state = new PulsingTermState();\n      state.wrappedState = wrappedPostingsWriter.writeTerm(term, termsEnum, docsSeen);\n      state.docFreq = state.wrappedState.docFreq;\n      state.totalTermFreq = state.wrappedState.totalTermFreq;\n      return state;\n    } else {\n      // Pulsed:\n      if (fieldHasPositions == false) {\n        docsEnum = termsEnum.docs(null, docsEnum, enumFlags);\n      } else {\n        posEnum = termsEnum.docsAndPositions(null, posEnum, enumFlags);\n        docsEnum = posEnum;\n      }\n      assert docsEnum != null;\n\n      // There were few enough total occurrences for this\n      // term, so we fully inline our postings data into\n      // terms dict, now:\n\n      // TODO: it'd be better to share this encoding logic\n      // in some inner codec that knows how to write a\n      // single doc / single position, etc.  This way if a\n      // given codec wants to store other interesting\n      // stuff, it could use this pulsing codec to do so\n\n      int lastDocID = 0;\n      int lastPayloadLength = -1;\n      int lastOffsetLength = -1;\n\n      int docFreq = 0;\n      long totalTermFreq = 0;\n      while (true) {\n        int docID = docsEnum.nextDoc();\n        if (docID == DocsEnum.NO_MORE_DOCS) {\n          break;\n        }\n        docsSeen.set(docID);\n\n        int delta = docID - lastDocID;\n        lastDocID = docID;\n\n        docFreq++;\n\n        if (fieldHasFreqs) {\n          int freq = docsEnum.freq();\n          totalTermFreq += freq;\n\n          if (freq == 1) {\n            buffer.writeVInt((delta << 1) | 1);\n          } else {\n            buffer.writeVInt(delta << 1);\n            buffer.writeVInt(freq);\n          }\n\n          if (fieldHasPositions) {\n            int lastPos = 0;\n            int lastOffset = 0;\n            for(int posIDX=0;posIDX<freq;posIDX++) {\n              int pos = posEnum.nextPosition();\n              int posDelta = pos - lastPos;\n              lastPos = pos;\n              int payloadLength;\n              BytesRef payload;\n              if (fieldHasPayloads) {\n                payload = posEnum.getPayload();\n                payloadLength = payload == null ? 0 : payload.length;\n                if (payloadLength != lastPayloadLength) {\n                  buffer.writeVInt((posDelta << 1)|1);\n                  buffer.writeVInt(payloadLength);\n                  lastPayloadLength = payloadLength;\n                } else {\n                  buffer.writeVInt(posDelta << 1);\n                }\n              } else {\n                payloadLength = 0;\n                payload = null;\n                buffer.writeVInt(posDelta);\n              }\n\n              if (fieldHasOffsets) {\n                int startOffset = posEnum.startOffset();\n                int endOffset = posEnum.endOffset();\n                int offsetDelta = startOffset - lastOffset;\n                int offsetLength = endOffset - startOffset;\n                if (offsetLength != lastOffsetLength) {\n                  buffer.writeVInt(offsetDelta << 1 | 1);\n                  buffer.writeVInt(offsetLength);\n                } else {\n                  buffer.writeVInt(offsetDelta << 1);\n                }\n                lastOffset = startOffset;\n                lastOffsetLength = offsetLength;             \n              }\n            \n              if (payloadLength > 0) {\n                assert fieldHasPayloads;\n                assert payload != null;\n                buffer.writeBytes(payload.bytes, payload.offset, payload.length);\n              }\n            }\n          }\n        } else {\n          buffer.writeVInt(delta);\n        }\n      }\n      \n      PulsingTermState state = new PulsingTermState();\n      state.bytes = new byte[(int) buffer.getFilePointer()];\n      state.docFreq = docFreq;\n      state.totalTermFreq = fieldHasFreqs ? totalTermFreq : -1;\n      buffer.writeTo(state.bytes, 0);\n      buffer.reset();\n      return state;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fbaae1c00d39df2c872bbe043af26d02d3818313":["fa80a35d7c4b2b1e83082b275e3e8328ab93db52"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fa80a35d7c4b2b1e83082b275e3e8328ab93db52":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fbaae1c00d39df2c872bbe043af26d02d3818313"]},"commit2Childs":{"fbaae1c00d39df2c872bbe043af26d02d3818313":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fa80a35d7c4b2b1e83082b275e3e8328ab93db52"],"fa80a35d7c4b2b1e83082b275e3e8328ab93db52":["fbaae1c00d39df2c872bbe043af26d02d3818313"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}