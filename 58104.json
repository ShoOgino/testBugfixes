{"path":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2dee33619431ada2a7a07f5fe2dbd94bac6a460","date":1337274029,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      // nocommit shouldn't we check si.getHasNorms()/si.getHasDocValues()...?\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4a8b14bc4241c302311422d5c6f7627f8febb86e","date":1337291675,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      // nocommit shouldn't we check si.getHasNorms()/si.getHasDocValues()...?\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      // nocommit shouldn't we check si.getHasNorms()/si.getHasDocValues()...?\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"22b3128eea8c61f8f1f387dac6b3e9504bc8036e","date":1337625491,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      // nocommit shouldn't we check si.getHasNorms()/si.getHasDocValues()...?\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfoPerCommit,IOContext,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentCoreReaders#SegmentCoreReaders(SegmentReader,Directory,SegmentInfo,IOContext,int).mjava","sourceNew":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfoPerCommit si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.info.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.info.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.info.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      fieldInfos = codec.fieldInfosFormat().getFieldInfosReader().read(cfsDir, si.info.name, IOContext.READONCE);\n\n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si.info, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.info.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si.info, fieldInfos, context);\n\n      if (fieldInfos.hasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.info.getCodec().termVectorsFormat().vectorsReader(cfsDir, si.info, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","sourceOld":"  SegmentCoreReaders(SegmentReader owner, Directory dir, SegmentInfo si, IOContext context, int termsIndexDivisor) throws IOException {\n    \n    if (termsIndexDivisor == 0) {\n      throw new IllegalArgumentException(\"indexDivisor must be < 0 (don't load terms index) or greater than 0 (got 0)\");\n    }\n    \n    final Codec codec = si.getCodec();\n    final Directory cfsDir; // confusing name: if (cfs) its the cfsdir, otherwise its the segment's directory.\n\n    boolean success = false;\n    \n    try {\n      if (si.getUseCompoundFile()) {\n        cfsDir = cfsReader = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(si.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION), context, false);\n      } else {\n        cfsReader = null;\n        cfsDir = dir;\n      }\n      si.loadFieldInfos(cfsDir, false); // prevent opening the CFS to load fieldInfos\n      fieldInfos = si.getFieldInfos();\n      \n      this.termsIndexDivisor = termsIndexDivisor;\n      final PostingsFormat format = codec.postingsFormat();\n      final SegmentReadState segmentReadState = new SegmentReadState(cfsDir, si, fieldInfos, context, termsIndexDivisor);\n      // Ask codec for its Fields\n      fields = format.fieldsProducer(segmentReadState);\n      assert fields != null;\n      // ask codec for its Norms: \n      // TODO: since we don't write any norms file if there are no norms,\n      // kinda jaky to assume the codec handles the case of no norms file at all gracefully?!\n      norms = codec.normsFormat().docsProducer(segmentReadState);\n      perDocProducer = codec.docValuesFormat().docsProducer(segmentReadState);\n  \n      fieldsReaderOrig = si.getCodec().storedFieldsFormat().fieldsReader(cfsDir, si, fieldInfos, context);\n \n      if (si.getHasVectors()) { // open term vector files only as needed\n        termVectorsReaderOrig = si.getCodec().termVectorsFormat().vectorsReader(cfsDir, si, fieldInfos, context);\n      } else {\n        termVectorsReaderOrig = null;\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        decRef();\n      }\n    }\n    \n    // Must assign this at the end -- if we hit an\n    // exception above core, we don't want to attempt to\n    // purge the FieldCache (will hit NPE because core is\n    // not assigned yet).\n    this.owner = owner;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"4a8b14bc4241c302311422d5c6f7627f8febb86e":["d2dee33619431ada2a7a07f5fe2dbd94bac6a460"],"d2dee33619431ada2a7a07f5fe2dbd94bac6a460":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","9d153abcf92dc5329d98571a8c3035df9bd80648"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9d153abcf92dc5329d98571a8c3035df9bd80648":["22b3128eea8c61f8f1f387dac6b3e9504bc8036e"],"22b3128eea8c61f8f1f387dac6b3e9504bc8036e":["4a8b14bc4241c302311422d5c6f7627f8febb86e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"]},"commit2Childs":{"4a8b14bc4241c302311422d5c6f7627f8febb86e":["22b3128eea8c61f8f1f387dac6b3e9504bc8036e"],"d2dee33619431ada2a7a07f5fe2dbd94bac6a460":["4a8b14bc4241c302311422d5c6f7627f8febb86e"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["d2dee33619431ada2a7a07f5fe2dbd94bac6a460","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"22b3128eea8c61f8f1f387dac6b3e9504bc8036e":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}