{"path":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","commits":[{"id":"4edc984f0f4ac77c37e48ace2932f780f888453c","date":1388475218,"type":1,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc728b07df73b197e6d940d27f9b08b63918f13","date":1388834348,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"/dev/null","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", _TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = _TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<String>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n\n    writer.shutdown();\n    IOUtils.close(searcher.getIndexReader(), taxoWriter, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n    \n    IOUtils.close(searcher.getIndexReader(), taxoWriter, writer, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n\n    writer.shutdown();\n    IOUtils.close(searcher.getIndexReader(), taxoWriter, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n\n    writer.shutdown();\n    IOUtils.close(searcher.getIndexReader(), taxoWriter, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n\n    writer.close();\n    IOUtils.close(searcher.getIndexReader(), taxoWriter, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n\n    writer.shutdown();\n    IOUtils.close(searcher.getIndexReader(), taxoWriter, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b8b2bc4b8b503cc0b5743b19445798c62069e4d","date":1477390943,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    Facets facets = getAllFacets(FacetsConfig.DEFAULT_INDEX_FIELD_NAME, searcher, taxoReader, config);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n\n    writer.close();\n    IOUtils.close(searcher.getIndexReader(), taxoWriter, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n\n    writer.close();\n    IOUtils.close(searcher.getIndexReader(), taxoWriter, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"60b61628d1912768f51eccaa8ead5a5a32ab34c6","date":1477427681,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    Facets facets = getAllFacets(FacetsConfig.DEFAULT_INDEX_FIELD_NAME, searcher, taxoReader, config);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n\n    writer.close();\n    IOUtils.close(searcher.getIndexReader(), taxoWriter, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n\n    writer.close();\n    IOUtils.close(searcher.getIndexReader(), taxoWriter, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"80d0e6d59ae23f4a6f30eaf40bfb40742300287f","date":1477598926,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    Facets facets = getAllFacets(FacetsConfig.DEFAULT_INDEX_FIELD_NAME, searcher, taxoReader, config);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n\n    writer.close();\n    IOUtils.close(searcher.getIndexReader(), taxoWriter, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    // Aggregate the facet counts:\n    FacetsCollector c = new FacetsCollector();\n    \n    // MatchAllDocsQuery is for \"browsing\" (counts facets\n    // for all non-deleted docs in the index); normally\n    // you'd use a \"normal\" query, and use MultiCollector to\n    // wrap collecting the \"normal\" hits and also facets:\n    searcher.search(new MatchAllDocsQuery(), c);\n    Facets facets = getTaxonomyFacetCounts(taxoReader, config, c);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n\n    writer.close();\n    IOUtils.close(searcher.getIndexReader(), taxoWriter, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57c6c784f777a2cc8fa014507ea129526822714d","date":1579733373,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyFacetCounts#testManyFacetsInOneDocument().mjava","sourceNew":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TEST_NIGHTLY ? TestUtil.nextInt(random(), 40000, 100000) : TestUtil.nextInt(random(), 4000, 10000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    Facets facets = getAllFacets(FacetsConfig.DEFAULT_INDEX_FIELD_NAME, searcher, taxoReader, config);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n\n    writer.close();\n    IOUtils.close(searcher.getIndexReader(), taxoWriter, taxoReader, dir, taxoDir);\n  }\n\n","sourceOld":"  // LUCENE-4583: make sure if we require > 32 KB for one\n  // document, we don't hit exc when using Facet42DocValuesFormat\n  public void testManyFacetsInOneDocument() throws Exception {\n    assumeTrue(\"default Codec doesn't support huge BinaryDocValues\", TestUtil.fieldSupportsHugeBinaryDocValues(FacetsConfig.DEFAULT_INDEX_FIELD_NAME));\n    Directory dir = newDirectory();\n    Directory taxoDir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    DirectoryTaxonomyWriter taxoWriter = new DirectoryTaxonomyWriter(taxoDir, IndexWriterConfig.OpenMode.CREATE);\n\n    FacetsConfig config = new FacetsConfig();\n    config.setMultiValued(\"dim\", true);\n    \n    int numLabels = TestUtil.nextInt(random(), 40000, 100000);\n    \n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"text\", Field.Store.NO));\n    for (int i = 0; i < numLabels; i++) {\n      doc.add(new FacetField(\"dim\", \"\" + i));\n    }\n    writer.addDocument(config.build(taxoWriter, doc));\n    \n    // NRT open\n    IndexSearcher searcher = newSearcher(writer.getReader());\n    \n    // NRT open\n    TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoWriter);\n    \n    Facets facets = getAllFacets(FacetsConfig.DEFAULT_INDEX_FIELD_NAME, searcher, taxoReader, config);\n\n    FacetResult result = facets.getTopChildren(Integer.MAX_VALUE, \"dim\");\n    assertEquals(numLabels, result.labelValues.length);\n    Set<String> allLabels = new HashSet<>();\n    for (LabelAndValue labelValue : result.labelValues) {\n      allLabels.add(labelValue.label);\n      assertEquals(1, labelValue.value.intValue());\n    }\n    assertEquals(numLabels, allLabels.size());\n\n    writer.close();\n    IOUtils.close(searcher.getIndexReader(), taxoWriter, taxoReader, dir, taxoDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6613659748fe4411a7dcf85266e55db1f95f7315"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"6613659748fe4411a7dcf85266e55db1f95f7315":["3cc728b07df73b197e6d940d27f9b08b63918f13"],"4edc984f0f4ac77c37e48ace2932f780f888453c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"60b61628d1912768f51eccaa8ead5a5a32ab34c6":["d0ef034a4f10871667ae75181537775ddcf8ade4","4b8b2bc4b8b503cc0b5743b19445798c62069e4d"],"57c6c784f777a2cc8fa014507ea129526822714d":["60b61628d1912768f51eccaa8ead5a5a32ab34c6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":["d0ef034a4f10871667ae75181537775ddcf8ade4","60b61628d1912768f51eccaa8ead5a5a32ab34c6"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"4b8b2bc4b8b503cc0b5743b19445798c62069e4d":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"3cc728b07df73b197e6d940d27f9b08b63918f13":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4edc984f0f4ac77c37e48ace2932f780f888453c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["57c6c784f777a2cc8fa014507ea129526822714d"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"6613659748fe4411a7dcf85266e55db1f95f7315":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"4edc984f0f4ac77c37e48ace2932f780f888453c":["3cc728b07df73b197e6d940d27f9b08b63918f13"],"60b61628d1912768f51eccaa8ead5a5a32ab34c6":["57c6c784f777a2cc8fa014507ea129526822714d","80d0e6d59ae23f4a6f30eaf40bfb40742300287f"],"57c6c784f777a2cc8fa014507ea129526822714d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4edc984f0f4ac77c37e48ace2932f780f888453c","3cc728b07df73b197e6d940d27f9b08b63918f13"],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["60b61628d1912768f51eccaa8ead5a5a32ab34c6","80d0e6d59ae23f4a6f30eaf40bfb40742300287f","4b8b2bc4b8b503cc0b5743b19445798c62069e4d"],"4b8b2bc4b8b503cc0b5743b19445798c62069e4d":["60b61628d1912768f51eccaa8ead5a5a32ab34c6"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"3cc728b07df73b197e6d940d27f9b08b63918f13":["6613659748fe4411a7dcf85266e55db1f95f7315"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}