{"path":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","sourceNew":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random.nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n          .setMergePolicy(mp);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random.nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        w.close(false);\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random.nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, null)\n        .setMergePolicy(mp);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      w.close(false);\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      new IndexUpgrader(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, null), false)\n        .upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random.nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n          .setMergePolicy(mp);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random.nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        w.close(false);\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random.nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, null)\n        .setMergePolicy(mp);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      w.close(false);\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      new IndexUpgrader(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, null), false)\n        .upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","sourceNew":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n          .setMergePolicy(mp);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random().nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        w.close(false);\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, null)\n        .setMergePolicy(mp);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      w.close(false);\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      new IndexUpgrader(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, null), false)\n        .upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random.nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n          .setMergePolicy(mp);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random.nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        w.close(false);\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random.nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, null)\n        .setMergePolicy(mp);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      w.close(false);\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      new IndexUpgrader(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, null), false)\n        .upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6f1e5b432d4a0520e976622998d1c85a0fa4f9fa","date":1379529236,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","sourceNew":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n          .setMergePolicy(mp);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random().nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        w.close(false);\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, null)\n        .setMergePolicy(mp);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      w.close(false);\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      newIndexUpgrader(dir).upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n          .setMergePolicy(mp);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random().nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        w.close(false);\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, null)\n        .setMergePolicy(mp);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      w.close(false);\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      new IndexUpgrader(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, null), false)\n        .upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","sourceNew":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n          .setMergePolicy(mp);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random().nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        w.shutdown(false);\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, null)\n        .setMergePolicy(mp);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      w.shutdown(false);\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      newIndexUpgrader(dir).upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n          .setMergePolicy(mp);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random().nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        w.close(false);\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, null)\n        .setMergePolicy(mp);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      w.close(false);\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      newIndexUpgrader(dir).upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","sourceNew":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(mp).setCommitOnClose(false);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random().nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        try {\n          w.commit();\n        } finally {\n          w.close();\n        }\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(null)\n        .setMergePolicy(mp).setCommitOnClose(false);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      try {\n        w.commit();\n      } finally {\n        w.close();\n      }\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      newIndexUpgrader(dir).upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n          .setMergePolicy(mp);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random().nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        w.shutdown(false);\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(TEST_VERSION_CURRENT, null)\n        .setMergePolicy(mp);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      w.shutdown(false);\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      newIndexUpgrader(dir).upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13","date":1409346855,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","sourceNew":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n      if (dir instanceof MockDirectoryWrapper) {\n        // we need to ensure we delete old commits for this test,\n        // otherwise IndexUpgrader gets angry\n        ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n      }\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(mp).setCommitOnClose(false);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random().nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        try {\n          w.commit();\n        } finally {\n          w.close();\n        }\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(null)\n        .setMergePolicy(mp).setCommitOnClose(false);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      try {\n        w.commit();\n      } finally {\n        w.close();\n      }\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      // ensure there is only one commit\n      assertEquals(1, DirectoryReader.listCommits(dir).size());\n      newIndexUpgrader(dir).upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(mp).setCommitOnClose(false);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random().nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        try {\n          w.commit();\n        } finally {\n          w.close();\n        }\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(null)\n        .setMergePolicy(mp).setCommitOnClose(false);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      try {\n        w.commit();\n      } finally {\n        w.close();\n      }\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      newIndexUpgrader(dir).upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cc45c615dbb82bf79d5f9550286098367874fbf","date":1409571423,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","sourceNew":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n      if (dir instanceof MockDirectoryWrapper) {\n        // we need to ensure we delete old commits for this test,\n        // otherwise IndexUpgrader gets angry\n        ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n      }\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(mp).setCommitOnClose(false);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random().nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        try {\n          w.commit();\n        } finally {\n          w.close();\n        }\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(null)\n        .setMergePolicy(mp).setCommitOnClose(false);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      try {\n        w.commit();\n      } finally {\n        w.close();\n      }\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      // ensure there is only one commit\n      assertEquals(1, DirectoryReader.listCommits(dir).size());\n      newIndexUpgrader(dir).upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n      if (dir instanceof MockDirectoryWrapper) {\n        // we need to ensure we delete old commits for this test,\n        // otherwise IndexUpgrader gets angry\n        ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n      }\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(mp).setCommitOnClose(false);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random().nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        try {\n          w.commit();\n        } finally {\n          w.close();\n        }\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(null)\n        .setMergePolicy(mp).setCommitOnClose(false);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      try {\n        w.commit();\n      } finally {\n        w.close();\n      }\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      // ensure there is only one commit\n      assertEquals(1, DirectoryReader.listCommits(dir).size());\n      newIndexUpgrader(dir).upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#testUpgradeOldSingleSegmentIndexWithAdditions().mjava","sourceNew":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n      if (dir instanceof MockDirectoryWrapper) {\n        // we need to ensure we delete old commits for this test,\n        // otherwise IndexUpgrader gets angry\n        ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n      }\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(mp).setCommitOnClose(false);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random().nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        try {\n          w.commit();\n        } finally {\n          w.close();\n        }\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(null)\n        .setMergePolicy(mp).setCommitOnClose(false);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      try {\n        w.commit();\n      } finally {\n        w.close();\n      }\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      // ensure there is only one commit\n      assertEquals(1, DirectoryReader.listCommits(dir).size());\n      newIndexUpgrader(dir).upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testUpgradeOldSingleSegmentIndexWithAdditions() throws Exception {\n    for (String name : oldSingleSegmentNames) {\n      if (VERBOSE) {\n        System.out.println(\"testUpgradeOldSingleSegmentIndexWithAdditions: index=\" +name);\n      }\n      Directory dir = newDirectory(oldIndexDirs.get(name));\n      if (dir instanceof MockDirectoryWrapper) {\n        // we need to ensure we delete old commits for this test,\n        // otherwise IndexUpgrader gets angry\n        ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n      }\n\n      assertEquals(\"Original index must be single segment\", 1, getNumberOfSegments(dir));\n\n      // create a bunch of dummy segments\n      int id = 40;\n      RAMDirectory ramDir = new RAMDirectory();\n      for (int i = 0; i < 3; i++) {\n        // only use Log- or TieredMergePolicy, to make document addition predictable and not suddenly merge:\n        MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n        IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(mp).setCommitOnClose(false);\n        IndexWriter w = new IndexWriter(ramDir, iwc);\n        // add few more docs:\n        for(int j = 0; j < RANDOM_MULTIPLIER * random().nextInt(30); j++) {\n          addDoc(w, id++);\n        }\n        try {\n          w.commit();\n        } finally {\n          w.close();\n        }\n      }\n      \n      // add dummy segments (which are all in current\n      // version) to single segment index\n      MergePolicy mp = random().nextBoolean() ? newLogMergePolicy() : newTieredMergePolicy();\n      IndexWriterConfig iwc = new IndexWriterConfig(null)\n        .setMergePolicy(mp).setCommitOnClose(false);\n      IndexWriter w = new IndexWriter(dir, iwc);\n      w.addIndexes(ramDir);\n      try {\n        w.commit();\n      } finally {\n        w.close();\n      }\n      \n      // determine count of segments in modified index\n      final int origSegCount = getNumberOfSegments(dir);\n      \n      // ensure there is only one commit\n      assertEquals(1, DirectoryReader.listCommits(dir).size());\n      newIndexUpgrader(dir).upgrade();\n\n      final int segCount = checkAllSegmentsUpgraded(dir);\n      assertEquals(\"Index must still contain the same number of segments, as only one segment was upgraded and nothing else merged\",\n        origSegCount, segCount);\n      \n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"6f1e5b432d4a0520e976622998d1c85a0fa4f9fa":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cc45c615dbb82bf79d5f9550286098367874fbf":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["6f1e5b432d4a0520e976622998d1c85a0fa4f9fa"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13","4cc45c615dbb82bf79d5f9550286098367874fbf"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"6f1e5b432d4a0520e976622998d1c85a0fa4f9fa":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"4cc45c615dbb82bf79d5f9550286098367874fbf":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13"],"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13":["4cc45c615dbb82bf79d5f9550286098367874fbf","402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["6f1e5b432d4a0520e976622998d1c85a0fa4f9fa"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}