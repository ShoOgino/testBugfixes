{"path":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","commits":[{"id":"e212ce9e66e9e69443bd5faec69d9f312b1574e8","date":1297606129,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"/dev/null","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      for(int id=0;id<5000*RANDOM_MULTIPLIER;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f1bdbf92da222965b46c0a942c3857ba56e5c638","date":1298297608,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"/dev/null","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      for(int id=0;id<5000*RANDOM_MULTIPLIER;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"/dev/null","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      for(int id=0;id<5000*RANDOM_MULTIPLIER;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f83af14a2a8131b14d7aee6274c740334e0363d3","date":1307579822,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      int num = atLeast(5000);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      for(int id=0;id<5000*RANDOM_MULTIPLIER;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      int num = atLeast(5000);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      for(int id=0;id<5000*RANDOM_MULTIPLIER;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      int num = atLeast(5000);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      for(int id=0;id<5000*RANDOM_MULTIPLIER;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9cc9d77712aba3662f24632df7539ab75e3667","date":1309095238,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      int num = atLeast(5000);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      int num = atLeast(5000);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      int num = atLeast(5000);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      int num = atLeast(5000);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      int num = atLeast(5000);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      int num = atLeast(5000);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seek(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"459280d4c73660ea582f38afce7968563068fe49","date":1311128716,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      int num = atLeast(5000);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", StringField.TYPE_STORED);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", StringField.TYPE_STORED);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.forceMerge(1);\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", StringField.TYPE_STORED);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.optimize();\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", StringField.TYPE_STORED);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.forceMerge(1);\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator(null);\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", StringField.TYPE_STORED);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.forceMerge(1);\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator();\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"872cff1d3a554e0cd64014cd97f88d3002b0f491","date":1323024658,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", StringField.TYPE_STORED);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.forceMerge(1);\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator(null);\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", StringField.TYPE_STORED);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.forceMerge(1);\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator(null);\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b65b350ca9588f9fc76ce7d6804160d06c45ff42","date":1323026297,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", StringField.TYPE_STORED);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.forceMerge(1);\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator(null);\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", StringField.TYPE_STORED);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.forceMerge(1);\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator(null);\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = te.docs(null, de);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = te.docs(null, de);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"59bfb89446d5591617d90031d670a157aba2f2f0","date":1327856853,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", StringField.TYPE_STORED);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.forceMerge(1);\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final DirectoryReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = getOnlySegmentReader(r).fields().terms(\"field\").iterator(null);\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", StringField.TYPE_STORED);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.forceMerge(1);\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator(null);\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", StringField.TYPE_STORED);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.forceMerge(1);\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final DirectoryReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = getOnlySegmentReader(r).fields().terms(\"field\").iterator(null);\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", StringField.TYPE_STORED);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.forceMerge(1);\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final IndexReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = r.getSequentialSubReaders()[0].fields().terms(\"field\").iterator(null);\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressAdvance#testStressAdvance().mjava","sourceNew":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", StringField.TYPE_STORED);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.forceMerge(1);\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final DirectoryReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = getOnlySegmentReader(r).fields().terms(\"field\").iterator(null);\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  public void testStressAdvance() throws Exception {\n    for(int iter=0;iter<3;iter++) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter);\n      }\n      Directory dir = newDirectory();\n      RandomIndexWriter w = new RandomIndexWriter(random, dir);\n      final Set<Integer> aDocs = new HashSet<Integer>();\n      final Document doc = new Document();\n      final Field f = newField(\"field\", \"\", StringField.TYPE_UNSTORED);\n      doc.add(f);\n      final Field idField = newField(\"id\", \"\", StringField.TYPE_STORED);\n      doc.add(idField);\n      int num = atLeast(4097);\n      for(int id=0;id<num;id++) {\n        if (random.nextInt(4) == 3) {\n          f.setValue(\"a\");\n          aDocs.add(id);\n        } else {\n          f.setValue(\"b\");\n        }\n        idField.setValue(\"\"+id);\n        w.addDocument(doc);\n      }\n\n      w.forceMerge(1);\n\n      final List<Integer> aDocIDs = new ArrayList<Integer>();\n      final List<Integer> bDocIDs = new ArrayList<Integer>();\n\n      final DirectoryReader r = w.getReader();\n      final int[] idToDocID = new int[r.maxDoc()];\n      for(int docID=0;docID<idToDocID.length;docID++) {\n        int id = Integer.parseInt(r.document(docID).get(\"id\"));\n        if (aDocs.contains(id)) {\n          aDocIDs.add(docID);\n        } else {\n          bDocIDs.add(docID);\n        }\n      }\n      final TermsEnum te = getOnlySegmentReader(r).fields().terms(\"field\").iterator(null);\n      \n      DocsEnum de = null;\n      for(int iter2=0;iter2<10;iter2++) {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: iter=\" + iter + \" iter2=\" + iter2);\n        }\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"a\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, aDocIDs);\n\n        assertEquals(TermsEnum.SeekStatus.FOUND, te.seekCeil(new BytesRef(\"b\")));\n        de = _TestUtil.docs(random, te, null, de, false);\n        testOne(de, bDocIDs);\n      }\n\n      w.close();\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["e212ce9e66e9e69443bd5faec69d9f312b1574e8","f83af14a2a8131b14d7aee6274c740334e0363d3"],"f83af14a2a8131b14d7aee6274c740334e0363d3":["e212ce9e66e9e69443bd5faec69d9f312b1574e8"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e212ce9e66e9e69443bd5faec69d9f312b1574e8"],"459280d4c73660ea582f38afce7968563068fe49":["fd9cc9d77712aba3662f24632df7539ab75e3667"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"3cc749c053615f5871f3b95715fe292f34e70a53":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["3cc749c053615f5871f3b95715fe292f34e70a53"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"2553b00f699380c64959ccb27991289aae87be2e":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","fd9cc9d77712aba3662f24632df7539ab75e3667"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["f83af14a2a8131b14d7aee6274c740334e0363d3","fd9cc9d77712aba3662f24632df7539ab75e3667"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["872cff1d3a554e0cd64014cd97f88d3002b0f491","59bfb89446d5591617d90031d670a157aba2f2f0"],"e212ce9e66e9e69443bd5faec69d9f312b1574e8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":["3cc749c053615f5871f3b95715fe292f34e70a53","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["f1bdbf92da222965b46c0a942c3857ba56e5c638","f83af14a2a8131b14d7aee6274c740334e0363d3"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["459280d4c73660ea582f38afce7968563068fe49"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["f83af14a2a8131b14d7aee6274c740334e0363d3"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e212ce9e66e9e69443bd5faec69d9f312b1574e8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"59bfb89446d5591617d90031d670a157aba2f2f0":["872cff1d3a554e0cd64014cd97f88d3002b0f491"]},"commit2Childs":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["2553b00f699380c64959ccb27991289aae87be2e"],"f83af14a2a8131b14d7aee6274c740334e0363d3":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","d083e83f225b11e5fdd900e83d26ddb385b6955c","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","fd9cc9d77712aba3662f24632df7539ab75e3667"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"459280d4c73660ea582f38afce7968563068fe49":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cc749c053615f5871f3b95715fe292f34e70a53":["872cff1d3a554e0cd64014cd97f88d3002b0f491","b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["3cc749c053615f5871f3b95715fe292f34e70a53"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["5cab9a86bd67202d20b6adc463008c8e982b070a","b65b350ca9588f9fc76ce7d6804160d06c45ff42","59bfb89446d5591617d90031d670a157aba2f2f0"],"2553b00f699380c64959ccb27991289aae87be2e":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"e212ce9e66e9e69443bd5faec69d9f312b1574e8":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","f83af14a2a8131b14d7aee6274c740334e0363d3","f1bdbf92da222965b46c0a942c3857ba56e5c638","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f1bdbf92da222965b46c0a942c3857ba56e5c638","e212ce9e66e9e69443bd5faec69d9f312b1574e8","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["459280d4c73660ea582f38afce7968563068fe49","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"59bfb89446d5591617d90031d670a157aba2f2f0":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","b65b350ca9588f9fc76ce7d6804160d06c45ff42","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}