{"path":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,boolean).mjava","commits":[{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,CodecProvider,boolean).mjava","sourceNew":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = writer.getConfig().getReaderTermsIndexDivisor();\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, CodecProvider codecs, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = writer.getConfig().getReaderTermsIndexDivisor();\n    if (codecs == null) {\n      this.codecs = CodecProvider.getDefault();\n    } else {\n      this.codecs = codecs;\n    }\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b8414cdacb05e1277df96a30710f570f4251d9a","date":1323040348,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,boolean).mjava","sourceNew":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = writer.getConfig().getReaderTermsIndexDivisor();\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = writer.getConfig().getReaderTermsIndexDivisor();\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,boolean).mjava","sourceNew":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = writer.getConfig().getReaderTermsIndexDivisor();\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = writer.getConfig().getReaderTermsIndexDivisor();\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,boolean).mjava","sourceNew":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = writer.getConfig().getReaderTermsIndexDivisor();\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.readOnly = true;\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = writer.getConfig().getReaderTermsIndexDivisor();\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6e2df1cc3e8621670ff46d098e43b7dd3f66eaf4","date":1323543613,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#open(IndexWriter,SegmentInfos,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,boolean).mjava","sourceNew":"  // Used by near real-time search\n  static DirectoryReader open(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes) throws IOException {\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    final SegmentInfos segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = writer.getReaderFinishedListeners();\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n    return new DirectoryReader(readers.toArray(new SegmentReader[readers.size()]),\n      dir, writer, segmentInfos, writer.getConfig().getReaderTermsIndexDivisor(),\n      applyAllDeletes, writer.getReaderFinishedListeners());\n  }\n\n","sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = writer.getConfig().getReaderTermsIndexDivisor();\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","date":1323720782,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DirectoryReader#open(IndexWriter,SegmentInfos,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DirectoryReader#DirectoryReader(IndexWriter,SegmentInfos,boolean).mjava","sourceNew":"  // Used by near real-time search\n  static DirectoryReader open(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes) throws IOException {\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    final SegmentInfos segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      IOException prior = null;\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = writer.getReaderFinishedListeners();\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } catch(IOException ex) {\n        prior = ex;\n      } finally {\n        if (!success)\n          IOUtils.closeWhileHandlingException(prior, readers);\n      }\n    }\n    return new DirectoryReader(readers.toArray(new SegmentReader[readers.size()]),\n      dir, writer, segmentInfos, writer.getConfig().getReaderTermsIndexDivisor(),\n      applyAllDeletes, writer.getReaderFinishedListeners());\n  }\n\n","sourceOld":"  // Used by near real-time search\n  DirectoryReader(IndexWriter writer, SegmentInfos infos, boolean applyAllDeletes) throws IOException {\n    this.directory = writer.getDirectory();\n    this.applyAllDeletes = applyAllDeletes;       // saved for reopen\n\n    this.termInfosIndexDivisor = writer.getConfig().getReaderTermsIndexDivisor();\n    readerFinishedListeners = writer.getReaderFinishedListeners();\n\n    // IndexWriter synchronizes externally before calling\n    // us, which ensures infos will not change; so there's\n    // no need to process segments in reverse order\n    final int numSegments = infos.size();\n\n    List<SegmentReader> readers = new ArrayList<SegmentReader>();\n    final Directory dir = writer.getDirectory();\n\n    segmentInfos = (SegmentInfos) infos.clone();\n    int infosUpto = 0;\n    for (int i=0;i<numSegments;i++) {\n      boolean success = false;\n      try {\n        final SegmentInfo info = infos.info(i);\n        assert info.dir == dir;\n        final SegmentReader reader = writer.readerPool.getReadOnlyClone(info, IOContext.READ);\n        if (reader.numDocs() > 0 || writer.getKeepFullyDeletedSegments()) {\n          reader.readerFinishedListeners = readerFinishedListeners;\n          readers.add(reader);\n          infosUpto++;\n        } else {\n          reader.close();\n          segmentInfos.remove(infosUpto);\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // Close all readers we had opened:\n          for(SegmentReader reader : readers) {\n            try {\n              reader.close();\n            } catch (Throwable ignore) {\n              // keep going - we want to clean up as much as possible\n            }\n          }\n        }\n      }\n    }\n\n    this.writer = writer;\n\n    initialize(readers.toArray(new SegmentReader[readers.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7b91922b55d15444d554721b352861d028eb8278":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4b8414cdacb05e1277df96a30710f570f4251d9a":["7b91922b55d15444d554721b352861d028eb8278"],"6e2df1cc3e8621670ff46d098e43b7dd3f66eaf4":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["7b91922b55d15444d554721b352861d028eb8278","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","6e2df1cc3e8621670ff46d098e43b7dd3f66eaf4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["7b91922b55d15444d554721b352861d028eb8278","4b8414cdacb05e1277df96a30710f570f4251d9a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6e2df1cc3e8621670ff46d098e43b7dd3f66eaf4"]},"commit2Childs":{"7b91922b55d15444d554721b352861d028eb8278":["4b8414cdacb05e1277df96a30710f570f4251d9a","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"4b8414cdacb05e1277df96a30710f570f4251d9a":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"6e2df1cc3e8621670ff46d098e43b7dd3f66eaf4":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7b91922b55d15444d554721b352861d028eb8278"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["6e2df1cc3e8621670ff46d098e43b7dd3f66eaf4","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}