{"path":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doGroupByWithAggregates(SQLVisitor,int,String,String).mjava","commits":[{"id":"8da9a71da64ce12a97dcfcdd912893aeb1fa2981","date":1437510515,"type":1,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doGroupByWithAggregates(SQLVisitor,int,String,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doGroupBy(SQLVisitor,Map[String,TableSpec],int,String,String).mjava","sourceNew":"  private static TupleStream doGroupByWithAggregates(SQLVisitor sqlVisitor,\n                                                     int numWorkers,\n                                                     String workerCollection,\n                                                     String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.groupBy, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n    if(metrics.length == 0) {\n      throw new IOException(\"Group by queries must include atleast one aggregate function.\");\n    }\n\n    String fl = fields(fieldSet);\n    String sortDirection = getSortDirection(sqlVisitor.sorts);\n    String sort = bucketSort(buckets, sortDirection);\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Group By Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new RollupStream(cstream, buckets, metrics);\n\n    if(numWorkers > 1) {\n      // Do the rollups in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      StreamComparator comp = bucketSortComp(buckets, sortDirection);\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"rollup\", RollupStream.class)\n          .withFunctionName(\"sum\", SumMetric.class)\n          .withFunctionName(\"min\", MinMetric.class)\n          .withFunctionName(\"max\", MaxMetric.class)\n          .withFunctionName(\"avg\", MeanMetric.class)\n          .withFunctionName(\"count\", CountMetric.class);\n\n      parallelStream.setStreamFactory(factory);\n      parallelStream.setObjectSerialize(false);\n      tupleStream = parallelStream;\n    }\n\n    //TODO: This should be done on the workers, but it won't serialize because it relies on Presto classes.\n    // Once we make this a Expressionable the problem will be solved.\n\n    if(sqlVisitor.havingExpression != null) {\n      tupleStream = new HavingStream(tupleStream, sqlVisitor.havingExpression);\n    }\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      if(!sortsEqual(buckets, sortDirection, sqlVisitor.sorts)) {\n        int limit = sqlVisitor.limit == -1 ? 100 : sqlVisitor.limit;\n        StreamComparator comp = getComp(sqlVisitor.sorts);\n        //Rank the Tuples\n        //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n        //Providing a true Top or Bottom.\n        tupleStream = new RankStream(tupleStream, limit, comp);\n      } else {\n        // Sort is the same as the same as the underlying stream\n        // Only need to limit the result, not Rank the result\n        if(sqlVisitor.limit > -1) {\n          tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n        }\n      }\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private static TupleStream doGroupBy(SQLVisitor sqlVisitor,\n                                       Map<String, TableSpec> tableMap,\n                                       int numWorkers,\n                                       String workerCollection,\n                                       String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.groupBy, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n\n    String fl = fields(fieldSet);\n    String sortDirection = getSortDirection(sqlVisitor.sorts);\n    String sort = bucketSort(buckets, sortDirection);\n\n    TableSpec tableSpec = tableMap.get(sqlVisitor.table);\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Group By Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new RollupStream(cstream, buckets, metrics);\n\n    if(numWorkers > 1) {\n      // Do the rollups in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      StreamComparator comp = bucketSortComp(buckets, sortDirection);\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"rollup\", RollupStream.class)\n          .withFunctionName(\"sum\", SumMetric.class)\n          .withFunctionName(\"min\", MinMetric.class)\n          .withFunctionName(\"max\", MaxMetric.class)\n          .withFunctionName(\"avg\", MeanMetric.class)\n          .withFunctionName(\"count\", CountMetric.class);\n\n      parallelStream.setStreamFactory(factory);\n      parallelStream.setObjectSerialize(false);\n      tupleStream = parallelStream;\n    }\n\n    //TODO: This should be done on the workers, but it won't serialize because it relies on Presto classes.\n    // Once we make this a Expressionable the problem will be solved.\n\n    if(sqlVisitor.havingExpression != null) {\n      tupleStream = new HavingStream(tupleStream, sqlVisitor.havingExpression);\n    }\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      if(!sortsEqual(buckets, sortDirection, sqlVisitor.sorts)) {\n        int limit = sqlVisitor.limit == -1 ? 100 : sqlVisitor.limit;\n        StreamComparator comp = getComp(sqlVisitor.sorts);\n        //Rank the Tuples\n        //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n        //Providing a true Top or Bottom.\n        tupleStream = new RankStream(tupleStream, limit, comp);\n      } else {\n        // Sort is the same as the same as the underlying stream\n        // Only need to limit the result, not Rank the result\n        if(sqlVisitor.limit > -1) {\n          tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n        }\n      }\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c3cf1396610fbacfdf69deb27bc5d3f36b5fbd43","date":1449690748,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doGroupByWithAggregates(SQLVisitor,int,String,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doGroupByWithAggregates(SQLVisitor,int,String,String).mjava","sourceNew":"  private static TupleStream doGroupByWithAggregates(SQLVisitor sqlVisitor,\n                                                     int numWorkers,\n                                                     String workerCollection,\n                                                     String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.groupBy, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n    if(metrics.length == 0) {\n      throw new IOException(\"Group by queries must include atleast one aggregate function.\");\n    }\n\n    String fl = fields(fieldSet);\n    String sortDirection = getSortDirection(sqlVisitor.sorts);\n    String sort = bucketSort(buckets, sortDirection);\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Group By Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new RollupStream(cstream, buckets, metrics);\n\n    if(numWorkers > 1) {\n      // Do the rollups in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      StreamComparator comp = bucketSortComp(buckets, sortDirection);\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"rollup\", RollupStream.class)\n          .withFunctionName(\"sum\", SumMetric.class)\n          .withFunctionName(\"min\", MinMetric.class)\n          .withFunctionName(\"max\", MaxMetric.class)\n          .withFunctionName(\"avg\", MeanMetric.class)\n          .withFunctionName(\"count\", CountMetric.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    //TODO: This should be done on the workers, but it won't serialize because it relies on Presto classes.\n    // Once we make this a Expressionable the problem will be solved.\n\n    if(sqlVisitor.havingExpression != null) {\n      tupleStream = new HavingStream(tupleStream, sqlVisitor.havingExpression);\n    }\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      if(!sortsEqual(buckets, sortDirection, sqlVisitor.sorts)) {\n        int limit = sqlVisitor.limit == -1 ? 100 : sqlVisitor.limit;\n        StreamComparator comp = getComp(sqlVisitor.sorts);\n        //Rank the Tuples\n        //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n        //Providing a true Top or Bottom.\n        tupleStream = new RankStream(tupleStream, limit, comp);\n      } else {\n        // Sort is the same as the same as the underlying stream\n        // Only need to limit the result, not Rank the result\n        if(sqlVisitor.limit > -1) {\n          tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n        }\n      }\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private static TupleStream doGroupByWithAggregates(SQLVisitor sqlVisitor,\n                                                     int numWorkers,\n                                                     String workerCollection,\n                                                     String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.groupBy, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n    if(metrics.length == 0) {\n      throw new IOException(\"Group by queries must include atleast one aggregate function.\");\n    }\n\n    String fl = fields(fieldSet);\n    String sortDirection = getSortDirection(sqlVisitor.sorts);\n    String sort = bucketSort(buckets, sortDirection);\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Group By Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new RollupStream(cstream, buckets, metrics);\n\n    if(numWorkers > 1) {\n      // Do the rollups in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      StreamComparator comp = bucketSortComp(buckets, sortDirection);\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"rollup\", RollupStream.class)\n          .withFunctionName(\"sum\", SumMetric.class)\n          .withFunctionName(\"min\", MinMetric.class)\n          .withFunctionName(\"max\", MaxMetric.class)\n          .withFunctionName(\"avg\", MeanMetric.class)\n          .withFunctionName(\"count\", CountMetric.class);\n\n      parallelStream.setStreamFactory(factory);\n      parallelStream.setObjectSerialize(false);\n      tupleStream = parallelStream;\n    }\n\n    //TODO: This should be done on the workers, but it won't serialize because it relies on Presto classes.\n    // Once we make this a Expressionable the problem will be solved.\n\n    if(sqlVisitor.havingExpression != null) {\n      tupleStream = new HavingStream(tupleStream, sqlVisitor.havingExpression);\n    }\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      if(!sortsEqual(buckets, sortDirection, sqlVisitor.sorts)) {\n        int limit = sqlVisitor.limit == -1 ? 100 : sqlVisitor.limit;\n        StreamComparator comp = getComp(sqlVisitor.sorts);\n        //Rank the Tuples\n        //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n        //Providing a true Top or Bottom.\n        tupleStream = new RankStream(tupleStream, limit, comp);\n      } else {\n        // Sort is the same as the same as the underlying stream\n        // Only need to limit the result, not Rank the result\n        if(sqlVisitor.limit > -1) {\n          tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n        }\n      }\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7","date":1452631653,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doGroupByWithAggregates(SQLVisitor,int,String,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doGroupByWithAggregates(SQLVisitor,int,String,String).mjava","sourceNew":"  private static TupleStream doGroupByWithAggregates(SQLVisitor sqlVisitor,\n                                                     int numWorkers,\n                                                     String workerCollection,\n                                                     String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.groupBy, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n    if(metrics.length == 0) {\n      throw new IOException(\"Group by queries must include atleast one aggregate function.\");\n    }\n\n    String fl = fields(fieldSet);\n    String sortDirection = getSortDirection(sqlVisitor.sorts);\n    String sort = bucketSort(buckets, sortDirection);\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Group By Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new RollupStream(cstream, buckets, metrics);\n\n    if(numWorkers > 1) {\n      // Do the rollups in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      StreamComparator comp = bucketSortComp(buckets, sortDirection);\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"rollup\", RollupStream.class)\n          .withFunctionName(\"sum\", SumMetric.class)\n          .withFunctionName(\"min\", MinMetric.class)\n          .withFunctionName(\"max\", MaxMetric.class)\n          .withFunctionName(\"avg\", MeanMetric.class)\n          .withFunctionName(\"count\", CountMetric.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    //TODO: This should be done on the workers, but it won't serialize because it relies on Presto classes.\n    // Once we make this a Expressionable the problem will be solved.\n\n    if(sqlVisitor.havingExpression != null) {\n      tupleStream = new HavingStream(tupleStream, sqlVisitor.havingExpression, sqlVisitor.reverseColumnAliases );\n    }\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      if(!sortsEqual(buckets, sortDirection, sqlVisitor.sorts, sqlVisitor.reverseColumnAliases)) {\n        int limit = sqlVisitor.limit == -1 ? 100 : sqlVisitor.limit;\n        StreamComparator comp = getComp(sqlVisitor.sorts, sqlVisitor.reverseColumnAliases);\n        //Rank the Tuples\n        //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n        //Providing a true Top or Bottom.\n        tupleStream = new RankStream(tupleStream, limit, comp);\n      } else {\n        // Sort is the same as the same as the underlying stream\n        // Only need to limit the result, not Rank the result\n        if(sqlVisitor.limit > -1) {\n          tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n        }\n      }\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private static TupleStream doGroupByWithAggregates(SQLVisitor sqlVisitor,\n                                                     int numWorkers,\n                                                     String workerCollection,\n                                                     String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.groupBy, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n    if(metrics.length == 0) {\n      throw new IOException(\"Group by queries must include atleast one aggregate function.\");\n    }\n\n    String fl = fields(fieldSet);\n    String sortDirection = getSortDirection(sqlVisitor.sorts);\n    String sort = bucketSort(buckets, sortDirection);\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Group By Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new RollupStream(cstream, buckets, metrics);\n\n    if(numWorkers > 1) {\n      // Do the rollups in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      StreamComparator comp = bucketSortComp(buckets, sortDirection);\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"rollup\", RollupStream.class)\n          .withFunctionName(\"sum\", SumMetric.class)\n          .withFunctionName(\"min\", MinMetric.class)\n          .withFunctionName(\"max\", MaxMetric.class)\n          .withFunctionName(\"avg\", MeanMetric.class)\n          .withFunctionName(\"count\", CountMetric.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    //TODO: This should be done on the workers, but it won't serialize because it relies on Presto classes.\n    // Once we make this a Expressionable the problem will be solved.\n\n    if(sqlVisitor.havingExpression != null) {\n      tupleStream = new HavingStream(tupleStream, sqlVisitor.havingExpression);\n    }\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      if(!sortsEqual(buckets, sortDirection, sqlVisitor.sorts)) {\n        int limit = sqlVisitor.limit == -1 ? 100 : sqlVisitor.limit;\n        StreamComparator comp = getComp(sqlVisitor.sorts);\n        //Rank the Tuples\n        //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n        //Providing a true Top or Bottom.\n        tupleStream = new RankStream(tupleStream, limit, comp);\n      } else {\n        // Sort is the same as the same as the underlying stream\n        // Only need to limit the result, not Rank the result\n        if(sqlVisitor.limit > -1) {\n          tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n        }\n      }\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d984627825732e682759c22df7a3b171a80f3812","date":1461857653,"type":4,"author":"Kevin Risden","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doGroupByWithAggregates(SQLVisitor,int,String,String).mjava","sourceNew":null,"sourceOld":"  private static TupleStream doGroupByWithAggregates(SQLVisitor sqlVisitor,\n                                                     int numWorkers,\n                                                     String workerCollection,\n                                                     String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.groupBy, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n    if(metrics.length == 0) {\n      throw new IOException(\"Group by queries must include atleast one aggregate function.\");\n    }\n\n    String fl = fields(fieldSet);\n    String sortDirection = getSortDirection(sqlVisitor.sorts);\n    String sort = bucketSort(buckets, sortDirection);\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Group By Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new RollupStream(cstream, buckets, metrics);\n\n    if(numWorkers > 1) {\n      // Do the rollups in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      StreamComparator comp = bucketSortComp(buckets, sortDirection);\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"rollup\", RollupStream.class)\n          .withFunctionName(\"sum\", SumMetric.class)\n          .withFunctionName(\"min\", MinMetric.class)\n          .withFunctionName(\"max\", MaxMetric.class)\n          .withFunctionName(\"avg\", MeanMetric.class)\n          .withFunctionName(\"count\", CountMetric.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    //TODO: This should be done on the workers, but it won't serialize because it relies on Presto classes.\n    // Once we make this a Expressionable the problem will be solved.\n\n    if(sqlVisitor.havingExpression != null) {\n      tupleStream = new HavingStream(tupleStream, sqlVisitor.havingExpression, sqlVisitor.reverseColumnAliases );\n    }\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      if(!sortsEqual(buckets, sortDirection, sqlVisitor.sorts, sqlVisitor.reverseColumnAliases)) {\n        int limit = sqlVisitor.limit == -1 ? 100 : sqlVisitor.limit;\n        StreamComparator comp = getComp(sqlVisitor.sorts, sqlVisitor.reverseColumnAliases);\n        //Rank the Tuples\n        //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n        //Providing a true Top or Bottom.\n        tupleStream = new RankStream(tupleStream, limit, comp);\n      } else {\n        // Sort is the same as the same as the underlying stream\n        // Only need to limit the result, not Rank the result\n        if(sqlVisitor.limit > -1) {\n          tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n        }\n      }\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"826d15444ddf61716dc768c229cd54b2c2ccce1c","date":1462822652,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doGroupByWithAggregates(SQLVisitor,int,String,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doGroupByWithAggregates(SQLVisitor,int,String,String).mjava","sourceNew":"  private static TupleStream doGroupByWithAggregates(SQLVisitor sqlVisitor,\n                                                     int numWorkers,\n                                                     String workerCollection,\n                                                     String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.groupBy, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n    if(metrics.length == 0) {\n      throw new IOException(\"Group by queries must include atleast one aggregate function.\");\n    }\n\n    String fl = fields(fieldSet);\n    String sortDirection = getSortDirection(sqlVisitor.sorts);\n    String sort = bucketSort(buckets, sortDirection);\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Group By Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new RollupStream(cstream, buckets, metrics);\n\n    if(numWorkers > 1) {\n      // Do the rollups in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      StreamComparator comp = bucketSortComp(buckets, sortDirection);\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"rollup\", RollupStream.class)\n          .withFunctionName(\"sum\", SumMetric.class)\n          .withFunctionName(\"min\", MinMetric.class)\n          .withFunctionName(\"max\", MaxMetric.class)\n          .withFunctionName(\"avg\", MeanMetric.class)\n          .withFunctionName(\"count\", CountMetric.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    //TODO: This should be done on the workers, but it won't serialize because it relies on Presto classes.\n    // Once we make this a Expressionable the problem will be solved.\n\n    if(sqlVisitor.havingExpression != null) {\n      tupleStream = new HavingStream(tupleStream, sqlVisitor.havingExpression, sqlVisitor.reverseColumnAliases );\n    }\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      if(!sortsEqual(buckets, sortDirection, sqlVisitor.sorts, sqlVisitor.reverseColumnAliases)) {\n        int limit = sqlVisitor.limit == -1 ? 100 : sqlVisitor.limit;\n        StreamComparator comp = getComp(sqlVisitor.sorts, sqlVisitor.reverseColumnAliases);\n        //Rank the Tuples\n        //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n        //Providing a true Top or Bottom.\n        tupleStream = new RankStream(tupleStream, limit, comp);\n      } else {\n        // Sort is the same as the same as the underlying stream\n        // Only need to limit the result, not Rank the result\n        if(sqlVisitor.limit > -1) {\n          tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n        }\n      }\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private static TupleStream doGroupByWithAggregates(SQLVisitor sqlVisitor,\n                                                     int numWorkers,\n                                                     String workerCollection,\n                                                     String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.groupBy, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n    if(metrics.length == 0) {\n      throw new IOException(\"Group by queries must include atleast one aggregate function.\");\n    }\n\n    String fl = fields(fieldSet);\n    String sortDirection = getSortDirection(sqlVisitor.sorts);\n    String sort = bucketSort(buckets, sortDirection);\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Group By Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new RollupStream(cstream, buckets, metrics);\n\n    if(numWorkers > 1) {\n      // Do the rollups in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      StreamComparator comp = bucketSortComp(buckets, sortDirection);\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"rollup\", RollupStream.class)\n          .withFunctionName(\"sum\", SumMetric.class)\n          .withFunctionName(\"min\", MinMetric.class)\n          .withFunctionName(\"max\", MaxMetric.class)\n          .withFunctionName(\"avg\", MeanMetric.class)\n          .withFunctionName(\"count\", CountMetric.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    //TODO: This should be done on the workers, but it won't serialize because it relies on Presto classes.\n    // Once we make this a Expressionable the problem will be solved.\n\n    if(sqlVisitor.havingExpression != null) {\n      tupleStream = new HavingStream(tupleStream, sqlVisitor.havingExpression, sqlVisitor.reverseColumnAliases );\n    }\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      if(!sortsEqual(buckets, sortDirection, sqlVisitor.sorts, sqlVisitor.reverseColumnAliases)) {\n        int limit = sqlVisitor.limit == -1 ? 100 : sqlVisitor.limit;\n        StreamComparator comp = getComp(sqlVisitor.sorts, sqlVisitor.reverseColumnAliases);\n        //Rank the Tuples\n        //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n        //Providing a true Top or Bottom.\n        tupleStream = new RankStream(tupleStream, limit, comp);\n      } else {\n        // Sort is the same as the same as the underlying stream\n        // Only need to limit the result, not Rank the result\n        if(sqlVisitor.limit > -1) {\n          tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n        }\n      }\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e66a459d38c1c4a2f97128433dab546f683a9fed","date":1462873476,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doGroupByWithAggregates(SQLVisitor,int,String,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doGroupByWithAggregates(SQLVisitor,int,String,String).mjava","sourceNew":"  private static TupleStream doGroupByWithAggregates(SQLVisitor sqlVisitor,\n                                                     int numWorkers,\n                                                     String workerCollection,\n                                                     String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.groupBy, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n    if(metrics.length == 0) {\n      throw new IOException(\"Group by queries must include atleast one aggregate function.\");\n    }\n\n    String fl = fields(fieldSet);\n    String sortDirection = getSortDirection(sqlVisitor.sorts);\n    String sort = bucketSort(buckets, sortDirection);\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Group By Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new RollupStream(cstream, buckets, metrics);\n\n    if(numWorkers > 1) {\n      // Do the rollups in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      StreamComparator comp = bucketSortComp(buckets, sortDirection);\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"rollup\", RollupStream.class)\n          .withFunctionName(\"sum\", SumMetric.class)\n          .withFunctionName(\"min\", MinMetric.class)\n          .withFunctionName(\"max\", MaxMetric.class)\n          .withFunctionName(\"avg\", MeanMetric.class)\n          .withFunctionName(\"count\", CountMetric.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    //TODO: This should be done on the workers, but it won't serialize because it relies on Presto classes.\n    // Once we make this a Expressionable the problem will be solved.\n\n    if(sqlVisitor.havingExpression != null) {\n      tupleStream = new HavingStream(tupleStream, sqlVisitor.havingExpression, sqlVisitor.reverseColumnAliases );\n    }\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      if(!sortsEqual(buckets, sortDirection, sqlVisitor.sorts, sqlVisitor.reverseColumnAliases)) {\n        int limit = sqlVisitor.limit == -1 ? 100 : sqlVisitor.limit;\n        StreamComparator comp = getComp(sqlVisitor.sorts, sqlVisitor.reverseColumnAliases);\n        //Rank the Tuples\n        //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n        //Providing a true Top or Bottom.\n        tupleStream = new RankStream(tupleStream, limit, comp);\n      } else {\n        // Sort is the same as the same as the underlying stream\n        // Only need to limit the result, not Rank the result\n        if(sqlVisitor.limit > -1) {\n          tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n        }\n      }\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private static TupleStream doGroupByWithAggregates(SQLVisitor sqlVisitor,\n                                                     int numWorkers,\n                                                     String workerCollection,\n                                                     String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.groupBy, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n    if(metrics.length == 0) {\n      throw new IOException(\"Group by queries must include atleast one aggregate function.\");\n    }\n\n    String fl = fields(fieldSet);\n    String sortDirection = getSortDirection(sqlVisitor.sorts);\n    String sort = bucketSort(buckets, sortDirection);\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Group By Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new RollupStream(cstream, buckets, metrics);\n\n    if(numWorkers > 1) {\n      // Do the rollups in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      StreamComparator comp = bucketSortComp(buckets, sortDirection);\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"rollup\", RollupStream.class)\n          .withFunctionName(\"sum\", SumMetric.class)\n          .withFunctionName(\"min\", MinMetric.class)\n          .withFunctionName(\"max\", MaxMetric.class)\n          .withFunctionName(\"avg\", MeanMetric.class)\n          .withFunctionName(\"count\", CountMetric.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    //TODO: This should be done on the workers, but it won't serialize because it relies on Presto classes.\n    // Once we make this a Expressionable the problem will be solved.\n\n    if(sqlVisitor.havingExpression != null) {\n      tupleStream = new HavingStream(tupleStream, sqlVisitor.havingExpression, sqlVisitor.reverseColumnAliases );\n    }\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      if(!sortsEqual(buckets, sortDirection, sqlVisitor.sorts, sqlVisitor.reverseColumnAliases)) {\n        int limit = sqlVisitor.limit == -1 ? 100 : sqlVisitor.limit;\n        StreamComparator comp = getComp(sqlVisitor.sorts, sqlVisitor.reverseColumnAliases);\n        //Rank the Tuples\n        //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n        //Providing a true Top or Bottom.\n        tupleStream = new RankStream(tupleStream, limit, comp);\n      } else {\n        // Sort is the same as the same as the underlying stream\n        // Only need to limit the result, not Rank the result\n        if(sqlVisitor.limit > -1) {\n          tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n        }\n      }\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doGroupByWithAggregates(SQLVisitor,int,String,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doGroupByWithAggregates(SQLVisitor,int,String,String).mjava","sourceNew":"  private static TupleStream doGroupByWithAggregates(SQLVisitor sqlVisitor,\n                                                     int numWorkers,\n                                                     String workerCollection,\n                                                     String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.groupBy, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n    if(metrics.length == 0) {\n      throw new IOException(\"Group by queries must include atleast one aggregate function.\");\n    }\n\n    String fl = fields(fieldSet);\n    String sortDirection = getSortDirection(sqlVisitor.sorts);\n    String sort = bucketSort(buckets, sortDirection);\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Group By Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new RollupStream(cstream, buckets, metrics);\n\n    if(numWorkers > 1) {\n      // Do the rollups in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      StreamComparator comp = bucketSortComp(buckets, sortDirection);\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"rollup\", RollupStream.class)\n          .withFunctionName(\"sum\", SumMetric.class)\n          .withFunctionName(\"min\", MinMetric.class)\n          .withFunctionName(\"max\", MaxMetric.class)\n          .withFunctionName(\"avg\", MeanMetric.class)\n          .withFunctionName(\"count\", CountMetric.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    //TODO: This should be done on the workers, but it won't serialize because it relies on Presto classes.\n    // Once we make this a Expressionable the problem will be solved.\n\n    if(sqlVisitor.havingExpression != null) {\n      tupleStream = new HavingStream(tupleStream, sqlVisitor.havingExpression, sqlVisitor.reverseColumnAliases );\n    }\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      if(!sortsEqual(buckets, sortDirection, sqlVisitor.sorts, sqlVisitor.reverseColumnAliases)) {\n        int limit = sqlVisitor.limit == -1 ? 100 : sqlVisitor.limit;\n        StreamComparator comp = getComp(sqlVisitor.sorts, sqlVisitor.reverseColumnAliases);\n        //Rank the Tuples\n        //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n        //Providing a true Top or Bottom.\n        tupleStream = new RankStream(tupleStream, limit, comp);\n      } else {\n        // Sort is the same as the same as the underlying stream\n        // Only need to limit the result, not Rank the result\n        if(sqlVisitor.limit > -1) {\n          tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n        }\n      }\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","sourceOld":"  private static TupleStream doGroupByWithAggregates(SQLVisitor sqlVisitor,\n                                                     int numWorkers,\n                                                     String workerCollection,\n                                                     String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.groupBy, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n    if(metrics.length == 0) {\n      throw new IOException(\"Group by queries must include atleast one aggregate function.\");\n    }\n\n    String fl = fields(fieldSet);\n    String sortDirection = getSortDirection(sqlVisitor.sorts);\n    String sort = bucketSort(buckets, sortDirection);\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    Map<String, String> params = new HashMap();\n\n    params.put(CommonParams.FL, fl);\n    params.put(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Group By Queries because it requires exporting full result sets.\n    params.put(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.put(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.put(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new RollupStream(cstream, buckets, metrics);\n\n    if(numWorkers > 1) {\n      // Do the rollups in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      StreamComparator comp = bucketSortComp(buckets, sortDirection);\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"rollup\", RollupStream.class)\n          .withFunctionName(\"sum\", SumMetric.class)\n          .withFunctionName(\"min\", MinMetric.class)\n          .withFunctionName(\"max\", MaxMetric.class)\n          .withFunctionName(\"avg\", MeanMetric.class)\n          .withFunctionName(\"count\", CountMetric.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    //TODO: This should be done on the workers, but it won't serialize because it relies on Presto classes.\n    // Once we make this a Expressionable the problem will be solved.\n\n    if(sqlVisitor.havingExpression != null) {\n      tupleStream = new HavingStream(tupleStream, sqlVisitor.havingExpression, sqlVisitor.reverseColumnAliases );\n    }\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      if(!sortsEqual(buckets, sortDirection, sqlVisitor.sorts, sqlVisitor.reverseColumnAliases)) {\n        int limit = sqlVisitor.limit == -1 ? 100 : sqlVisitor.limit;\n        StreamComparator comp = getComp(sqlVisitor.sorts, sqlVisitor.reverseColumnAliases);\n        //Rank the Tuples\n        //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n        //Providing a true Top or Bottom.\n        tupleStream = new RankStream(tupleStream, limit, comp);\n      } else {\n        // Sort is the same as the same as the underlying stream\n        // Only need to limit the result, not Rank the result\n        if(sqlVisitor.limit > -1) {\n          tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n        }\n      }\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"116fdd6b9e04e18a6547a5650bc0afd3fda020aa","date":1487184909,"type":4,"author":"Joel Bernstein","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/handler/SQLHandler#doGroupByWithAggregates(SQLVisitor,int,String,String).mjava","sourceNew":null,"sourceOld":"  private static TupleStream doGroupByWithAggregates(SQLVisitor sqlVisitor,\n                                                     int numWorkers,\n                                                     String workerCollection,\n                                                     String workerZkHost) throws IOException {\n\n    Set<String> fieldSet = new HashSet();\n    Bucket[] buckets = getBuckets(sqlVisitor.groupBy, fieldSet);\n    Metric[] metrics = getMetrics(sqlVisitor.fields, fieldSet);\n    if(metrics.length == 0) {\n      throw new IOException(\"Group by queries must include atleast one aggregate function.\");\n    }\n\n    String fl = fields(fieldSet);\n    String sortDirection = getSortDirection(sqlVisitor.sorts);\n    String sort = bucketSort(buckets, sortDirection);\n\n    TableSpec tableSpec = new TableSpec(sqlVisitor.table, defaultZkhost);\n\n    String zkHost = tableSpec.zkHost;\n    String collection = tableSpec.collection;\n    ModifiableSolrParams params = new ModifiableSolrParams();\n\n    params.set(CommonParams.FL, fl);\n    params.set(CommonParams.Q, sqlVisitor.query);\n    //Always use the /export handler for Group By Queries because it requires exporting full result sets.\n    params.set(CommonParams.QT, \"/export\");\n\n    if(numWorkers > 1) {\n      params.set(\"partitionKeys\", getPartitionKeys(buckets));\n    }\n\n    params.set(\"sort\", sort);\n\n    TupleStream tupleStream = null;\n\n    CloudSolrStream cstream = new CloudSolrStream(zkHost, collection, params);\n    tupleStream = new RollupStream(cstream, buckets, metrics);\n\n    if(numWorkers > 1) {\n      // Do the rollups in parallel\n      // Maintain the sort of the Tuples coming from the workers.\n      StreamComparator comp = bucketSortComp(buckets, sortDirection);\n      ParallelStream parallelStream = new ParallelStream(workerZkHost, workerCollection, tupleStream, numWorkers, comp);\n\n      StreamFactory factory = new StreamFactory()\n          .withFunctionName(\"search\", CloudSolrStream.class)\n          .withFunctionName(\"parallel\", ParallelStream.class)\n          .withFunctionName(\"rollup\", RollupStream.class)\n          .withFunctionName(\"sum\", SumMetric.class)\n          .withFunctionName(\"min\", MinMetric.class)\n          .withFunctionName(\"max\", MaxMetric.class)\n          .withFunctionName(\"avg\", MeanMetric.class)\n          .withFunctionName(\"count\", CountMetric.class);\n\n      parallelStream.setStreamFactory(factory);\n      tupleStream = parallelStream;\n    }\n\n    //TODO: This should be done on the workers, but it won't serialize because it relies on Presto classes.\n    // Once we make this a Expressionable the problem will be solved.\n\n    if(sqlVisitor.havingExpression != null) {\n      tupleStream = new HavingStream(tupleStream, sqlVisitor.havingExpression, sqlVisitor.reverseColumnAliases );\n    }\n\n    if(sqlVisitor.sorts != null && sqlVisitor.sorts.size() > 0) {\n      if(!sortsEqual(buckets, sortDirection, sqlVisitor.sorts, sqlVisitor.reverseColumnAliases)) {\n        int limit = sqlVisitor.limit == -1 ? 100 : sqlVisitor.limit;\n        StreamComparator comp = getComp(sqlVisitor.sorts, sqlVisitor.reverseColumnAliases);\n        //Rank the Tuples\n        //If parallel stream is used ALL the Rolled up tuples from the workers will be ranked\n        //Providing a true Top or Bottom.\n        tupleStream = new RankStream(tupleStream, limit, comp);\n      } else {\n        // Sort is the same as the same as the underlying stream\n        // Only need to limit the result, not Rank the result\n        if(sqlVisitor.limit > -1) {\n          tupleStream = new LimitStream(tupleStream, sqlVisitor.limit);\n        }\n      }\n    }\n\n    if(sqlVisitor.hasColumnAliases) {\n      tupleStream = new SelectStream(tupleStream, sqlVisitor.columnAliases);\n    }\n\n    return tupleStream;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"116fdd6b9e04e18a6547a5650bc0afd3fda020aa":["d470c8182e92b264680e34081b75e70a9f2b3c89","d984627825732e682759c22df7a3b171a80f3812"],"d984627825732e682759c22df7a3b171a80f3812":["5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7"],"5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7":["c3cf1396610fbacfdf69deb27bc5d3f36b5fbd43"],"c3cf1396610fbacfdf69deb27bc5d3f36b5fbd43":["8da9a71da64ce12a97dcfcdd912893aeb1fa2981"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e66a459d38c1c4a2f97128433dab546f683a9fed":["5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7","826d15444ddf61716dc768c229cd54b2c2ccce1c"],"8da9a71da64ce12a97dcfcdd912893aeb1fa2981":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"826d15444ddf61716dc768c229cd54b2c2ccce1c":["5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["116fdd6b9e04e18a6547a5650bc0afd3fda020aa"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7","826d15444ddf61716dc768c229cd54b2c2ccce1c"]},"commit2Childs":{"116fdd6b9e04e18a6547a5650bc0afd3fda020aa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d984627825732e682759c22df7a3b171a80f3812":["116fdd6b9e04e18a6547a5650bc0afd3fda020aa"],"5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7":["d984627825732e682759c22df7a3b171a80f3812","e66a459d38c1c4a2f97128433dab546f683a9fed","826d15444ddf61716dc768c229cd54b2c2ccce1c","d470c8182e92b264680e34081b75e70a9f2b3c89"],"c3cf1396610fbacfdf69deb27bc5d3f36b5fbd43":["5f90f992f4e4fdedb0fe0cc2fe3925df71a5b9f7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8da9a71da64ce12a97dcfcdd912893aeb1fa2981"],"e66a459d38c1c4a2f97128433dab546f683a9fed":[],"8da9a71da64ce12a97dcfcdd912893aeb1fa2981":["c3cf1396610fbacfdf69deb27bc5d3f36b5fbd43"],"826d15444ddf61716dc768c229cd54b2c2ccce1c":["e66a459d38c1c4a2f97128433dab546f683a9fed","d470c8182e92b264680e34081b75e70a9f2b3c89"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["116fdd6b9e04e18a6547a5650bc0afd3fda020aa"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["e66a459d38c1c4a2f97128433dab546f683a9fed","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}