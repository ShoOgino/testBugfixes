{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","commits":[{"id":"f366ce28775e2b8ea4e06355009471328711666d","date":1360551293,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    throw new UnsupportedOperationException(); // nocommit\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f15adb143a3097f2342f07eb0929f6ce1877ad7e","date":1361027406,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex;\n    synchronized (ordIndexInstances) {\n      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);\n      if (ordIndexInstance == null) {\n        NumericEntry entry = ordIndexes.get(field.number);\n        IndexInput data = this.data.clone();\n        data.seek(entry.offset);\n        ordIndexInstance = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);\n      }\n      ordIndex = ordIndexInstance;\n    }\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    throw new UnsupportedOperationException(); // nocommit\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"56fca4cf418a84a71d0701bbb6fda4db84fa5796","date":1361031660,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex;\n    synchronized (ordIndexInstances) {\n      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);\n      if (ordIndexInstance == null) {\n        NumericEntry entry = ordIndexes.get(field.number);\n        IndexInput data = this.data.clone();\n        data.seek(entry.offset);\n        ordIndexInstance = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);\n        ordIndexInstances.put(field.number, ordIndexInstance);\n      }\n      ordIndex = ordIndexInstance;\n    }\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex;\n    synchronized (ordIndexInstances) {\n      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);\n      if (ordIndexInstance == null) {\n        NumericEntry entry = ordIndexes.get(field.number);\n        IndexInput data = this.data.clone();\n        data.seek(entry.offset);\n        ordIndexInstance = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);\n      }\n      ordIndex = ordIndexInstance;\n    }\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddbb72a33557d2b5bc22ee95daf3281c43560502","date":1361334582,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex;\n    synchronized (ordIndexInstances) {\n      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);\n      if (ordIndexInstance == null) {\n        NumericEntry entry = ordIndexes.get(field.number);\n        IndexInput data = this.data.clone();\n        data.seek(entry.offset);\n        ordIndexInstance = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);\n        ordIndexInstances.put(field.number, ordIndexInstance);\n      }\n      ordIndex = ordIndexInstance;\n    }\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0ad01348544f9eb6ee985c300245013a75addfc6","date":1376095061,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex;\n    synchronized (ordIndexInstances) {\n      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);\n      if (ordIndexInstance == null) {\n        NumericEntry entry = ordIndexes.get(field.number);\n        IndexInput data = this.data.clone();\n        data.seek(entry.offset);\n        ordIndexInstance = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);\n        ordIndexInstances.put(field.number, ordIndexInstance);\n      }\n      ordIndex = ordIndexInstance;\n    }\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex;\n    synchronized (ordIndexInstances) {\n      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);\n      if (ordIndexInstance == null) {\n        NumericEntry entry = ordIndexes.get(field.number);\n        IndexInput data = this.data.clone();\n        data.seek(entry.offset);\n        ordIndexInstance = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);\n        ordIndexInstances.put(field.number, ordIndexInstance);\n      }\n      ordIndex = ordIndexInstance;\n    }\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex;\n    synchronized (ordIndexInstances) {\n      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);\n      if (ordIndexInstance == null) {\n        NumericEntry entry = ordIndexes.get(field.number);\n        IndexInput data = this.data.clone();\n        data.seek(entry.offset);\n        ordIndexInstance = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);\n        ordIndexInstances.put(field.number, ordIndexInstance);\n      }\n      ordIndex = ordIndexInstance;\n    }\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex;\n    synchronized (ordIndexInstances) {\n      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);\n      if (ordIndexInstance == null) {\n        NumericEntry entry = ordIndexes.get(field.number);\n        IndexInput data = this.data.clone();\n        data.seek(entry.offset);\n        ordIndexInstance = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);\n        ordIndexInstances.put(field.number, ordIndexInstance);\n      }\n      ordIndex = ordIndexInstance;\n    }\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"11a746437bc5c0a0b3df0337ed249c387c812871","date":1376687959,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(field, ords.get(field.number));\n    NumericEntry entry = ordIndexes.get(field.number);\n    IndexInput data = this.data.clone();\n    data.seek(entry.offset);\n    final MonotonicBlockPackedReader ordIndex = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, true);\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex;\n    synchronized (ordIndexInstances) {\n      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);\n      if (ordIndexInstance == null) {\n        NumericEntry entry = ordIndexes.get(field.number);\n        IndexInput data = this.data.clone();\n        data.seek(entry.offset);\n        ordIndexInstance = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);\n        ordIndexInstances.put(field.number, ordIndexInstance);\n      }\n      ordIndex = ordIndexInstance;\n    }\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a7bf5332d569e3d07c4b248462f5d212e26e9af","date":1376929683,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":null,"sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(field, ords.get(field.number));\n    NumericEntry entry = ordIndexes.get(field.number);\n    IndexInput data = this.data.clone();\n    data.seek(entry.offset);\n    final MonotonicBlockPackedReader ordIndex = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, true);\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff","date":1377034255,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene45/Lucene45DocValuesProducer#getSortedSet(FieldInfo).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final IndexInput data = this.data.clone();\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex = getOrdIndexInstance(data, field, ordIndexes.get(field.number));\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex;\n    synchronized (ordIndexInstances) {\n      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);\n      if (ordIndexInstance == null) {\n        NumericEntry entry = ordIndexes.get(field.number);\n        IndexInput data = this.data.clone();\n        data.seek(entry.offset);\n        ordIndexInstance = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);\n        ordIndexInstances.put(field.number, ordIndexInstance);\n      }\n      ordIndex = ordIndexInstance;\n    }\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":4,"author":"Han Jiang","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/diskdv/DiskDocValuesProducer#getSortedSet(FieldInfo).mjava","sourceNew":null,"sourceOld":"  @Override\n  public SortedSetDocValues getSortedSet(FieldInfo field) throws IOException {\n    final long valueCount = binaries.get(field.number).count;\n    // we keep the byte[]s and list of ords on disk, these could be large\n    final LongBinaryDocValues binary = (LongBinaryDocValues) getBinary(field);\n    final LongNumericDocValues ordinals = getNumeric(ords.get(field.number));\n    // but the addresses to the ord stream are in RAM\n    final MonotonicBlockPackedReader ordIndex;\n    synchronized (ordIndexInstances) {\n      MonotonicBlockPackedReader ordIndexInstance = ordIndexInstances.get(field.number);\n      if (ordIndexInstance == null) {\n        NumericEntry entry = ordIndexes.get(field.number);\n        IndexInput data = this.data.clone();\n        data.seek(entry.offset);\n        ordIndexInstance = new MonotonicBlockPackedReader(data, entry.packedIntsVersion, entry.blockSize, entry.count, false);\n        ordIndexInstances.put(field.number, ordIndexInstance);\n      }\n      ordIndex = ordIndexInstance;\n    }\n    \n    return new SortedSetDocValues() {\n      long offset;\n      long endOffset;\n      \n      @Override\n      public long nextOrd() {\n        if (offset == endOffset) {\n          return NO_MORE_ORDS;\n        } else {\n          long ord = ordinals.get(offset);\n          offset++;\n          return ord;\n        }\n      }\n\n      @Override\n      public void setDocument(int docID) {\n        offset = (docID == 0 ? 0 : ordIndex.get(docID-1));\n        endOffset = ordIndex.get(docID);\n      }\n\n      @Override\n      public void lookupOrd(long ord, BytesRef result) {\n        binary.get(ord, result);\n      }\n\n      @Override\n      public long getValueCount() {\n        return valueCount;\n      }\n      \n      @Override\n      public long lookupTerm(BytesRef key) {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).lookupTerm(key);\n        } else {\n          return super.lookupTerm(key);\n        }\n      }\n\n      @Override\n      public TermsEnum termsEnum() {\n        if (binary instanceof CompressedBinaryDocValues) {\n          return ((CompressedBinaryDocValues)binary).getTermsEnum();\n        } else {\n          return super.termsEnum();\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"11a746437bc5c0a0b3df0337ed249c387c812871":["0ad01348544f9eb6ee985c300245013a75addfc6"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["ddbb72a33557d2b5bc22ee95daf3281c43560502"],"56fca4cf418a84a71d0701bbb6fda4db84fa5796":["f15adb143a3097f2342f07eb0929f6ce1877ad7e"],"1a7bf5332d569e3d07c4b248462f5d212e26e9af":["11a746437bc5c0a0b3df0337ed249c387c812871"],"0ad01348544f9eb6ee985c300245013a75addfc6":["ddbb72a33557d2b5bc22ee95daf3281c43560502"],"f366ce28775e2b8ea4e06355009471328711666d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff":["0ad01348544f9eb6ee985c300245013a75addfc6","1a7bf5332d569e3d07c4b248462f5d212e26e9af"],"ddbb72a33557d2b5bc22ee95daf3281c43560502":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","56fca4cf418a84a71d0701bbb6fda4db84fa5796"],"f15adb143a3097f2342f07eb0929f6ce1877ad7e":["f366ce28775e2b8ea4e06355009471328711666d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"]},"commit2Childs":{"11a746437bc5c0a0b3df0337ed249c387c812871":["1a7bf5332d569e3d07c4b248462f5d212e26e9af"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f366ce28775e2b8ea4e06355009471328711666d","ddbb72a33557d2b5bc22ee95daf3281c43560502"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576"],"56fca4cf418a84a71d0701bbb6fda4db84fa5796":["ddbb72a33557d2b5bc22ee95daf3281c43560502"],"1a7bf5332d569e3d07c4b248462f5d212e26e9af":["e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"0ad01348544f9eb6ee985c300245013a75addfc6":["11a746437bc5c0a0b3df0337ed249c387c812871","e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f366ce28775e2b8ea4e06355009471328711666d":["f15adb143a3097f2342f07eb0929f6ce1877ad7e"],"ddbb72a33557d2b5bc22ee95daf3281c43560502":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","0ad01348544f9eb6ee985c300245013a75addfc6"],"f15adb143a3097f2342f07eb0929f6ce1877ad7e":["56fca4cf418a84a71d0701bbb6fda4db84fa5796"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}