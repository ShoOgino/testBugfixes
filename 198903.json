{"path":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer#testNonIdeographic().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer#testNonIdeographic().mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer#testNonIdeographic().mjava","sourceNew":"  /*\n   * Non-english text (not just CJK) is treated the same as CJK: C1C2 C2C3 \n   */\n  public void testNonIdeographic() throws Exception {\n    String str = \"\\u4e00 روبرت موير\";\n    TestToken[] out_tokens = {\n        newToken(\"\\u4e00\", 0, 1, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"رو\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"وب\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"بر\", 4, 6, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"رت\", 5, 7, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"مو\", 8, 10, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"وي\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"ير\", 10, 12, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKToken(str, out_tokens);\n  }\n\n","sourceOld":"  /*\n   * Non-english text (not just CJK) is treated the same as CJK: C1C2 C2C3 \n   */\n  public void testNonIdeographic() throws Exception {\n    String str = \"\\u4e00 روبرت موير\";\n    TestToken[] out_tokens = {\n        newToken(\"\\u4e00\", 0, 1, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"رو\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"وب\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"بر\", 4, 6, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"رت\", 5, 7, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"مو\", 8, 10, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"وي\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"ير\", 10, 12, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKToken(str, out_tokens);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f080986da691a3bba7b757f43ab72cdc82b57ce","date":1273069619,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"modules/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer#testNonIdeographic().mjava","pathOld":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer#testNonIdeographic().mjava","sourceNew":"  /*\n   * Non-english text (not just CJK) is treated the same as CJK: C1C2 C2C3 \n   */\n  public void testNonIdeographic() throws Exception {\n    String str = \"\\u4e00 روبرت موير\";\n    TestToken[] out_tokens = {\n        newToken(\"\\u4e00\", 0, 1, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"رو\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"وب\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"بر\", 4, 6, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"رت\", 5, 7, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"مو\", 8, 10, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"وي\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"ير\", 10, 12, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKToken(str, out_tokens);\n  }\n\n","sourceOld":"  /*\n   * Non-english text (not just CJK) is treated the same as CJK: C1C2 C2C3 \n   */\n  public void testNonIdeographic() throws Exception {\n    String str = \"\\u4e00 روبرت موير\";\n    TestToken[] out_tokens = {\n        newToken(\"\\u4e00\", 0, 1, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"رو\", 2, 4, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"وب\", 3, 5, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"بر\", 4, 6, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"رت\", 5, 7, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"مو\", 8, 10, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"وي\", 9, 11, CJKTokenizer.DOUBLE_TOKEN_TYPE),\n        newToken(\"ير\", 10, 12, CJKTokenizer.DOUBLE_TOKEN_TYPE)\n    };\n    checkCJKToken(str, out_tokens);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0f080986da691a3bba7b757f43ab72cdc82b57ce":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0f080986da691a3bba7b757f43ab72cdc82b57ce"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"0f080986da691a3bba7b757f43ab72cdc82b57ce":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["0f080986da691a3bba7b757f43ab72cdc82b57ce"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}