{"path":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40TermVectorsReader#rawDocs(int[],int[],int,int).mjava","commits":[{"id":"cfd7f00f3dbc4c50d336540f063493fc0f7d830f","date":1322850565,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40TermVectorsReader#rawDocs(int[],int[],int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/DefaultTermVectorsReader#rawDocs(int[],int[],int,int).mjava","sourceNew":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","sourceOld":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40TermVectorsReader#rawDocs(int[],int[],int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40TermVectorsReader#rawDocs(int[],int[],int,int).mjava","sourceNew":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","sourceOld":"  /** Retrieve the length (in bytes) of the tvd and tvf\n   *  entries for the next numDocs starting with\n   *  startDocID.  This is used for bulk copying when\n   *  merging segments, if the field numbers are\n   *  congruent.  Once this returns, the tvf & tvd streams\n   *  are seeked to the startDocID. */\n  final void rawDocs(int[] tvdLengths, int[] tvfLengths, int startDocID, int numDocs) throws IOException {\n\n    if (tvx == null) {\n      Arrays.fill(tvdLengths, 0);\n      Arrays.fill(tvfLengths, 0);\n      return;\n    }\n\n    seekTvx(startDocID);\n\n    long tvdPosition = tvx.readLong();\n    tvd.seek(tvdPosition);\n\n    long tvfPosition = tvx.readLong();\n    tvf.seek(tvfPosition);\n\n    long lastTvdPosition = tvdPosition;\n    long lastTvfPosition = tvfPosition;\n\n    int count = 0;\n    while (count < numDocs) {\n      final int docID = docStoreOffset + startDocID + count + 1;\n      assert docID <= numTotalDocs;\n      if (docID < numTotalDocs)  {\n        tvdPosition = tvx.readLong();\n        tvfPosition = tvx.readLong();\n      } else {\n        tvdPosition = tvd.length();\n        tvfPosition = tvf.length();\n        assert count == numDocs-1;\n      }\n      tvdLengths[count] = (int) (tvdPosition-lastTvdPosition);\n      tvfLengths[count] = (int) (tvfPosition-lastTvfPosition);\n      count++;\n      lastTvdPosition = tvdPosition;\n      lastTvfPosition = tvfPosition;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"cfd7f00f3dbc4c50d336540f063493fc0f7d830f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["cfd7f00f3dbc4c50d336540f063493fc0f7d830f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"]},"commit2Childs":{"cfd7f00f3dbc4c50d336540f063493fc0f7d830f":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cfd7f00f3dbc4c50d336540f063493fc0f7d830f"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}