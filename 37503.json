{"path":"solr/core/src/test/org/apache/solr/search/TestSolrCachePerf#doTestGetPutCompute(Map[String,SummaryStatistics],Map[String,SummaryStatistics],int,boolean).mjava","commits":[{"id":"bfa27be7bde9d711ce2b418fadc555654849383f","date":1573652589,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestSolrCachePerf#doTestGetPutCompute(Map[String,SummaryStatistics],Map[String,SummaryStatistics],int,boolean).mjava","pathOld":"/dev/null","sourceNew":"  private void doTestGetPutCompute(Map<String, SummaryStatistics> ratioStats, Map<String, SummaryStatistics> timeStats, int numThreads, boolean useCompute) throws Exception {\n    for (Class<? extends SolrCache> clazz : IMPLS) {\n      SolrMetricManager metricManager = new SolrMetricManager();\n      SolrCache<String, String> cache = clazz.getDeclaredConstructor().newInstance();\n      Map<String, String> params = new HashMap<>();\n      params.put(\"size\", \"\" + NUM_KEYS);\n      CacheRegenerator cr = new NoOpRegenerator();\n      Object o = cache.init(params, null, cr);\n      cache.setState(SolrCache.State.LIVE);\n      cache.initializeMetrics(new SolrMetricsContext(metricManager, \"foo\", \"bar\"), \"foo\");\n      AtomicBoolean stop = new AtomicBoolean();\n      SummaryStatistics perImplRatio = ratioStats.computeIfAbsent(clazz.getSimpleName(), c -> new SummaryStatistics());\n      SummaryStatistics perImplTime = timeStats.computeIfAbsent(clazz.getSimpleName(), c -> new SummaryStatistics());\n      CountDownLatch startLatch = new CountDownLatch(1);\n      CountDownLatch stopLatch = new CountDownLatch(numThreads * NUM_KEYS);\n      List<Thread> runners = new ArrayList<>();\n      for (int i = 0; i < numThreads; i++) {\n        Thread t = new Thread(() -> {\n          try {\n            startLatch.await();\n            int ik = 0;\n            while (!stop.get()) {\n              String key = keys[ik % NUM_KEYS];\n              ik++;\n              if (useCompute) {\n                String value = cache.computeIfAbsent(key, k -> VALUE);\n                assertNotNull(value);\n              } else {\n                String value = cache.get(key);\n                if (value == null) {\n                  // increase a likelihood of context switch\n                  Thread.yield();\n                  cache.put(key, VALUE);\n                }\n              }\n              Thread.yield();\n              stopLatch.countDown();\n            }\n          } catch (InterruptedException e) {\n            fail(e.toString());\n            return;\n          }\n        });\n        t.start();\n        runners.add(t);\n      }\n      // fire them up\n      long startTime = System.nanoTime();\n      startLatch.countDown();\n      stopLatch.await();\n      stop.set(true);\n      for (Thread t : runners) {\n        t.join();\n      }\n      long stopTime = System.nanoTime();\n      Map<String, Object> metrics = cache.getSolrMetricsContext().getMetricsSnapshot();\n      perImplRatio.addValue(\n          Double.parseDouble(String.valueOf(metrics.get(\"CACHE.foo.hitratio\"))));\n      perImplTime.addValue((double)(stopTime - startTime));\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"31ecc981dc25a90bf2ac19cace122c85954f78e3","date":1573846700,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestSolrCachePerf#doTestGetPutCompute(Map[String,SummaryStatistics],Map[String,SummaryStatistics],int,boolean).mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestSolrCachePerf#doTestGetPutCompute(Map[String,SummaryStatistics],Map[String,SummaryStatistics],int,boolean).mjava","sourceNew":"  private void doTestGetPutCompute(Map<String, SummaryStatistics> ratioStats, Map<String, SummaryStatistics> timeStats, int numThreads, boolean useCompute) throws Exception {\n    for (Class<? extends SolrCache> clazz : IMPLS) {\n      SolrMetricManager metricManager = new SolrMetricManager();\n      SolrCache<String, String> cache = clazz.getDeclaredConstructor().newInstance();\n      Map<String, String> params = new HashMap<>();\n      params.put(\"size\", \"\" + NUM_KEYS);\n      CacheRegenerator cr = new NoOpRegenerator();\n      Object o = cache.init(params, null, cr);\n      cache.setState(SolrCache.State.LIVE);\n      cache.initializeMetrics(new SolrMetricsContext(metricManager, \"foo\", \"bar\"), \"foo\");\n      AtomicBoolean stop = new AtomicBoolean();\n      SummaryStatistics perImplRatio = ratioStats.computeIfAbsent(clazz.getSimpleName(), c -> new SummaryStatistics());\n      SummaryStatistics perImplTime = timeStats.computeIfAbsent(clazz.getSimpleName(), c -> new SummaryStatistics());\n      CountDownLatch startLatch = new CountDownLatch(1);\n      CountDownLatch stopLatch = new CountDownLatch(numThreads * NUM_KEYS);\n      List<Thread> runners = new ArrayList<>();\n      for (int i = 0; i < numThreads; i++) {\n        Thread t = new Thread(() -> {\n          try {\n            startLatch.await();\n            int ik = 0;\n            while (!stop.get()) {\n              String key = keys[ik % NUM_KEYS];\n              ik++;\n              if (useCompute) {\n                String value = cache.computeIfAbsent(key, k -> VALUE);\n                assertNotNull(value);\n              } else {\n                String value = cache.get(key);\n                if (value == null) {\n                  // increase a likelihood of context switch\n                  Thread.yield();\n                  cache.put(key, VALUE);\n                }\n              }\n              Thread.yield();\n              stopLatch.countDown();\n            }\n          } catch (InterruptedException e) {\n            fail(e.toString());\n            return;\n          }\n        });\n        t.start();\n        runners.add(t);\n      }\n      // fire them up\n      long startTime = System.nanoTime();\n      startLatch.countDown();\n      stopLatch.await();\n      stop.set(true);\n      for (Thread t : runners) {\n        t.join();\n      }\n      long stopTime = System.nanoTime();\n      Map<String, Object> metrics = cache.getSolrMetricsContext().getMetricsSnapshot();\n      perImplRatio.addValue(\n          Double.parseDouble(String.valueOf(metrics.get(\"CACHE.foo.hitratio\"))));\n      perImplTime.addValue((double)(stopTime - startTime));\n      cache.close();\n    }\n  }\n\n","sourceOld":"  private void doTestGetPutCompute(Map<String, SummaryStatistics> ratioStats, Map<String, SummaryStatistics> timeStats, int numThreads, boolean useCompute) throws Exception {\n    for (Class<? extends SolrCache> clazz : IMPLS) {\n      SolrMetricManager metricManager = new SolrMetricManager();\n      SolrCache<String, String> cache = clazz.getDeclaredConstructor().newInstance();\n      Map<String, String> params = new HashMap<>();\n      params.put(\"size\", \"\" + NUM_KEYS);\n      CacheRegenerator cr = new NoOpRegenerator();\n      Object o = cache.init(params, null, cr);\n      cache.setState(SolrCache.State.LIVE);\n      cache.initializeMetrics(new SolrMetricsContext(metricManager, \"foo\", \"bar\"), \"foo\");\n      AtomicBoolean stop = new AtomicBoolean();\n      SummaryStatistics perImplRatio = ratioStats.computeIfAbsent(clazz.getSimpleName(), c -> new SummaryStatistics());\n      SummaryStatistics perImplTime = timeStats.computeIfAbsent(clazz.getSimpleName(), c -> new SummaryStatistics());\n      CountDownLatch startLatch = new CountDownLatch(1);\n      CountDownLatch stopLatch = new CountDownLatch(numThreads * NUM_KEYS);\n      List<Thread> runners = new ArrayList<>();\n      for (int i = 0; i < numThreads; i++) {\n        Thread t = new Thread(() -> {\n          try {\n            startLatch.await();\n            int ik = 0;\n            while (!stop.get()) {\n              String key = keys[ik % NUM_KEYS];\n              ik++;\n              if (useCompute) {\n                String value = cache.computeIfAbsent(key, k -> VALUE);\n                assertNotNull(value);\n              } else {\n                String value = cache.get(key);\n                if (value == null) {\n                  // increase a likelihood of context switch\n                  Thread.yield();\n                  cache.put(key, VALUE);\n                }\n              }\n              Thread.yield();\n              stopLatch.countDown();\n            }\n          } catch (InterruptedException e) {\n            fail(e.toString());\n            return;\n          }\n        });\n        t.start();\n        runners.add(t);\n      }\n      // fire them up\n      long startTime = System.nanoTime();\n      startLatch.countDown();\n      stopLatch.await();\n      stop.set(true);\n      for (Thread t : runners) {\n        t.join();\n      }\n      long stopTime = System.nanoTime();\n      Map<String, Object> metrics = cache.getSolrMetricsContext().getMetricsSnapshot();\n      perImplRatio.addValue(\n          Double.parseDouble(String.valueOf(metrics.get(\"CACHE.foo.hitratio\"))));\n      perImplTime.addValue((double)(stopTime - startTime));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e98520789adb1d5ad05afb4956eca0944a929688","date":1592430701,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestSolrCachePerf#doTestGetPutCompute(Map[String,SummaryStatistics],Map[String,SummaryStatistics],int,boolean).mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestSolrCachePerf#doTestGetPutCompute(Map[String,SummaryStatistics],Map[String,SummaryStatistics],int,boolean).mjava","sourceNew":"  @SuppressWarnings({\"rawtypes\"})\n  private void doTestGetPutCompute(Map<String, SummaryStatistics> ratioStats, Map<String, SummaryStatistics> timeStats, int numThreads, boolean useCompute) throws Exception {\n    for (Class<? extends SolrCache> clazz : IMPLS) {\n      SolrMetricManager metricManager = new SolrMetricManager();\n      @SuppressWarnings({\"unchecked\"})\n      SolrCache<String, String> cache = clazz.getDeclaredConstructor().newInstance();\n      Map<String, String> params = new HashMap<>();\n      params.put(\"size\", \"\" + NUM_KEYS);\n      CacheRegenerator cr = new NoOpRegenerator();\n      Object o = cache.init(params, null, cr);\n      cache.setState(SolrCache.State.LIVE);\n      cache.initializeMetrics(new SolrMetricsContext(metricManager, \"foo\", \"bar\"), \"foo\");\n      AtomicBoolean stop = new AtomicBoolean();\n      SummaryStatistics perImplRatio = ratioStats.computeIfAbsent(clazz.getSimpleName(), c -> new SummaryStatistics());\n      SummaryStatistics perImplTime = timeStats.computeIfAbsent(clazz.getSimpleName(), c -> new SummaryStatistics());\n      CountDownLatch startLatch = new CountDownLatch(1);\n      CountDownLatch stopLatch = new CountDownLatch(numThreads * NUM_KEYS);\n      List<Thread> runners = new ArrayList<>();\n      for (int i = 0; i < numThreads; i++) {\n        Thread t = new Thread(() -> {\n          try {\n            startLatch.await();\n            int ik = 0;\n            while (!stop.get()) {\n              String key = keys[ik % NUM_KEYS];\n              ik++;\n              if (useCompute) {\n                String value = cache.computeIfAbsent(key, k -> VALUE);\n                assertNotNull(value);\n              } else {\n                String value = cache.get(key);\n                if (value == null) {\n                  // increase a likelihood of context switch\n                  Thread.yield();\n                  cache.put(key, VALUE);\n                }\n              }\n              Thread.yield();\n              stopLatch.countDown();\n            }\n          } catch (InterruptedException e) {\n            fail(e.toString());\n            return;\n          }\n        });\n        t.start();\n        runners.add(t);\n      }\n      // fire them up\n      long startTime = System.nanoTime();\n      startLatch.countDown();\n      stopLatch.await();\n      stop.set(true);\n      for (Thread t : runners) {\n        t.join();\n      }\n      long stopTime = System.nanoTime();\n      Map<String, Object> metrics = cache.getSolrMetricsContext().getMetricsSnapshot();\n      perImplRatio.addValue(\n          Double.parseDouble(String.valueOf(metrics.get(\"CACHE.foo.hitratio\"))));\n      perImplTime.addValue((double)(stopTime - startTime));\n      cache.close();\n    }\n  }\n\n","sourceOld":"  private void doTestGetPutCompute(Map<String, SummaryStatistics> ratioStats, Map<String, SummaryStatistics> timeStats, int numThreads, boolean useCompute) throws Exception {\n    for (Class<? extends SolrCache> clazz : IMPLS) {\n      SolrMetricManager metricManager = new SolrMetricManager();\n      SolrCache<String, String> cache = clazz.getDeclaredConstructor().newInstance();\n      Map<String, String> params = new HashMap<>();\n      params.put(\"size\", \"\" + NUM_KEYS);\n      CacheRegenerator cr = new NoOpRegenerator();\n      Object o = cache.init(params, null, cr);\n      cache.setState(SolrCache.State.LIVE);\n      cache.initializeMetrics(new SolrMetricsContext(metricManager, \"foo\", \"bar\"), \"foo\");\n      AtomicBoolean stop = new AtomicBoolean();\n      SummaryStatistics perImplRatio = ratioStats.computeIfAbsent(clazz.getSimpleName(), c -> new SummaryStatistics());\n      SummaryStatistics perImplTime = timeStats.computeIfAbsent(clazz.getSimpleName(), c -> new SummaryStatistics());\n      CountDownLatch startLatch = new CountDownLatch(1);\n      CountDownLatch stopLatch = new CountDownLatch(numThreads * NUM_KEYS);\n      List<Thread> runners = new ArrayList<>();\n      for (int i = 0; i < numThreads; i++) {\n        Thread t = new Thread(() -> {\n          try {\n            startLatch.await();\n            int ik = 0;\n            while (!stop.get()) {\n              String key = keys[ik % NUM_KEYS];\n              ik++;\n              if (useCompute) {\n                String value = cache.computeIfAbsent(key, k -> VALUE);\n                assertNotNull(value);\n              } else {\n                String value = cache.get(key);\n                if (value == null) {\n                  // increase a likelihood of context switch\n                  Thread.yield();\n                  cache.put(key, VALUE);\n                }\n              }\n              Thread.yield();\n              stopLatch.countDown();\n            }\n          } catch (InterruptedException e) {\n            fail(e.toString());\n            return;\n          }\n        });\n        t.start();\n        runners.add(t);\n      }\n      // fire them up\n      long startTime = System.nanoTime();\n      startLatch.countDown();\n      stopLatch.await();\n      stop.set(true);\n      for (Thread t : runners) {\n        t.join();\n      }\n      long stopTime = System.nanoTime();\n      Map<String, Object> metrics = cache.getSolrMetricsContext().getMetricsSnapshot();\n      perImplRatio.addValue(\n          Double.parseDouble(String.valueOf(metrics.get(\"CACHE.foo.hitratio\"))));\n      perImplTime.addValue((double)(stopTime - startTime));\n      cache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"bfa27be7bde9d711ce2b418fadc555654849383f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"31ecc981dc25a90bf2ac19cace122c85954f78e3":["bfa27be7bde9d711ce2b418fadc555654849383f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e98520789adb1d5ad05afb4956eca0944a929688"],"e98520789adb1d5ad05afb4956eca0944a929688":["31ecc981dc25a90bf2ac19cace122c85954f78e3"]},"commit2Childs":{"bfa27be7bde9d711ce2b418fadc555654849383f":["31ecc981dc25a90bf2ac19cace122c85954f78e3"],"31ecc981dc25a90bf2ac19cace122c85954f78e3":["e98520789adb1d5ad05afb4956eca0944a929688"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["bfa27be7bde9d711ce2b418fadc555654849383f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"e98520789adb1d5ad05afb4956eca0944a929688":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}