{"path":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":null,"sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"10d2f7af0975ac83900a2c970a62fe4c8667176b","date":1282358169,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<SolrIndexSearcher.GroupCommand>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req.getSchema()) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            SolrIndexSearcher.GroupCommandFunc gc;\n            if (groupSort != null) {\n              SolrIndexSearcher.GroupSortCommand gcSort = new SolrIndexSearcher.GroupSortCommand();\n              gcSort.sort = groupSort;\n              gc = gcSort;\n            } else {\n              gc =  new SolrIndexSearcher.GroupCommandFunc();\n            }\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.groupLimit = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          searcher.search(result,cmd);\n          rsp.add(\"grouped\", result.groupedResults);\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"71f160a09c8926e48290b7f4342a47eab588a11d","date":1284584360,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<SolrIndexSearcher.GroupCommand>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req.getSchema()) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            SolrIndexSearcher.GroupCommandFunc gc;\n            if (groupSort != null) {\n              SolrIndexSearcher.GroupSortCommand gcSort = new SolrIndexSearcher.GroupSortCommand();\n              gcSort.sort = groupSort;\n              gc = gcSort;\n            } else {\n              gc =  new SolrIndexSearcher.GroupCommandFunc();\n            }\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.groupLimit = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<SolrIndexSearcher.GroupCommand>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req.getSchema()) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            SolrIndexSearcher.GroupCommandFunc gc;\n            if (groupSort != null) {\n              SolrIndexSearcher.GroupSortCommand gcSort = new SolrIndexSearcher.GroupSortCommand();\n              gcSort.sort = groupSort;\n              gc = gcSort;\n            } else {\n              gc =  new SolrIndexSearcher.GroupCommandFunc();\n            }\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.groupLimit = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          searcher.search(result,cmd);\n          rsp.add(\"grouped\", result.groupedResults);\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6d7a4063d87c3c1f313aef4c02d5d02c3d2e18be","date":1284660971,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<SolrIndexSearcher.GroupCommand>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req.getSchema()) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            SolrIndexSearcher.GroupCommandFunc gc;\n            if (groupSort != null) {\n              SolrIndexSearcher.GroupSortCommand gcSort = new SolrIndexSearcher.GroupSortCommand();\n              gcSort.sort = groupSort;\n              gc = gcSort;\n            } else {\n              gc =  new SolrIndexSearcher.GroupCommandFunc();\n            }\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.groupLimit = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          if (rb.doHighlights || rb.isDebug()) {\n            // we need a single list of the returned docs\n            cmd.setFlags(cmd.getFlags() | SolrIndexSearcher.GET_DOCLIST);\n          }\n\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way to log\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<SolrIndexSearcher.GroupCommand>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req.getSchema()) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            SolrIndexSearcher.GroupCommandFunc gc;\n            if (groupSort != null) {\n              SolrIndexSearcher.GroupSortCommand gcSort = new SolrIndexSearcher.GroupSortCommand();\n              gcSort.sort = groupSort;\n              gc = gcSort;\n            } else {\n              gc =  new SolrIndexSearcher.GroupCommandFunc();\n            }\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.groupLimit = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4794c296bd2c2d028cb0c217981cb94f9314b5a9","date":1284757850,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<SolrIndexSearcher.GroupCommand>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req.getSchema()) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            SolrIndexSearcher.GroupCommandFunc gc = new SolrIndexSearcher.GroupCommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.groupLimit = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          if (rb.doHighlights || rb.isDebug()) {\n            // we need a single list of the returned docs\n            cmd.setFlags(cmd.getFlags() | SolrIndexSearcher.GET_DOCLIST);\n          }\n\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way to log\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<SolrIndexSearcher.GroupCommand>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req.getSchema()) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            SolrIndexSearcher.GroupCommandFunc gc;\n            if (groupSort != null) {\n              SolrIndexSearcher.GroupSortCommand gcSort = new SolrIndexSearcher.GroupSortCommand();\n              gcSort.sort = groupSort;\n              gc = gcSort;\n            } else {\n              gc =  new SolrIndexSearcher.GroupCommandFunc();\n            }\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.groupLimit = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          if (rb.doHighlights || rb.isDebug()) {\n            // we need a single list of the returned docs\n            cmd.setFlags(cmd.getFlags() | SolrIndexSearcher.GET_DOCLIST);\n          }\n\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way to log\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6c4b47f71232ba35bfb8afffa22ca4af2145a628","date":1284759228,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<SolrIndexSearcher.GroupCommand>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req.getSchema()) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            SolrIndexSearcher.GroupCommandFunc gc = new SolrIndexSearcher.GroupCommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.groupLimit = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          if (rb.doHighlights || rb.isDebug()) {\n            // we need a single list of the returned docs\n            cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n          }\n\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way to log\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<SolrIndexSearcher.GroupCommand>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req.getSchema()) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            SolrIndexSearcher.GroupCommandFunc gc = new SolrIndexSearcher.GroupCommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.groupLimit = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          if (rb.doHighlights || rb.isDebug()) {\n            // we need a single list of the returned docs\n            cmd.setFlags(cmd.getFlags() | SolrIndexSearcher.GET_DOCLIST);\n          }\n\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way to log\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9d9916984e99244c407152f6cfc2c3bf89a30bc8","date":1284760018,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<Grouping.Command>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req.getSchema()) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = new Grouping.CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.groupLimit = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          if (rb.doHighlights || rb.isDebug()) {\n            // we need a single list of the returned docs\n            cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n          }\n\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way to log\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<SolrIndexSearcher.GroupCommand>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req.getSchema()) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            SolrIndexSearcher.GroupCommandFunc gc = new SolrIndexSearcher.GroupCommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.groupLimit = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          if (rb.doHighlights || rb.isDebug()) {\n            // we need a single list of the returned docs\n            cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n          }\n\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way to log\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4723db11f8550520912d26e73d0d91869f9eedd2","date":1284919173,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<Grouping.Command>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req.getSchema()) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = new Grouping.CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = new Grouping.CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          if (rb.doHighlights || rb.isDebug()) {\n            // we need a single list of the returned docs\n            cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n          }\n\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way to log\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<Grouping.Command>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req.getSchema()) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = new Grouping.CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.groupLimit = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          if (rb.doHighlights || rb.isDebug()) {\n            // we need a single list of the returned docs\n            cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n          }\n\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way to log\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0883328ff2cc09b5c999d05c04e16530d819c627","date":1285860918,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<Grouping.Command>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n\n        // TODO: don't use groupSort==null to test for the presense of a sort since \"score desc\" will normalize to null\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = new Grouping.CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = new Grouping.CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          if (rb.doHighlights || rb.isDebug()) {\n            // we need a single list of the returned docs\n            cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n          }\n\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way to log\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<Grouping.Command>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req.getSchema()) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = new Grouping.CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = new Grouping.CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          if (rb.doHighlights || rb.isDebug()) {\n            // we need a single list of the returned docs\n            cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n          }\n\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way to log\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ddd83ce02b85f7d0c728af48e14e0eeb42de813a","date":1288533972,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<Grouping.Command>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n\n        // TODO: don't use groupSort==null to test for the presense of a sort since \"score desc\" will normalize to null\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = new Grouping.CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = new Grouping.CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          if (rb.doHighlights || rb.isDebug()) {\n            // we need a single list of the returned docs\n            cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n          }\n\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way to log\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<Grouping.Command>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n\n        // TODO: don't use groupSort==null to test for the presense of a sort since \"score desc\" will normalize to null\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = new Grouping.CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = new Grouping.CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          if (rb.doHighlights || rb.isDebug()) {\n            // we need a single list of the returned docs\n            cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n          }\n\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way to log\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4bf528aa2b9571ce1ec892ecf726201ef1e404e3","date":1288732150,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n\n        // TODO: don't use groupSort==null to test for the presense of a sort since \"score desc\" will normalize to null\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<Grouping.Command>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n\n        // TODO: don't use groupSort==null to test for the presense of a sort since \"score desc\" will normalize to null\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = new Grouping.CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = new Grouping.CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          if (rb.doHighlights || rb.isDebug()) {\n            // we need a single list of the returned docs\n            cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n          }\n\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way to log\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n\n        // TODO: don't use groupSort==null to test for the presense of a sort since \"score desc\" will normalize to null\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        cmd.groupCommands = new ArrayList<Grouping.Command>();\n        \n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n\n        // TODO: don't use groupSort==null to test for the presense of a sort since \"score desc\" will normalize to null\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = new Grouping.CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = new Grouping.CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n\n            cmd.groupCommands.add(gc);\n          }\n        }\n\n\n        if (cmd.groupCommands.size() == 0)\n          cmd.groupCommands = null;\n\n        if (cmd.groupCommands != null) {\n          if (rb.doHighlights || rb.isDebug()) {\n            // we need a single list of the returned docs\n            cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n          }\n\n          searcher.search(result,cmd);\n          rb.setResult( result );\n          rsp.add(\"grouped\", result.groupedResults);\n          // TODO: get \"hits\" a different way to log\n          return;\n        }\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b2b1c725218c10a43512759db57f636658a1695a","date":1289684758,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n\n        // TODO: don't use groupSort==null to test for the presense of a sort since \"score desc\" will normalize to null\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":["bc4283a38102a08c5832529ccbd1dbe8bcb81da9","bc4283a38102a08c5832529ccbd1dbe8bcb81da9","bc4283a38102a08c5832529ccbd1dbe8bcb81da9"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c498d3f8d75170b121f5eda2c6210ac5beb5d411","date":1289726298,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n\n        // TODO: don't use groupSort==null to test for the presense of a sort since \"score desc\" will normalize to null\n        Sort groupSort = groupSortStr != null ? QueryParsing.parseSort(groupSortStr, req) : null;\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c32d2a50662592e12dae8ea10960cce611c7ba1c","date":1290627254,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n\n            if (main) {\n              gc.main = true;\n              main = false;\n              gc.groupOffset = 0;  // doesn't make sense\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            // these two params will only be used if this is for the main result set\n            gc.offset = cmd.getOffset();\n            gc.numGroups = limitDefault;\n\n            if (main) {\n              gc.main = true;\n              main = false;\n              gc.docsPerGroup = gc.numGroups;  // doesn't make sense to limit to one\n              gc.groupOffset = gc.offset;\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n\n        if (grouping.mainResult != null) {\n          rsp.add(\"response\",grouping.mainResult);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        }\n\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c800a92bdddc053fba2b1b33e434f7536a2daae1","date":1290628554,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n        String format = params.get(GroupParams.GROUP_FORMAT);\n        Grouping.Format defaultFormat = \"simple\".equals(format) ? Grouping.Format.Simple : Grouping.Format.Grouped; \n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n            gc.format = defaultFormat;\n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n\n            if (gc.format == Grouping.Format.Simple) {\n              gc.groupOffset = 0;  // doesn't make sense\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            // these two params will only be used if this is for the main result set\n            gc.offset = cmd.getOffset();\n            gc.numGroups = limitDefault;\n\n            gc.format = defaultFormat;            \n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n            if (gc.format == Grouping.Format.Simple) {\n              gc.docsPerGroup = gc.numGroups;  // doesn't make sense to limit to one\n              gc.groupOffset = gc.offset;\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n\n        if (grouping.mainResult != null) {\n          rsp.add(\"response\",grouping.mainResult);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        }\n\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n\n            if (main) {\n              gc.main = true;\n              main = false;\n              gc.groupOffset = 0;  // doesn't make sense\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            // these two params will only be used if this is for the main result set\n            gc.offset = cmd.getOffset();\n            gc.numGroups = limitDefault;\n\n            if (main) {\n              gc.main = true;\n              main = false;\n              gc.docsPerGroup = gc.numGroups;  // doesn't make sense to limit to one\n              gc.groupOffset = gc.offset;\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n\n        if (grouping.mainResult != null) {\n          rsp.add(\"response\",grouping.mainResult);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        }\n\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n        String format = params.get(GroupParams.GROUP_FORMAT);\n        Grouping.Format defaultFormat = \"simple\".equals(format) ? Grouping.Format.Simple : Grouping.Format.Grouped; \n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n            gc.format = defaultFormat;\n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n\n            if (gc.format == Grouping.Format.Simple) {\n              gc.groupOffset = 0;  // doesn't make sense\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            // these two params will only be used if this is for the main result set\n            gc.offset = cmd.getOffset();\n            gc.numGroups = limitDefault;\n\n            gc.format = defaultFormat;            \n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n            if (gc.format == Grouping.Format.Simple) {\n              gc.docsPerGroup = gc.numGroups;  // doesn't make sense to limit to one\n              gc.groupOffset = gc.offset;\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n\n        if (grouping.mainResult != null) {\n          rsp.add(\"response\",grouping.mainResult);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        }\n\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n        String format = params.get(GroupParams.GROUP_FORMAT);\n        Grouping.Format defaultFormat = \"simple\".equals(format) ? Grouping.Format.Simple : Grouping.Format.Grouped; \n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n            gc.format = defaultFormat;\n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n\n            if (gc.format == Grouping.Format.Simple) {\n              gc.groupOffset = 0;  // doesn't make sense\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            // these two params will only be used if this is for the main result set\n            gc.offset = cmd.getOffset();\n            gc.numGroups = limitDefault;\n\n            gc.format = defaultFormat;            \n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n            if (gc.format == Grouping.Format.Simple) {\n              gc.docsPerGroup = gc.numGroups;  // doesn't make sense to limit to one\n              gc.groupOffset = gc.offset;\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n\n        if (grouping.mainResult != null) {\n          rsp.add(\"response\",grouping.mainResult);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        }\n\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6aedf81f068e430dec27d94310415cc6ff52731c","date":1301070261,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n        String format = params.get(GroupParams.GROUP_FORMAT);\n        Grouping.Format defaultFormat = \"simple\".equals(format) ? Grouping.Format.Simple : Grouping.Format.Grouped; \n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n            gc.format = defaultFormat;\n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n\n            if (gc.format == Grouping.Format.Simple) {\n              gc.groupOffset = 0;  // doesn't make sense\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            // these two params will only be used if this is for the main result set\n            gc.offset = cmd.getOffset();\n            gc.numGroups = limitDefault;\n\n            gc.format = defaultFormat;            \n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n            if (gc.format == Grouping.Format.Simple) {\n              gc.docsPerGroup = gc.numGroups;  // doesn't make sense to limit to one\n              gc.groupOffset = gc.offset;\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        }\n\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n        String format = params.get(GroupParams.GROUP_FORMAT);\n        Grouping.Format defaultFormat = \"simple\".equals(format) ? Grouping.Format.Simple : Grouping.Format.Grouped; \n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n            gc.format = defaultFormat;\n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n\n            if (gc.format == Grouping.Format.Simple) {\n              gc.groupOffset = 0;  // doesn't make sense\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            // these two params will only be used if this is for the main result set\n            gc.offset = cmd.getOffset();\n            gc.numGroups = limitDefault;\n\n            gc.format = defaultFormat;            \n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n            if (gc.format == Grouping.Format.Simple) {\n              gc.docsPerGroup = gc.numGroups;  // doesn't make sense to limit to one\n              gc.groupOffset = gc.offset;\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n\n        if (grouping.mainResult != null) {\n          rsp.add(\"response\",grouping.mainResult);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        }\n\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n        String format = params.get(GroupParams.GROUP_FORMAT);\n        Grouping.Format defaultFormat = \"simple\".equals(format) ? Grouping.Format.Simple : Grouping.Format.Grouped; \n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n            gc.format = defaultFormat;\n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n\n            if (gc.format == Grouping.Format.Simple) {\n              gc.groupOffset = 0;  // doesn't make sense\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            // these two params will only be used if this is for the main result set\n            gc.offset = cmd.getOffset();\n            gc.numGroups = limitDefault;\n\n            gc.format = defaultFormat;            \n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n            if (gc.format == Grouping.Format.Simple) {\n              gc.docsPerGroup = gc.numGroups;  // doesn't make sense to limit to one\n              gc.groupOffset = gc.offset;\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        }\n\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n        String format = params.get(GroupParams.GROUP_FORMAT);\n        Grouping.Format defaultFormat = \"simple\".equals(format) ? Grouping.Format.Simple : Grouping.Format.Grouped; \n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n            gc.format = defaultFormat;\n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n\n            if (gc.format == Grouping.Format.Simple) {\n              gc.groupOffset = 0;  // doesn't make sense\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            // these two params will only be used if this is for the main result set\n            gc.offset = cmd.getOffset();\n            gc.numGroups = limitDefault;\n\n            gc.format = defaultFormat;            \n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n            if (gc.format == Grouping.Format.Simple) {\n              gc.docsPerGroup = gc.numGroups;  // doesn't make sense to limit to one\n              gc.groupOffset = gc.offset;\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n\n        if (grouping.mainResult != null) {\n          rsp.add(\"response\",grouping.mainResult);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        }\n\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0ef0193974807e4bddf5432a6b0287fe4d6c9df","date":1301476645,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n        String format = params.get(GroupParams.GROUP_FORMAT);\n        Grouping.Format defaultFormat = \"simple\".equals(format) ? Grouping.Format.Simple : Grouping.Format.Grouped; \n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n            gc.format = defaultFormat;\n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n\n            if (gc.format == Grouping.Format.Simple) {\n              gc.groupOffset = 0;  // doesn't make sense\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            // these two params will only be used if this is for the main result set\n            gc.offset = cmd.getOffset();\n            gc.numGroups = limitDefault;\n\n            gc.format = defaultFormat;            \n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n            if (gc.format == Grouping.Format.Simple) {\n              gc.docsPerGroup = gc.numGroups;  // doesn't make sense to limit to one\n              gc.groupOffset = gc.offset;\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        }\n\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      rsp.add(\"response\",rb.getResults().docList);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n        String format = params.get(GroupParams.GROUP_FORMAT);\n        Grouping.Format defaultFormat = \"simple\".equals(format) ? Grouping.Format.Simple : Grouping.Format.Grouped; \n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n            gc.format = defaultFormat;\n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n\n            if (gc.format == Grouping.Format.Simple) {\n              gc.groupOffset = 0;  // doesn't make sense\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            // these two params will only be used if this is for the main result set\n            gc.offset = cmd.getOffset();\n            gc.numGroups = limitDefault;\n\n            gc.format = defaultFormat;            \n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n            if (gc.format == Grouping.Format.Simple) {\n              gc.docsPerGroup = gc.numGroups;  // doesn't make sense to limit to one\n              gc.groupOffset = gc.offset;\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n\n        if (grouping.mainResult != null) {\n          rsp.add(\"response\",grouping.mainResult);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        }\n\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n    rsp.add(\"response\",rb.getResults().docList);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9c7cdfe5a1ea9db97faa404b251fa644faa73597","date":1308345959,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n        String format = params.get(GroupParams.GROUP_FORMAT);\n        Grouping.Format defaultFormat = \"simple\".equals(format) ? Grouping.Format.Simple : Grouping.Format.Grouped; \n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n            gc.format = defaultFormat;\n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n\n            if (gc.format == Grouping.Format.Simple) {\n              gc.groupOffset = 0;  // doesn't make sense\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            // these two params will only be used if this is for the main result set\n            gc.offset = cmd.getOffset();\n            gc.numGroups = limitDefault;\n\n            gc.format = defaultFormat;            \n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n            if (gc.format == Grouping.Format.Simple) {\n              gc.docsPerGroup = gc.numGroups;  // doesn't make sense to limit to one\n              gc.groupOffset = gc.offset;\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        }\n\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":["bc4283a38102a08c5832529ccbd1dbe8bcb81da9","bc4283a38102a08c5832529ccbd1dbe8bcb81da9","bc4283a38102a08c5832529ccbd1dbe8bcb81da9"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7edfc3f7caa7b49a18fe367692768b33b018e9db","date":1308374217,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        Grouping grouping = new Grouping(searcher, result, cmd);\n\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n        String format = params.get(GroupParams.GROUP_FORMAT);\n        Grouping.Format defaultFormat = \"simple\".equals(format) ? Grouping.Format.Simple : Grouping.Format.Grouped; \n\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        // temporary: implement all group-by-field as group-by-func\n        if (funcs == null) {\n          funcs = fields;\n        } else if (fields != null) {\n          // catenate functions and fields\n          String[] both = new String[fields.length + funcs.length];\n          System.arraycopy(fields, 0, both, 0, fields.length);\n          System.arraycopy(funcs, 0, both, fields.length, funcs.length);\n          funcs = both;\n        }\n\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            QParser parser = QParser.getParser(groupByStr, \"func\", rb.req);\n            Query q = parser.getQuery();\n            Grouping.CommandFunc gc = grouping.new CommandFunc();\n            gc.groupSort = groupSort;\n\n            if (q instanceof FunctionQuery) {\n              gc.groupBy = ((FunctionQuery)q).getValueSource();\n            } else {\n              gc.groupBy = new QueryValueSource(q, 0.0f);\n            }\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n            gc.offset = cmd.getOffset();\n            gc.sort = cmd.getSort();\n            gc.format = defaultFormat;\n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n\n            if (gc.format == Grouping.Format.Simple) {\n              gc.groupOffset = 0;  // doesn't make sense\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            QParser parser = QParser.getParser(groupByStr, null, rb.req);\n            Query gq = parser.getQuery();\n            Grouping.CommandQuery gc = grouping.new CommandQuery();\n            gc.query = gq;\n            gc.groupSort = groupSort;\n            gc.key = groupByStr;\n            gc.numGroups = limitDefault;\n            gc.docsPerGroup = docsPerGroupDefault;\n            gc.groupOffset = groupOffsetDefault;\n\n            // these two params will only be used if this is for the main result set\n            gc.offset = cmd.getOffset();\n            gc.numGroups = limitDefault;\n\n            gc.format = defaultFormat;            \n\n            if (main) {\n              gc.main = true;\n              gc.format = Grouping.Format.Simple;\n              main = false;\n            }\n            if (gc.format == Grouping.Format.Simple) {\n              gc.docsPerGroup = gc.numGroups;  // doesn't make sense to limit to one\n              gc.groupOffset = gc.offset;\n            }\n\n            grouping.add(gc);\n          }\n        }\n\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        // searcher.search(result,cmd);\n        grouping.execute();\n        rb.setResult( result );\n        rsp.add(\"grouped\", result.groupedResults);\n        // TODO: get \"hits\" a different way to log\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        }\n\n        return;\n\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34","date":1309197122,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/QueryComponent#process(ResponseBuilder).mjava","sourceNew":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","sourceOld":"  /**\n   * Actually run the query\n   */\n  @Override\n  public void process(ResponseBuilder rb) throws IOException\n  {\n    SolrQueryRequest req = rb.req;\n    SolrQueryResponse rsp = rb.rsp;\n    SolrParams params = req.getParams();\n    if (!params.getBool(COMPONENT_NAME, true)) {\n      return;\n    }\n    SolrIndexSearcher searcher = req.getSearcher();\n\n    if (rb.getQueryCommand().getOffset() < 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"'start' parameter cannot be negative\");\n    }\n\n    // -1 as flag if not set.\n    long timeAllowed = (long)params.getInt( CommonParams.TIME_ALLOWED, -1 );\n\n    // Optional: This could also be implemented by the top-level searcher sending\n    // a filter that lists the ids... that would be transparent to\n    // the request handler, but would be more expensive (and would preserve score\n    // too if desired).\n    String ids = params.get(ShardParams.IDS);\n    if (ids != null) {\n      SchemaField idField = req.getSchema().getUniqueKeyField();\n      List<String> idArr = StrUtils.splitSmart(ids, \",\", true);\n      int[] luceneIds = new int[idArr.size()];\n      int docs = 0;\n      for (int i=0; i<idArr.size(); i++) {\n        int id = req.getSearcher().getFirstMatch(\n                new Term(idField.getName(), idField.getType().toInternal(idArr.get(i))));\n        if (id >= 0)\n          luceneIds[docs++] = id;\n      }\n\n      DocListAndSet res = new DocListAndSet();\n      res.docList = new DocSlice(0, docs, luceneIds, null, docs, 0);\n      if (rb.isNeedDocSet()) {\n        // TODO: create a cache for this!\n        List<Query> queries = new ArrayList<Query>();\n        queries.add(rb.getQuery());\n        List<Query> filters = rb.getFilters();\n        if (filters != null) queries.addAll(filters);\n        res.docSet = searcher.getDocSet(queries);\n      }\n      rb.setResults(res);\n      \n      ResultContext ctx = new ResultContext();\n      ctx.docs = rb.getResults().docList;\n      ctx.query = null; // anything?\n      rsp.add(\"response\", ctx);\n      return;\n    }\n\n    SolrIndexSearcher.QueryCommand cmd = rb.getQueryCommand();\n    cmd.setTimeAllowed(timeAllowed);\n    SolrIndexSearcher.QueryResult result = new SolrIndexSearcher.QueryResult();\n\n    //\n    // grouping / field collapsing\n    //\n    boolean doGroup = params.getBool(GroupParams.GROUP, false);\n    if (doGroup) {\n      try {\n        int maxDocsPercentageToCache = params.getInt(GroupParams.GROUP_CACHE_PERCENTAGE, 0);\n        boolean cacheSecondPassSearch = maxDocsPercentageToCache >= 1 && maxDocsPercentageToCache <= 100;\n        String[] fields = params.getParams(GroupParams.GROUP_FIELD);\n        String[] funcs = params.getParams(GroupParams.GROUP_FUNC);\n        String[] queries = params.getParams(GroupParams.GROUP_QUERY);\n        String groupSortStr = params.get(GroupParams.GROUP_SORT);\n        boolean main = params.getBool(GroupParams.GROUP_MAIN, false);\n\n        String formatStr = params.get(GroupParams.GROUP_FORMAT, Grouping.Format.grouped.name());\n        Grouping.Format defaultFormat;\n        try {\n          defaultFormat = Grouping.Format.valueOf(formatStr);\n        } catch (IllegalArgumentException e) {\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, String.format(\"Illegal %s parameter\", GroupParams.GROUP_FORMAT));\n        }\n\n        boolean includeTotalGroupCount = params.getBool(GroupParams.GROUP_TOTAL_COUNT, false);\n        Grouping.TotalCount defaultTotalCount = includeTotalGroupCount ? Grouping.TotalCount.grouped : Grouping.TotalCount.ungrouped;\n        Sort sort = cmd.getSort();\n        // groupSort defaults to sort\n        Sort groupSort = groupSortStr == null ? cmd.getSort() : QueryParsing.parseSort(groupSortStr, req);\n\n        int limitDefault = cmd.getLen(); // this is normally from \"rows\"\n        int groupOffsetDefault = params.getInt(GroupParams.GROUP_OFFSET, 0);\n        int docsPerGroupDefault = params.getInt(GroupParams.GROUP_LIMIT, 1);\n\n        Grouping grouping = new Grouping(searcher, result, cmd, cacheSecondPassSearch, maxDocsPercentageToCache, main);\n        grouping.setSort(sort)\n            .setGroupSort(groupSort)\n            .setDefaultFormat(defaultFormat)\n            .setLimitDefault(limitDefault)\n            .setDefaultTotalCount(defaultTotalCount)\n            .setDocsPerGroupDefault(docsPerGroupDefault)\n            .setGroupOffsetDefault(groupOffsetDefault);\n\n        if (fields != null) {\n          for (String field : fields) {\n            grouping.addFieldCommand(field, rb.req);\n          }\n        }\n\n        if (funcs != null) {\n          for (String groupByStr : funcs) {\n            grouping.addFunctionCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (queries != null) {\n          for (String groupByStr : queries) {\n            grouping.addQueryCommand(groupByStr, rb.req);\n          }\n        }\n\n        if (rb.doHighlights || rb.isDebug()) {\n          // we need a single list of the returned docs\n          cmd.setFlags(SolrIndexSearcher.GET_DOCLIST);\n        }\n\n        grouping.execute();\n        if (grouping.isSignalCacheWarning()) {\n          rsp.add(\n              \"cacheWarning\",\n              String.format(\"Cache limit of %d percent relative to maxdoc has exceeded. Please increase cache size or disable caching.\", maxDocsPercentageToCache)\n          );\n        }\n        rb.setResult(result);\n        rsp.add(\"grouped\", result.groupedResults);\n\n        if (grouping.mainResult != null) {\n          ResultContext ctx = new ResultContext();\n          ctx.docs = grouping.mainResult;\n          ctx.query = null; // TODO? add the query?\n          rsp.add(\"response\", ctx);\n          rsp.getToLog().add(\"hits\", grouping.mainResult.matches());\n        } else if (!grouping.getCommands().isEmpty()) { // Can never be empty since grouping.execute() checks for this.\n          rsp.getToLog().add(\"hits\", grouping.getCommands().get(0).getMatches());\n        }\n        return;\n      } catch (ParseException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n    }\n\n    // normal search result\n    searcher.search(result,cmd);\n    rb.setResult( result );\n\n\n    ResultContext ctx = new ResultContext();\n    ctx.docs = rb.getResults().docList;\n    ctx.query = rb.getQuery();\n    rsp.add(\"response\", ctx);\n    rsp.getToLog().add(\"hits\", rb.getResults().docList.matches());\n\n    doFieldSortValues(rb, searcher);\n    doPrefetch(rb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"0883328ff2cc09b5c999d05c04e16530d819c627":["4723db11f8550520912d26e73d0d91869f9eedd2"],"4bf528aa2b9571ce1ec892ecf726201ef1e404e3":["ddd83ce02b85f7d0c728af48e14e0eeb42de813a"],"10d2f7af0975ac83900a2c970a62fe4c8667176b":["1da8d55113b689b06716246649de6f62430f15c0"],"c32d2a50662592e12dae8ea10960cce611c7ba1c":["b2b1c725218c10a43512759db57f636658a1695a"],"c26f00b574427b55127e869b935845554afde1fa":["f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"c800a92bdddc053fba2b1b33e434f7536a2daae1":["c32d2a50662592e12dae8ea10960cce611c7ba1c"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["1da8d55113b689b06716246649de6f62430f15c0","c800a92bdddc053fba2b1b33e434f7536a2daae1"],"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"9d9916984e99244c407152f6cfc2c3bf89a30bc8":["6c4b47f71232ba35bfb8afffa22ca4af2145a628"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","6aedf81f068e430dec27d94310415cc6ff52731c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9c7cdfe5a1ea9db97faa404b251fa644faa73597":["6aedf81f068e430dec27d94310415cc6ff52731c"],"f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34":["9c7cdfe5a1ea9db97faa404b251fa644faa73597"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"6d7a4063d87c3c1f313aef4c02d5d02c3d2e18be":["71f160a09c8926e48290b7f4342a47eab588a11d"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b2b1c725218c10a43512759db57f636658a1695a":["4bf528aa2b9571ce1ec892ecf726201ef1e404e3"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["85a883878c0af761245ab048babc63d099f835f3","b2b1c725218c10a43512759db57f636658a1695a"],"4723db11f8550520912d26e73d0d91869f9eedd2":["9d9916984e99244c407152f6cfc2c3bf89a30bc8"],"85a883878c0af761245ab048babc63d099f835f3":["0883328ff2cc09b5c999d05c04e16530d819c627","4bf528aa2b9571ce1ec892ecf726201ef1e404e3"],"2553b00f699380c64959ccb27991289aae87be2e":["7edfc3f7caa7b49a18fe367692768b33b018e9db","f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["9c7cdfe5a1ea9db97faa404b251fa644faa73597","f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34"],"7edfc3f7caa7b49a18fe367692768b33b018e9db":["6aedf81f068e430dec27d94310415cc6ff52731c","9c7cdfe5a1ea9db97faa404b251fa644faa73597"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["2553b00f699380c64959ccb27991289aae87be2e"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["3bb13258feba31ab676502787ab2e1779f129b7a","6aedf81f068e430dec27d94310415cc6ff52731c"],"6c4b47f71232ba35bfb8afffa22ca4af2145a628":["4794c296bd2c2d028cb0c217981cb94f9314b5a9"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34"],"71f160a09c8926e48290b7f4342a47eab588a11d":["10d2f7af0975ac83900a2c970a62fe4c8667176b"],"ddd83ce02b85f7d0c728af48e14e0eeb42de813a":["0883328ff2cc09b5c999d05c04e16530d819c627"],"6aedf81f068e430dec27d94310415cc6ff52731c":["c800a92bdddc053fba2b1b33e434f7536a2daae1"],"4794c296bd2c2d028cb0c217981cb94f9314b5a9":["6d7a4063d87c3c1f313aef4c02d5d02c3d2e18be"],"3bb13258feba31ab676502787ab2e1779f129b7a":["c498d3f8d75170b121f5eda2c6210ac5beb5d411","c800a92bdddc053fba2b1b33e434f7536a2daae1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"0883328ff2cc09b5c999d05c04e16530d819c627":["85a883878c0af761245ab048babc63d099f835f3","ddd83ce02b85f7d0c728af48e14e0eeb42de813a"],"4bf528aa2b9571ce1ec892ecf726201ef1e404e3":["b2b1c725218c10a43512759db57f636658a1695a","85a883878c0af761245ab048babc63d099f835f3"],"10d2f7af0975ac83900a2c970a62fe4c8667176b":["71f160a09c8926e48290b7f4342a47eab588a11d"],"c32d2a50662592e12dae8ea10960cce611c7ba1c":["c800a92bdddc053fba2b1b33e434f7536a2daae1"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"c800a92bdddc053fba2b1b33e434f7536a2daae1":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","6aedf81f068e430dec27d94310415cc6ff52731c","3bb13258feba31ab676502787ab2e1779f129b7a"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"1da8d55113b689b06716246649de6f62430f15c0":["10d2f7af0975ac83900a2c970a62fe4c8667176b","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"9d9916984e99244c407152f6cfc2c3bf89a30bc8":["4723db11f8550520912d26e73d0d91869f9eedd2"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"9c7cdfe5a1ea9db97faa404b251fa644faa73597":["f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34","d083e83f225b11e5fdd900e83d26ddb385b6955c","7edfc3f7caa7b49a18fe367692768b33b018e9db"],"f8bf47b67b38083a0c4d9d2e3f53b59a48e8db34":["c26f00b574427b55127e869b935845554afde1fa","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","a258fbb26824fd104ed795e5d9033d2d040049ee"],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"6d7a4063d87c3c1f313aef4c02d5d02c3d2e18be":["4794c296bd2c2d028cb0c217981cb94f9314b5a9"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"b2b1c725218c10a43512759db57f636658a1695a":["c32d2a50662592e12dae8ea10960cce611c7ba1c","c498d3f8d75170b121f5eda2c6210ac5beb5d411"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["3bb13258feba31ab676502787ab2e1779f129b7a"],"4723db11f8550520912d26e73d0d91869f9eedd2":["0883328ff2cc09b5c999d05c04e16530d819c627"],"85a883878c0af761245ab048babc63d099f835f3":["c498d3f8d75170b121f5eda2c6210ac5beb5d411"],"2553b00f699380c64959ccb27991289aae87be2e":["c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"7edfc3f7caa7b49a18fe367692768b33b018e9db":["2553b00f699380c64959ccb27991289aae87be2e"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"d619839baa8ce5503e496b94a9e42ad6f079293f":[],"6c4b47f71232ba35bfb8afffa22ca4af2145a628":["9d9916984e99244c407152f6cfc2c3bf89a30bc8"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"71f160a09c8926e48290b7f4342a47eab588a11d":["6d7a4063d87c3c1f313aef4c02d5d02c3d2e18be"],"ddd83ce02b85f7d0c728af48e14e0eeb42de813a":["4bf528aa2b9571ce1ec892ecf726201ef1e404e3"],"6aedf81f068e430dec27d94310415cc6ff52731c":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df","9c7cdfe5a1ea9db97faa404b251fa644faa73597","7edfc3f7caa7b49a18fe367692768b33b018e9db","d619839baa8ce5503e496b94a9e42ad6f079293f"],"3bb13258feba31ab676502787ab2e1779f129b7a":["d619839baa8ce5503e496b94a9e42ad6f079293f"],"4794c296bd2c2d028cb0c217981cb94f9314b5a9":["6c4b47f71232ba35bfb8afffa22ca4af2145a628"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df","d083e83f225b11e5fdd900e83d26ddb385b6955c","d619839baa8ce5503e496b94a9e42ad6f079293f","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}