{"path":"lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random, directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.shutdown();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), directory, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.shutdown();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.shutdown();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), directory, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), directory, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.shutdown();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","date":1424799790,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), directory, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, 1000);\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), directory, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, null, 1000);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f68d01cf19df971dcdcb05e30247f4ad7ec9747","date":1434611645,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestTimeLimitingCollector#setUp().mjava","sourceNew":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), directory, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery.Builder booleanQuery = new BooleanQuery.Builder();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery.build();\n    \n    // warm the searcher\n    searcher.search(query, 1000);\n  }\n\n","sourceOld":"  /**\n   * initializes searcher with a document set\n   */\n  @Override\n  public void setUp() throws Exception {\n    super.setUp();\n    counter = Counter.newCounter(true);\n    counterThread = new TimerThread(counter);\n    counterThread.start();\n    final String docText[] = {\n        \"docThatNeverMatchesSoWeCanRequireLastDocCollectedToBeGreaterThanZero\",\n        \"one blah three\",\n        \"one foo three multiOne\",\n        \"one foobar three multiThree\",\n        \"blueberry pancakes\",\n        \"blueberry pie\",\n        \"blueberry strudel\",\n        \"blueberry pizza\",\n    };\n    directory = newDirectory();\n    RandomIndexWriter iw = new RandomIndexWriter(random(), directory, newIndexWriterConfig(new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    \n    for (int i=0; i<N_DOCS; i++) {\n      add(docText[i%docText.length], iw);\n    }\n    reader = iw.getReader();\n    iw.close();\n    searcher = newSearcher(reader);\n\n    BooleanQuery booleanQuery = new BooleanQuery();\n    booleanQuery.add(new TermQuery(new Term(FIELD_NAME, \"one\")), BooleanClause.Occur.SHOULD);\n    // start from 1, so that the 0th doc never matches\n    for (int i = 1; i < docText.length; i++) {\n      String[] docTextParts = docText[i].split(\"\\\\s+\");\n      for (String docTextPart : docTextParts) { // large query so that search will be longer\n        booleanQuery.add(new TermQuery(new Term(FIELD_NAME, docTextPart)), BooleanClause.Occur.SHOULD);\n      }\n    }\n\n    query = booleanQuery;\n    \n    // warm the searcher\n    searcher.search(query, 1000);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"]},"commit2Childs":{"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}