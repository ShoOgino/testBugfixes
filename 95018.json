{"path":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","commits":[{"id":"89f15687f60bd49cd3d9de427e85c17fd9397d61","date":1309381327,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   * Test was added for tracker 143670.\n   * At the time of writing the test it exposes the bug fixed in tracker 143670.\n   * However NOTE that this exposure depends on Lucene internal implementation and \n   * as such in the future it may stop to expose that specific bug.\n   * The test should always pass, though :) \n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = new RAMDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    DataTokenStream dts2 = new DataTokenStream(\"2\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new KeywordAnalyzer()));\n    for (int i = 0; i < data.length; i++) {\n      dts.setIdx(i);\n      Document doc = new Document();\n      if (i==0 || i == 2) {\n        doc.add(new Field(\"f\", dts)); // only docs 0 & 2 have payloads!\n      }\n      dts2.setIdx(i);\n      doc.add(new Field(\"f\", dts2));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    // add more documents to expose the bug.\n    // for some reason, this bug is not exposed unless these additional documents are added.\n    for (int i = 0; i < 10; ++i) {\n      Document d = new Document();\n      dts.setIdx(2);\n      d.add(new Field(\"f\", dts2));\n      writer.addDocument(d);\n      if (i %10 == 0) {\n        writer.commit();\n      }\n      \n    }\n\n    writer.commit();\n    writer.close();\n\n    IndexReader reader = IndexReader.open(dir, true);\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    cli.init();\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \"+i+\" must not have a payload!\", i==0 || i==2 );\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \"+i+\" must have a payload!\", i==0 || i==2 );\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 4, totalCats);\n\n    // Ok.. went through the first 4 docs, now lets try the 6th doc (docid 5)\n    assertFalse(\"Doc #6 (docid=5) should not have a payload!\",cli.skipTo(5));\n    reader.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a4df66e06e0c3b520d7d5941e1c043076f06f17","date":1309454196,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   * Test was added for tracker 143670.\n   * At the time of writing the test it exposes the bug fixed in tracker 143670.\n   * However NOTE that this exposure depends on Lucene internal implementation and \n   * as such in the future it may stop to expose that specific bug.\n   * The test should always pass, though :) \n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    DataTokenStream dts2 = new DataTokenStream(\"2\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new MockTokenizer(reader, MockTokenizer.KEYWORD, false);\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      dts.setIdx(i);\n      Document doc = new Document();\n      if (i==0 || i == 2) {\n        doc.add(new Field(\"f\", dts)); // only docs 0 & 2 have payloads!\n      }\n      dts2.setIdx(i);\n      doc.add(new Field(\"f\", dts2));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    // add more documents to expose the bug.\n    // for some reason, this bug is not exposed unless these additional documents are added.\n    for (int i = 0; i < 10; ++i) {\n      Document d = new Document();\n      dts.setIdx(2);\n      d.add(new Field(\"f\", dts2));\n      writer.addDocument(d);\n      if (i %10 == 0) {\n        writer.commit();\n      }\n      \n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    cli.init();\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \"+i+\" must not have a payload!\", i==0 || i==2 );\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \"+i+\" must have a payload!\", i==0 || i==2 );\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 4, totalCats);\n\n    // Ok.. went through the first 4 docs, now lets try the 6th doc (docid 5)\n    assertFalse(\"Doc #6 (docid=5) should not have a payload!\",cli.skipTo(5));\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   * Test was added for tracker 143670.\n   * At the time of writing the test it exposes the bug fixed in tracker 143670.\n   * However NOTE that this exposure depends on Lucene internal implementation and \n   * as such in the future it may stop to expose that specific bug.\n   * The test should always pass, though :) \n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = new RAMDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    DataTokenStream dts2 = new DataTokenStream(\"2\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new KeywordAnalyzer()));\n    for (int i = 0; i < data.length; i++) {\n      dts.setIdx(i);\n      Document doc = new Document();\n      if (i==0 || i == 2) {\n        doc.add(new Field(\"f\", dts)); // only docs 0 & 2 have payloads!\n      }\n      dts2.setIdx(i);\n      doc.add(new Field(\"f\", dts2));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    // add more documents to expose the bug.\n    // for some reason, this bug is not exposed unless these additional documents are added.\n    for (int i = 0; i < 10; ++i) {\n      Document d = new Document();\n      dts.setIdx(2);\n      d.add(new Field(\"f\", dts2));\n      writer.addDocument(d);\n      if (i %10 == 0) {\n        writer.commit();\n      }\n      \n    }\n\n    writer.commit();\n    writer.close();\n\n    IndexReader reader = IndexReader.open(dir, true);\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    cli.init();\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \"+i+\" must not have a payload!\", i==0 || i==2 );\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \"+i+\" must have a payload!\", i==0 || i==2 );\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 4, totalCats);\n\n    // Ok.. went through the first 4 docs, now lets try the 6th doc (docid 5)\n    assertFalse(\"Doc #6 (docid=5) should not have a payload!\",cli.skipTo(5));\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5ccc019b3619afcedec96f9b28ac60c90e87d06c","date":1309679398,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    DataTokenStream dts2 = new DataTokenStream(\"2\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new MockTokenizer(reader, MockTokenizer.KEYWORD, false);\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      dts.setIdx(i);\n      Document doc = new Document();\n      if (i==0 || i == 2) {\n        doc.add(new Field(\"f\", dts)); // only docs 0 & 2 have payloads!\n      }\n      dts2.setIdx(i);\n      doc.add(new Field(\"f\", dts2));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    // add more documents to expose the bug.\n    // for some reason, this bug is not exposed unless these additional documents are added.\n    for (int i = 0; i < 10; ++i) {\n      Document d = new Document();\n      dts.setIdx(2);\n      d.add(new Field(\"f\", dts2));\n      writer.addDocument(d);\n      if (i %10 == 0) {\n        writer.commit();\n      }\n      \n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    cli.init();\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \"+i+\" must not have a payload!\", i==0 || i==2 );\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \"+i+\" must have a payload!\", i==0 || i==2 );\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 4, totalCats);\n\n    // Ok.. went through the first 4 docs, now lets try the 6th doc (docid 5)\n    assertFalse(\"Doc #6 (docid=5) should not have a payload!\",cli.skipTo(5));\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   * Test was added for tracker 143670.\n   * At the time of writing the test it exposes the bug fixed in tracker 143670.\n   * However NOTE that this exposure depends on Lucene internal implementation and \n   * as such in the future it may stop to expose that specific bug.\n   * The test should always pass, though :) \n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    DataTokenStream dts2 = new DataTokenStream(\"2\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new MockTokenizer(reader, MockTokenizer.KEYWORD, false);\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      dts.setIdx(i);\n      Document doc = new Document();\n      if (i==0 || i == 2) {\n        doc.add(new Field(\"f\", dts)); // only docs 0 & 2 have payloads!\n      }\n      dts2.setIdx(i);\n      doc.add(new Field(\"f\", dts2));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    // add more documents to expose the bug.\n    // for some reason, this bug is not exposed unless these additional documents are added.\n    for (int i = 0; i < 10; ++i) {\n      Document d = new Document();\n      dts.setIdx(2);\n      d.add(new Field(\"f\", dts2));\n      writer.addDocument(d);\n      if (i %10 == 0) {\n        writer.commit();\n      }\n      \n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    cli.init();\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \"+i+\" must not have a payload!\", i==0 || i==2 );\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \"+i+\" must have a payload!\", i==0 || i==2 );\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 4, totalCats);\n\n    // Ok.. went through the first 4 docs, now lets try the 6th doc (docid 5)\n    assertFalse(\"Doc #6 (docid=5) should not have a payload!\",cli.skipTo(5));\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    DataTokenStream dts2 = new DataTokenStream(\"2\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new MockTokenizer(reader, MockTokenizer.KEYWORD, false);\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      dts.setIdx(i);\n      Document doc = new Document();\n      if (i==0 || i == 2) {\n        doc.add(new Field(\"f\", dts)); // only docs 0 & 2 have payloads!\n      }\n      dts2.setIdx(i);\n      doc.add(new Field(\"f\", dts2));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    // add more documents to expose the bug.\n    // for some reason, this bug is not exposed unless these additional documents are added.\n    for (int i = 0; i < 10; ++i) {\n      Document d = new Document();\n      dts.setIdx(2);\n      d.add(new Field(\"f\", dts2));\n      writer.addDocument(d);\n      if (i %10 == 0) {\n        writer.commit();\n      }\n      \n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    cli.init();\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \"+i+\" must not have a payload!\", i==0 || i==2 );\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \"+i+\" must have a payload!\", i==0 || i==2 );\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 4, totalCats);\n\n    // Ok.. went through the first 4 docs, now lets try the 6th doc (docid 5)\n    assertFalse(\"Doc #6 (docid=5) should not have a payload!\",cli.skipTo(5));\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    DataTokenStream dts2 = new DataTokenStream(\"2\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new MockTokenizer(reader, MockTokenizer.KEYWORD, false);\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      dts.setIdx(i);\n      Document doc = new Document();\n      if (i==0 || i == 2) {\n        doc.add(new Field(\"f\", dts)); // only docs 0 & 2 have payloads!\n      }\n      dts2.setIdx(i);\n      doc.add(new Field(\"f\", dts2));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    // add more documents to expose the bug.\n    // for some reason, this bug is not exposed unless these additional documents are added.\n    for (int i = 0; i < 10; ++i) {\n      Document d = new Document();\n      dts.setIdx(2);\n      d.add(new Field(\"f\", dts2));\n      writer.addDocument(d);\n      if (i %10 == 0) {\n        writer.commit();\n      }\n      \n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    cli.init();\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \"+i+\" must not have a payload!\", i==0 || i==2 );\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \"+i+\" must have a payload!\", i==0 || i==2 );\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 4, totalCats);\n\n    // Ok.. went through the first 4 docs, now lets try the 6th doc (docid 5)\n    assertFalse(\"Doc #6 (docid=5) should not have a payload!\",cli.skipTo(5));\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    DataTokenStream dts2 = new DataTokenStream(\"2\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new MockTokenizer(reader, MockTokenizer.KEYWORD, false);\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      dts.setIdx(i);\n      Document doc = new Document();\n      if (i==0 || i == 2) {\n        doc.add(new TextField(\"f\", dts)); // only docs 0 & 2 have payloads!\n      }\n      dts2.setIdx(i);\n      doc.add(new TextField(\"f\", dts2));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    // add more documents to expose the bug.\n    // for some reason, this bug is not exposed unless these additional documents are added.\n    for (int i = 0; i < 10; ++i) {\n      Document d = new Document();\n      dts.setIdx(2);\n      d.add(new TextField(\"f\", dts2));\n      writer.addDocument(d);\n      if (i %10 == 0) {\n        writer.commit();\n      }\n      \n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    cli.init();\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \"+i+\" must not have a payload!\", i==0 || i==2 );\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \"+i+\" must have a payload!\", i==0 || i==2 );\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 4, totalCats);\n\n    // Ok.. went through the first 4 docs, now lets try the 6th doc (docid 5)\n    assertFalse(\"Doc #6 (docid=5) should not have a payload!\",cli.skipTo(5));\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    DataTokenStream dts2 = new DataTokenStream(\"2\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new MockTokenizer(reader, MockTokenizer.KEYWORD, false);\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      dts.setIdx(i);\n      Document doc = new Document();\n      if (i==0 || i == 2) {\n        doc.add(new Field(\"f\", dts)); // only docs 0 & 2 have payloads!\n      }\n      dts2.setIdx(i);\n      doc.add(new Field(\"f\", dts2));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    // add more documents to expose the bug.\n    // for some reason, this bug is not exposed unless these additional documents are added.\n    for (int i = 0; i < 10; ++i) {\n      Document d = new Document();\n      dts.setIdx(2);\n      d.add(new Field(\"f\", dts2));\n      writer.addDocument(d);\n      if (i %10 == 0) {\n        writer.commit();\n      }\n      \n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    cli.init();\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \"+i+\" must not have a payload!\", i==0 || i==2 );\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \"+i+\" must have a payload!\", i==0 || i==2 );\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 4, totalCats);\n\n    // Ok.. went through the first 4 docs, now lets try the 6th doc (docid 5)\n    assertFalse(\"Doc #6 (docid=5) should not have a payload!\",cli.skipTo(5));\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"53ae89cd75b0acbdfb8890710c6742f3fb80e65d","date":1315806626,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    DataTokenStream dts2 = new DataTokenStream(\"2\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new ReusableAnalyzerBase() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      dts.setIdx(i);\n      Document doc = new Document();\n      if (i==0 || i == 2) {\n        doc.add(new TextField(\"f\", dts)); // only docs 0 & 2 have payloads!\n      }\n      dts2.setIdx(i);\n      doc.add(new TextField(\"f\", dts2));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    // add more documents to expose the bug.\n    // for some reason, this bug is not exposed unless these additional documents are added.\n    for (int i = 0; i < 10; ++i) {\n      Document d = new Document();\n      dts.setIdx(2);\n      d.add(new TextField(\"f\", dts2));\n      writer.addDocument(d);\n      if (i %10 == 0) {\n        writer.commit();\n      }\n      \n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    cli.init();\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \"+i+\" must not have a payload!\", i==0 || i==2 );\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \"+i+\" must have a payload!\", i==0 || i==2 );\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 4, totalCats);\n\n    // Ok.. went through the first 4 docs, now lets try the 6th doc (docid 5)\n    assertFalse(\"Doc #6 (docid=5) should not have a payload!\",cli.skipTo(5));\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    DataTokenStream dts2 = new DataTokenStream(\"2\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStream tokenStream(String fieldName, Reader reader) {\n        return new MockTokenizer(reader, MockTokenizer.KEYWORD, false);\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      dts.setIdx(i);\n      Document doc = new Document();\n      if (i==0 || i == 2) {\n        doc.add(new TextField(\"f\", dts)); // only docs 0 & 2 have payloads!\n      }\n      dts2.setIdx(i);\n      doc.add(new TextField(\"f\", dts2));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    // add more documents to expose the bug.\n    // for some reason, this bug is not exposed unless these additional documents are added.\n    for (int i = 0; i < 10; ++i) {\n      Document d = new Document();\n      dts.setIdx(2);\n      d.add(new TextField(\"f\", dts2));\n      writer.addDocument(d);\n      if (i %10 == 0) {\n        writer.commit();\n      }\n      \n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    cli.init();\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \"+i+\" must not have a payload!\", i==0 || i==2 );\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \"+i+\" must have a payload!\", i==0 || i==2 );\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 4, totalCats);\n\n    // Ok.. went through the first 4 docs, now lets try the 6th doc (docid 5)\n    assertFalse(\"Doc #6 (docid=5) should not have a payload!\",cli.skipTo(5));\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2f49143da0a5d278a72f741432047fcfa6da996e","date":1316927425,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    DataTokenStream dts2 = new DataTokenStream(\"2\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      dts.setIdx(i);\n      Document doc = new Document();\n      if (i==0 || i == 2) {\n        doc.add(new TextField(\"f\", dts)); // only docs 0 & 2 have payloads!\n      }\n      dts2.setIdx(i);\n      doc.add(new TextField(\"f\", dts2));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    // add more documents to expose the bug.\n    // for some reason, this bug is not exposed unless these additional documents are added.\n    for (int i = 0; i < 10; ++i) {\n      Document d = new Document();\n      dts.setIdx(2);\n      d.add(new TextField(\"f\", dts2));\n      writer.addDocument(d);\n      if (i %10 == 0) {\n        writer.commit();\n      }\n      \n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    cli.init();\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \"+i+\" must not have a payload!\", i==0 || i==2 );\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \"+i+\" must have a payload!\", i==0 || i==2 );\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 4, totalCats);\n\n    // Ok.. went through the first 4 docs, now lets try the 6th doc (docid 5)\n    assertFalse(\"Doc #6 (docid=5) should not have a payload!\",cli.skipTo(5));\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    DataTokenStream dts2 = new DataTokenStream(\"2\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new ReusableAnalyzerBase() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      dts.setIdx(i);\n      Document doc = new Document();\n      if (i==0 || i == 2) {\n        doc.add(new TextField(\"f\", dts)); // only docs 0 & 2 have payloads!\n      }\n      dts2.setIdx(i);\n      doc.add(new TextField(\"f\", dts2));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    // add more documents to expose the bug.\n    // for some reason, this bug is not exposed unless these additional documents are added.\n    for (int i = 0; i < 10; ++i) {\n      Document d = new Document();\n      dts.setIdx(2);\n      d.add(new TextField(\"f\", dts2));\n      writer.addDocument(d);\n      if (i %10 == 0) {\n        writer.commit();\n      }\n      \n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    cli.init();\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \"+i+\" must not have a payload!\", i==0 || i==2 );\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \"+i+\" must have a payload!\", i==0 || i==2 );\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 4, totalCats);\n\n    // Ok.. went through the first 4 docs, now lets try the 6th doc (docid 5)\n    assertFalse(\"Doc #6 (docid=5) should not have a payload!\",cli.skipTo(5));\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"056f70824cc48de597e42753d004f6747ff6d521","date":1321258381,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\"));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    assertTrue(\"Failed to initialize payload iterator\", cli.init());\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \" + i + \" must not have a payload!\", i == 0);\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \" + i + \" must have a payload!\", i == 0);\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCats);\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    DataTokenStream dts2 = new DataTokenStream(\"2\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      dts.setIdx(i);\n      Document doc = new Document();\n      if (i==0 || i == 2) {\n        doc.add(new TextField(\"f\", dts)); // only docs 0 & 2 have payloads!\n      }\n      dts2.setIdx(i);\n      doc.add(new TextField(\"f\", dts2));\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    // add more documents to expose the bug.\n    // for some reason, this bug is not exposed unless these additional documents are added.\n    for (int i = 0; i < 10; ++i) {\n      Document d = new Document();\n      dts.setIdx(2);\n      d.add(new TextField(\"f\", dts2));\n      writer.addDocument(d);\n      if (i %10 == 0) {\n        writer.commit();\n      }\n      \n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    cli.init();\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \"+i+\" must not have a payload!\", i==0 || i==2 );\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \"+i+\" must have a payload!\", i==0 || i==2 );\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 4, totalCats);\n\n    // Ok.. went through the first 4 docs, now lets try the 6th doc (docid 5)\n    assertFalse(\"Doc #6 (docid=5) should not have a payload!\",cli.skipTo(5));\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\"));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    assertTrue(\"Failed to initialize payload iterator\", cli.init());\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \" + i + \" must not have a payload!\", i == 0);\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \" + i + \" must have a payload!\", i == 0);\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCats);\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\"));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    assertTrue(\"Failed to initialize payload iterator\", cli.init());\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \" + i + \" must not have a payload!\", i == 0);\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \" + i + \" must have a payload!\", i == 0);\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCats);\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\"));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    assertTrue(\"Failed to initialize payload iterator\", cli.init());\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \" + i + \" must not have a payload!\", i == 0);\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \" + i + \" must have a payload!\", i == 0);\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCats);\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\"));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    assertTrue(\"Failed to initialize payload iterator\", cli.init());\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \" + i + \" must not have a payload!\", i == 0);\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \" + i + \" must have a payload!\", i == 0);\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCats);\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"056f70824cc48de597e42753d004f6747ff6d521":["2f49143da0a5d278a72f741432047fcfa6da996e"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5ccc019b3619afcedec96f9b28ac60c90e87d06c"],"89f15687f60bd49cd3d9de427e85c17fd9397d61":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5ccc019b3619afcedec96f9b28ac60c90e87d06c"],"53ae89cd75b0acbdfb8890710c6742f3fb80e65d":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"5ccc019b3619afcedec96f9b28ac60c90e87d06c":["7a4df66e06e0c3b520d7d5941e1c043076f06f17"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2f49143da0a5d278a72f741432047fcfa6da996e":["53ae89cd75b0acbdfb8890710c6742f3fb80e65d"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["056f70824cc48de597e42753d004f6747ff6d521"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["5ccc019b3619afcedec96f9b28ac60c90e87d06c"],"7a4df66e06e0c3b520d7d5941e1c043076f06f17":["89f15687f60bd49cd3d9de427e85c17fd9397d61"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"056f70824cc48de597e42753d004f6747ff6d521":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"89f15687f60bd49cd3d9de427e85c17fd9397d61":["7a4df66e06e0c3b520d7d5941e1c043076f06f17"],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"5ccc019b3619afcedec96f9b28ac60c90e87d06c":["d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"53ae89cd75b0acbdfb8890710c6742f3fb80e65d":["2f49143da0a5d278a72f741432047fcfa6da996e"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d083e83f225b11e5fdd900e83d26ddb385b6955c","89f15687f60bd49cd3d9de427e85c17fd9397d61","817d8435e9135b756f08ce6710ab0baac51bdf88"],"2f49143da0a5d278a72f741432047fcfa6da996e":["056f70824cc48de597e42753d004f6747ff6d521"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["53ae89cd75b0acbdfb8890710c6742f3fb80e65d"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"7a4df66e06e0c3b520d7d5941e1c043076f06f17":["5ccc019b3619afcedec96f9b28ac60c90e87d06c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}