{"path":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"/dev/null","sourceNew":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList termVectors = new NamedList();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    //figure out what options we have, and try to get the appropriate vector\n    boolean termFreq = params.getBool(TermVectorParams.TF, false);\n    boolean positions = params.getBool(TermVectorParams.POSITIONS, false);\n    boolean offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    boolean docFreq = params.getBool(TermVectorParams.DF, false);\n    boolean tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true){\n      termFreq = true;\n      positions = true;\n      offsets = true;\n      docFreq = true;\n      tfIdf = true;\n    }\n\n    String[] fields = params.getParams(TermVectorParams.FIELDS);\n    if (fields == null) {\n      fields = params.getParams(CommonParams.FL);\n    }\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    TVMapper mapper = new TVMapper(fields, reader, termFreq, positions, offsets, docFreq, tfIdf);\n    IndexSchema schema = rb.req.getSchema();\n    String uniqFieldName = schema.getUniqueKeyField().getName();\n    //Only load the id field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.emptySet());\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList docNL = new NamedList();\n      termVectors.add(\"doc-\" + docId, docNL);\n      mapper.docNL = docNL;\n      Document document = reader.document(docId, fieldSelector);\n      String uniqId = document.get(uniqFieldName);\n      docNL.add(\"uniqueKey\", uniqId);\n      reader.getTermFreqVector(docId, mapper);\n    }\n    termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":null,"sourceOld":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList termVectors = new NamedList();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    //figure out what options we have, and try to get the appropriate vector\n    boolean termFreq = params.getBool(TermVectorParams.TF, false);\n    boolean positions = params.getBool(TermVectorParams.POSITIONS, false);\n    boolean offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    boolean docFreq = params.getBool(TermVectorParams.DF, false);\n    boolean tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true){\n      termFreq = true;\n      positions = true;\n      offsets = true;\n      docFreq = true;\n      tfIdf = true;\n    }\n\n    String[] fields = params.getParams(TermVectorParams.FIELDS);\n    if (fields == null) {\n      fields = params.getParams(CommonParams.FL);\n    }\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    TVMapper mapper = new TVMapper(fields, reader, termFreq, positions, offsets, docFreq, tfIdf);\n    IndexSchema schema = rb.req.getSchema();\n    String uniqFieldName = schema.getUniqueKeyField().getName();\n    //Only load the id field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.emptySet());\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList docNL = new NamedList();\n      termVectors.add(\"doc-\" + docId, docNL);\n      mapper.docNL = docNL;\n      Document document = reader.document(docId, fieldSelector);\n      String uniqId = document.get(uniqFieldName);\n      docNL.add(\"uniqueKey\", uniqId);\n      reader.getTermFreqVector(docId, mapper);\n    }\n    termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList termVectors = new NamedList();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    //figure out what options we have, and try to get the appropriate vector\n    boolean termFreq = params.getBool(TermVectorParams.TF, false);\n    boolean positions = params.getBool(TermVectorParams.POSITIONS, false);\n    boolean offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    boolean docFreq = params.getBool(TermVectorParams.DF, false);\n    boolean tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true){\n      termFreq = true;\n      positions = true;\n      offsets = true;\n      docFreq = true;\n      tfIdf = true;\n    }\n\n    String[] fields = params.getParams(TermVectorParams.FIELDS);\n    if (fields == null) {\n      fields = params.getParams(CommonParams.FL);\n    }\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    TVMapper mapper = new TVMapper(fields, reader, termFreq, positions, offsets, docFreq, tfIdf);\n    IndexSchema schema = rb.req.getSchema();\n    String uniqFieldName = schema.getUniqueKeyField().getName();\n    //Only load the id field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList docNL = new NamedList();\n      termVectors.add(\"doc-\" + docId, docNL);\n      mapper.docNL = docNL;\n      Document document = reader.document(docId, fieldSelector);\n      String uniqId = document.get(uniqFieldName);\n      docNL.add(\"uniqueKey\", uniqId);\n      reader.getTermFreqVector(docId, mapper);\n    }\n    termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n  }\n\n","sourceOld":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList termVectors = new NamedList();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    //figure out what options we have, and try to get the appropriate vector\n    boolean termFreq = params.getBool(TermVectorParams.TF, false);\n    boolean positions = params.getBool(TermVectorParams.POSITIONS, false);\n    boolean offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    boolean docFreq = params.getBool(TermVectorParams.DF, false);\n    boolean tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true){\n      termFreq = true;\n      positions = true;\n      offsets = true;\n      docFreq = true;\n      tfIdf = true;\n    }\n\n    String[] fields = params.getParams(TermVectorParams.FIELDS);\n    if (fields == null) {\n      fields = params.getParams(CommonParams.FL);\n    }\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    TVMapper mapper = new TVMapper(fields, reader, termFreq, positions, offsets, docFreq, tfIdf);\n    IndexSchema schema = rb.req.getSchema();\n    String uniqFieldName = schema.getUniqueKeyField().getName();\n    //Only load the id field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList docNL = new NamedList();\n      termVectors.add(\"doc-\" + docId, docNL);\n      mapper.docNL = docNL;\n      Document document = reader.document(docId, fieldSelector);\n      String uniqId = document.get(uniqFieldName);\n      docNL.add(\"uniqueKey\", uniqId);\n      reader.getTermFreqVector(docId, mapper);\n    }\n    termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"/dev/null","sourceNew":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList termVectors = new NamedList();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    //figure out what options we have, and try to get the appropriate vector\n    boolean termFreq = params.getBool(TermVectorParams.TF, false);\n    boolean positions = params.getBool(TermVectorParams.POSITIONS, false);\n    boolean offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    boolean docFreq = params.getBool(TermVectorParams.DF, false);\n    boolean tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true){\n      termFreq = true;\n      positions = true;\n      offsets = true;\n      docFreq = true;\n      tfIdf = true;\n    }\n\n    String[] fields = params.getParams(TermVectorParams.FIELDS);\n    if (fields == null) {\n      fields = params.getParams(CommonParams.FL);\n    }\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    TVMapper mapper = new TVMapper(fields, reader, termFreq, positions, offsets, docFreq, tfIdf);\n    IndexSchema schema = rb.req.getSchema();\n    String uniqFieldName = schema.getUniqueKeyField().getName();\n    //Only load the id field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList docNL = new NamedList();\n      termVectors.add(\"doc-\" + docId, docNL);\n      mapper.docNL = docNL;\n      Document document = reader.document(docId, fieldSelector);\n      String uniqId = document.get(uniqFieldName);\n      docNL.add(\"uniqueKey\", uniqId);\n      reader.getTermFreqVector(docId, mapper);\n    }\n    termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"df18b2465217a237531d0d944c22ea4a4316411e","date":1278157467,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList termVectors = new NamedList();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList warnings = new NamedList();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList docNL = new NamedList();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList termVectors = new NamedList();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    //figure out what options we have, and try to get the appropriate vector\n    boolean termFreq = params.getBool(TermVectorParams.TF, false);\n    boolean positions = params.getBool(TermVectorParams.POSITIONS, false);\n    boolean offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    boolean docFreq = params.getBool(TermVectorParams.DF, false);\n    boolean tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true){\n      termFreq = true;\n      positions = true;\n      offsets = true;\n      docFreq = true;\n      tfIdf = true;\n    }\n\n    String[] fields = params.getParams(TermVectorParams.FIELDS);\n    if (fields == null) {\n      fields = params.getParams(CommonParams.FL);\n    }\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    TVMapper mapper = new TVMapper(fields, reader, termFreq, positions, offsets, docFreq, tfIdf);\n    IndexSchema schema = rb.req.getSchema();\n    String uniqFieldName = schema.getUniqueKeyField().getName();\n    //Only load the id field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList docNL = new NamedList();\n      termVectors.add(\"doc-\" + docId, docNL);\n      mapper.docNL = docNL;\n      Document document = reader.document(docId, fieldSelector);\n      String uniqId = document.get(uniqFieldName);\n      docNL.add(\"uniqueKey\", uniqId);\n      reader.getTermFreqVector(docId, mapper);\n    }\n    termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n  }\n\n","bugFix":["3a04bdb295a363a052bdc5a2fcd6e8ce977aa51c","6eec7020a8347c329fda5615de48884c0a21ad7d","a2686717a32b40222a4361bd16ae295511cb8ce7"],"bugIntro":["4e32cd9d49e5cda7e131c54c05d8e970583b7063","4e32cd9d49e5cda7e131c54c05d8e970583b7063","4e32cd9d49e5cda7e131c54c05d8e970583b7063"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList termVectors = new NamedList();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList warnings = new NamedList();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList docNL = new NamedList();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList termVectors = new NamedList();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    //figure out what options we have, and try to get the appropriate vector\n    boolean termFreq = params.getBool(TermVectorParams.TF, false);\n    boolean positions = params.getBool(TermVectorParams.POSITIONS, false);\n    boolean offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    boolean docFreq = params.getBool(TermVectorParams.DF, false);\n    boolean tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true){\n      termFreq = true;\n      positions = true;\n      offsets = true;\n      docFreq = true;\n      tfIdf = true;\n    }\n\n    String[] fields = params.getParams(TermVectorParams.FIELDS);\n    if (fields == null) {\n      fields = params.getParams(CommonParams.FL);\n    }\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    TVMapper mapper = new TVMapper(fields, reader, termFreq, positions, offsets, docFreq, tfIdf);\n    IndexSchema schema = rb.req.getSchema();\n    String uniqFieldName = schema.getUniqueKeyField().getName();\n    //Only load the id field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList docNL = new NamedList();\n      termVectors.add(\"doc-\" + docId, docNL);\n      mapper.docNL = docNL;\n      Document document = reader.document(docId, fieldSelector);\n      String uniqId = document.get(uniqFieldName);\n      docNL.add(\"uniqueKey\", uniqId);\n      reader.getTermFreqVector(docId, mapper);\n    }\n    termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b5f7137bd9491c6596681b1f56e481e17964e581","date":1294458451,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList termVectors = new NamedList();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList warnings = new NamedList();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList docNL = new NamedList();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c220849f876de24a79f756f65b3eb045db59f63f","date":1294902803,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList termVectors = new NamedList();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList warnings = new NamedList();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList docNL = new NamedList();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01","date":1296400215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList termVectors = new NamedList();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList warnings = new NamedList();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList docNL = new NamedList();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab0e9f7ce724e6aea1fea746dded19e76d231cf8","date":1304774078,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getField(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b48b42b82c149773b4ccb139507e9bd29da91ca2","date":1309410544,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["4e32cd9d49e5cda7e131c54c05d8e970583b7063","4e32cd9d49e5cda7e131c54c05d8e970583b7063","4e32cd9d49e5cda7e131c54c05d8e970583b7063"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    boolean all = params.getBool(TermVectorParams.ALL, false);\n    if (all == true) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions == true && sf.storeTermPositions() == false){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets == true && sf.storeTermOffsets() == false){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (noTV.isEmpty() == false) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (noPos.isEmpty() == false) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (noOff.isEmpty() == false) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings == true) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && docIds.isEmpty() == false) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (fieldOptions.isEmpty() == false) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/TermVectorComponent#process(ResponseBuilder).mjava","sourceNew":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void process(ResponseBuilder rb) throws IOException {\n    SolrParams params = rb.req.getParams();\n    if (!params.getBool(COMPONENT_NAME, false)) {\n      return;\n    }\n\n    NamedList<Object> termVectors = new NamedList<Object>();\n    rb.rsp.add(TERM_VECTORS, termVectors);\n    FieldOptions allFields = new FieldOptions();\n    //figure out what options we have, and try to get the appropriate vector\n    allFields.termFreq = params.getBool(TermVectorParams.TF, false);\n    allFields.positions = params.getBool(TermVectorParams.POSITIONS, false);\n    allFields.offsets = params.getBool(TermVectorParams.OFFSETS, false);\n    allFields.docFreq = params.getBool(TermVectorParams.DF, false);\n    allFields.tfIdf = params.getBool(TermVectorParams.TF_IDF, false);\n    //boolean cacheIdf = params.getBool(TermVectorParams.IDF, false);\n    //short cut to all values.\n    if (params.getBool(TermVectorParams.ALL, false)) {\n      allFields.termFreq = true;\n      allFields.positions = true;\n      allFields.offsets = true;\n      allFields.docFreq = true;\n      allFields.tfIdf = true;\n    }\n\n    String fldLst = params.get(TermVectorParams.FIELDS);\n    if (fldLst == null) {\n      fldLst = params.get(CommonParams.FL);\n    }\n\n    //use this to validate our fields\n    IndexSchema schema = rb.req.getSchema();\n    //Build up our per field mapping\n    Map<String, FieldOptions> fieldOptions = new HashMap<String, FieldOptions>();\n    NamedList<List<String>> warnings = new NamedList<List<String>>();\n    List<String>  noTV = new ArrayList<String>();\n    List<String>  noPos = new ArrayList<String>();\n    List<String>  noOff = new ArrayList<String>();\n\n    //we have specific fields to retrieve\n    if (fldLst != null) {\n      String [] fields = SolrPluginUtils.split(fldLst);\n      for (String field : fields) {\n        SchemaField sf = schema.getFieldOrNull(field);\n        if (sf != null) {\n          if (sf.storeTermVector()) {\n            FieldOptions option = fieldOptions.get(field);\n            if (option == null) {\n              option = new FieldOptions();\n              option.fieldName = field;\n              fieldOptions.put(field, option);\n            }\n            //get the per field mappings\n            option.termFreq = params.getFieldBool(field, TermVectorParams.TF, allFields.termFreq);\n            option.docFreq = params.getFieldBool(field, TermVectorParams.DF, allFields.docFreq);\n            option.tfIdf = params.getFieldBool(field, TermVectorParams.TF_IDF, allFields.tfIdf);\n            //Validate these are even an option\n            option.positions = params.getFieldBool(field, TermVectorParams.POSITIONS, allFields.positions);\n            if (option.positions && !sf.storeTermPositions()){\n              noPos.add(field);\n            }\n            option.offsets = params.getFieldBool(field, TermVectorParams.OFFSETS, allFields.offsets);\n            if (option.offsets && !sf.storeTermOffsets()){\n              noOff.add(field);\n            }\n          } else {//field doesn't have term vectors\n            noTV.add(field);\n          }\n        } else {\n          //field doesn't exist\n          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"undefined field: \" + field);\n        }\n      }\n    } //else, deal with all fields\n    boolean hasWarnings = false;\n    if (!noTV.isEmpty()) {\n      warnings.add(\"noTermVectors\", noTV);\n      hasWarnings = true;\n    }\n    if (!noPos.isEmpty()) {\n      warnings.add(\"noPositions\", noPos);\n      hasWarnings = true;\n    }\n    if (!noOff.isEmpty()) {\n      warnings.add(\"noOffsets\", noOff);\n      hasWarnings = true;\n    }\n    if (hasWarnings) {\n      termVectors.add(\"warnings\", warnings);\n    }\n\n    DocListAndSet listAndSet = rb.getResults();\n    List<Integer> docIds = getInts(params.getParams(TermVectorParams.DOC_IDS));\n    Iterator<Integer> iter;\n    if (docIds != null && !docIds.isEmpty()) {\n      iter = docIds.iterator();\n    } else {\n      DocList list = listAndSet.docList;\n      iter = list.iterator();\n    }\n    SolrIndexSearcher searcher = rb.req.getSearcher();\n\n    IndexReader reader = searcher.getIndexReader();\n    //the TVMapper is a TermVectorMapper which can be used to optimize loading of Term Vectors\n    SchemaField keyField = schema.getUniqueKeyField();\n    String uniqFieldName = null;\n    if (keyField != null) {\n      uniqFieldName = keyField.getName();\n    }\n    //Only load the id field to get the uniqueKey of that field\n    SetBasedFieldSelector fieldSelector = new SetBasedFieldSelector(Collections.singleton(uniqFieldName), Collections.<String>emptySet());\n    TVMapper mapper = new TVMapper(reader);\n    mapper.fieldOptions = allFields; //this will only stay set if fieldOptions.isEmpty() (in other words, only if the user didn't set any fields)\n    while (iter.hasNext()) {\n      Integer docId = iter.next();\n      NamedList<Object> docNL = new NamedList<Object>();\n      mapper.docNL = docNL;\n      termVectors.add(\"doc-\" + docId, docNL);\n\n      if (keyField != null) {\n        Document document = reader.document(docId, fieldSelector);\n        Fieldable uniqId = document.getFieldable(uniqFieldName);\n        String uniqVal = null;\n        if (uniqId != null) {\n          uniqVal = keyField.getType().storedToReadable(uniqId);          \n        }\n        if (uniqVal != null) {\n          docNL.add(\"uniqueKey\", uniqVal);\n          termVectors.add(\"uniqueKeyFieldName\", uniqFieldName);\n        }\n      }\n      if (!fieldOptions.isEmpty()) {\n        for (Map.Entry<String, FieldOptions> entry : fieldOptions.entrySet()) {\n          mapper.fieldOptions = entry.getValue();\n          reader.getTermFreqVector(docId, entry.getKey(), mapper);\n        }\n      } else {\n        //deal with all fields by using the allFieldMapper\n        reader.getTermFreqVector(docId, mapper);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01":["c220849f876de24a79f756f65b3eb045db59f63f"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b5f7137bd9491c6596681b1f56e481e17964e581":["df18b2465217a237531d0d944c22ea4a4316411e"],"ab0e9f7ce724e6aea1fea746dded19e76d231cf8":["70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c26f00b574427b55127e869b935845554afde1fa":["b48b42b82c149773b4ccb139507e9bd29da91ca2","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"5f4e87790277826a2aea119328600dfb07761f32":["1da8d55113b689b06716246649de6f62430f15c0","df18b2465217a237531d0d944c22ea4a4316411e"],"b48b42b82c149773b4ccb139507e9bd29da91ca2":["ab0e9f7ce724e6aea1fea746dded19e76d231cf8"],"df18b2465217a237531d0d944c22ea4a4316411e":["1da8d55113b689b06716246649de6f62430f15c0"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["ab0e9f7ce724e6aea1fea746dded19e76d231cf8","b48b42b82c149773b4ccb139507e9bd29da91ca2"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["a3776dccca01c11e7046323cfad46a3b4a471233","b48b42b82c149773b4ccb139507e9bd29da91ca2"],"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"c220849f876de24a79f756f65b3eb045db59f63f":["b5f7137bd9491c6596681b1f56e481e17964e581"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"a3776dccca01c11e7046323cfad46a3b4a471233":["70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01","ab0e9f7ce724e6aea1fea746dded19e76d231cf8"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["df18b2465217a237531d0d944c22ea4a4316411e","70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["29ef99d61cda9641b6250bf9567329a6e65f901d","ab0e9f7ce724e6aea1fea746dded19e76d231cf8"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["b48b42b82c149773b4ccb139507e9bd29da91ca2"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["5f4e87790277826a2aea119328600dfb07761f32","c220849f876de24a79f756f65b3eb045db59f63f"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["868da859b43505d9d2a023bfeae6dd0c795f5295","70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01":["ab0e9f7ce724e6aea1fea746dded19e76d231cf8","a3776dccca01c11e7046323cfad46a3b4a471233","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"b5f7137bd9491c6596681b1f56e481e17964e581":["c220849f876de24a79f756f65b3eb045db59f63f"],"ab0e9f7ce724e6aea1fea746dded19e76d231cf8":["b48b42b82c149773b4ccb139507e9bd29da91ca2","d083e83f225b11e5fdd900e83d26ddb385b6955c","a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"5f4e87790277826a2aea119328600dfb07761f32":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"df18b2465217a237531d0d944c22ea4a4316411e":["b5f7137bd9491c6596681b1f56e481e17964e581","5f4e87790277826a2aea119328600dfb07761f32","29ef99d61cda9641b6250bf9567329a6e65f901d"],"b48b42b82c149773b4ccb139507e9bd29da91ca2":["c26f00b574427b55127e869b935845554afde1fa","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","a258fbb26824fd104ed795e5d9033d2d040049ee"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"817d8435e9135b756f08ce6710ab0baac51bdf88":["c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"1da8d55113b689b06716246649de6f62430f15c0":["5f4e87790277826a2aea119328600dfb07761f32","df18b2465217a237531d0d944c22ea4a4316411e"],"c220849f876de24a79f756f65b3eb045db59f63f":["70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01","868da859b43505d9d2a023bfeae6dd0c795f5295"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a3776dccca01c11e7046323cfad46a3b4a471233":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d083e83f225b11e5fdd900e83d26ddb385b6955c","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","a258fbb26824fd104ed795e5d9033d2d040049ee","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}