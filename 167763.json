{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#incrementToken().mjava","commits":[{"id":"098528909bb70948871fd7ed865fafb87ed73964","date":1484667487,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#incrementToken().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (savedState == null) {\n\n        // process a new input token\n        if (input.incrementToken() == false) {\n          return false;\n        }\n\n        int termLength = termAttribute.length();\n        char[] termBuffer = termAttribute.buffer();\n\n        accumPosInc += posIncAttribute.getPositionIncrement();\n\n        // iterate & cache all word parts up front:\n        iterator.setText(termBuffer, termLength);\n        iterator.next();\n        \n        // word of no delimiters, or protected word: just return it\n        if ((iterator.current == 0 && iterator.end == termLength) ||\n            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {\n          posIncAttribute.setPositionIncrement(accumPosInc);\n          accumPosInc = 0;\n          return true;\n        }\n        \n        // word of simply delimiters: swallow this token, creating a hole, and move on to next token\n        if (iterator.end == WordDelimiterIterator.DONE) {\n          if (has(PRESERVE_ORIGINAL) == false) {\n            continue;\n          } else {\n            return true;\n          }\n        }\n\n        // otherwise, we have delimiters, process & buffer all parts:\n        bufferWordParts();\n      }\n\n      if (bufferedPos < bufferedLen) {\n        clearAttributes();\n        restoreState(savedState);\n\n        char[] termPart = bufferedTermParts[bufferedPos];\n        int startPos = bufferedParts[4*bufferedPos];\n        int endPos = bufferedParts[4*bufferedPos+1];\n        int startPart = bufferedParts[4*bufferedPos+2];\n        int endPart = bufferedParts[4*bufferedPos+3];\n        bufferedPos++;\n\n        if (hasIllegalOffsets) {\n          offsetAttribute.setOffset(savedStartOffset, savedEndOffset);\n        } else {\n          offsetAttribute.setOffset(savedStartOffset + startPart, savedStartOffset + endPart);\n        }\n\n        if (termPart == null) {\n          termAttribute.copyBuffer(savedTermBuffer, startPart, endPart - startPart);\n        } else {\n          termAttribute.copyBuffer(termPart, 0, termPart.length);\n        }\n\n        posIncAttribute.setPositionIncrement(accumPosInc + startPos - wordPos);\n        accumPosInc = 0;\n        posLenAttribute.setPositionLength(endPos - startPos);\n        wordPos = startPos;\n        return true;\n      }\n        \n      // no saved concatenations, on to the next input word\n      savedState = null;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e34efa6b1fb7009ad746bc241b203a8b3ba17535","date":1484693831,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (savedState == null) {\n\n        // process a new input token\n        if (input.incrementToken() == false) {\n          return false;\n        }\n\n        int termLength = termAttribute.length();\n        char[] termBuffer = termAttribute.buffer();\n\n        accumPosInc += posIncAttribute.getPositionIncrement();\n\n        // iterate & cache all word parts up front:\n        iterator.setText(termBuffer, termLength);\n        iterator.next();\n        \n        // word of no delimiters, or protected word: just return it\n        if ((iterator.current == 0 && iterator.end == termLength) ||\n            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {\n          posIncAttribute.setPositionIncrement(accumPosInc);\n          accumPosInc = 0;\n          return true;\n        }\n        \n        // word of simply delimiters: swallow this token, creating a hole, and move on to next token\n        if (iterator.end == WordDelimiterIterator.DONE) {\n          if (has(PRESERVE_ORIGINAL) == false) {\n            continue;\n          } else {\n            return true;\n          }\n        }\n\n        // otherwise, we have delimiters, process & buffer all parts:\n        bufferWordParts();\n      }\n\n      if (bufferedPos < bufferedLen) {\n        clearAttributes();\n        restoreState(savedState);\n\n        char[] termPart = bufferedTermParts[bufferedPos];\n        int startPos = bufferedParts[4*bufferedPos];\n        int endPos = bufferedParts[4*bufferedPos+1];\n        int startPart = bufferedParts[4*bufferedPos+2];\n        int endPart = bufferedParts[4*bufferedPos+3];\n        bufferedPos++;\n\n        int startOffset;\n        int endOffset;\n\n        if (hasIllegalOffsets) {\n          startOffset = savedStartOffset;\n          endOffset = savedEndOffset;\n        } else {\n          startOffset = savedStartOffset + startPart;\n          endOffset = savedStartOffset + endPart;\n        }\n\n        // never let offsets go backwards:\n        startOffset = Math.max(startOffset, lastStartOffset);\n        endOffset = Math.max(endOffset, lastStartOffset);\n\n        offsetAttribute.setOffset(startOffset, endOffset);\n        lastStartOffset = startOffset;\n\n        if (termPart == null) {\n          termAttribute.copyBuffer(savedTermBuffer, startPart, endPart - startPart);\n        } else {\n          termAttribute.copyBuffer(termPart, 0, termPart.length);\n        }\n\n        posIncAttribute.setPositionIncrement(accumPosInc + startPos - wordPos);\n        accumPosInc = 0;\n        posLenAttribute.setPositionLength(endPos - startPos);\n        wordPos = startPos;\n        return true;\n      }\n        \n      // no saved concatenations, on to the next input word\n      savedState = null;\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (savedState == null) {\n\n        // process a new input token\n        if (input.incrementToken() == false) {\n          return false;\n        }\n\n        int termLength = termAttribute.length();\n        char[] termBuffer = termAttribute.buffer();\n\n        accumPosInc += posIncAttribute.getPositionIncrement();\n\n        // iterate & cache all word parts up front:\n        iterator.setText(termBuffer, termLength);\n        iterator.next();\n        \n        // word of no delimiters, or protected word: just return it\n        if ((iterator.current == 0 && iterator.end == termLength) ||\n            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {\n          posIncAttribute.setPositionIncrement(accumPosInc);\n          accumPosInc = 0;\n          return true;\n        }\n        \n        // word of simply delimiters: swallow this token, creating a hole, and move on to next token\n        if (iterator.end == WordDelimiterIterator.DONE) {\n          if (has(PRESERVE_ORIGINAL) == false) {\n            continue;\n          } else {\n            return true;\n          }\n        }\n\n        // otherwise, we have delimiters, process & buffer all parts:\n        bufferWordParts();\n      }\n\n      if (bufferedPos < bufferedLen) {\n        clearAttributes();\n        restoreState(savedState);\n\n        char[] termPart = bufferedTermParts[bufferedPos];\n        int startPos = bufferedParts[4*bufferedPos];\n        int endPos = bufferedParts[4*bufferedPos+1];\n        int startPart = bufferedParts[4*bufferedPos+2];\n        int endPart = bufferedParts[4*bufferedPos+3];\n        bufferedPos++;\n\n        if (hasIllegalOffsets) {\n          offsetAttribute.setOffset(savedStartOffset, savedEndOffset);\n        } else {\n          offsetAttribute.setOffset(savedStartOffset + startPart, savedStartOffset + endPart);\n        }\n\n        if (termPart == null) {\n          termAttribute.copyBuffer(savedTermBuffer, startPart, endPart - startPart);\n        } else {\n          termAttribute.copyBuffer(termPart, 0, termPart.length);\n        }\n\n        posIncAttribute.setPositionIncrement(accumPosInc + startPos - wordPos);\n        accumPosInc = 0;\n        posLenAttribute.setPositionLength(endPos - startPos);\n        wordPos = startPos;\n        return true;\n      }\n        \n      // no saved concatenations, on to the next input word\n      savedState = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"302d34f2c66e8d489ee13078305c330cbf67b226","date":1484754357,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#incrementToken().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (savedState == null) {\n\n        // process a new input token\n        if (input.incrementToken() == false) {\n          return false;\n        }\n\n        int termLength = termAttribute.length();\n        char[] termBuffer = termAttribute.buffer();\n\n        accumPosInc += posIncAttribute.getPositionIncrement();\n\n        // iterate & cache all word parts up front:\n        iterator.setText(termBuffer, termLength);\n        iterator.next();\n        \n        // word of no delimiters, or protected word: just return it\n        if ((iterator.current == 0 && iterator.end == termLength) ||\n            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {\n          posIncAttribute.setPositionIncrement(accumPosInc);\n          accumPosInc = 0;\n          return true;\n        }\n        \n        // word of simply delimiters: swallow this token, creating a hole, and move on to next token\n        if (iterator.end == WordDelimiterIterator.DONE) {\n          if (has(PRESERVE_ORIGINAL) == false) {\n            continue;\n          } else {\n            return true;\n          }\n        }\n\n        // otherwise, we have delimiters, process & buffer all parts:\n        bufferWordParts();\n      }\n\n      if (bufferedPos < bufferedLen) {\n        clearAttributes();\n        restoreState(savedState);\n\n        char[] termPart = bufferedTermParts[bufferedPos];\n        int startPos = bufferedParts[4*bufferedPos];\n        int endPos = bufferedParts[4*bufferedPos+1];\n        int startPart = bufferedParts[4*bufferedPos+2];\n        int endPart = bufferedParts[4*bufferedPos+3];\n        bufferedPos++;\n\n        int startOffset;\n        int endOffset;\n\n        if (hasIllegalOffsets) {\n          startOffset = savedStartOffset;\n          endOffset = savedEndOffset;\n        } else {\n          startOffset = savedStartOffset + startPart;\n          endOffset = savedStartOffset + endPart;\n        }\n\n        // never let offsets go backwards:\n        startOffset = Math.max(startOffset, lastStartOffset);\n        endOffset = Math.max(endOffset, lastStartOffset);\n\n        offsetAttribute.setOffset(startOffset, endOffset);\n        lastStartOffset = startOffset;\n\n        if (termPart == null) {\n          termAttribute.copyBuffer(savedTermBuffer, startPart, endPart - startPart);\n        } else {\n          termAttribute.copyBuffer(termPart, 0, termPart.length);\n        }\n\n        posIncAttribute.setPositionIncrement(accumPosInc + startPos - wordPos);\n        accumPosInc = 0;\n        posLenAttribute.setPositionLength(endPos - startPos);\n        wordPos = startPos;\n        return true;\n      }\n        \n      // no saved concatenations, on to the next input word\n      savedState = null;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eaa82f7ae8119e5850fcdeb0a7f2362a7d732bac","date":1524923226,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (savedState == null) {\n\n        // process a new input token\n        if (input.incrementToken() == false) {\n          return false;\n        }\n        if (has(IGNORE_KEYWORDS) && keywordAttribute.isKeyword()) {\n            return true;\n        }\n        int termLength = termAttribute.length();\n        char[] termBuffer = termAttribute.buffer();\n\n        accumPosInc += posIncAttribute.getPositionIncrement();\n\n        // iterate & cache all word parts up front:\n        iterator.setText(termBuffer, termLength);\n        iterator.next();\n        \n        // word of no delimiters, or protected word: just return it\n        if ((iterator.current == 0 && iterator.end == termLength) ||\n            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {\n          posIncAttribute.setPositionIncrement(accumPosInc);\n          accumPosInc = 0;\n          return true;\n        }\n        \n        // word of simply delimiters: swallow this token, creating a hole, and move on to next token\n        if (iterator.end == WordDelimiterIterator.DONE) {\n          if (has(PRESERVE_ORIGINAL) == false) {\n            continue;\n          } else {\n            return true;\n          }\n        }\n\n        // otherwise, we have delimiters, process & buffer all parts:\n        bufferWordParts();\n      }\n\n      if (bufferedPos < bufferedLen) {\n        clearAttributes();\n        restoreState(savedState);\n\n        char[] termPart = bufferedTermParts[bufferedPos];\n        int startPos = bufferedParts[4*bufferedPos];\n        int endPos = bufferedParts[4*bufferedPos+1];\n        int startPart = bufferedParts[4*bufferedPos+2];\n        int endPart = bufferedParts[4*bufferedPos+3];\n        bufferedPos++;\n\n        int startOffset;\n        int endOffset;\n\n        if (hasIllegalOffsets) {\n          startOffset = savedStartOffset;\n          endOffset = savedEndOffset;\n        } else {\n          startOffset = savedStartOffset + startPart;\n          endOffset = savedStartOffset + endPart;\n        }\n\n        // never let offsets go backwards:\n        startOffset = Math.max(startOffset, lastStartOffset);\n        endOffset = Math.max(endOffset, lastStartOffset);\n\n        offsetAttribute.setOffset(startOffset, endOffset);\n        lastStartOffset = startOffset;\n\n        if (termPart == null) {\n          termAttribute.copyBuffer(savedTermBuffer, startPart, endPart - startPart);\n        } else {\n          termAttribute.copyBuffer(termPart, 0, termPart.length);\n        }\n\n        posIncAttribute.setPositionIncrement(accumPosInc + startPos - wordPos);\n        accumPosInc = 0;\n        posLenAttribute.setPositionLength(endPos - startPos);\n        wordPos = startPos;\n        return true;\n      }\n        \n      // no saved concatenations, on to the next input word\n      savedState = null;\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (savedState == null) {\n\n        // process a new input token\n        if (input.incrementToken() == false) {\n          return false;\n        }\n\n        int termLength = termAttribute.length();\n        char[] termBuffer = termAttribute.buffer();\n\n        accumPosInc += posIncAttribute.getPositionIncrement();\n\n        // iterate & cache all word parts up front:\n        iterator.setText(termBuffer, termLength);\n        iterator.next();\n        \n        // word of no delimiters, or protected word: just return it\n        if ((iterator.current == 0 && iterator.end == termLength) ||\n            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {\n          posIncAttribute.setPositionIncrement(accumPosInc);\n          accumPosInc = 0;\n          return true;\n        }\n        \n        // word of simply delimiters: swallow this token, creating a hole, and move on to next token\n        if (iterator.end == WordDelimiterIterator.DONE) {\n          if (has(PRESERVE_ORIGINAL) == false) {\n            continue;\n          } else {\n            return true;\n          }\n        }\n\n        // otherwise, we have delimiters, process & buffer all parts:\n        bufferWordParts();\n      }\n\n      if (bufferedPos < bufferedLen) {\n        clearAttributes();\n        restoreState(savedState);\n\n        char[] termPart = bufferedTermParts[bufferedPos];\n        int startPos = bufferedParts[4*bufferedPos];\n        int endPos = bufferedParts[4*bufferedPos+1];\n        int startPart = bufferedParts[4*bufferedPos+2];\n        int endPart = bufferedParts[4*bufferedPos+3];\n        bufferedPos++;\n\n        int startOffset;\n        int endOffset;\n\n        if (hasIllegalOffsets) {\n          startOffset = savedStartOffset;\n          endOffset = savedEndOffset;\n        } else {\n          startOffset = savedStartOffset + startPart;\n          endOffset = savedStartOffset + endPart;\n        }\n\n        // never let offsets go backwards:\n        startOffset = Math.max(startOffset, lastStartOffset);\n        endOffset = Math.max(endOffset, lastStartOffset);\n\n        offsetAttribute.setOffset(startOffset, endOffset);\n        lastStartOffset = startOffset;\n\n        if (termPart == null) {\n          termAttribute.copyBuffer(savedTermBuffer, startPart, endPart - startPart);\n        } else {\n          termAttribute.copyBuffer(termPart, 0, termPart.length);\n        }\n\n        posIncAttribute.setPositionIncrement(accumPosInc + startPos - wordPos);\n        accumPosInc = 0;\n        posLenAttribute.setPositionLength(endPos - startPos);\n        wordPos = startPos;\n        return true;\n      }\n        \n      // no saved concatenations, on to the next input word\n      savedState = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"23972866716431cb443f3c6f50c0c37e301366d4","date":1531397584,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (savedState == null) {\n\n        // process a new input token\n        if (input.incrementToken() == false) {\n          return false;\n        }\n        if (has(IGNORE_KEYWORDS) && keywordAttribute.isKeyword()) {\n            return true;\n        }\n        int termLength = termAttribute.length();\n        char[] termBuffer = termAttribute.buffer();\n\n        accumPosInc += posIncAttribute.getPositionIncrement();\n\n        // iterate & cache all word parts up front:\n        iterator.setText(termBuffer, termLength);\n        iterator.next();\n        \n        // word of no delimiters, or protected word: just return it\n        if ((iterator.current == 0 && iterator.end == termLength) ||\n            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {\n          posIncAttribute.setPositionIncrement(accumPosInc);\n          accumPosInc = 0;\n          return true;\n        }\n        \n        // word of simply delimiters: swallow this token, creating a hole, and move on to next token\n        if (iterator.end == WordDelimiterIterator.DONE) {\n          if (has(PRESERVE_ORIGINAL) == false) {\n            continue;\n          } else {\n            accumPosInc = 0;\n            return true;\n          }\n        }\n\n        // otherwise, we have delimiters, process & buffer all parts:\n        bufferWordParts();\n      }\n\n      if (bufferedPos < bufferedLen) {\n        clearAttributes();\n        restoreState(savedState);\n\n        char[] termPart = bufferedTermParts[bufferedPos];\n        int startPos = bufferedParts[4*bufferedPos];\n        int endPos = bufferedParts[4*bufferedPos+1];\n        int startPart = bufferedParts[4*bufferedPos+2];\n        int endPart = bufferedParts[4*bufferedPos+3];\n        bufferedPos++;\n\n        int startOffset;\n        int endOffset;\n\n        if (hasIllegalOffsets) {\n          startOffset = savedStartOffset;\n          endOffset = savedEndOffset;\n        } else {\n          startOffset = savedStartOffset + startPart;\n          endOffset = savedStartOffset + endPart;\n        }\n\n        // never let offsets go backwards:\n        startOffset = Math.max(startOffset, lastStartOffset);\n        endOffset = Math.max(endOffset, lastStartOffset);\n\n        offsetAttribute.setOffset(startOffset, endOffset);\n        lastStartOffset = startOffset;\n\n        if (termPart == null) {\n          termAttribute.copyBuffer(savedTermBuffer, startPart, endPart - startPart);\n        } else {\n          termAttribute.copyBuffer(termPart, 0, termPart.length);\n        }\n\n        posIncAttribute.setPositionIncrement(accumPosInc + startPos - wordPos);\n        accumPosInc = 0;\n        posLenAttribute.setPositionLength(endPos - startPos);\n        wordPos = startPos;\n        return true;\n      }\n        \n      // no saved concatenations, on to the next input word\n      savedState = null;\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (savedState == null) {\n\n        // process a new input token\n        if (input.incrementToken() == false) {\n          return false;\n        }\n        if (has(IGNORE_KEYWORDS) && keywordAttribute.isKeyword()) {\n            return true;\n        }\n        int termLength = termAttribute.length();\n        char[] termBuffer = termAttribute.buffer();\n\n        accumPosInc += posIncAttribute.getPositionIncrement();\n\n        // iterate & cache all word parts up front:\n        iterator.setText(termBuffer, termLength);\n        iterator.next();\n        \n        // word of no delimiters, or protected word: just return it\n        if ((iterator.current == 0 && iterator.end == termLength) ||\n            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {\n          posIncAttribute.setPositionIncrement(accumPosInc);\n          accumPosInc = 0;\n          return true;\n        }\n        \n        // word of simply delimiters: swallow this token, creating a hole, and move on to next token\n        if (iterator.end == WordDelimiterIterator.DONE) {\n          if (has(PRESERVE_ORIGINAL) == false) {\n            continue;\n          } else {\n            return true;\n          }\n        }\n\n        // otherwise, we have delimiters, process & buffer all parts:\n        bufferWordParts();\n      }\n\n      if (bufferedPos < bufferedLen) {\n        clearAttributes();\n        restoreState(savedState);\n\n        char[] termPart = bufferedTermParts[bufferedPos];\n        int startPos = bufferedParts[4*bufferedPos];\n        int endPos = bufferedParts[4*bufferedPos+1];\n        int startPart = bufferedParts[4*bufferedPos+2];\n        int endPart = bufferedParts[4*bufferedPos+3];\n        bufferedPos++;\n\n        int startOffset;\n        int endOffset;\n\n        if (hasIllegalOffsets) {\n          startOffset = savedStartOffset;\n          endOffset = savedEndOffset;\n        } else {\n          startOffset = savedStartOffset + startPart;\n          endOffset = savedStartOffset + endPart;\n        }\n\n        // never let offsets go backwards:\n        startOffset = Math.max(startOffset, lastStartOffset);\n        endOffset = Math.max(endOffset, lastStartOffset);\n\n        offsetAttribute.setOffset(startOffset, endOffset);\n        lastStartOffset = startOffset;\n\n        if (termPart == null) {\n          termAttribute.copyBuffer(savedTermBuffer, startPart, endPart - startPart);\n        } else {\n          termAttribute.copyBuffer(termPart, 0, termPart.length);\n        }\n\n        posIncAttribute.setPositionIncrement(accumPosInc + startPos - wordPos);\n        accumPosInc = 0;\n        posLenAttribute.setPositionLength(endPos - startPos);\n        wordPos = startPos;\n        return true;\n      }\n        \n      // no saved concatenations, on to the next input word\n      savedState = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (savedState == null) {\n\n        // process a new input token\n        if (input.incrementToken() == false) {\n          return false;\n        }\n        if (has(IGNORE_KEYWORDS) && keywordAttribute.isKeyword()) {\n            return true;\n        }\n        int termLength = termAttribute.length();\n        char[] termBuffer = termAttribute.buffer();\n\n        accumPosInc += posIncAttribute.getPositionIncrement();\n\n        // iterate & cache all word parts up front:\n        iterator.setText(termBuffer, termLength);\n        iterator.next();\n        \n        // word of no delimiters, or protected word: just return it\n        if ((iterator.current == 0 && iterator.end == termLength) ||\n            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {\n          posIncAttribute.setPositionIncrement(accumPosInc);\n          accumPosInc = 0;\n          return true;\n        }\n        \n        // word of simply delimiters: swallow this token, creating a hole, and move on to next token\n        if (iterator.end == WordDelimiterIterator.DONE) {\n          if (has(PRESERVE_ORIGINAL) == false) {\n            continue;\n          } else {\n            accumPosInc = 0;\n            return true;\n          }\n        }\n\n        // otherwise, we have delimiters, process & buffer all parts:\n        bufferWordParts();\n      }\n\n      if (bufferedPos < bufferedLen) {\n        clearAttributes();\n        restoreState(savedState);\n\n        char[] termPart = bufferedTermParts[bufferedPos];\n        int startPos = bufferedParts[4*bufferedPos];\n        int endPos = bufferedParts[4*bufferedPos+1];\n        int startPart = bufferedParts[4*bufferedPos+2];\n        int endPart = bufferedParts[4*bufferedPos+3];\n        bufferedPos++;\n\n        int startOffset;\n        int endOffset;\n\n        if (hasIllegalOffsets) {\n          startOffset = savedStartOffset;\n          endOffset = savedEndOffset;\n        } else {\n          startOffset = savedStartOffset + startPart;\n          endOffset = savedStartOffset + endPart;\n        }\n\n        // never let offsets go backwards:\n        startOffset = Math.max(startOffset, lastStartOffset);\n        endOffset = Math.max(endOffset, lastStartOffset);\n\n        offsetAttribute.setOffset(startOffset, endOffset);\n        lastStartOffset = startOffset;\n\n        if (termPart == null) {\n          termAttribute.copyBuffer(savedTermBuffer, startPart, endPart - startPart);\n        } else {\n          termAttribute.copyBuffer(termPart, 0, termPart.length);\n        }\n\n        posIncAttribute.setPositionIncrement(accumPosInc + startPos - wordPos);\n        accumPosInc = 0;\n        posLenAttribute.setPositionLength(endPos - startPos);\n        wordPos = startPos;\n        return true;\n      }\n        \n      // no saved concatenations, on to the next input word\n      savedState = null;\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (savedState == null) {\n\n        // process a new input token\n        if (input.incrementToken() == false) {\n          return false;\n        }\n        if (has(IGNORE_KEYWORDS) && keywordAttribute.isKeyword()) {\n            return true;\n        }\n        int termLength = termAttribute.length();\n        char[] termBuffer = termAttribute.buffer();\n\n        accumPosInc += posIncAttribute.getPositionIncrement();\n\n        // iterate & cache all word parts up front:\n        iterator.setText(termBuffer, termLength);\n        iterator.next();\n        \n        // word of no delimiters, or protected word: just return it\n        if ((iterator.current == 0 && iterator.end == termLength) ||\n            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {\n          posIncAttribute.setPositionIncrement(accumPosInc);\n          accumPosInc = 0;\n          return true;\n        }\n        \n        // word of simply delimiters: swallow this token, creating a hole, and move on to next token\n        if (iterator.end == WordDelimiterIterator.DONE) {\n          if (has(PRESERVE_ORIGINAL) == false) {\n            continue;\n          } else {\n            return true;\n          }\n        }\n\n        // otherwise, we have delimiters, process & buffer all parts:\n        bufferWordParts();\n      }\n\n      if (bufferedPos < bufferedLen) {\n        clearAttributes();\n        restoreState(savedState);\n\n        char[] termPart = bufferedTermParts[bufferedPos];\n        int startPos = bufferedParts[4*bufferedPos];\n        int endPos = bufferedParts[4*bufferedPos+1];\n        int startPart = bufferedParts[4*bufferedPos+2];\n        int endPart = bufferedParts[4*bufferedPos+3];\n        bufferedPos++;\n\n        int startOffset;\n        int endOffset;\n\n        if (hasIllegalOffsets) {\n          startOffset = savedStartOffset;\n          endOffset = savedEndOffset;\n        } else {\n          startOffset = savedStartOffset + startPart;\n          endOffset = savedStartOffset + endPart;\n        }\n\n        // never let offsets go backwards:\n        startOffset = Math.max(startOffset, lastStartOffset);\n        endOffset = Math.max(endOffset, lastStartOffset);\n\n        offsetAttribute.setOffset(startOffset, endOffset);\n        lastStartOffset = startOffset;\n\n        if (termPart == null) {\n          termAttribute.copyBuffer(savedTermBuffer, startPart, endPart - startPart);\n        } else {\n          termAttribute.copyBuffer(termPart, 0, termPart.length);\n        }\n\n        posIncAttribute.setPositionIncrement(accumPosInc + startPos - wordPos);\n        accumPosInc = 0;\n        posLenAttribute.setPositionLength(endPos - startPos);\n        wordPos = startPos;\n        return true;\n      }\n        \n      // no saved concatenations, on to the next input word\n      savedState = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (savedState == null) {\n\n        // process a new input token\n        if (input.incrementToken() == false) {\n          return false;\n        }\n        if (has(IGNORE_KEYWORDS) && keywordAttribute.isKeyword()) {\n            return true;\n        }\n        int termLength = termAttribute.length();\n        char[] termBuffer = termAttribute.buffer();\n\n        accumPosInc += posIncAttribute.getPositionIncrement();\n\n        // iterate & cache all word parts up front:\n        iterator.setText(termBuffer, termLength);\n        iterator.next();\n        \n        // word of no delimiters, or protected word: just return it\n        if ((iterator.current == 0 && iterator.end == termLength) ||\n            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {\n          posIncAttribute.setPositionIncrement(accumPosInc);\n          accumPosInc = 0;\n          return true;\n        }\n        \n        // word of simply delimiters: swallow this token, creating a hole, and move on to next token\n        if (iterator.end == WordDelimiterIterator.DONE) {\n          if (has(PRESERVE_ORIGINAL) == false) {\n            continue;\n          } else {\n            accumPosInc = 0;\n            return true;\n          }\n        }\n\n        // otherwise, we have delimiters, process & buffer all parts:\n        bufferWordParts();\n      }\n\n      if (bufferedPos < bufferedLen) {\n        clearAttributes();\n        restoreState(savedState);\n\n        char[] termPart = bufferedTermParts[bufferedPos];\n        int startPos = bufferedParts[4*bufferedPos];\n        int endPos = bufferedParts[4*bufferedPos+1];\n        int startPart = bufferedParts[4*bufferedPos+2];\n        int endPart = bufferedParts[4*bufferedPos+3];\n        bufferedPos++;\n\n        int startOffset;\n        int endOffset;\n\n        if (hasIllegalOffsets) {\n          startOffset = savedStartOffset;\n          endOffset = savedEndOffset;\n        } else {\n          startOffset = savedStartOffset + startPart;\n          endOffset = savedStartOffset + endPart;\n        }\n\n        // never let offsets go backwards:\n        startOffset = Math.max(startOffset, lastStartOffset);\n        endOffset = Math.max(endOffset, lastStartOffset);\n\n        offsetAttribute.setOffset(startOffset, endOffset);\n        lastStartOffset = startOffset;\n\n        if (termPart == null) {\n          termAttribute.copyBuffer(savedTermBuffer, startPart, endPart - startPart);\n        } else {\n          termAttribute.copyBuffer(termPart, 0, termPart.length);\n        }\n\n        posIncAttribute.setPositionIncrement(accumPosInc + startPos - wordPos);\n        accumPosInc = 0;\n        posLenAttribute.setPositionLength(endPos - startPos);\n        wordPos = startPos;\n        return true;\n      }\n        \n      // no saved concatenations, on to the next input word\n      savedState = null;\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (savedState == null) {\n\n        // process a new input token\n        if (input.incrementToken() == false) {\n          return false;\n        }\n        if (has(IGNORE_KEYWORDS) && keywordAttribute.isKeyword()) {\n            return true;\n        }\n        int termLength = termAttribute.length();\n        char[] termBuffer = termAttribute.buffer();\n\n        accumPosInc += posIncAttribute.getPositionIncrement();\n\n        // iterate & cache all word parts up front:\n        iterator.setText(termBuffer, termLength);\n        iterator.next();\n        \n        // word of no delimiters, or protected word: just return it\n        if ((iterator.current == 0 && iterator.end == termLength) ||\n            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {\n          posIncAttribute.setPositionIncrement(accumPosInc);\n          accumPosInc = 0;\n          return true;\n        }\n        \n        // word of simply delimiters: swallow this token, creating a hole, and move on to next token\n        if (iterator.end == WordDelimiterIterator.DONE) {\n          if (has(PRESERVE_ORIGINAL) == false) {\n            continue;\n          } else {\n            return true;\n          }\n        }\n\n        // otherwise, we have delimiters, process & buffer all parts:\n        bufferWordParts();\n      }\n\n      if (bufferedPos < bufferedLen) {\n        clearAttributes();\n        restoreState(savedState);\n\n        char[] termPart = bufferedTermParts[bufferedPos];\n        int startPos = bufferedParts[4*bufferedPos];\n        int endPos = bufferedParts[4*bufferedPos+1];\n        int startPart = bufferedParts[4*bufferedPos+2];\n        int endPart = bufferedParts[4*bufferedPos+3];\n        bufferedPos++;\n\n        int startOffset;\n        int endOffset;\n\n        if (hasIllegalOffsets) {\n          startOffset = savedStartOffset;\n          endOffset = savedEndOffset;\n        } else {\n          startOffset = savedStartOffset + startPart;\n          endOffset = savedStartOffset + endPart;\n        }\n\n        // never let offsets go backwards:\n        startOffset = Math.max(startOffset, lastStartOffset);\n        endOffset = Math.max(endOffset, lastStartOffset);\n\n        offsetAttribute.setOffset(startOffset, endOffset);\n        lastStartOffset = startOffset;\n\n        if (termPart == null) {\n          termAttribute.copyBuffer(savedTermBuffer, startPart, endPart - startPart);\n        } else {\n          termAttribute.copyBuffer(termPart, 0, termPart.length);\n        }\n\n        posIncAttribute.setPositionIncrement(accumPosInc + startPos - wordPos);\n        accumPosInc = 0;\n        posLenAttribute.setPositionLength(endPos - startPos);\n        wordPos = startPos;\n        return true;\n      }\n        \n      // no saved concatenations, on to the next input word\n      savedState = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"47e241984c8185946746fd8e18cff4200659091e","date":1543916862,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterGraphFilter#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (savedState == null) {\n\n        // process a new input token\n        if (input.incrementToken() == false) {\n          return false;\n        }\n        if (has(IGNORE_KEYWORDS) && keywordAttribute.isKeyword()) {\n            return true;\n        }\n        int termLength = termAttribute.length();\n        char[] termBuffer = termAttribute.buffer();\n\n        accumPosInc += posIncAttribute.getPositionIncrement();\n\n        // iterate & cache all word parts up front:\n        iterator.setText(termBuffer, termLength);\n        iterator.next();\n        \n        // word of no delimiters, or protected word: just return it\n        if ((iterator.current == 0 && iterator.end == termLength) ||\n            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {\n          posIncAttribute.setPositionIncrement(accumPosInc);\n          accumPosInc = 0;\n          return true;\n        }\n        \n        // word of simply delimiters: swallow this token, creating a hole, and move on to next token\n        if (iterator.end == WordDelimiterIterator.DONE) {\n          if (has(PRESERVE_ORIGINAL) == false) {\n            continue;\n          } else {\n            accumPosInc = 0;\n            return true;\n          }\n        }\n\n        // otherwise, we have delimiters, process & buffer all parts:\n        bufferWordParts();\n      }\n\n      if (bufferedPos < bufferedLen) {\n        clearAttributes();\n        restoreState(savedState);\n\n        char[] termPart = bufferedTermParts[bufferedPos];\n        int startPos = bufferedParts[4*bufferedPos];\n        int endPos = bufferedParts[4*bufferedPos+1];\n        int startPart = bufferedParts[4*bufferedPos+2];\n        int endPart = bufferedParts[4*bufferedPos+3];\n        bufferedPos++;\n\n        int startOffset;\n        int endOffset;\n\n        if (adjustingOffsets == false) {\n          startOffset = savedStartOffset;\n          endOffset = savedEndOffset;\n        } else {\n          startOffset = savedStartOffset + startPart;\n          endOffset = savedStartOffset + endPart;\n        }\n\n        // never let offsets go backwards:\n        startOffset = Math.max(startOffset, lastStartOffset);\n        endOffset = Math.max(endOffset, lastStartOffset);\n\n        offsetAttribute.setOffset(startOffset, endOffset);\n        lastStartOffset = startOffset;\n\n        if (termPart == null) {\n          termAttribute.copyBuffer(savedTermBuffer, startPart, endPart - startPart);\n        } else {\n          termAttribute.copyBuffer(termPart, 0, termPart.length);\n        }\n\n        posIncAttribute.setPositionIncrement(accumPosInc + startPos - wordPos);\n        accumPosInc = 0;\n        posLenAttribute.setPositionLength(endPos - startPos);\n        wordPos = startPos;\n        return true;\n      }\n        \n      // no saved concatenations, on to the next input word\n      savedState = null;\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n    while (true) {\n      if (savedState == null) {\n\n        // process a new input token\n        if (input.incrementToken() == false) {\n          return false;\n        }\n        if (has(IGNORE_KEYWORDS) && keywordAttribute.isKeyword()) {\n            return true;\n        }\n        int termLength = termAttribute.length();\n        char[] termBuffer = termAttribute.buffer();\n\n        accumPosInc += posIncAttribute.getPositionIncrement();\n\n        // iterate & cache all word parts up front:\n        iterator.setText(termBuffer, termLength);\n        iterator.next();\n        \n        // word of no delimiters, or protected word: just return it\n        if ((iterator.current == 0 && iterator.end == termLength) ||\n            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {\n          posIncAttribute.setPositionIncrement(accumPosInc);\n          accumPosInc = 0;\n          return true;\n        }\n        \n        // word of simply delimiters: swallow this token, creating a hole, and move on to next token\n        if (iterator.end == WordDelimiterIterator.DONE) {\n          if (has(PRESERVE_ORIGINAL) == false) {\n            continue;\n          } else {\n            accumPosInc = 0;\n            return true;\n          }\n        }\n\n        // otherwise, we have delimiters, process & buffer all parts:\n        bufferWordParts();\n      }\n\n      if (bufferedPos < bufferedLen) {\n        clearAttributes();\n        restoreState(savedState);\n\n        char[] termPart = bufferedTermParts[bufferedPos];\n        int startPos = bufferedParts[4*bufferedPos];\n        int endPos = bufferedParts[4*bufferedPos+1];\n        int startPart = bufferedParts[4*bufferedPos+2];\n        int endPart = bufferedParts[4*bufferedPos+3];\n        bufferedPos++;\n\n        int startOffset;\n        int endOffset;\n\n        if (hasIllegalOffsets) {\n          startOffset = savedStartOffset;\n          endOffset = savedEndOffset;\n        } else {\n          startOffset = savedStartOffset + startPart;\n          endOffset = savedStartOffset + endPart;\n        }\n\n        // never let offsets go backwards:\n        startOffset = Math.max(startOffset, lastStartOffset);\n        endOffset = Math.max(endOffset, lastStartOffset);\n\n        offsetAttribute.setOffset(startOffset, endOffset);\n        lastStartOffset = startOffset;\n\n        if (termPart == null) {\n          termAttribute.copyBuffer(savedTermBuffer, startPart, endPart - startPart);\n        } else {\n          termAttribute.copyBuffer(termPart, 0, termPart.length);\n        }\n\n        posIncAttribute.setPositionIncrement(accumPosInc + startPos - wordPos);\n        accumPosInc = 0;\n        posLenAttribute.setPositionLength(endPos - startPos);\n        wordPos = startPos;\n        return true;\n      }\n        \n      // no saved concatenations, on to the next input word\n      savedState = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e34efa6b1fb7009ad746bc241b203a8b3ba17535":["098528909bb70948871fd7ed865fafb87ed73964"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["eaa82f7ae8119e5850fcdeb0a7f2362a7d732bac","23972866716431cb443f3c6f50c0c37e301366d4"],"098528909bb70948871fd7ed865fafb87ed73964":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"eaa82f7ae8119e5850fcdeb0a7f2362a7d732bac":["e34efa6b1fb7009ad746bc241b203a8b3ba17535"],"47e241984c8185946746fd8e18cff4200659091e":["23972866716431cb443f3c6f50c0c37e301366d4"],"23972866716431cb443f3c6f50c0c37e301366d4":["eaa82f7ae8119e5850fcdeb0a7f2362a7d732bac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["47e241984c8185946746fd8e18cff4200659091e"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["eaa82f7ae8119e5850fcdeb0a7f2362a7d732bac","23972866716431cb443f3c6f50c0c37e301366d4"],"302d34f2c66e8d489ee13078305c330cbf67b226":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e34efa6b1fb7009ad746bc241b203a8b3ba17535"]},"commit2Childs":{"e34efa6b1fb7009ad746bc241b203a8b3ba17535":["eaa82f7ae8119e5850fcdeb0a7f2362a7d732bac","302d34f2c66e8d489ee13078305c330cbf67b226"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"098528909bb70948871fd7ed865fafb87ed73964":["e34efa6b1fb7009ad746bc241b203a8b3ba17535"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["098528909bb70948871fd7ed865fafb87ed73964","302d34f2c66e8d489ee13078305c330cbf67b226"],"eaa82f7ae8119e5850fcdeb0a7f2362a7d732bac":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","23972866716431cb443f3c6f50c0c37e301366d4","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"47e241984c8185946746fd8e18cff4200659091e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"23972866716431cb443f3c6f50c0c37e301366d4":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","47e241984c8185946746fd8e18cff4200659091e","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[],"302d34f2c66e8d489ee13078305c330cbf67b226":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","302d34f2c66e8d489ee13078305c330cbf67b226"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}