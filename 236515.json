{"path":"lucene/contrib/wordnet/src/test/org/apache/lucene/wordnet/TestSynonymTokenFilter.SynonymWhitespaceAnalyzer#reusableTokenStream(String,Reader).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/wordnet/src/test/org/apache/lucene/wordnet/TestSynonymTokenFilter.SynonymWhitespaceAnalyzer#reusableTokenStream(String,Reader).mjava","pathOld":"contrib/wordnet/src/test/org/apache/lucene/wordnet/TestSynonymTokenFilter.SynonymWhitespaceAnalyzer#reusableTokenStream(String,Reader).mjava","sourceNew":"    @Override\n    public TokenStream reusableTokenStream(String fieldName, Reader reader)\n        throws IOException {\n      SavedStreams streams = (SavedStreams) getPreviousTokenStream();\n      if (streams == null) {\n        streams = new SavedStreams();\n        streams.source = new WhitespaceTokenizer(TEST_VERSION_CURRENT, reader);\n        streams.result = new LowerCaseFilter(TEST_VERSION_CURRENT, streams.source);\n        streams.result = new SynonymTokenFilter(streams.result, synonyms, maxSynonyms);\n        setPreviousTokenStream(streams);\n      } else {\n        streams.source.reset(reader);\n        streams.result.reset(); // reset the SynonymTokenFilter\n      }\n      return streams.result;\n    }\n\n","sourceOld":"    @Override\n    public TokenStream reusableTokenStream(String fieldName, Reader reader)\n        throws IOException {\n      SavedStreams streams = (SavedStreams) getPreviousTokenStream();\n      if (streams == null) {\n        streams = new SavedStreams();\n        streams.source = new WhitespaceTokenizer(TEST_VERSION_CURRENT, reader);\n        streams.result = new LowerCaseFilter(TEST_VERSION_CURRENT, streams.source);\n        streams.result = new SynonymTokenFilter(streams.result, synonyms, maxSynonyms);\n        setPreviousTokenStream(streams);\n      } else {\n        streams.source.reset(reader);\n        streams.result.reset(); // reset the SynonymTokenFilter\n      }\n      return streams.result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"03276b2744036b1b19a7a2dd4b74ba7bc484f107","date":1274048508,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/wordnet/src/test/org/apache/lucene/wordnet/TestSynonymTokenFilter.SynonymWhitespaceAnalyzer#reusableTokenStream(String,Reader).mjava","pathOld":"lucene/contrib/wordnet/src/test/org/apache/lucene/wordnet/TestSynonymTokenFilter.SynonymWhitespaceAnalyzer#reusableTokenStream(String,Reader).mjava","sourceNew":"    @Override\n    public TokenStream reusableTokenStream(String fieldName, Reader reader)\n        throws IOException {\n      SavedStreams streams = (SavedStreams) getPreviousTokenStream();\n      if (streams == null) {\n        streams = new SavedStreams();\n        streams.source = new MockTokenizer(reader, MockTokenizer.WHITESPACE, true);\n        streams.result = new SynonymTokenFilter(streams.source, synonyms, maxSynonyms);\n        setPreviousTokenStream(streams);\n      } else {\n        streams.source.reset(reader);\n        streams.result.reset(); // reset the SynonymTokenFilter\n      }\n      return streams.result;\n    }\n\n","sourceOld":"    @Override\n    public TokenStream reusableTokenStream(String fieldName, Reader reader)\n        throws IOException {\n      SavedStreams streams = (SavedStreams) getPreviousTokenStream();\n      if (streams == null) {\n        streams = new SavedStreams();\n        streams.source = new WhitespaceTokenizer(TEST_VERSION_CURRENT, reader);\n        streams.result = new LowerCaseFilter(TEST_VERSION_CURRENT, streams.source);\n        streams.result = new SynonymTokenFilter(streams.result, synonyms, maxSynonyms);\n        setPreviousTokenStream(streams);\n      } else {\n        streams.source.reset(reader);\n        streams.result.reset(); // reset the SynonymTokenFilter\n      }\n      return streams.result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4","date":1305207152,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/wordnet/src/test/org/apache/lucene/wordnet/TestSynonymTokenFilter.SynonymWhitespaceAnalyzer#reusableTokenStream(String,Reader).mjava","pathOld":"lucene/contrib/wordnet/src/test/org/apache/lucene/wordnet/TestSynonymTokenFilter.SynonymWhitespaceAnalyzer#reusableTokenStream(String,Reader).mjava","sourceNew":"    @Override\n    public TokenStream reusableTokenStream(String fieldName, Reader reader)\n        throws IOException {\n      SavedStreams streams = (SavedStreams) getPreviousTokenStream();\n      if (streams == null) {\n        streams = new SavedStreams();\n        streams.source = new MockTokenizer(reader, MockTokenizer.WHITESPACE, true);\n        streams.result = new SynonymTokenFilter(streams.source, synonyms, maxSynonyms);\n        setPreviousTokenStream(streams);\n      } else {\n        streams.source.reset(reader);\n      }\n      return streams.result;\n    }\n\n","sourceOld":"    @Override\n    public TokenStream reusableTokenStream(String fieldName, Reader reader)\n        throws IOException {\n      SavedStreams streams = (SavedStreams) getPreviousTokenStream();\n      if (streams == null) {\n        streams = new SavedStreams();\n        streams.source = new MockTokenizer(reader, MockTokenizer.WHITESPACE, true);\n        streams.result = new SynonymTokenFilter(streams.source, synonyms, maxSynonyms);\n        setPreviousTokenStream(streams);\n      } else {\n        streams.source.reset(reader);\n        streams.result.reset(); // reset the SynonymTokenFilter\n      }\n      return streams.result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/wordnet/src/test/org/apache/lucene/wordnet/TestSynonymTokenFilter.SynonymWhitespaceAnalyzer#reusableTokenStream(String,Reader).mjava","pathOld":"lucene/contrib/wordnet/src/test/org/apache/lucene/wordnet/TestSynonymTokenFilter.SynonymWhitespaceAnalyzer#reusableTokenStream(String,Reader).mjava","sourceNew":"    @Override\n    public TokenStream reusableTokenStream(String fieldName, Reader reader)\n        throws IOException {\n      SavedStreams streams = (SavedStreams) getPreviousTokenStream();\n      if (streams == null) {\n        streams = new SavedStreams();\n        streams.source = new MockTokenizer(reader, MockTokenizer.WHITESPACE, true);\n        streams.result = new SynonymTokenFilter(streams.source, synonyms, maxSynonyms);\n        setPreviousTokenStream(streams);\n      } else {\n        streams.source.reset(reader);\n      }\n      return streams.result;\n    }\n\n","sourceOld":"    @Override\n    public TokenStream reusableTokenStream(String fieldName, Reader reader)\n        throws IOException {\n      SavedStreams streams = (SavedStreams) getPreviousTokenStream();\n      if (streams == null) {\n        streams = new SavedStreams();\n        streams.source = new MockTokenizer(reader, MockTokenizer.WHITESPACE, true);\n        streams.result = new SynonymTokenFilter(streams.source, synonyms, maxSynonyms);\n        setPreviousTokenStream(streams);\n      } else {\n        streams.source.reset(reader);\n        streams.result.reset(); // reset the SynonymTokenFilter\n      }\n      return streams.result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/wordnet/src/test/org/apache/lucene/wordnet/TestSynonymTokenFilter.SynonymWhitespaceAnalyzer#reusableTokenStream(String,Reader).mjava","pathOld":"lucene/contrib/wordnet/src/test/org/apache/lucene/wordnet/TestSynonymTokenFilter.SynonymWhitespaceAnalyzer#reusableTokenStream(String,Reader).mjava","sourceNew":"    @Override\n    public TokenStream reusableTokenStream(String fieldName, Reader reader)\n        throws IOException {\n      SavedStreams streams = (SavedStreams) getPreviousTokenStream();\n      if (streams == null) {\n        streams = new SavedStreams();\n        streams.source = new MockTokenizer(reader, MockTokenizer.WHITESPACE, true);\n        streams.result = new SynonymTokenFilter(streams.source, synonyms, maxSynonyms);\n        setPreviousTokenStream(streams);\n      } else {\n        streams.source.reset(reader);\n      }\n      return streams.result;\n    }\n\n","sourceOld":"    @Override\n    public TokenStream reusableTokenStream(String fieldName, Reader reader)\n        throws IOException {\n      SavedStreams streams = (SavedStreams) getPreviousTokenStream();\n      if (streams == null) {\n        streams = new SavedStreams();\n        streams.source = new MockTokenizer(reader, MockTokenizer.WHITESPACE, true);\n        streams.result = new SynonymTokenFilter(streams.source, synonyms, maxSynonyms);\n        setPreviousTokenStream(streams);\n      } else {\n        streams.source.reset(reader);\n        streams.result.reset(); // reset the SynonymTokenFilter\n      }\n      return streams.result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"44d6f0ab53c1962856b9f48dedb7a2a6cc18905c","date":1310389132,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/contrib/wordnet/src/test/org/apache/lucene/wordnet/TestSynonymTokenFilter.SynonymWhitespaceAnalyzer#reusableTokenStream(String,Reader).mjava","sourceNew":null,"sourceOld":"    @Override\n    public TokenStream reusableTokenStream(String fieldName, Reader reader)\n        throws IOException {\n      SavedStreams streams = (SavedStreams) getPreviousTokenStream();\n      if (streams == null) {\n        streams = new SavedStreams();\n        streams.source = new MockTokenizer(reader, MockTokenizer.WHITESPACE, true);\n        streams.result = new SynonymTokenFilter(streams.source, synonyms, maxSynonyms);\n        setPreviousTokenStream(streams);\n      } else {\n        streams.source.reset(reader);\n      }\n      return streams.result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"03276b2744036b1b19a7a2dd4b74ba7bc484f107":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4":["03276b2744036b1b19a7a2dd4b74ba7bc484f107"],"a3776dccca01c11e7046323cfad46a3b4a471233":["03276b2744036b1b19a7a2dd4b74ba7bc484f107","e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["03276b2744036b1b19a7a2dd4b74ba7bc484f107","e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4"],"44d6f0ab53c1962856b9f48dedb7a2a6cc18905c":["e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"03276b2744036b1b19a7a2dd4b74ba7bc484f107":["e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4","a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4":["a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","44d6f0ab53c1962856b9f48dedb7a2a6cc18905c"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":[],"44d6f0ab53c1962856b9f48dedb7a2a6cc18905c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["03276b2744036b1b19a7a2dd4b74ba7bc484f107"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}