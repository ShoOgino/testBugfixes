{"path":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if ( (!\"Lucene3x\".equals(Codec.getDefault().getName())) && random.nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random.nextBoolean())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random.nextDouble() : 5*random.nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random.nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random.nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if ( (!\"Lucene3x\".equals(Codec.getDefault().getName())) && random.nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random.nextBoolean())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random.nextDouble() : 5*random.nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random.nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random.nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a78a90fc9701e511308346ea29f4f5e548bb39fe","date":1329489995,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if ( (!\"Lucene3x\".equals(Codec.getDefault().getName())) && random.nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random.nextBoolean())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random.nextDouble() : 5*random.nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random.nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random.nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if ( (!\"Lucene3x\".equals(Codec.getDefault().getName())) && random.nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random.nextBoolean())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random.nextDouble() : 5*random.nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random.nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random.nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"86365ce8db75e42ebe10805e99e92c463fef63b6","date":1330370408,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, defaultCodecSupportsDocValues());\n\n    //provider.register(new MemoryCodec());\n    if ( (!\"Lucene3x\".equals(Codec.getDefault().getName())) && random.nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random.nextBoolean())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random.nextDouble() : 5*random.nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random.nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random.nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if ( (!\"Lucene3x\".equals(Codec.getDefault().getName())) && random.nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random.nextBoolean())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random.nextDouble() : 5*random.nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random.nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random.nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, defaultCodecSupportsDocValues());\n\n    //provider.register(new MemoryCodec());\n    if ( (!\"Lucene3x\".equals(Codec.getDefault().getName())) && random.nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random.nextBoolean())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random.nextDouble() : 5*random.nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random.nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random.nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if ( (!\"Lucene3x\".equals(Codec.getDefault().getName())) && random.nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random.nextBoolean())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random.nextDouble() : 5*random.nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random.nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random.nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, defaultCodecSupportsDocValues());\n\n    //provider.register(new MemoryCodec());\n    if ( (!\"Lucene3x\".equals(Codec.getDefault().getName())) && random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random().nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, defaultCodecSupportsDocValues());\n\n    //provider.register(new MemoryCodec());\n    if ( (!\"Lucene3x\".equals(Codec.getDefault().getName())) && random.nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random.nextBoolean())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random.nextDouble() : 5*random.nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random.nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random.nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"57ae3024996ccdb3c36c42cb890e1efb37df4ce8","date":1338343651,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random().nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, defaultCodecSupportsDocValues());\n\n    //provider.register(new MemoryCodec());\n    if ( (!\"Lucene3x\".equals(Codec.getDefault().getName())) && random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random().nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"edb74c83fff94196b864e08ca033d92823252cb7","date":1339593164,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random().nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random().nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d19974432be9aed28ee7dca73bdf01d139e763a9","date":1342822166,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random().nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random().nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":["7a2ad3e19433f4c343b5e95ecc8a85cc33dffccc"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","date":1343059585,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random().nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random().nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random().nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final MockDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random().nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9f34c5d933e4285a78285d5ec91cd6b4baf2bb81","date":1343947587,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = new IndexSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random().nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["7e4c214a1f904dde76f5611b56d4081533055b3b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8fd5be977c105554c6a7b68afcdbc511439723ab","date":1344115570,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = new IndexSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random().nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = new IndexSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n      w.updateDocument(new Term(\"docid\", myID), doc);\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n        final boolean applyDeletions = random().nextBoolean();\n        r = w.getReader(applyDeletions);\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"409324b31a1419d7c05a38211168cf317e39be77","date":1344866765,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = new IndexSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = new IndexSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = new IndexSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = new IndexSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"90dfa8ee4e9e118b4c2c1c042bf57d9b460613de","date":1349114144,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = new IndexSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n\n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentInfoPerCommit sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = new IndexSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9eae2a56dc810a17cf807d831f720dec931a03de","date":1349262073,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = new IndexSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentInfoPerCommit sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    dir.setCheckIndexOnClose(false); // we use a custom codec provider\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = new IndexSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n    docs.close();\n    \n    _TestUtil.checkIndex(dir);\n\n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentInfoPerCommit sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173","date":1365631993,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentInfoPerCommit sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = new IndexSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentInfoPerCommit sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"59a0020b413d44dd79d85d7a66ed5004265fb453","date":1371758877,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentInfoPerCommit sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentInfoPerCommit sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentInfoPerCommit sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = \"\"+id;\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentInfoPerCommit sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentInfoPerCommit sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(_TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0400125abecdd77e3fb03fb5c7d0e339db632e8b","date":1394277288,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","date":1394564625,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.shutdown();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.shutdown();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.shutdown();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.shutdown();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13","date":1409346855,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3384e6013a93e4d11b7d75388693f8d0388602bf","date":1413951663,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = new SegmentInfos();\n    infos.read(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e4c214a1f904dde76f5611b56d4081533055b3b","date":1421938451,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        w.updateDocument(idTerm, doc);\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":["9f34c5d933e4285a78285d5ec91cd6b4baf2bb81"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"22989c36ff05c657df26dd3377b37c9ad35859bc","date":1424477375,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    for(String fileName : dir.listAll()) {\n      if (!fileName.startsWith(IndexFileNames.SEGMENTS)) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      doc.getField(\"docid\").setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d49a158012a8ff48f328a4558e4bfcffbaed16f","date":1453677440,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6bfe104fc023fadc9e709f8d17403d2cc61133fe","date":1454446396,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b470f36a9372c97283360b1304eacbde22df6c0d","date":1454765175,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a207d19eac354d649c3f0e2cce070017c78125e","date":1454776470,"type":3,"author":"Erick Erickson","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    // test checks for no unref'ed files with the IW helper method, which isn't aware of \"tried to delete files\"\n    if (dir instanceof MockDirectoryWrapper) {\n      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);\n    }\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"68496c2200e559fb7802f7575427b7a482659afb","date":1455207618,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"221076a44effb5561a3b799974ba1a35119fbcc0","date":1457468497,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random, true);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f6df47cbfd656ea50ca2996361f7954531ee18b","date":1464133540,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = w.tryDeleteDocument(r, hits.scoreDocs[0].doc) == -1;\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6483e4260c08168709c02238ae083a51519a28dd","date":1465117546,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = w.tryDeleteDocument(r, hits.scoreDocs[0].doc) == -1;\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"191128ac5b85671b1671e2c857437694283b6ebf","date":1465297861,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = w.tryDeleteDocument(r, hits.scoreDocs[0].doc) == -1;\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = w.tryDeleteDocument(r, hits.scoreDocs[0].doc) == -1;\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = !w.tryDeleteDocument(r, hits.scoreDocs[0].doc);\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"24f89e8a6aac05753cde4c83d62a74356098200d","date":1525768331,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random);\n\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(\n          new DirectPostingsFormat()));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = w.tryDeleteDocument(r, hits.scoreDocs[0].doc) == -1;\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random);\n\n    //provider.register(new MemoryCodec());\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(new MemoryPostingsFormat(random().nextBoolean(), random.nextFloat())));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = w.tryDeleteDocument(r, hits.scoreDocs[0].doc) == -1;\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random);\n\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(\n          new DirectPostingsFormat()));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits.value);\n        doUpdate = w.tryDeleteDocument(r, hits.scoreDocs[0].doc) == -1;\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random);\n\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(\n          new DirectPostingsFormat()));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits);\n        doUpdate = w.tryDeleteDocument(r, hits.scoreDocs[0].doc) == -1;\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"feb4029567b43f074ed7b6eb8fb126d355075dfd","date":1544812585,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestRollingUpdates#testRollingUpdates().mjava","sourceNew":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random);\n\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(\n          new DirectPostingsFormat()));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits.value);\n        doUpdate = w.tryDeleteDocument(r, hits.scoreDocs[0].doc) == -1;\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.getDocStats().numDocs);\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testRollingUpdates() throws Exception {\n    Random random = new Random(random().nextLong());\n    final BaseDirectoryWrapper dir = newDirectory();\n    \n    final LineFileDocs docs = new LineFileDocs(random);\n\n    if (random().nextBoolean()) {\n      Codec.setDefault(TestUtil.alwaysPostingsFormat(\n          new DirectPostingsFormat()));\n    }\n\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    final int SIZE = atLeast(20);\n    int id = 0;\n    IndexReader r = null;\n    IndexSearcher s = null;\n    final int numUpdates = (int) (SIZE * (2+(TEST_NIGHTLY ? 200*random().nextDouble() : 5*random().nextDouble())));\n    if (VERBOSE) {\n      System.out.println(\"TEST: numUpdates=\" + numUpdates);\n    }\n    int updateCount = 0;\n    // TODO: sometimes update ids not in order...\n    for(int docIter=0;docIter<numUpdates;docIter++) {\n      final Document doc = docs.nextDoc();\n      final String myID = Integer.toString(id);\n      if (id == SIZE-1) {\n        id = 0;\n      } else {\n        id++;\n      }\n      if (VERBOSE) {\n        System.out.println(\"  docIter=\" + docIter + \" id=\" + id);\n      }\n      ((Field) doc.getField(\"docid\")).setStringValue(myID);\n\n      Term idTerm = new Term(\"docid\", myID);\n\n      final boolean doUpdate;\n      if (s != null && updateCount < SIZE) {\n        TopDocs hits = s.search(new TermQuery(idTerm), 1);\n        assertEquals(1, hits.totalHits.value);\n        doUpdate = w.tryDeleteDocument(r, hits.scoreDocs[0].doc) == -1;\n        if (VERBOSE) {\n          if (doUpdate) {\n            System.out.println(\"  tryDeleteDocument failed\");\n          } else {\n            System.out.println(\"  tryDeleteDocument succeeded\");\n          }\n        }\n      } else {\n        doUpdate = true;\n        if (VERBOSE) {\n          System.out.println(\"  no searcher: doUpdate=true\");\n        }\n      }\n\n      updateCount++;\n\n      if (doUpdate) {\n        if (random().nextBoolean()) {\n          w.updateDocument(idTerm, doc);\n        } else {\n          // It's OK to not be atomic for this test (no separate thread reopening readers):\n          w.deleteDocuments(new TermQuery(idTerm));\n          w.addDocument(doc);\n        }\n      } else {\n        w.addDocument(doc);\n      }\n\n      if (docIter >= SIZE && random().nextInt(50) == 17) {\n        if (r != null) {\n          r.close();\n        }\n\n        final boolean applyDeletions = random().nextBoolean();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: reopen applyDeletions=\" + applyDeletions);\n        }\n\n        r = w.getReader(applyDeletions, false);\n        if (applyDeletions) {\n          s = newSearcher(r);\n        } else {\n          s = null;\n        }\n        assertTrue(\"applyDeletions=\" + applyDeletions + \" r.numDocs()=\" + r.numDocs() + \" vs SIZE=\" + SIZE, !applyDeletions || r.numDocs() == SIZE);\n        updateCount = 0;\n      }\n    }\n\n    if (r != null) {\n      r.close();\n    }\n\n    w.commit();\n    assertEquals(SIZE, w.numDocs());\n\n    w.close();\n\n    TestIndexWriter.assertNoUnreferencedFiles(dir, \"leftover files after rolling updates\");\n\n    docs.close();\n    \n    // LUCENE-4455:\n    SegmentInfos infos = SegmentInfos.readLatestCommit(dir);\n    long totalBytes = 0;\n    for(SegmentCommitInfo sipc : infos) {\n      totalBytes += sipc.sizeInBytes();\n    }\n    long totalBytes2 = 0;\n    \n    for(String fileName : dir.listAll()) {\n      if (IndexFileNames.CODEC_FILE_PATTERN.matcher(fileName).matches()) {\n        totalBytes2 += dir.fileLength(fileName);\n      }\n    }\n    assertEquals(totalBytes2, totalBytes);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"409324b31a1419d7c05a38211168cf317e39be77":["d6f074e73200c07d54f242d3880a8da5a35ff97b"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173","59a0020b413d44dd79d85d7a66ed5004265fb453"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["a78a90fc9701e511308346ea29f4f5e548bb39fe","86365ce8db75e42ebe10805e99e92c463fef63b6"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"221076a44effb5561a3b799974ba1a35119fbcc0":["68496c2200e559fb7802f7575427b7a482659afb"],"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"aba371508186796cc6151d8223a5b4e16d02e26e":["edb74c83fff94196b864e08ca033d92823252cb7","d19974432be9aed28ee7dca73bdf01d139e763a9"],"24f89e8a6aac05753cde4c83d62a74356098200d":["191128ac5b85671b1671e2c857437694283b6ebf"],"6bfe104fc023fadc9e709f8d17403d2cc61133fe":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"68496c2200e559fb7802f7575427b7a482659afb":["5a207d19eac354d649c3f0e2cce070017c78125e","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["0400125abecdd77e3fb03fb5c7d0e339db632e8b"],"edb74c83fff94196b864e08ca033d92823252cb7":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["22989c36ff05c657df26dd3377b37c9ad35859bc"],"86365ce8db75e42ebe10805e99e92c463fef63b6":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["0d49a158012a8ff48f328a4558e4bfcffbaed16f","b470f36a9372c97283360b1304eacbde22df6c0d"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13"],"d19974432be9aed28ee7dca73bdf01d139e763a9":["edb74c83fff94196b864e08ca033d92823252cb7"],"feb4029567b43f074ed7b6eb8fb126d355075dfd":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"b470f36a9372c97283360b1304eacbde22df6c0d":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","6bfe104fc023fadc9e709f8d17403d2cc61133fe"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["aba371508186796cc6151d8223a5b4e16d02e26e","9f34c5d933e4285a78285d5ec91cd6b4baf2bb81"],"22989c36ff05c657df26dd3377b37c9ad35859bc":["7e4c214a1f904dde76f5611b56d4081533055b3b"],"0f6df47cbfd656ea50ca2996361f7954531ee18b":["221076a44effb5561a3b799974ba1a35119fbcc0"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["59a0020b413d44dd79d85d7a66ed5004265fb453"],"9f34c5d933e4285a78285d5ec91cd6b4baf2bb81":["d19974432be9aed28ee7dca73bdf01d139e763a9"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":["6613659748fe4411a7dcf85266e55db1f95f7315","0400125abecdd77e3fb03fb5c7d0e339db632e8b"],"5a207d19eac354d649c3f0e2cce070017c78125e":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","b470f36a9372c97283360b1304eacbde22df6c0d"],"0400125abecdd77e3fb03fb5c7d0e339db632e8b":["6613659748fe4411a7dcf85266e55db1f95f7315"],"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"191128ac5b85671b1671e2c857437694283b6ebf":["221076a44effb5561a3b799974ba1a35119fbcc0","6483e4260c08168709c02238ae083a51519a28dd"],"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173":["9eae2a56dc810a17cf807d831f720dec931a03de"],"a78a90fc9701e511308346ea29f4f5e548bb39fe":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"1d028314cced5858683a1bb4741423d0f934257b":["9f34c5d933e4285a78285d5ec91cd6b4baf2bb81","409324b31a1419d7c05a38211168cf317e39be77"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"59a0020b413d44dd79d85d7a66ed5004265fb453":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173"],"90dfa8ee4e9e118b4c2c1c042bf57d9b460613de":["1d028314cced5858683a1bb4741423d0f934257b"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":["edb74c83fff94196b864e08ca033d92823252cb7","d19974432be9aed28ee7dca73bdf01d139e763a9"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["24f89e8a6aac05753cde4c83d62a74356098200d"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"9eae2a56dc810a17cf807d831f720dec931a03de":["90dfa8ee4e9e118b4c2c1c042bf57d9b460613de"],"6613659748fe4411a7dcf85266e55db1f95f7315":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"6483e4260c08168709c02238ae083a51519a28dd":["221076a44effb5561a3b799974ba1a35119fbcc0","0f6df47cbfd656ea50ca2996361f7954531ee18b"],"8fd5be977c105554c6a7b68afcdbc511439723ab":["4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","9f34c5d933e4285a78285d5ec91cd6b4baf2bb81"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["221076a44effb5561a3b799974ba1a35119fbcc0","191128ac5b85671b1671e2c857437694283b6ebf"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"7e4c214a1f904dde76f5611b56d4081533055b3b":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13","3384e6013a93e4d11b7d75388693f8d0388602bf"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["86365ce8db75e42ebe10805e99e92c463fef63b6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["feb4029567b43f074ed7b6eb8fb126d355075dfd"],"0d49a158012a8ff48f328a4558e4bfcffbaed16f":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"]},"commit2Childs":{"409324b31a1419d7c05a38211168cf317e39be77":["1d028314cced5858683a1bb4741423d0f934257b"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"221076a44effb5561a3b799974ba1a35119fbcc0":["0f6df47cbfd656ea50ca2996361f7954531ee18b","191128ac5b85671b1671e2c857437694283b6ebf","6483e4260c08168709c02238ae083a51519a28dd","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["edb74c83fff94196b864e08ca033d92823252cb7"],"aba371508186796cc6151d8223a5b4e16d02e26e":["d6f074e73200c07d54f242d3880a8da5a35ff97b"],"24f89e8a6aac05753cde4c83d62a74356098200d":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"68496c2200e559fb7802f7575427b7a482659afb":["221076a44effb5561a3b799974ba1a35119fbcc0"],"6bfe104fc023fadc9e709f8d17403d2cc61133fe":["b470f36a9372c97283360b1304eacbde22df6c0d"],"edb74c83fff94196b864e08ca033d92823252cb7":["aba371508186796cc6151d8223a5b4e16d02e26e","d19974432be9aed28ee7dca73bdf01d139e763a9","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["6bfe104fc023fadc9e709f8d17403d2cc61133fe","b470f36a9372c97283360b1304eacbde22df6c0d","5a207d19eac354d649c3f0e2cce070017c78125e","0d49a158012a8ff48f328a4558e4bfcffbaed16f"],"86365ce8db75e42ebe10805e99e92c463fef63b6":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["68496c2200e559fb7802f7575427b7a482659afb"],"3384e6013a93e4d11b7d75388693f8d0388602bf":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"d19974432be9aed28ee7dca73bdf01d139e763a9":["aba371508186796cc6151d8223a5b4e16d02e26e","9f34c5d933e4285a78285d5ec91cd6b4baf2bb81","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7"],"b470f36a9372c97283360b1304eacbde22df6c0d":["1e6acbaae7af722f17204ceccf0f7db5753eccf3","5a207d19eac354d649c3f0e2cce070017c78125e"],"feb4029567b43f074ed7b6eb8fb126d355075dfd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["409324b31a1419d7c05a38211168cf317e39be77"],"22989c36ff05c657df26dd3377b37c9ad35859bc":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"0f6df47cbfd656ea50ca2996361f7954531ee18b":["6483e4260c08168709c02238ae083a51519a28dd"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["6613659748fe4411a7dcf85266e55db1f95f7315"],"9f34c5d933e4285a78285d5ec91cd6b4baf2bb81":["d6f074e73200c07d54f242d3880a8da5a35ff97b","1d028314cced5858683a1bb4741423d0f934257b","8fd5be977c105554c6a7b68afcdbc511439723ab"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":[],"5a207d19eac354d649c3f0e2cce070017c78125e":["68496c2200e559fb7802f7575427b7a482659afb"],"0400125abecdd77e3fb03fb5c7d0e339db632e8b":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a","a58bbbe1c866963764d3f15d3a26a6a85f6c6af4"],"98d2deb8c96c79ebef084a1f8e5a1a6c08608f13":["3384e6013a93e4d11b7d75388693f8d0388602bf","db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"191128ac5b85671b1671e2c857437694283b6ebf":["24f89e8a6aac05753cde4c83d62a74356098200d","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173":["37a0f60745e53927c4c876cfe5b5a58170f0646c","59a0020b413d44dd79d85d7a66ed5004265fb453"],"a78a90fc9701e511308346ea29f4f5e548bb39fe":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","86365ce8db75e42ebe10805e99e92c463fef63b6"],"1d028314cced5858683a1bb4741423d0f934257b":["90dfa8ee4e9e118b4c2c1c042bf57d9b460613de"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"59a0020b413d44dd79d85d7a66ed5004265fb453":["37a0f60745e53927c4c876cfe5b5a58170f0646c","73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"90dfa8ee4e9e118b4c2c1c042bf57d9b460613de":["9eae2a56dc810a17cf807d831f720dec931a03de"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":["8fd5be977c105554c6a7b68afcdbc511439723ab"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["feb4029567b43f074ed7b6eb8fb126d355075dfd"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"9eae2a56dc810a17cf807d831f720dec931a03de":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173"],"6613659748fe4411a7dcf85266e55db1f95f7315":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","0400125abecdd77e3fb03fb5c7d0e339db632e8b"],"6483e4260c08168709c02238ae083a51519a28dd":["191128ac5b85671b1671e2c857437694283b6ebf"],"8fd5be977c105554c6a7b68afcdbc511439723ab":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["98d2deb8c96c79ebef084a1f8e5a1a6c08608f13"],"7e4c214a1f904dde76f5611b56d4081533055b3b":["22989c36ff05c657df26dd3377b37c9ad35859bc"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["7e4c214a1f904dde76f5611b56d4081533055b3b"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"],"0d49a158012a8ff48f328a4558e4bfcffbaed16f":["1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","8fd5be977c105554c6a7b68afcdbc511439723ab","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}