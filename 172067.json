{"path":"solr/core/src/java/org/apache/solr/cloud/OverseerProcessor#run().mjava","commits":[{"id":"e31e6ce5848e5040d4c9ecbb25bc6ccf5d0894ac","date":1438841252,"type":1,"author":"Gregory Chanan","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerProcessor#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor#run().mjava","sourceNew":"  @Override\n  public void run() {\n    log.info(\"Process current queue of overseer operations\");\n    LeaderStatus isLeader = amILeader();\n    while (isLeader == LeaderStatus.DONT_KNOW) {\n      log.debug(\"am_i_leader unclear {}\", isLeader);\n      isLeader = amILeader();  // not a no, not a yes, try ask again\n    }\n\n    String oldestItemInWorkQueue = null;\n    // hasLeftOverItems - used for avoiding re-execution of async tasks that were processed by a previous Overseer.\n    // This variable is set in case there's any task found on the workQueue when the OCP starts up and\n    // the id for the queue tail is used as a marker to check for the task in completed/failed map in zk.\n    // Beyond the marker, all tasks can safely be assumed to have never been executed.\n    boolean hasLeftOverItems = true;\n\n    try {\n      oldestItemInWorkQueue = workQueue.getTailId();\n    } catch (KeeperException e) {\n      // We don't need to handle this. This is just a fail-safe which comes in handy in skipping already processed\n      // async calls.\n      SolrException.log(log, \"\", e);\n    } catch (InterruptedException e) {\n      Thread.currentThread().interrupt();\n    }\n\n    if (oldestItemInWorkQueue == null)\n      hasLeftOverItems = false;\n    else\n      log.debug(\"Found already existing elements in the work-queue. Last element: {}\", oldestItemInWorkQueue);\n\n    try {\n      prioritizer.prioritizeOverseerNodes(myId);\n    } catch (Exception e) {\n      log.error(\"Unable to prioritize overseer \", e);\n    }\n\n    // TODO: Make maxThreads configurable.\n\n    this.tpe = new ExecutorUtil.MDCAwareThreadPoolExecutor(5, 100, 0L, TimeUnit.MILLISECONDS,\n        new SynchronousQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"OverseerThreadFactory\"));\n    try {\n      while (!this.isClosed) {\n        try {\n          isLeader = amILeader();\n          if (LeaderStatus.NO == isLeader) {\n            break;\n          } else if (LeaderStatus.YES != isLeader) {\n            log.debug(\"am_i_leader unclear {}\", isLeader);\n            continue; // not a no, not a yes, try asking again\n          }\n\n          log.debug(\"Cleaning up work-queue. #Running tasks: {}\", runningTasks.size());\n          cleanUpWorkQueue();\n\n          printTrackingMaps();\n\n          boolean waited = false;\n\n          while (runningTasks.size() > maxParallelThreads) {\n            synchronized (waitLock) {\n              waitLock.wait(100);//wait for 100 ms or till a task is complete\n            }\n            waited = true;\n          }\n\n          if (waited)\n            cleanUpWorkQueue();\n\n          List<QueueEvent> heads = workQueue.peekTopN(maxParallelThreads, runningZKTasks, 2000L);\n\n          if (heads == null)\n            continue;\n\n          log.debug(\"Got {} tasks from work-queue : [{}]\", heads.size(), heads.toString());\n\n          if (isClosed) break;\n\n          for (QueueEvent head : heads) {\n            final ZkNodeProps message = ZkNodeProps.load(head.getBytes());\n            OverseerMessageHandler messageHandler = selector.selectOverseerMessageHandler(message);\n            String taskKey = messageHandler.getTaskKey(message);\n            final String asyncId = message.getStr(ASYNC);\n            if (hasLeftOverItems) {\n              if (head.getId().equals(oldestItemInWorkQueue))\n                hasLeftOverItems = false;\n              if (asyncId != null && (completedMap.contains(asyncId) || failureMap.contains(asyncId))) {\n                log.debug(\"Found already processed task in workQueue, cleaning up. AsyncId [{}]\",asyncId );\n                workQueue.remove(head);\n                continue;\n              }\n            }\n\n            if (!checkExclusivity(messageHandler, message, head.getId())) {\n              log.debug(\"Exclusivity check failed for [{}]\", message.toString());\n              continue;\n            }\n\n            try {\n              markTaskAsRunning(messageHandler, head, taskKey, asyncId, message);\n              log.debug(\"Marked task [{}] as running\", head.getId());\n            } catch (KeeperException.NodeExistsException e) {\n              // This should never happen\n              log.error(\"Tried to pick up task [{}] when it was already running!\", head.getId());\n            } catch (InterruptedException e) {\n              log.error(\"Thread interrupted while trying to pick task for execution.\", head.getId());\n              Thread.currentThread().interrupt();\n            }\n\n            log.info(messageHandler.getName() + \": Get the message id:\" + head.getId() + \" message:\" + message.toString());\n            String operation = message.getStr(Overseer.QUEUE_OPERATION);\n            Runner runner = new Runner(messageHandler, message,\n                operation, head);\n            tpe.execute(runner);\n          }\n\n        } catch (KeeperException e) {\n          if (e.code() == KeeperException.Code.SESSIONEXPIRED) {\n            log.warn(\"Overseer cannot talk to ZK\");\n            return;\n          }\n          SolrException.log(log, \"\", e);\n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          return;\n        } catch (Exception e) {\n          SolrException.log(log, \"\", e);\n        }\n      }\n    } finally {\n      this.close();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    log.info(\"Process current queue of collection creations\");\n    LeaderStatus isLeader = amILeader();\n    while (isLeader == LeaderStatus.DONT_KNOW) {\n      log.debug(\"am_i_leader unclear {}\", isLeader);\n      isLeader = amILeader();  // not a no, not a yes, try ask again\n    }\n\n    String oldestItemInWorkQueue = null;\n    // hasLeftOverItems - used for avoiding re-execution of async tasks that were processed by a previous Overseer.\n    // This variable is set in case there's any task found on the workQueue when the OCP starts up and\n    // the id for the queue tail is used as a marker to check for the task in completed/failed map in zk.\n    // Beyond the marker, all tasks can safely be assumed to have never been executed.\n    boolean hasLeftOverItems = true;\n\n    try {\n      oldestItemInWorkQueue = workQueue.getTailId();\n    } catch (KeeperException e) {\n      // We don't need to handle this. This is just a fail-safe which comes in handy in skipping already processed\n      // async calls.\n      SolrException.log(log, \"\", e);\n    } catch (InterruptedException e) {\n      Thread.currentThread().interrupt();\n    }\n\n    if (oldestItemInWorkQueue == null)\n      hasLeftOverItems = false;\n    else\n      log.debug(\"Found already existing elements in the work-queue. Last element: {}\", oldestItemInWorkQueue);\n\n    try {\n      prioritizeOverseerNodes();\n    } catch (Exception e) {\n      log.error(\"Unable to prioritize overseer \", e);\n    }\n\n    // TODO: Make maxThreads configurable.\n\n    this.tpe = new ExecutorUtil.MDCAwareThreadPoolExecutor(5, 100, 0L, TimeUnit.MILLISECONDS,\n        new SynchronousQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"OverseerThreadFactory\"));\n    try {\n      while (!this.isClosed) {\n        try {\n          isLeader = amILeader();\n          if (LeaderStatus.NO == isLeader) {\n            break;\n          } else if (LeaderStatus.YES != isLeader) {\n            log.debug(\"am_i_leader unclear {}\", isLeader);\n            continue; // not a no, not a yes, try asking again\n          }\n\n          log.debug(\"Cleaning up work-queue. #Running tasks: {}\", runningTasks.size());\n          cleanUpWorkQueue();\n\n          printTrackingMaps();\n\n          boolean waited = false;\n\n          while (runningTasks.size() > maxParallelThreads) {\n            synchronized (waitLock) {\n              waitLock.wait(100);//wait for 100 ms or till a task is complete\n            }\n            waited = true;\n          }\n\n          if (waited)\n            cleanUpWorkQueue();\n\n          List<QueueEvent> heads = workQueue.peekTopN(maxParallelThreads, runningZKTasks, 2000L);\n\n          if (heads == null)\n            continue;\n\n          log.debug(\"Got {} tasks from work-queue : [{}]\", heads.size(), heads.toString());\n\n          if (isClosed) break;\n\n          for (QueueEvent head : heads) {\n            final ZkNodeProps message = ZkNodeProps.load(head.getBytes());\n            String collectionName = message.containsKey(COLLECTION_PROP) ?\n                message.getStr(COLLECTION_PROP) : message.getStr(NAME);\n            final String asyncId = message.getStr(ASYNC);\n            if (hasLeftOverItems) {\n              if (head.getId().equals(oldestItemInWorkQueue))\n                hasLeftOverItems = false;\n              if (asyncId != null && (completedMap.contains(asyncId) || failureMap.contains(asyncId))) {\n                log.debug(\"Found already processed task in workQueue, cleaning up. AsyncId [{}]\",asyncId );\n                workQueue.remove(head);\n                continue;\n              }\n            }\n\n            if (!checkExclusivity(message, head.getId())) {\n              log.debug(\"Exclusivity check failed for [{}]\", message.toString());\n              continue;\n            }\n\n            try {\n              markTaskAsRunning(head, collectionName, asyncId, message);\n              log.debug(\"Marked task [{}] as running\", head.getId());\n            } catch (KeeperException.NodeExistsException e) {\n              // This should never happen\n              log.error(\"Tried to pick up task [{}] when it was already running!\", head.getId());\n            } catch (InterruptedException e) {\n              log.error(\"Thread interrupted while trying to pick task for execution.\", head.getId());\n              Thread.currentThread().interrupt();\n            }\n\n            log.info(\"Overseer Collection Processor: Get the message id:\" + head.getId() + \" message:\" + message.toString());\n            String operation = message.getStr(Overseer.QUEUE_OPERATION);\n            Runner runner = new Runner(message,\n                operation, head);\n            tpe.execute(runner);\n          }\n\n        } catch (KeeperException e) {\n          if (e.code() == KeeperException.Code.SESSIONEXPIRED) {\n            log.warn(\"Overseer cannot talk to ZK\");\n            return;\n          }\n          SolrException.log(log, \"\", e);\n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          return;\n        } catch (Exception e) {\n          SolrException.log(log, \"\", e);\n        }\n      }\n    } finally {\n      this.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2209af2c265d2258ec4b29c8cc78622d36994a15","date":1440641916,"type":5,"author":"Gregory Chanan","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerTaskProcessor#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerProcessor#run().mjava","sourceNew":"  @Override\n  public void run() {\n    log.info(\"Process current queue of overseer operations\");\n    LeaderStatus isLeader = amILeader();\n    while (isLeader == LeaderStatus.DONT_KNOW) {\n      log.debug(\"am_i_leader unclear {}\", isLeader);\n      isLeader = amILeader();  // not a no, not a yes, try ask again\n    }\n\n    String oldestItemInWorkQueue = null;\n    // hasLeftOverItems - used for avoiding re-execution of async tasks that were processed by a previous Overseer.\n    // This variable is set in case there's any task found on the workQueue when the OCP starts up and\n    // the id for the queue tail is used as a marker to check for the task in completed/failed map in zk.\n    // Beyond the marker, all tasks can safely be assumed to have never been executed.\n    boolean hasLeftOverItems = true;\n\n    try {\n      oldestItemInWorkQueue = workQueue.getTailId();\n    } catch (KeeperException e) {\n      // We don't need to handle this. This is just a fail-safe which comes in handy in skipping already processed\n      // async calls.\n      SolrException.log(log, \"\", e);\n    } catch (InterruptedException e) {\n      Thread.currentThread().interrupt();\n    }\n\n    if (oldestItemInWorkQueue == null)\n      hasLeftOverItems = false;\n    else\n      log.debug(\"Found already existing elements in the work-queue. Last element: {}\", oldestItemInWorkQueue);\n\n    try {\n      prioritizer.prioritizeOverseerNodes(myId);\n    } catch (Exception e) {\n      log.error(\"Unable to prioritize overseer \", e);\n    }\n\n    // TODO: Make maxThreads configurable.\n\n    this.tpe = new ExecutorUtil.MDCAwareThreadPoolExecutor(5, 100, 0L, TimeUnit.MILLISECONDS,\n        new SynchronousQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"OverseerThreadFactory\"));\n    try {\n      while (!this.isClosed) {\n        try {\n          isLeader = amILeader();\n          if (LeaderStatus.NO == isLeader) {\n            break;\n          } else if (LeaderStatus.YES != isLeader) {\n            log.debug(\"am_i_leader unclear {}\", isLeader);\n            continue; // not a no, not a yes, try asking again\n          }\n\n          log.debug(\"Cleaning up work-queue. #Running tasks: {}\", runningTasks.size());\n          cleanUpWorkQueue();\n\n          printTrackingMaps();\n\n          boolean waited = false;\n\n          while (runningTasks.size() > maxParallelThreads) {\n            synchronized (waitLock) {\n              waitLock.wait(100);//wait for 100 ms or till a task is complete\n            }\n            waited = true;\n          }\n\n          if (waited)\n            cleanUpWorkQueue();\n\n          List<QueueEvent> heads = workQueue.peekTopN(maxParallelThreads, runningZKTasks, 2000L);\n\n          if (heads == null)\n            continue;\n\n          log.debug(\"Got {} tasks from work-queue : [{}]\", heads.size(), heads.toString());\n\n          if (isClosed) break;\n\n          for (QueueEvent head : heads) {\n            final ZkNodeProps message = ZkNodeProps.load(head.getBytes());\n            OverseerMessageHandler messageHandler = selector.selectOverseerMessageHandler(message);\n            String taskKey = messageHandler.getTaskKey(message);\n            final String asyncId = message.getStr(ASYNC);\n            if (hasLeftOverItems) {\n              if (head.getId().equals(oldestItemInWorkQueue))\n                hasLeftOverItems = false;\n              if (asyncId != null && (completedMap.contains(asyncId) || failureMap.contains(asyncId))) {\n                log.debug(\"Found already processed task in workQueue, cleaning up. AsyncId [{}]\",asyncId );\n                workQueue.remove(head);\n                continue;\n              }\n            }\n\n            if (!checkExclusivity(messageHandler, message, head.getId())) {\n              log.debug(\"Exclusivity check failed for [{}]\", message.toString());\n              continue;\n            }\n\n            try {\n              markTaskAsRunning(messageHandler, head, taskKey, asyncId, message);\n              log.debug(\"Marked task [{}] as running\", head.getId());\n            } catch (KeeperException.NodeExistsException e) {\n              // This should never happen\n              log.error(\"Tried to pick up task [{}] when it was already running!\", head.getId());\n            } catch (InterruptedException e) {\n              log.error(\"Thread interrupted while trying to pick task for execution.\", head.getId());\n              Thread.currentThread().interrupt();\n            }\n\n            log.info(messageHandler.getName() + \": Get the message id:\" + head.getId() + \" message:\" + message.toString());\n            String operation = message.getStr(Overseer.QUEUE_OPERATION);\n            Runner runner = new Runner(messageHandler, message,\n                operation, head);\n            tpe.execute(runner);\n          }\n\n        } catch (KeeperException e) {\n          if (e.code() == KeeperException.Code.SESSIONEXPIRED) {\n            log.warn(\"Overseer cannot talk to ZK\");\n            return;\n          }\n          SolrException.log(log, \"\", e);\n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          return;\n        } catch (Exception e) {\n          SolrException.log(log, \"\", e);\n        }\n      }\n    } finally {\n      this.close();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    log.info(\"Process current queue of overseer operations\");\n    LeaderStatus isLeader = amILeader();\n    while (isLeader == LeaderStatus.DONT_KNOW) {\n      log.debug(\"am_i_leader unclear {}\", isLeader);\n      isLeader = amILeader();  // not a no, not a yes, try ask again\n    }\n\n    String oldestItemInWorkQueue = null;\n    // hasLeftOverItems - used for avoiding re-execution of async tasks that were processed by a previous Overseer.\n    // This variable is set in case there's any task found on the workQueue when the OCP starts up and\n    // the id for the queue tail is used as a marker to check for the task in completed/failed map in zk.\n    // Beyond the marker, all tasks can safely be assumed to have never been executed.\n    boolean hasLeftOverItems = true;\n\n    try {\n      oldestItemInWorkQueue = workQueue.getTailId();\n    } catch (KeeperException e) {\n      // We don't need to handle this. This is just a fail-safe which comes in handy in skipping already processed\n      // async calls.\n      SolrException.log(log, \"\", e);\n    } catch (InterruptedException e) {\n      Thread.currentThread().interrupt();\n    }\n\n    if (oldestItemInWorkQueue == null)\n      hasLeftOverItems = false;\n    else\n      log.debug(\"Found already existing elements in the work-queue. Last element: {}\", oldestItemInWorkQueue);\n\n    try {\n      prioritizer.prioritizeOverseerNodes(myId);\n    } catch (Exception e) {\n      log.error(\"Unable to prioritize overseer \", e);\n    }\n\n    // TODO: Make maxThreads configurable.\n\n    this.tpe = new ExecutorUtil.MDCAwareThreadPoolExecutor(5, 100, 0L, TimeUnit.MILLISECONDS,\n        new SynchronousQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"OverseerThreadFactory\"));\n    try {\n      while (!this.isClosed) {\n        try {\n          isLeader = amILeader();\n          if (LeaderStatus.NO == isLeader) {\n            break;\n          } else if (LeaderStatus.YES != isLeader) {\n            log.debug(\"am_i_leader unclear {}\", isLeader);\n            continue; // not a no, not a yes, try asking again\n          }\n\n          log.debug(\"Cleaning up work-queue. #Running tasks: {}\", runningTasks.size());\n          cleanUpWorkQueue();\n\n          printTrackingMaps();\n\n          boolean waited = false;\n\n          while (runningTasks.size() > maxParallelThreads) {\n            synchronized (waitLock) {\n              waitLock.wait(100);//wait for 100 ms or till a task is complete\n            }\n            waited = true;\n          }\n\n          if (waited)\n            cleanUpWorkQueue();\n\n          List<QueueEvent> heads = workQueue.peekTopN(maxParallelThreads, runningZKTasks, 2000L);\n\n          if (heads == null)\n            continue;\n\n          log.debug(\"Got {} tasks from work-queue : [{}]\", heads.size(), heads.toString());\n\n          if (isClosed) break;\n\n          for (QueueEvent head : heads) {\n            final ZkNodeProps message = ZkNodeProps.load(head.getBytes());\n            OverseerMessageHandler messageHandler = selector.selectOverseerMessageHandler(message);\n            String taskKey = messageHandler.getTaskKey(message);\n            final String asyncId = message.getStr(ASYNC);\n            if (hasLeftOverItems) {\n              if (head.getId().equals(oldestItemInWorkQueue))\n                hasLeftOverItems = false;\n              if (asyncId != null && (completedMap.contains(asyncId) || failureMap.contains(asyncId))) {\n                log.debug(\"Found already processed task in workQueue, cleaning up. AsyncId [{}]\",asyncId );\n                workQueue.remove(head);\n                continue;\n              }\n            }\n\n            if (!checkExclusivity(messageHandler, message, head.getId())) {\n              log.debug(\"Exclusivity check failed for [{}]\", message.toString());\n              continue;\n            }\n\n            try {\n              markTaskAsRunning(messageHandler, head, taskKey, asyncId, message);\n              log.debug(\"Marked task [{}] as running\", head.getId());\n            } catch (KeeperException.NodeExistsException e) {\n              // This should never happen\n              log.error(\"Tried to pick up task [{}] when it was already running!\", head.getId());\n            } catch (InterruptedException e) {\n              log.error(\"Thread interrupted while trying to pick task for execution.\", head.getId());\n              Thread.currentThread().interrupt();\n            }\n\n            log.info(messageHandler.getName() + \": Get the message id:\" + head.getId() + \" message:\" + message.toString());\n            String operation = message.getStr(Overseer.QUEUE_OPERATION);\n            Runner runner = new Runner(messageHandler, message,\n                operation, head);\n            tpe.execute(runner);\n          }\n\n        } catch (KeeperException e) {\n          if (e.code() == KeeperException.Code.SESSIONEXPIRED) {\n            log.warn(\"Overseer cannot talk to ZK\");\n            return;\n          }\n          SolrException.log(log, \"\", e);\n        } catch (InterruptedException e) {\n          Thread.currentThread().interrupt();\n          return;\n        } catch (Exception e) {\n          SolrException.log(log, \"\", e);\n        }\n      }\n    } finally {\n      this.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"e31e6ce5848e5040d4c9ecbb25bc6ccf5d0894ac":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2209af2c265d2258ec4b29c8cc78622d36994a15":["e31e6ce5848e5040d4c9ecbb25bc6ccf5d0894ac"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2209af2c265d2258ec4b29c8cc78622d36994a15"]},"commit2Childs":{"e31e6ce5848e5040d4c9ecbb25bc6ccf5d0894ac":["2209af2c265d2258ec4b29c8cc78622d36994a15"],"2209af2c265d2258ec4b29c8cc78622d36994a15":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e31e6ce5848e5040d4c9ecbb25bc6ccf5d0894ac"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}