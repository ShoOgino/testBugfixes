{"path":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random.nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random.nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random.nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random.nextInt(100) < 50) ? fromField : types.get(random.nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random.nextInt(compat.length)];\n          fromField = group[random.nextInt(group.length)];\n          toField = group[random.nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random.nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"08970e5b8411182a29412c177eff67ec1110095b","date":1366640815,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<FldType>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<String, Map<Comparable, Set<Comparable>>>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<Doc>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<String,Object>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"028d44c0f49701c30d33df171be0fc11bd8d8ce3","date":1439405596,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ JSONUtil.toJSON(model)\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"46dc9ac8b3e748407baaef82453138ff3974480c","date":1484789241,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"90a682dc1bfd188ef61cc28373c7f5d700b4ac75","date":1485186128,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"487de3f55283f58d7e02a16993f8be55bbe32061","date":1502123368,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        /* disable matching incompatible fields since 7.0... it doesn't work with point fields and doesn't really make sense?\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else\n        */\n        {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":["843b845d397272dbafe8b80ebb8f9336d94568ef"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        /* disable matching incompatible fields since 7.0... it doesn't work with point fields and doesn't really make sense?\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else\n        */\n        {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"58884af1f68e9d61c217c753fbd6266d86a63b14","date":1502363401,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        /* disable matching incompatible fields since 7.0... it doesn't work with point fields and doesn't really make sense?\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else\n        */\n        {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3714bcf66a68a1600e9dd11442fc1b33b62ef088","date":1556832005,"type":3,"author":"noble","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        /* disable matching incompatible fields since 7.0... it doesn't work with point fields and doesn't really make sense?\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else\n        */\n        {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ Utils.toJSONString(resultSet)\n           + \"\\n\\tmodel=\"+ model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        /* disable matching incompatible fields since 7.0... it doesn't work with point fields and doesn't really make sense?\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else\n        */\n        {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = ObjectBuilder.fromJSON(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ JSONUtil.toJSON(resultSet)\n           + \"\\n\\tmodel=\"+ model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        /* disable matching incompatible fields since 7.0... it doesn't work with point fields and doesn't really make sense?\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else\n        */\n        {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: {}\\n\\trequest={}\\n\\tresult={}\\n\\texpected={}\\n\\tmodel={}\"\n              , err, req, strResponse, Utils.toJSONString(resultSet), model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        /* disable matching incompatible fields since 7.0... it doesn't work with point fields and doesn't really make sense?\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else\n        */\n        {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: \" + err\n           + \"\\n\\trequest=\"+req\n           + \"\\n\\tresult=\"+strResponse\n           + \"\\n\\texpected=\"+ Utils.toJSONString(resultSet)\n           + \"\\n\\tmodel=\"+ model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"640ded7811e1b7d29236a5e2934ec3cd266a8199","date":1588973147,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        /* disable matching incompatible fields since 7.0... it doesn't work with point fields and doesn't really make sense?\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else\n        */\n        {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"numFoundExact\", true);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: {}\\n\\trequest={}\\n\\tresult={}\\n\\texpected={}\\n\\tmodel={}\"\n              , err, req, strResponse, Utils.toJSONString(resultSet), model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        /* disable matching incompatible fields since 7.0... it doesn't work with point fields and doesn't really make sense?\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else\n        */\n        {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: {}\\n\\trequest={}\\n\\tresult={}\\n\\texpected={}\\n\\tmodel={}\"\n              , err, req, strResponse, Utils.toJSONString(resultSet), model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aa2585c33d5d66a1c837c312221eb55ddb3c4300","date":1592493170,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestJoin#testRandomJoin().mjava","sourceNew":"  @Test\n  @SuppressWarnings({\"unchecked\"})\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      @SuppressWarnings({\"rawtypes\"})\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      @SuppressWarnings({\"rawtypes\"})\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        /* disable matching incompatible fields since 7.0... it doesn't work with point fields and doesn't really make sense?\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else\n        */\n        {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        @SuppressWarnings({\"rawtypes\"})\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        @SuppressWarnings({\"rawtypes\"})\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (@SuppressWarnings({\"rawtypes\"})Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        @SuppressWarnings({\"rawtypes\"})\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"numFoundExact\", true);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: {}\\n\\trequest={}\\n\\tresult={}\\n\\texpected={}\\n\\tmodel={}\"\n              , err, req, strResponse, Utils.toJSONString(resultSet), model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRandomJoin() throws Exception {\n    int indexIter=50 * RANDOM_MULTIPLIER;\n    int queryIter=50 * RANDOM_MULTIPLIER;\n\n    // groups of fields that have any chance of matching... used to\n    // increase test effectiveness by avoiding 0 resultsets much of the time.\n    String[][] compat = new String[][] {\n        {\"small_s\",\"small2_s\",\"small2_ss\",\"small3_ss\"},\n        {\"small_i\",\"small2_i\",\"small2_is\",\"small3_is\", \"small_i_dv\", \"small_is_dv\"}\n    };\n\n\n    while (--indexIter >= 0) {\n      int indexSize = random().nextInt(20 * RANDOM_MULTIPLIER);\n\n      List<FldType> types = new ArrayList<>();\n      types.add(new FldType(\"id\",ONE_ONE, new SVal('A','Z',4,4)));\n      types.add(new FldType(\"score_f\",ONE_ONE, new FVal(1,100)));  // field used to score\n      types.add(new FldType(\"small_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_s\",ZERO_ONE, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small2_ss\",ZERO_TWO, new SVal('a',(char)('c'+indexSize/3),1,1)));\n      types.add(new FldType(\"small3_ss\",new IRange(0,25), new SVal('A','z',1,1)));\n      types.add(new FldType(\"small_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_i\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small2_is\",ZERO_TWO, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small3_is\",new IRange(0,25), new IRange(0,100)));\n      types.add(new FldType(\"small_i_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n      types.add(new FldType(\"small_is_dv\",ZERO_ONE, new IRange(0,5+indexSize/3)));\n\n      clearIndex();\n      Map<Comparable, Doc> model = indexDocs(types, null, indexSize);\n      Map<String, Map<Comparable, Set<Comparable>>> pivots = new HashMap<>();\n\n      for (int qiter=0; qiter<queryIter; qiter++) {\n        String fromField;\n        String toField;\n        /* disable matching incompatible fields since 7.0... it doesn't work with point fields and doesn't really make sense?\n        if (random().nextInt(100) < 5) {\n          // pick random fields 5% of the time\n          fromField = types.get(random().nextInt(types.size())).fname;\n          // pick the same field 50% of the time we pick a random field (since other fields won't match anything)\n          toField = (random().nextInt(100) < 50) ? fromField : types.get(random().nextInt(types.size())).fname;\n        } else\n        */\n        {\n          // otherwise, pick compatible fields that have a chance of matching indexed tokens\n          String[] group = compat[random().nextInt(compat.length)];\n          fromField = group[random().nextInt(group.length)];\n          toField = group[random().nextInt(group.length)];\n        }\n\n        Map<Comparable, Set<Comparable>> pivot = pivots.get(fromField+\"/\"+toField);\n        if (pivot == null) {\n          pivot = createJoinMap(model, fromField, toField);\n          pivots.put(fromField+\"/\"+toField, pivot);\n        }\n\n        Collection<Doc> fromDocs = model.values();\n        Set<Comparable> docs = join(fromDocs, pivot);\n        List<Doc> docList = new ArrayList<>(docs.size());\n        for (Comparable id : docs) docList.add(model.get(id));\n        Collections.sort(docList, createComparator(\"_docid_\",true,false,false,false));\n        List sortedDocs = new ArrayList();\n        for (Doc doc : docList) {\n          if (sortedDocs.size() >= 10) break;\n          sortedDocs.add(doc.toObject(h.getCore().getLatestSchema()));\n        }\n\n        Map<String,Object> resultSet = new LinkedHashMap<>();\n        resultSet.put(\"numFound\", docList.size());\n        resultSet.put(\"start\", 0);\n        resultSet.put(\"numFoundExact\", true);\n        resultSet.put(\"docs\", sortedDocs);\n\n        // todo: use different join queries for better coverage\n\n        SolrQueryRequest req = req(\"wt\",\"json\",\"indent\",\"true\", \"echoParams\",\"all\",\n            \"q\",\"{!join from=\"+fromField+\" to=\"+toField\n                + (random().nextInt(4)==0 ? \" fromIndex=collection1\" : \"\")\n                +\"}*:*\"\n        );\n\n        String strResponse = h.query(req);\n\n        Object realResponse = Utils.fromJSONString(strResponse);\n        String err = JSONTestUtil.matchObj(\"/response\", realResponse, resultSet);\n        if (err != null) {\n          log.error(\"JOIN MISMATCH: {}\\n\\trequest={}\\n\\tresult={}\\n\\texpected={}\\n\\tmodel={}\"\n              , err, req, strResponse, Utils.toJSONString(resultSet), model\n          );\n\n          // re-execute the request... good for putting a breakpoint here for debugging\n          String rsp = h.query(req);\n\n          fail(err);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["08970e5b8411182a29412c177eff67ec1110095b"],"640ded7811e1b7d29236a5e2934ec3cd266a8199":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"46dc9ac8b3e748407baaef82453138ff3974480c":["028d44c0f49701c30d33df171be0fc11bd8d8ce3"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"487de3f55283f58d7e02a16993f8be55bbe32061":["46dc9ac8b3e748407baaef82453138ff3974480c"],"3714bcf66a68a1600e9dd11442fc1b33b62ef088":["487de3f55283f58d7e02a16993f8be55bbe32061"],"028d44c0f49701c30d33df171be0fc11bd8d8ce3":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["3714bcf66a68a1600e9dd11442fc1b33b62ef088"],"90a682dc1bfd188ef61cc28373c7f5d700b4ac75":["028d44c0f49701c30d33df171be0fc11bd8d8ce3","46dc9ac8b3e748407baaef82453138ff3974480c"],"08970e5b8411182a29412c177eff67ec1110095b":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"58884af1f68e9d61c217c753fbd6266d86a63b14":["46dc9ac8b3e748407baaef82453138ff3974480c","487de3f55283f58d7e02a16993f8be55bbe32061"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["46dc9ac8b3e748407baaef82453138ff3974480c","487de3f55283f58d7e02a16993f8be55bbe32061"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["640ded7811e1b7d29236a5e2934ec3cd266a8199"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["c26f00b574427b55127e869b935845554afde1fa"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["028d44c0f49701c30d33df171be0fc11bd8d8ce3"],"640ded7811e1b7d29236a5e2934ec3cd266a8199":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"46dc9ac8b3e748407baaef82453138ff3974480c":["487de3f55283f58d7e02a16993f8be55bbe32061","90a682dc1bfd188ef61cc28373c7f5d700b4ac75","58884af1f68e9d61c217c753fbd6266d86a63b14","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"c26f00b574427b55127e869b935845554afde1fa":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"487de3f55283f58d7e02a16993f8be55bbe32061":["3714bcf66a68a1600e9dd11442fc1b33b62ef088","58884af1f68e9d61c217c753fbd6266d86a63b14","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"028d44c0f49701c30d33df171be0fc11bd8d8ce3":["46dc9ac8b3e748407baaef82453138ff3974480c","90a682dc1bfd188ef61cc28373c7f5d700b4ac75"],"3714bcf66a68a1600e9dd11442fc1b33b62ef088":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["640ded7811e1b7d29236a5e2934ec3cd266a8199"],"90a682dc1bfd188ef61cc28373c7f5d700b4ac75":[],"08970e5b8411182a29412c177eff67ec1110095b":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"58884af1f68e9d61c217c753fbd6266d86a63b14":[],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":[],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["08970e5b8411182a29412c177eff67ec1110095b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["90a682dc1bfd188ef61cc28373c7f5d700b4ac75","58884af1f68e9d61c217c753fbd6266d86a63b14","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}