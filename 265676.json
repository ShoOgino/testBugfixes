{"path":"contrib/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","commits":[{"id":"df2d68685a69bd82bf79243e28623c0775eb7bd8","date":1185567892,"type":0,"author":"Doron Cohen","isMerge":false,"pathNew":"contrib/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"/dev/null","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the complete reuters index\n    createReutersIndex();\n    \n    File workDir = new File(System.getProperty(\"benchmark.work.dir\",\"work\"));\n    assertTrue(\"Bad workDir: \"+workDir, workDir.exists()&& workDir.isDirectory());\n\n    int maxResults = 1000;\n    String docNameField = \"docid\"; \n    \n    PrintWriter logger = DEBUG ? new PrintWriter(System.out,true) : null;\n\n    // <tests src dir> for topics/qrels files - src/test/org/apache/lucene/benchmark/quality\n    File srcTestDir = new File(new File(new File(new File(new File(\n      new File(new File(workDir.getAbsoluteFile().getParentFile(),\n        \"src\"),\"test\"),\"org\"),\"apache\"),\"lucene\"),\"benchmark\"),\"quality\");\n    \n    // prepare topics\n    File topicsFile = new File(srcTestDir, \"trecTopics.txt\");\n    assertTrue(\"Bad topicsFile: \"+topicsFile, topicsFile.exists()&& topicsFile.isFile());\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new FileReader(topicsFile)));\n    \n    // prepare judge\n    File qrelsFile = new File(srcTestDir, \"trecQRels.txt\");\n    assertTrue(\"Bad qrelsFile: \"+qrelsFile, qrelsFile.exists()&& qrelsFile.isFile());\n    Judge judge = new TrecJudge(new BufferedReader(new FileReader(qrelsFile)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    IndexSearcher searcher = new IndexSearcher(FSDirectory.getDirectory(new File(workDir,\"index\")));\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = DEBUG ? new SubmissionReport(logger) : null;\n    QualityStats stats[] = qrun.execute(maxResults, judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-9);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n\n    \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05d64184e4c44205b1dfa1cdf3869230c4025dc9","date":1199346280,"type":3,"author":"Doron Cohen","isMerge":false,"pathNew":"contrib/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"contrib/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the complete reuters index\n    createReutersIndex();\n    \n    File workDir = new File(System.getProperty(\"benchmark.work.dir\",\"work\"));\n    assertTrue(\"Bad workDir: \"+workDir, workDir.exists()&& workDir.isDirectory());\n\n    int maxResults = 1000;\n    String docNameField = \"docid\"; \n    \n    PrintWriter logger = DEBUG ? new PrintWriter(System.out,true) : null;\n\n    // <tests src dir> for topics/qrels files - src/test/org/apache/lucene/benchmark/quality\n    File srcTestDir = new File(new File(new File(new File(new File(\n      new File(new File(workDir.getAbsoluteFile().getParentFile(),\n        \"src\"),\"test\"),\"org\"),\"apache\"),\"lucene\"),\"benchmark\"),\"quality\");\n    \n    // prepare topics\n    File topicsFile = new File(srcTestDir, \"trecTopics.txt\");\n    assertTrue(\"Bad topicsFile: \"+topicsFile, topicsFile.exists()&& topicsFile.isFile());\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new FileReader(topicsFile)));\n    \n    // prepare judge\n    File qrelsFile = new File(srcTestDir, \"trecQRels.txt\");\n    assertTrue(\"Bad qrelsFile: \"+qrelsFile, qrelsFile.exists()&& qrelsFile.isFile());\n    Judge judge = new TrecJudge(new BufferedReader(new FileReader(qrelsFile)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    IndexSearcher searcher = new IndexSearcher(FSDirectory.getDirectory(new File(workDir,\"index\")));\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = DEBUG ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-9);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n\n    \n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the complete reuters index\n    createReutersIndex();\n    \n    File workDir = new File(System.getProperty(\"benchmark.work.dir\",\"work\"));\n    assertTrue(\"Bad workDir: \"+workDir, workDir.exists()&& workDir.isDirectory());\n\n    int maxResults = 1000;\n    String docNameField = \"docid\"; \n    \n    PrintWriter logger = DEBUG ? new PrintWriter(System.out,true) : null;\n\n    // <tests src dir> for topics/qrels files - src/test/org/apache/lucene/benchmark/quality\n    File srcTestDir = new File(new File(new File(new File(new File(\n      new File(new File(workDir.getAbsoluteFile().getParentFile(),\n        \"src\"),\"test\"),\"org\"),\"apache\"),\"lucene\"),\"benchmark\"),\"quality\");\n    \n    // prepare topics\n    File topicsFile = new File(srcTestDir, \"trecTopics.txt\");\n    assertTrue(\"Bad topicsFile: \"+topicsFile, topicsFile.exists()&& topicsFile.isFile());\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new FileReader(topicsFile)));\n    \n    // prepare judge\n    File qrelsFile = new File(srcTestDir, \"trecQRels.txt\");\n    assertTrue(\"Bad qrelsFile: \"+qrelsFile, qrelsFile.exists()&& qrelsFile.isFile());\n    Judge judge = new TrecJudge(new BufferedReader(new FileReader(qrelsFile)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    IndexSearcher searcher = new IndexSearcher(FSDirectory.getDirectory(new File(workDir,\"index\")));\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = DEBUG ? new SubmissionReport(logger) : null;\n    QualityStats stats[] = qrun.execute(maxResults, judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-9);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba712167ee848727018d8b77aa0c273839fbe15c","date":1244411561,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"contrib/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the complete reuters index\n    createReutersIndex();\n    \n    File workDir = new File(System.getProperty(\"benchmark.work.dir\",\"work\"));\n    assertTrue(\"Bad workDir: \"+workDir, workDir.exists()&& workDir.isDirectory());\n\n    int maxResults = 1000;\n    String docNameField = \"docid\"; \n    \n    PrintWriter logger = DEBUG ? new PrintWriter(System.out,true) : null;\n\n    // <tests src dir> for topics/qrels files - src/test/org/apache/lucene/benchmark/quality\n    File srcTestDir = new File(new File(new File(new File(new File(\n      new File(new File(workDir.getAbsoluteFile().getParentFile(),\n        \"src\"),\"test\"),\"org\"),\"apache\"),\"lucene\"),\"benchmark\"),\"quality\");\n    \n    // prepare topics\n    File topicsFile = new File(srcTestDir, \"trecTopics.txt\");\n    assertTrue(\"Bad topicsFile: \"+topicsFile, topicsFile.exists()&& topicsFile.isFile());\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new FileReader(topicsFile)));\n    \n    // prepare judge\n    File qrelsFile = new File(srcTestDir, \"trecQRels.txt\");\n    assertTrue(\"Bad qrelsFile: \"+qrelsFile, qrelsFile.exists()&& qrelsFile.isFile());\n    Judge judge = new TrecJudge(new BufferedReader(new FileReader(qrelsFile)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    IndexSearcher searcher = new IndexSearcher(FSDirectory.open(new File(workDir,\"index\")));\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = DEBUG ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-9);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n\n    \n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the complete reuters index\n    createReutersIndex();\n    \n    File workDir = new File(System.getProperty(\"benchmark.work.dir\",\"work\"));\n    assertTrue(\"Bad workDir: \"+workDir, workDir.exists()&& workDir.isDirectory());\n\n    int maxResults = 1000;\n    String docNameField = \"docid\"; \n    \n    PrintWriter logger = DEBUG ? new PrintWriter(System.out,true) : null;\n\n    // <tests src dir> for topics/qrels files - src/test/org/apache/lucene/benchmark/quality\n    File srcTestDir = new File(new File(new File(new File(new File(\n      new File(new File(workDir.getAbsoluteFile().getParentFile(),\n        \"src\"),\"test\"),\"org\"),\"apache\"),\"lucene\"),\"benchmark\"),\"quality\");\n    \n    // prepare topics\n    File topicsFile = new File(srcTestDir, \"trecTopics.txt\");\n    assertTrue(\"Bad topicsFile: \"+topicsFile, topicsFile.exists()&& topicsFile.isFile());\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new FileReader(topicsFile)));\n    \n    // prepare judge\n    File qrelsFile = new File(srcTestDir, \"trecQRels.txt\");\n    assertTrue(\"Bad qrelsFile: \"+qrelsFile, qrelsFile.exists()&& qrelsFile.isFile());\n    Judge judge = new TrecJudge(new BufferedReader(new FileReader(qrelsFile)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    IndexSearcher searcher = new IndexSearcher(FSDirectory.getDirectory(new File(workDir,\"index\")));\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = DEBUG ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-9);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4256bc1b3c94786287ccdfc751230374521843cf","date":1254612273,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"contrib/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the complete reuters index\n    createReutersIndex();\n    \n    File workDir = new File(System.getProperty(\"benchmark.work.dir\",\"work\"));\n    assertTrue(\"Bad workDir: \"+workDir, workDir.exists()&& workDir.isDirectory());\n\n    int maxResults = 1000;\n    String docNameField = \"docid\"; \n    \n    PrintWriter logger = DEBUG ? new PrintWriter(System.out,true) : null;\n\n    // <tests src dir> for topics/qrels files - src/test/org/apache/lucene/benchmark/quality\n    File srcTestDir = new File(new File(new File(new File(new File(\n      new File(new File(workDir.getAbsoluteFile().getParentFile(),\n        \"src\"),\"test\"),\"org\"),\"apache\"),\"lucene\"),\"benchmark\"),\"quality\");\n    \n    // prepare topics\n    File topicsFile = new File(srcTestDir, \"trecTopics.txt\");\n    assertTrue(\"Bad topicsFile: \"+topicsFile, topicsFile.exists()&& topicsFile.isFile());\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new FileReader(topicsFile)));\n    \n    // prepare judge\n    File qrelsFile = new File(srcTestDir, \"trecQRels.txt\");\n    assertTrue(\"Bad qrelsFile: \"+qrelsFile, qrelsFile.exists()&& qrelsFile.isFile());\n    Judge judge = new TrecJudge(new BufferedReader(new FileReader(qrelsFile)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    IndexSearcher searcher = new IndexSearcher(FSDirectory.open(new File(workDir,\"index\")), true);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = DEBUG ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-9);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n\n    \n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the complete reuters index\n    createReutersIndex();\n    \n    File workDir = new File(System.getProperty(\"benchmark.work.dir\",\"work\"));\n    assertTrue(\"Bad workDir: \"+workDir, workDir.exists()&& workDir.isDirectory());\n\n    int maxResults = 1000;\n    String docNameField = \"docid\"; \n    \n    PrintWriter logger = DEBUG ? new PrintWriter(System.out,true) : null;\n\n    // <tests src dir> for topics/qrels files - src/test/org/apache/lucene/benchmark/quality\n    File srcTestDir = new File(new File(new File(new File(new File(\n      new File(new File(workDir.getAbsoluteFile().getParentFile(),\n        \"src\"),\"test\"),\"org\"),\"apache\"),\"lucene\"),\"benchmark\"),\"quality\");\n    \n    // prepare topics\n    File topicsFile = new File(srcTestDir, \"trecTopics.txt\");\n    assertTrue(\"Bad topicsFile: \"+topicsFile, topicsFile.exists()&& topicsFile.isFile());\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new FileReader(topicsFile)));\n    \n    // prepare judge\n    File qrelsFile = new File(srcTestDir, \"trecQRels.txt\");\n    assertTrue(\"Bad qrelsFile: \"+qrelsFile, qrelsFile.exists()&& qrelsFile.isFile());\n    Judge judge = new TrecJudge(new BufferedReader(new FileReader(qrelsFile)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    IndexSearcher searcher = new IndexSearcher(FSDirectory.open(new File(workDir,\"index\")));\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = DEBUG ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-9);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c972e92a005a8b26f565dfaa00d04e46df5cb025","date":1266752436,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"contrib/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"contrib/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    File workDir = new File(System.getProperty(\"benchmark.work.dir\",\"work\"));\n    assertTrue(\"Bad workDir: \"+workDir, workDir.exists()&& workDir.isDirectory());\n\n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = DEBUG ? new PrintWriter(System.out,true) : null;\n\n    // <tests src dir> for topics/qrels files - src/test/org/apache/lucene/benchmark/quality\n    File srcTestDir = new File(new File(new File(new File(new File(\n      new File(new File(workDir.getAbsoluteFile().getParentFile(),\n        \"src\"),\"test\"),\"org\"),\"apache\"),\"lucene\"),\"benchmark\"),\"quality\");\n    \n    // prepare topics\n    File topicsFile = new File(srcTestDir, \"trecTopics.txt\");\n    assertTrue(\"Bad topicsFile: \"+topicsFile, topicsFile.exists()&& topicsFile.isFile());\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new FileReader(topicsFile)));\n    \n    // prepare judge\n    File qrelsFile = new File(srcTestDir, \"trecQRels.txt\");\n    assertTrue(\"Bad qrelsFile: \"+qrelsFile, qrelsFile.exists()&& qrelsFile.isFile());\n    Judge judge = new TrecJudge(new BufferedReader(new FileReader(qrelsFile)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    IndexSearcher searcher = new IndexSearcher(FSDirectory.open(new File(workDir,\"index\")), true);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = DEBUG ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n\n    \n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the complete reuters index\n    createReutersIndex();\n    \n    File workDir = new File(System.getProperty(\"benchmark.work.dir\",\"work\"));\n    assertTrue(\"Bad workDir: \"+workDir, workDir.exists()&& workDir.isDirectory());\n\n    int maxResults = 1000;\n    String docNameField = \"docid\"; \n    \n    PrintWriter logger = DEBUG ? new PrintWriter(System.out,true) : null;\n\n    // <tests src dir> for topics/qrels files - src/test/org/apache/lucene/benchmark/quality\n    File srcTestDir = new File(new File(new File(new File(new File(\n      new File(new File(workDir.getAbsoluteFile().getParentFile(),\n        \"src\"),\"test\"),\"org\"),\"apache\"),\"lucene\"),\"benchmark\"),\"quality\");\n    \n    // prepare topics\n    File topicsFile = new File(srcTestDir, \"trecTopics.txt\");\n    assertTrue(\"Bad topicsFile: \"+topicsFile, topicsFile.exists()&& topicsFile.isFile());\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new FileReader(topicsFile)));\n    \n    // prepare judge\n    File qrelsFile = new File(srcTestDir, \"trecQRels.txt\");\n    assertTrue(\"Bad qrelsFile: \"+qrelsFile, qrelsFile.exists()&& qrelsFile.isFile());\n    Judge judge = new TrecJudge(new BufferedReader(new FileReader(qrelsFile)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    IndexSearcher searcher = new IndexSearcher(FSDirectory.open(new File(workDir,\"index\")), true);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = DEBUG ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-9);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-9);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-9);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"08b1bd489731fa5d64ddb1c235d63789efbb220f","date":1268478313,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"contrib/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    File workDir = new File(System.getProperty(\"benchmark.work.dir\",\"work\"));\n    assertTrue(\"Bad workDir: \"+workDir, workDir.exists()&& workDir.isDirectory());\n\n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(System.out,true) : null;\n\n    // <tests src dir> for topics/qrels files - src/test/org/apache/lucene/benchmark/quality\n    File srcTestDir = new File(new File(new File(new File(new File(\n      new File(new File(workDir.getAbsoluteFile().getParentFile(),\n        \"src\"),\"test\"),\"org\"),\"apache\"),\"lucene\"),\"benchmark\"),\"quality\");\n    \n    // prepare topics\n    File topicsFile = new File(srcTestDir, \"trecTopics.txt\");\n    assertTrue(\"Bad topicsFile: \"+topicsFile, topicsFile.exists()&& topicsFile.isFile());\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new FileReader(topicsFile)));\n    \n    // prepare judge\n    File qrelsFile = new File(srcTestDir, \"trecQRels.txt\");\n    assertTrue(\"Bad qrelsFile: \"+qrelsFile, qrelsFile.exists()&& qrelsFile.isFile());\n    Judge judge = new TrecJudge(new BufferedReader(new FileReader(qrelsFile)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    IndexSearcher searcher = new IndexSearcher(FSDirectory.open(new File(workDir,\"index\")), true);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n\n    \n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    File workDir = new File(System.getProperty(\"benchmark.work.dir\",\"work\"));\n    assertTrue(\"Bad workDir: \"+workDir, workDir.exists()&& workDir.isDirectory());\n\n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = DEBUG ? new PrintWriter(System.out,true) : null;\n\n    // <tests src dir> for topics/qrels files - src/test/org/apache/lucene/benchmark/quality\n    File srcTestDir = new File(new File(new File(new File(new File(\n      new File(new File(workDir.getAbsoluteFile().getParentFile(),\n        \"src\"),\"test\"),\"org\"),\"apache\"),\"lucene\"),\"benchmark\"),\"quality\");\n    \n    // prepare topics\n    File topicsFile = new File(srcTestDir, \"trecTopics.txt\");\n    assertTrue(\"Bad topicsFile: \"+topicsFile, topicsFile.exists()&& topicsFile.isFile());\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new FileReader(topicsFile)));\n    \n    // prepare judge\n    File qrelsFile = new File(srcTestDir, \"trecQRels.txt\");\n    assertTrue(\"Bad qrelsFile: \"+qrelsFile, qrelsFile.exists()&& qrelsFile.isFile());\n    Judge judge = new TrecJudge(new BufferedReader(new FileReader(qrelsFile)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    IndexSearcher searcher = new IndexSearcher(FSDirectory.open(new File(workDir,\"index\")), true);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = DEBUG ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"contrib/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    File workDir = new File(System.getProperty(\"benchmark.work.dir\",\"work\"));\n    assertTrue(\"Bad workDir: \"+workDir, workDir.exists()&& workDir.isDirectory());\n\n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(System.out,true) : null;\n\n    // <tests src dir> for topics/qrels files - src/test/org/apache/lucene/benchmark/quality\n    File srcTestDir = new File(new File(new File(new File(new File(\n      new File(new File(workDir.getAbsoluteFile().getParentFile(),\n        \"src\"),\"test\"),\"org\"),\"apache\"),\"lucene\"),\"benchmark\"),\"quality\");\n    \n    // prepare topics\n    File topicsFile = new File(srcTestDir, \"trecTopics.txt\");\n    assertTrue(\"Bad topicsFile: \"+topicsFile, topicsFile.exists()&& topicsFile.isFile());\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new FileReader(topicsFile)));\n    \n    // prepare judge\n    File qrelsFile = new File(srcTestDir, \"trecQRels.txt\");\n    assertTrue(\"Bad qrelsFile: \"+qrelsFile, qrelsFile.exists()&& qrelsFile.isFile());\n    Judge judge = new TrecJudge(new BufferedReader(new FileReader(qrelsFile)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    IndexSearcher searcher = new IndexSearcher(FSDirectory.open(new File(workDir,\"index\")), true);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n\n    \n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    File workDir = new File(System.getProperty(\"benchmark.work.dir\",\"work\"));\n    assertTrue(\"Bad workDir: \"+workDir, workDir.exists()&& workDir.isDirectory());\n\n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(System.out,true) : null;\n\n    // <tests src dir> for topics/qrels files - src/test/org/apache/lucene/benchmark/quality\n    File srcTestDir = new File(new File(new File(new File(new File(\n      new File(new File(workDir.getAbsoluteFile().getParentFile(),\n        \"src\"),\"test\"),\"org\"),\"apache\"),\"lucene\"),\"benchmark\"),\"quality\");\n    \n    // prepare topics\n    File topicsFile = new File(srcTestDir, \"trecTopics.txt\");\n    assertTrue(\"Bad topicsFile: \"+topicsFile, topicsFile.exists()&& topicsFile.isFile());\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new FileReader(topicsFile)));\n    \n    // prepare judge\n    File qrelsFile = new File(srcTestDir, \"trecQRels.txt\");\n    assertTrue(\"Bad qrelsFile: \"+qrelsFile, qrelsFile.exists()&& qrelsFile.isFile());\n    Judge judge = new TrecJudge(new BufferedReader(new FileReader(qrelsFile)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    IndexSearcher searcher = new IndexSearcher(FSDirectory.open(new File(workDir,\"index\")), true);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c972e92a005a8b26f565dfaa00d04e46df5cb025":["4256bc1b3c94786287ccdfc751230374521843cf"],"df2d68685a69bd82bf79243e28623c0775eb7bd8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"05d64184e4c44205b1dfa1cdf3869230c4025dc9":["df2d68685a69bd82bf79243e28623c0775eb7bd8"],"4256bc1b3c94786287ccdfc751230374521843cf":["ba712167ee848727018d8b77aa0c273839fbe15c"],"08b1bd489731fa5d64ddb1c235d63789efbb220f":["c972e92a005a8b26f565dfaa00d04e46df5cb025"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["08b1bd489731fa5d64ddb1c235d63789efbb220f"],"ba712167ee848727018d8b77aa0c273839fbe15c":["05d64184e4c44205b1dfa1cdf3869230c4025dc9"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["df2d68685a69bd82bf79243e28623c0775eb7bd8"],"c972e92a005a8b26f565dfaa00d04e46df5cb025":["08b1bd489731fa5d64ddb1c235d63789efbb220f"],"df2d68685a69bd82bf79243e28623c0775eb7bd8":["05d64184e4c44205b1dfa1cdf3869230c4025dc9"],"05d64184e4c44205b1dfa1cdf3869230c4025dc9":["ba712167ee848727018d8b77aa0c273839fbe15c"],"4256bc1b3c94786287ccdfc751230374521843cf":["c972e92a005a8b26f565dfaa00d04e46df5cb025"],"08b1bd489731fa5d64ddb1c235d63789efbb220f":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"ba712167ee848727018d8b77aa0c273839fbe15c":["4256bc1b3c94786287ccdfc751230374521843cf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}