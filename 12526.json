{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testPostings().mjava","commits":[{"id":"ceaef6cfc68c8ab22a684192e469a8280f9e6e70","date":1462354657,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testPostings().mjava","pathOld":"/dev/null","sourceNew":"  public void testPostings() throws Exception {\n    for(LeafReaderContext ctx : sortedReader.leaves()) {\n      LeafReader reader = ctx.reader();\n      TermsEnum termsEnum = reader.terms(DOC_POSITIONS_FIELD).iterator();\n      assertEquals(SeekStatus.FOUND, termsEnum.seekCeil(new BytesRef(DOC_POSITIONS_TERM)));\n      PostingsEnum sortedPositions = termsEnum.postings(null, PostingsEnum.ALL);\n      int doc;\n      boolean isSorted = reader.getIndexSort() != null;\n    \n      // test nextDoc()\n      while ((doc = sortedPositions.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = sortedPositions.freq();\n        int id = Integer.parseInt(reader.document(doc).get(ID_FIELD));\n        assertEquals(\"incorrect freq for doc=\" + doc, id / 10 + 1, freq);\n        for (int i = 0; i < freq; i++) {\n          assertEquals(\"incorrect position for doc=\" + doc, i, sortedPositions.nextPosition());\n          assertEquals(\"incorrect startOffset for doc=\" + doc, i, sortedPositions.startOffset());\n          assertEquals(\"incorrect endOffset for doc=\" + doc, i, sortedPositions.endOffset());\n          assertEquals(\"incorrect payload for doc=\" + doc, freq - i, Integer.parseInt(sortedPositions.getPayload().utf8ToString()));\n        }\n      }\n    \n      // test advance()\n      final PostingsEnum reuse = sortedPositions;\n      sortedPositions = termsEnum.postings(reuse, PostingsEnum.ALL);\n\n      doc = 0;\n      while ((doc = sortedPositions.advance(doc + TestUtil.nextInt(random(), 1, 5))) != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = sortedPositions.freq();\n        int id = Integer.parseInt(reader.document(doc).get(ID_FIELD));\n        assertEquals(\"incorrect freq for doc=\" + doc, id / 10 + 1, freq);\n        for (int i = 0; i < freq; i++) {\n          assertEquals(\"incorrect position for doc=\" + doc, i, sortedPositions.nextPosition());\n          assertEquals(\"incorrect startOffset for doc=\" + doc, i, sortedPositions.startOffset());\n          assertEquals(\"incorrect endOffset for doc=\" + doc, i, sortedPositions.endOffset());\n          assertEquals(\"incorrect payload for doc=\" + doc, freq - i, Integer.parseInt(sortedPositions.getPayload().utf8ToString()));\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fbe8fc0e68a5e2e7acce82ba880a982bd15cfab8","date":1462567286,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testPostings().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testPostings().mjava","sourceNew":"  public void testPostings() throws Exception {\n    for(LeafReaderContext ctx : sortedReader.leaves()) {\n      LeafReader reader = ctx.reader();\n      TermsEnum termsEnum = reader.terms(DOC_POSITIONS_FIELD).iterator();\n      assertEquals(SeekStatus.FOUND, termsEnum.seekCeil(new BytesRef(DOC_POSITIONS_TERM)));\n      PostingsEnum sortedPositions = termsEnum.postings(null, PostingsEnum.ALL);\n      int doc;\n    \n      // test nextDoc()\n      while ((doc = sortedPositions.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = sortedPositions.freq();\n        int id = Integer.parseInt(reader.document(doc).get(ID_FIELD));\n        assertEquals(\"incorrect freq for doc=\" + doc, id / 10 + 1, freq);\n        for (int i = 0; i < freq; i++) {\n          assertEquals(\"incorrect position for doc=\" + doc, i, sortedPositions.nextPosition());\n          assertEquals(\"incorrect startOffset for doc=\" + doc, i, sortedPositions.startOffset());\n          assertEquals(\"incorrect endOffset for doc=\" + doc, i, sortedPositions.endOffset());\n          assertEquals(\"incorrect payload for doc=\" + doc, freq - i, Integer.parseInt(sortedPositions.getPayload().utf8ToString()));\n        }\n      }\n    \n      // test advance()\n      final PostingsEnum reuse = sortedPositions;\n      sortedPositions = termsEnum.postings(reuse, PostingsEnum.ALL);\n\n      doc = 0;\n      while ((doc = sortedPositions.advance(doc + TestUtil.nextInt(random(), 1, 5))) != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = sortedPositions.freq();\n        int id = Integer.parseInt(reader.document(doc).get(ID_FIELD));\n        assertEquals(\"incorrect freq for doc=\" + doc, id / 10 + 1, freq);\n        for (int i = 0; i < freq; i++) {\n          assertEquals(\"incorrect position for doc=\" + doc, i, sortedPositions.nextPosition());\n          assertEquals(\"incorrect startOffset for doc=\" + doc, i, sortedPositions.startOffset());\n          assertEquals(\"incorrect endOffset for doc=\" + doc, i, sortedPositions.endOffset());\n          assertEquals(\"incorrect payload for doc=\" + doc, freq - i, Integer.parseInt(sortedPositions.getPayload().utf8ToString()));\n        }\n      }\n    }\n  }\n\n","sourceOld":"  public void testPostings() throws Exception {\n    for(LeafReaderContext ctx : sortedReader.leaves()) {\n      LeafReader reader = ctx.reader();\n      TermsEnum termsEnum = reader.terms(DOC_POSITIONS_FIELD).iterator();\n      assertEquals(SeekStatus.FOUND, termsEnum.seekCeil(new BytesRef(DOC_POSITIONS_TERM)));\n      PostingsEnum sortedPositions = termsEnum.postings(null, PostingsEnum.ALL);\n      int doc;\n      boolean isSorted = reader.getIndexSort() != null;\n    \n      // test nextDoc()\n      while ((doc = sortedPositions.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = sortedPositions.freq();\n        int id = Integer.parseInt(reader.document(doc).get(ID_FIELD));\n        assertEquals(\"incorrect freq for doc=\" + doc, id / 10 + 1, freq);\n        for (int i = 0; i < freq; i++) {\n          assertEquals(\"incorrect position for doc=\" + doc, i, sortedPositions.nextPosition());\n          assertEquals(\"incorrect startOffset for doc=\" + doc, i, sortedPositions.startOffset());\n          assertEquals(\"incorrect endOffset for doc=\" + doc, i, sortedPositions.endOffset());\n          assertEquals(\"incorrect payload for doc=\" + doc, freq - i, Integer.parseInt(sortedPositions.getPayload().utf8ToString()));\n        }\n      }\n    \n      // test advance()\n      final PostingsEnum reuse = sortedPositions;\n      sortedPositions = termsEnum.postings(reuse, PostingsEnum.ALL);\n\n      doc = 0;\n      while ((doc = sortedPositions.advance(doc + TestUtil.nextInt(random(), 1, 5))) != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = sortedPositions.freq();\n        int id = Integer.parseInt(reader.document(doc).get(ID_FIELD));\n        assertEquals(\"incorrect freq for doc=\" + doc, id / 10 + 1, freq);\n        for (int i = 0; i < freq; i++) {\n          assertEquals(\"incorrect position for doc=\" + doc, i, sortedPositions.nextPosition());\n          assertEquals(\"incorrect startOffset for doc=\" + doc, i, sortedPositions.startOffset());\n          assertEquals(\"incorrect endOffset for doc=\" + doc, i, sortedPositions.endOffset());\n          assertEquals(\"incorrect payload for doc=\" + doc, freq - i, Integer.parseInt(sortedPositions.getPayload().utf8ToString()));\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ff25cb7bb787cbe9d05740c89a527ddd2617c16","date":1462702859,"type":4,"author":"Mike McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexSorting#testPostings().mjava","sourceNew":null,"sourceOld":"  public void testPostings() throws Exception {\n    for(LeafReaderContext ctx : sortedReader.leaves()) {\n      LeafReader reader = ctx.reader();\n      TermsEnum termsEnum = reader.terms(DOC_POSITIONS_FIELD).iterator();\n      assertEquals(SeekStatus.FOUND, termsEnum.seekCeil(new BytesRef(DOC_POSITIONS_TERM)));\n      PostingsEnum sortedPositions = termsEnum.postings(null, PostingsEnum.ALL);\n      int doc;\n    \n      // test nextDoc()\n      while ((doc = sortedPositions.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = sortedPositions.freq();\n        int id = Integer.parseInt(reader.document(doc).get(ID_FIELD));\n        assertEquals(\"incorrect freq for doc=\" + doc, id / 10 + 1, freq);\n        for (int i = 0; i < freq; i++) {\n          assertEquals(\"incorrect position for doc=\" + doc, i, sortedPositions.nextPosition());\n          assertEquals(\"incorrect startOffset for doc=\" + doc, i, sortedPositions.startOffset());\n          assertEquals(\"incorrect endOffset for doc=\" + doc, i, sortedPositions.endOffset());\n          assertEquals(\"incorrect payload for doc=\" + doc, freq - i, Integer.parseInt(sortedPositions.getPayload().utf8ToString()));\n        }\n      }\n    \n      // test advance()\n      final PostingsEnum reuse = sortedPositions;\n      sortedPositions = termsEnum.postings(reuse, PostingsEnum.ALL);\n\n      doc = 0;\n      while ((doc = sortedPositions.advance(doc + TestUtil.nextInt(random(), 1, 5))) != DocIdSetIterator.NO_MORE_DOCS) {\n        int freq = sortedPositions.freq();\n        int id = Integer.parseInt(reader.document(doc).get(ID_FIELD));\n        assertEquals(\"incorrect freq for doc=\" + doc, id / 10 + 1, freq);\n        for (int i = 0; i < freq; i++) {\n          assertEquals(\"incorrect position for doc=\" + doc, i, sortedPositions.nextPosition());\n          assertEquals(\"incorrect startOffset for doc=\" + doc, i, sortedPositions.startOffset());\n          assertEquals(\"incorrect endOffset for doc=\" + doc, i, sortedPositions.endOffset());\n          assertEquals(\"incorrect payload for doc=\" + doc, freq - i, Integer.parseInt(sortedPositions.getPayload().utf8ToString()));\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ceaef6cfc68c8ab22a684192e469a8280f9e6e70":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4ff25cb7bb787cbe9d05740c89a527ddd2617c16":["fbe8fc0e68a5e2e7acce82ba880a982bd15cfab8"],"fbe8fc0e68a5e2e7acce82ba880a982bd15cfab8":["ceaef6cfc68c8ab22a684192e469a8280f9e6e70"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"ceaef6cfc68c8ab22a684192e469a8280f9e6e70":["fbe8fc0e68a5e2e7acce82ba880a982bd15cfab8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ceaef6cfc68c8ab22a684192e469a8280f9e6e70","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4ff25cb7bb787cbe9d05740c89a527ddd2617c16":[],"fbe8fc0e68a5e2e7acce82ba880a982bd15cfab8":["4ff25cb7bb787cbe9d05740c89a527ddd2617c16"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4ff25cb7bb787cbe9d05740c89a527ddd2617c16","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}