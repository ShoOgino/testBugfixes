{"path":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean,Integer).mjava","commits":[{"id":"2b82485108ad24cfd45d88a7465e68000f54055c","date":1430225324,"type":1,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean,Integer).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean).mjava","sourceNew":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting, Integer tlogDfsReplication) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf(), new CallerInfo(){\n\n          @Override\n          public boolean isCallerClosed() {\n            return isClosed;\n          }});\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)tlogDfsReplication.intValue());\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf(), new CallerInfo(){\n\n          @Override\n          public boolean isCallerClosed() {\n            return isClosed;\n          }});\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)1);\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eb24889d3ba121c74276a3052cf3c6d0b4f69661","date":1478016658,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean,Integer).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean,Integer).mjava","sourceNew":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting, Integer tlogDfsReplication) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf(), new CallerInfo(){\n\n          @Override\n          public boolean isCallerClosed() {\n            return isClosed;\n          }});\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)tlogDfsReplication.intValue());\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      log.debug(\"Opening new tlog {}\", this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting, Integer tlogDfsReplication) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf(), new CallerInfo(){\n\n          @Override\n          public boolean isCallerClosed() {\n            return isClosed;\n          }});\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)tlogDfsReplication.intValue());\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9720b151fde2073f4e401450f4574e5f31c2d0ff","date":1478184029,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean,Integer).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean,Integer).mjava","sourceNew":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting, Integer tlogDfsReplication) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf(), new CallerInfo(){\n\n          @Override\n          public boolean isCallerClosed() {\n            return isClosed;\n          }});\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)tlogDfsReplication.intValue());\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      log.debug(\"Opening new tlog {}\", this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting, Integer tlogDfsReplication) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf(), new CallerInfo(){\n\n          @Override\n          public boolean isCallerClosed() {\n            return isClosed;\n          }});\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)tlogDfsReplication.intValue());\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d07fa4efb9b60aa1f13314628734cd1412ffca8","date":1552990809,"type":3,"author":"Kevin Risden","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean,Integer).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean,Integer).mjava","sourceNew":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting, Integer tlogDfsReplication) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf(), new CallerInfo(){\n\n          @Override\n          public boolean isCallerClosed() {\n            return isClosed;\n          }});\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)tlogDfsReplication.intValue());\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      log.debug(\"Opening new tlog {}\", this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting, Integer tlogDfsReplication) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      if (debug) {\n        //log.debug(\"New TransactionLog file=\" + tlogFile + \", exists=\" + tlogFile.exists() + \", size=\" + tlogFile.length() + \", openExisting=\" + openExisting);\n      }\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf(), new CallerInfo(){\n\n          @Override\n          public boolean isCallerClosed() {\n            return isClosed;\n          }});\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)tlogDfsReplication.intValue());\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      log.debug(\"Opening new tlog {}\", this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"740d649f013f07efbeb73ca854f106c60166e7c0","date":1587431295,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean,Integer).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/HdfsTransactionLog#HdfsTransactionLog(FileSystem,Path,Collection[String],boolean,Integer).mjava","sourceNew":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting, Integer tlogDfsReplication) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf(), new CallerInfo(){\n\n          @Override\n          public boolean isCallerClosed() {\n            return isClosed;\n          }});\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)tlogDfsReplication.intValue());\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:{} size={}\", tlogFile, tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      log.debug(\"Opening new tlog {}\", this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  HdfsTransactionLog(FileSystem fs, Path tlogFile, Collection<String> globalStrings, boolean openExisting, Integer tlogDfsReplication) {\n    super();\n    boolean success = false;\n    this.fs = fs;\n\n    try {\n      this.tlogFile = tlogFile;\n      \n      if (fs.exists(tlogFile) && openExisting) {\n        FSHDFSUtils.recoverFileLease(fs, tlogFile, fs.getConf(), new CallerInfo(){\n\n          @Override\n          public boolean isCallerClosed() {\n            return isClosed;\n          }});\n        \n        tlogOutStream = fs.append(tlogFile);\n      } else {\n        fs.delete(tlogFile, false);\n        \n        tlogOutStream = fs.create(tlogFile, (short)tlogDfsReplication.intValue());\n        tlogOutStream.hsync();\n      }\n\n      fos = new FastOutputStream(tlogOutStream, new byte[65536], 0);\n      long start = tlogOutStream.getPos(); \n\n      if (openExisting) {\n        if (start > 0) {\n          readHeader(null);\n          \n         // we should already be at the end \n         // raf.seek(start);\n\n        //  assert channel.position() == start;\n          fos.setWritten(start);    // reflect that we aren't starting at the beginning\n          //assert fos.size() == channel.size();\n        } else {\n          addGlobalStrings(globalStrings);\n        }\n      } else {\n        if (start > 0) {\n          log.error(\"New transaction log already exists:\" + tlogFile + \" size=\" + tlogOutStream.size());\n        }\n\n        addGlobalStrings(globalStrings);\n      }\n\n      success = true;\n\n      assert ObjectReleaseTracker.track(this);\n      log.debug(\"Opening new tlog {}\", this);\n      \n    } catch (IOException e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n    } finally {\n      if (!success && tlogOutStream != null) {\n        try {\n          tlogOutStream.close();\n        } catch (Exception e) {\n          log.error(\"Error closing tlog file (after error opening)\", e);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"740d649f013f07efbeb73ca854f106c60166e7c0":["1d07fa4efb9b60aa1f13314628734cd1412ffca8"],"2b82485108ad24cfd45d88a7465e68000f54055c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9720b151fde2073f4e401450f4574e5f31c2d0ff":["2b82485108ad24cfd45d88a7465e68000f54055c","eb24889d3ba121c74276a3052cf3c6d0b4f69661"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1d07fa4efb9b60aa1f13314628734cd1412ffca8":["eb24889d3ba121c74276a3052cf3c6d0b4f69661"],"eb24889d3ba121c74276a3052cf3c6d0b4f69661":["2b82485108ad24cfd45d88a7465e68000f54055c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["740d649f013f07efbeb73ca854f106c60166e7c0"]},"commit2Childs":{"740d649f013f07efbeb73ca854f106c60166e7c0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2b82485108ad24cfd45d88a7465e68000f54055c":["9720b151fde2073f4e401450f4574e5f31c2d0ff","eb24889d3ba121c74276a3052cf3c6d0b4f69661"],"9720b151fde2073f4e401450f4574e5f31c2d0ff":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["2b82485108ad24cfd45d88a7465e68000f54055c"],"1d07fa4efb9b60aa1f13314628734cd1412ffca8":["740d649f013f07efbeb73ca854f106c60166e7c0"],"eb24889d3ba121c74276a3052cf3c6d0b4f69661":["9720b151fde2073f4e401450f4574e5f31c2d0ff","1d07fa4efb9b60aa1f13314628734cd1412ffca8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9720b151fde2073f4e401450f4574e5f31c2d0ff","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}