{"path":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore,SolrIndexSearcher).mjava","commits":[{"id":"08970e5b8411182a29412c177eff67ec1110095b","date":1366640815,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore,SolrIndexSearcher).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core, SolrIndexSearcher searcher) {\n    try {\n      IndexSchema schema = null == searcher ? core.getLatestSchema() : searcher.getSchema();\n      // Get the field's analyzer\n      if (fieldTypeName != null && schema.getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = schema.getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s, Field.Store.NO));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(DirectoryReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core) {\n    try {\n\n      // Get the field's analyzer\n      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s, Field.Store.NO));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(DirectoryReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore,SolrIndexSearcher).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore,SolrIndexSearcher).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core, SolrIndexSearcher searcher) {\n    try {\n      IndexSchema schema = null == searcher ? core.getLatestSchema() : searcher.getSchema();\n      // Get the field's analyzer\n      if (fieldTypeName != null && schema.getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = schema.getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s, Field.Store.NO));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.shutdown();\n\n        dictionary = new HighFrequencyDictionary(DirectoryReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core, SolrIndexSearcher searcher) {\n    try {\n      IndexSchema schema = null == searcher ? core.getLatestSchema() : searcher.getSchema();\n      // Get the field's analyzer\n      if (fieldTypeName != null && schema.getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = schema.getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s, Field.Store.NO));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(DirectoryReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"123698fbe83b595f9e084f0019cd35ab4a01d7f7","date":1399070065,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore,SolrIndexSearcher).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore,SolrIndexSearcher).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core, SolrIndexSearcher searcher) {\n    try {\n      IndexSchema schema = null == searcher ? core.getLatestSchema() : searcher.getSchema();\n      // Get the field's analyzer\n      if (fieldTypeName != null && schema.getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = schema.getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getIndexAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s, Field.Store.NO));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.shutdown();\n\n        dictionary = new HighFrequencyDictionary(DirectoryReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core, SolrIndexSearcher searcher) {\n    try {\n      IndexSchema schema = null == searcher ? core.getLatestSchema() : searcher.getSchema();\n      // Get the field's analyzer\n      if (fieldTypeName != null && schema.getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = schema.getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s, Field.Store.NO));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.shutdown();\n\n        dictionary = new HighFrequencyDictionary(DirectoryReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore,SolrIndexSearcher).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore,SolrIndexSearcher).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core, SolrIndexSearcher searcher) {\n    try {\n      IndexSchema schema = null == searcher ? core.getLatestSchema() : searcher.getSchema();\n      // Get the field's analyzer\n      if (fieldTypeName != null && schema.getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = schema.getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(fieldType.getIndexAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s, Field.Store.NO));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(DirectoryReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core, SolrIndexSearcher searcher) {\n    try {\n      IndexSchema schema = null == searcher ? core.getLatestSchema() : searcher.getSchema();\n      // Get the field's analyzer\n      if (fieldTypeName != null && schema.getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = schema.getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getIndexAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s, Field.Store.NO));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.shutdown();\n\n        dictionary = new HighFrequencyDictionary(DirectoryReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d77dafd89756a5161d244985903e3487ca109182","date":1548679743,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore,SolrIndexSearcher).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/FileBasedSpellChecker#loadExternalFileDictionary(SolrCore,SolrIndexSearcher).mjava","sourceNew":"  private void loadExternalFileDictionary(SolrCore core, SolrIndexSearcher searcher) {\n    try {\n      IndexSchema schema = null == searcher ? core.getLatestSchema() : searcher.getSchema();\n      // Get the field's analyzer\n      if (fieldTypeName != null && schema.getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = schema.getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        Directory ramDir = new ByteBuffersDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(fieldType.getIndexAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s, Field.Store.NO));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(DirectoryReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","sourceOld":"  private void loadExternalFileDictionary(SolrCore core, SolrIndexSearcher searcher) {\n    try {\n      IndexSchema schema = null == searcher ? core.getLatestSchema() : searcher.getSchema();\n      // Get the field's analyzer\n      if (fieldTypeName != null && schema.getFieldTypeNoEx(fieldTypeName) != null) {\n        FieldType fieldType = schema.getFieldTypes().get(fieldTypeName);\n        // Do index-time analysis using the given fieldType's analyzer\n        RAMDirectory ramDir = new RAMDirectory();\n\n        LogMergePolicy mp = new LogByteSizeMergePolicy();\n        mp.setMergeFactor(300);\n\n        IndexWriter writer = new IndexWriter(\n            ramDir,\n            new IndexWriterConfig(fieldType.getIndexAnalyzer()).\n                setMaxBufferedDocs(150).\n                setMergePolicy(mp).\n                setOpenMode(IndexWriterConfig.OpenMode.CREATE)\n                // TODO: if we enable this, codec gets angry since field won't exist in the schema\n                // .setCodec(core.getCodec())\n        );\n\n        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);\n\n        for (String s : lines) {\n          Document d = new Document();\n          d.add(new TextField(WORD_FIELD_NAME, s, Field.Store.NO));\n          writer.addDocument(d);\n        }\n        writer.forceMerge(1);\n        writer.close();\n\n        dictionary = new HighFrequencyDictionary(DirectoryReader.open(ramDir),\n                WORD_FIELD_NAME, 0.0f);\n      } else {\n        // check if character encoding is defined\n        if (characterEncoding == null) {\n          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));\n        } else {\n          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));\n        }\n      }\n\n\n    } catch (IOException e) {\n      log.error( \"Unable to load spellings\", e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"123698fbe83b595f9e084f0019cd35ab4a01d7f7":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["123698fbe83b595f9e084f0019cd35ab4a01d7f7"],"d77dafd89756a5161d244985903e3487ca109182":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["08970e5b8411182a29412c177eff67ec1110095b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d77dafd89756a5161d244985903e3487ca109182"],"08970e5b8411182a29412c177eff67ec1110095b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"123698fbe83b595f9e084f0019cd35ab4a01d7f7":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["08970e5b8411182a29412c177eff67ec1110095b"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["d77dafd89756a5161d244985903e3487ca109182"],"d77dafd89756a5161d244985903e3487ca109182":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["123698fbe83b595f9e084f0019cd35ab4a01d7f7"],"08970e5b8411182a29412c177eff67ec1110095b":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}