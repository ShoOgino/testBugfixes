{"path":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester#lookup(LeafReader,Automaton,int,DocIdSet,TopSuggestDocsCollector).mjava","commits":[{"id":"07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a","date":1427495869,"type":0,"author":"Areek Zillur","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester#lookup(LeafReader,Automaton,int,DocIdSet,TopSuggestDocsCollector).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Collects at most Top <code>num</code> completions, filtered by <code>filter</code> on\n   * corresponding documents, which has a prefix accepted by <code>automaton</code>\n   * <p>\n   * Supports near real time deleted document filtering using <code>reader</code>\n   * <p>\n   * {@link TopSuggestDocsCollector#collect(int, CharSequence, long)} is called\n   * for every matched completion\n   * <p>\n   * Completion collection can be early terminated by throwing {@link org.apache.lucene.search.CollectionTerminatedException}\n   */\n  public void lookup(final LeafReader reader, final Automaton automaton, final int num, final DocIdSet filter, final TopSuggestDocsCollector collector) {\n    final Bits filterDocs;\n    try {\n      if (filter != null) {\n        if (filter.iterator() == null) {\n          return;\n        }\n        if (filter.bits() == null) {\n          throw new IllegalArgumentException(\"DocIDSet does not provide random access interface\");\n        } else {\n          filterDocs = filter.bits();\n        }\n      } else {\n        filterDocs = null;\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    int queueSize = getMaxTopNSearcherQueueSize(num, reader, filterDocs != null);\n    if (queueSize == -1) {\n      return;\n    }\n\n    final Bits liveDocs = reader.getLiveDocs();\n    try {\n      final List<FSTUtil.Path<Pair<Long, BytesRef>>> prefixPaths = FSTUtil.intersectPrefixPaths(automaton, fst);\n      Util.TopNSearcher<Pair<Long, BytesRef>> searcher = new Util.TopNSearcher<Pair<Long, BytesRef>>(fst, num, queueSize, getComparator()) {\n\n        private final CharsRefBuilder spare = new CharsRefBuilder();\n\n        @Override\n        protected boolean acceptResult(IntsRef input, Pair<Long, BytesRef> output) {\n          int payloadSepIndex = parseSurfaceForm(output.output2, payloadSep, spare);\n          int docID = parseDocID(output.output2, payloadSepIndex);\n\n          // filter out deleted docs only if no filter is set\n          if (filterDocs == null && liveDocs != null && !liveDocs.get(docID)) {\n            return false;\n          }\n\n          // filter by filter context\n          if (filterDocs != null && !filterDocs.get(docID)) {\n            return false;\n          }\n\n          try {\n            collector.collect(docID, spare.toCharsRef(), decode(output.output1));\n            return true;\n          } catch (IOException e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      // TODO: add fuzzy support\n      for (FSTUtil.Path<Pair<Long, BytesRef>> path : prefixPaths) {\n        searcher.addStartPaths(path.fstNode, path.output, false, path.input);\n      }\n\n      try {\n        // hits are also returned by search()\n        // we do not use it, instead collect at acceptResult\n        Util.TopResults<Pair<Long, BytesRef>> search = searcher.search();\n        // search admissibility is not guaranteed\n        // see comment on getMaxTopNSearcherQueueSize\n        // assert  search.isComplete;\n      } catch (CollectionTerminatedException e) {\n        // terminate\n      }\n\n    } catch (IOException bogus) {\n      throw new RuntimeException(bogus);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":0,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester#lookup(LeafReader,Automaton,int,DocIdSet,TopSuggestDocsCollector).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Collects at most Top <code>num</code> completions, filtered by <code>filter</code> on\n   * corresponding documents, which has a prefix accepted by <code>automaton</code>\n   * <p>\n   * Supports near real time deleted document filtering using <code>reader</code>\n   * <p>\n   * {@link TopSuggestDocsCollector#collect(int, CharSequence, long)} is called\n   * for every matched completion\n   * <p>\n   * Completion collection can be early terminated by throwing {@link org.apache.lucene.search.CollectionTerminatedException}\n   */\n  public void lookup(final LeafReader reader, final Automaton automaton, final int num, final DocIdSet filter, final TopSuggestDocsCollector collector) {\n    final Bits filterDocs;\n    try {\n      if (filter != null) {\n        if (filter.iterator() == null) {\n          return;\n        }\n        if (filter.bits() == null) {\n          throw new IllegalArgumentException(\"DocIDSet does not provide random access interface\");\n        } else {\n          filterDocs = filter.bits();\n        }\n      } else {\n        filterDocs = null;\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    int queueSize = getMaxTopNSearcherQueueSize(num, reader, filterDocs != null);\n    if (queueSize == -1) {\n      return;\n    }\n\n    final Bits liveDocs = reader.getLiveDocs();\n    try {\n      final List<FSTUtil.Path<Pair<Long, BytesRef>>> prefixPaths = FSTUtil.intersectPrefixPaths(automaton, fst);\n      Util.TopNSearcher<Pair<Long, BytesRef>> searcher = new Util.TopNSearcher<Pair<Long, BytesRef>>(fst, num, queueSize, getComparator()) {\n\n        private final CharsRefBuilder spare = new CharsRefBuilder();\n\n        @Override\n        protected boolean acceptResult(IntsRef input, Pair<Long, BytesRef> output) {\n          int payloadSepIndex = parseSurfaceForm(output.output2, payloadSep, spare);\n          int docID = parseDocID(output.output2, payloadSepIndex);\n\n          // filter out deleted docs only if no filter is set\n          if (filterDocs == null && liveDocs != null && !liveDocs.get(docID)) {\n            return false;\n          }\n\n          // filter by filter context\n          if (filterDocs != null && !filterDocs.get(docID)) {\n            return false;\n          }\n\n          try {\n            collector.collect(docID, spare.toCharsRef(), decode(output.output1));\n            return true;\n          } catch (IOException e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      // TODO: add fuzzy support\n      for (FSTUtil.Path<Pair<Long, BytesRef>> path : prefixPaths) {\n        searcher.addStartPaths(path.fstNode, path.output, false, path.input);\n      }\n\n      try {\n        // hits are also returned by search()\n        // we do not use it, instead collect at acceptResult\n        Util.TopResults<Pair<Long, BytesRef>> search = searcher.search();\n        // search admissibility is not guaranteed\n        // see comment on getMaxTopNSearcherQueueSize\n        // assert  search.isComplete;\n      } catch (CollectionTerminatedException e) {\n        // terminate\n      }\n\n    } catch (IOException bogus) {\n      throw new RuntimeException(bogus);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8c33f6677a2078739058f81eca1df69d12cd62b0","date":1432799589,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/document/NRTSuggester#lookup(LeafReader,Automaton,int,DocIdSet,TopSuggestDocsCollector).mjava","sourceNew":null,"sourceOld":"  /**\n   * Collects at most Top <code>num</code> completions, filtered by <code>filter</code> on\n   * corresponding documents, which has a prefix accepted by <code>automaton</code>\n   * <p>\n   * Supports near real time deleted document filtering using <code>reader</code>\n   * <p>\n   * {@link TopSuggestDocsCollector#collect(int, CharSequence, long)} is called\n   * for every matched completion\n   * <p>\n   * Completion collection can be early terminated by throwing {@link org.apache.lucene.search.CollectionTerminatedException}\n   */\n  public void lookup(final LeafReader reader, final Automaton automaton, final int num, final DocIdSet filter, final TopSuggestDocsCollector collector) {\n    final Bits filterDocs;\n    try {\n      if (filter != null) {\n        if (filter.iterator() == null) {\n          return;\n        }\n        if (filter.bits() == null) {\n          throw new IllegalArgumentException(\"DocIDSet does not provide random access interface\");\n        } else {\n          filterDocs = filter.bits();\n        }\n      } else {\n        filterDocs = null;\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n\n    int queueSize = getMaxTopNSearcherQueueSize(num, reader, filterDocs != null);\n    if (queueSize == -1) {\n      return;\n    }\n\n    final Bits liveDocs = reader.getLiveDocs();\n    try {\n      final List<FSTUtil.Path<Pair<Long, BytesRef>>> prefixPaths = FSTUtil.intersectPrefixPaths(automaton, fst);\n      Util.TopNSearcher<Pair<Long, BytesRef>> searcher = new Util.TopNSearcher<Pair<Long, BytesRef>>(fst, num, queueSize, getComparator()) {\n\n        private final CharsRefBuilder spare = new CharsRefBuilder();\n\n        @Override\n        protected boolean acceptResult(IntsRef input, Pair<Long, BytesRef> output) {\n          int payloadSepIndex = parseSurfaceForm(output.output2, payloadSep, spare);\n          int docID = parseDocID(output.output2, payloadSepIndex);\n\n          // filter out deleted docs only if no filter is set\n          if (filterDocs == null && liveDocs != null && !liveDocs.get(docID)) {\n            return false;\n          }\n\n          // filter by filter context\n          if (filterDocs != null && !filterDocs.get(docID)) {\n            return false;\n          }\n\n          try {\n            collector.collect(docID, spare.toCharsRef(), decode(output.output1));\n            return true;\n          } catch (IOException e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      // TODO: add fuzzy support\n      for (FSTUtil.Path<Pair<Long, BytesRef>> path : prefixPaths) {\n        searcher.addStartPaths(path.fstNode, path.output, false, path.input);\n      }\n\n      try {\n        // hits are also returned by search()\n        // we do not use it, instead collect at acceptResult\n        Util.TopResults<Pair<Long, BytesRef>> search = searcher.search();\n        // search admissibility is not guaranteed\n        // see comment on getMaxTopNSearcherQueueSize\n        // assert  search.isComplete;\n      } catch (CollectionTerminatedException e) {\n        // terminate\n      }\n\n    } catch (IOException bogus) {\n      throw new RuntimeException(bogus);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a"],"07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8c33f6677a2078739058f81eca1df69d12cd62b0":["07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8c33f6677a2078739058f81eca1df69d12cd62b0"]},"commit2Childs":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","8c33f6677a2078739058f81eca1df69d12cd62b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","07e29e9a1cbba8cc30091c3e4f8e9eac7ec7d22a"],"8c33f6677a2078739058f81eca1df69d12cd62b0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}