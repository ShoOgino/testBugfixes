{"path":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","commits":[{"id":"e11b7252d34d00665befca520dee82fd64aed3c2","date":1429595379,"type":0,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","pathOld":"/dev/null","sourceNew":"  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = ZkStateReader.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().updateClusterState(true);\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ac55fed957ade417f7bf7a9f3aaa3d69ab294b05","date":1429607057,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","sourceNew":"  @AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-6665\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = ZkStateReader.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().updateClusterState(true);\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","sourceOld":"  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = ZkStateReader.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().updateClusterState(true);\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"920467eb07043f217d3793ecdaa61740984b013d","date":1435654691,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","sourceNew":"  @AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-7736\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = ZkStateReader.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().updateClusterState(true);\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","sourceOld":"  @AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-6665\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = ZkStateReader.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().updateClusterState(true);\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b693a83132c9e45afcd564fd65a25b60ed80388b","date":1436882146,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","sourceNew":"  @AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-7736\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = Utils.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().updateClusterState(true);\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","sourceOld":"  @AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-7736\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = ZkStateReader.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().updateClusterState(true);\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"102da6baafc0f534a59f31729343dbab9d3b9e9a","date":1438410244,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","sourceNew":"  @AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-7736\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = Utils.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().updateClusterState();\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","sourceOld":"  @AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-7736\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = Utils.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().updateClusterState(true);\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f","date":1457343183,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","sourceNew":"  @AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-7736\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = Utils.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().forceUpdateCollection(\"testPublishAndWaitForDownStates\");\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","sourceOld":"  @AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-7736\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = Utils.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().updateClusterState();\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ff5e25fb60ccc8574bcbd65396786ae9163f0149","date":1519706112,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","sourceNew":"  @BadApple(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-12028, https://issues.apache.org/jira/browse/SOLR-7736\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = Utils.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().forceUpdateCollection(\"testPublishAndWaitForDownStates\");\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","sourceOld":"  @AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-7736\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = Utils.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().forceUpdateCollection(\"testPublishAndWaitForDownStates\");\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0e2a782a06f40ec809b5e18df859c8c42d444be","date":1520449454,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","sourceNew":"  @AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-12028, https://issues.apache.org/jira/browse/SOLR-7736\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = Utils.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().forceUpdateCollection(\"testPublishAndWaitForDownStates\");\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","sourceOld":"  @BadApple(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-12028, https://issues.apache.org/jira/browse/SOLR-7736\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = Utils.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().forceUpdateCollection(\"testPublishAndWaitForDownStates\");\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a92d3a78193c351661c38ed287536e76ebf2a852","date":1522126714,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","sourceNew":"  @Slow\n  @LogLevel(value = \"org.apache.solr.cloud=DEBUG;org.apache.solr.cloud.overseer=DEBUG\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n\n    /*\n    This test asserts that if zkController.publishAndWaitForDownStates uses only core name to check if all local\n    cores are down then the method will return immediately but if it uses coreNodeName (as it does after SOLR-6665 then\n    the method will timeout).\n    We setup the cluster state in such a way that two replicas with same core name exist on non-existent nodes\n    and core container also has a dummy core that has the same core name. The publishAndWaitForDownStates before SOLR-6665\n    would only check the core names and therefore return immediately but after SOLR-6665 it should time out.\n     */\n\n    assumeWorkingMockito();\n    final String collectionName = \"testPublishAndWaitForDownStates\";\n    String zkDir = createTempDir(collectionName).toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    String nodeName = \"127.0.0.1:8983_solr\";\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = new MockCoreContainer()  {\n        @Override\n        public List<CoreDescriptor> getCoreDescriptors() {\n          CoreDescriptor descriptor = new CoreDescriptor(collectionName, TEST_PATH(), Collections.emptyMap(), new Properties(), true);\n          // non-existent coreNodeName, this will cause zkController.publishAndWaitForDownStates to wait indefinitely\n          // when using coreNodeName but usage of core name alone will return immediately\n          descriptor.getCloudDescriptor().setCoreNodeName(\"core_node0\");\n          return Collections.singletonList(descriptor);\n        }\n      };\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPathRoot(collectionName), new byte[0], CreateMode.PERSISTENT, true);\n\n        ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,\n            CollectionParams.CollectionAction.CREATE.toLower(), ZkStateReader.NODE_NAME_PROP, nodeName, ZkStateReader.NUM_SHARDS_PROP, \"1\",\n            \"name\", collectionName, DocCollection.STATE_FORMAT, \"2\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(m));\n\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host1\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"active\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host2\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"down\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        zkController.getZkStateReader().forciblyRefreshAllClusterStateSlow();\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","sourceOld":"  @AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-12028, https://issues.apache.org/jira/browse/SOLR-7736\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = Utils.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().forceUpdateCollection(\"testPublishAndWaitForDownStates\");\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7","date":1522191940,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","sourceNew":"  @Slow\n  @LogLevel(value = \"org.apache.solr.cloud=DEBUG;org.apache.solr.cloud.overseer=DEBUG\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n\n    /*\n    This test asserts that if zkController.publishAndWaitForDownStates uses only core name to check if all local\n    cores are down then the method will return immediately but if it uses coreNodeName (as it does after SOLR-6665 then\n    the method will timeout).\n    We setup the cluster state in such a way that two replicas with same core name exist on non-existent nodes\n    and core container also has a dummy core that has the same core name. The publishAndWaitForDownStates before SOLR-6665\n    would only check the core names and therefore return immediately but after SOLR-6665 it should time out.\n     */\n\n    assumeWorkingMockito();\n    final String collectionName = \"testPublishAndWaitForDownStates\";\n    String zkDir = createTempDir(collectionName).toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    String nodeName = \"127.0.0.1:8983_solr\";\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = new MockCoreContainer()  {\n        @Override\n        public List<CoreDescriptor> getCoreDescriptors() {\n          CoreDescriptor descriptor = new CoreDescriptor(collectionName, TEST_PATH(), Collections.emptyMap(), new Properties(), true);\n          // non-existent coreNodeName, this will cause zkController.publishAndWaitForDownStates to wait indefinitely\n          // when using coreNodeName but usage of core name alone will return immediately\n          descriptor.getCloudDescriptor().setCoreNodeName(\"core_node0\");\n          return Collections.singletonList(descriptor);\n        }\n      };\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPathRoot(collectionName), new byte[0], CreateMode.PERSISTENT, true);\n\n        ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,\n            CollectionParams.CollectionAction.CREATE.toLower(), ZkStateReader.NODE_NAME_PROP, nodeName, ZkStateReader.NUM_SHARDS_PROP, \"1\",\n            \"name\", collectionName, DocCollection.STATE_FORMAT, \"2\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(m));\n\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host1\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"active\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host2\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"down\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        zkController.getZkStateReader().forciblyRefreshAllClusterStateSlow();\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","sourceOld":"  @AwaitsFix(bugUrl = \"https://issues.apache.org/jira/browse/SOLR-12028, https://issues.apache.org/jira/browse/SOLR-7736\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n    String zkDir = createTempDir(\"testPublishAndWaitForDownStates\").toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = getCoreContainer();\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        HashMap<String, DocCollection> collectionStates = new HashMap<>();\n        HashMap<String, Replica> replicas = new HashMap<>();\n        // add two replicas with the same core name but one of them should be on a different node\n        // than this ZkController instance\n        for (int i=1; i<=2; i++)  {\n          Replica r = new Replica(\"core_node\" + i,\n              map(ZkStateReader.STATE_PROP, i == 1 ? \"active\" : \"down\",\n              ZkStateReader.NODE_NAME_PROP, i == 1 ? \"127.0.0.1:8983_solr\" : \"non_existent_host\",\n              ZkStateReader.CORE_NAME_PROP, \"collection1\"));\n          replicas.put(\"core_node\" + i, r);\n        }\n        HashMap<String, Object> sliceProps = new HashMap<>();\n        sliceProps.put(\"state\", Slice.State.ACTIVE.toString());\n        Slice slice = new Slice(\"shard1\", replicas, sliceProps);\n        DocCollection c = new DocCollection(\"testPublishAndWaitForDownStates\", map(\"shard1\", slice), Collections.emptyMap(), DocRouter.DEFAULT);\n        ClusterState state = new ClusterState(0, Collections.emptySet(), map(\"testPublishAndWaitForDownStates\", c));\n        byte[] bytes = Utils.toJSON(state);\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPath(\"testPublishAndWaitForDownStates\"), bytes, CreateMode.PERSISTENT, true);\n\n        zkController.getZkStateReader().forceUpdateCollection(\"testPublishAndWaitForDownStates\");\n        assertTrue(zkController.getZkStateReader().getClusterState().hasCollection(\"testPublishAndWaitForDownStates\"));\n        assertNotNull(zkController.getZkStateReader().getClusterState().getCollection(\"testPublishAndWaitForDownStates\"));\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","sourceNew":"  @Slow\n  @LogLevel(value = \"org.apache.solr.cloud=DEBUG;org.apache.solr.cloud.overseer=DEBUG\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n\n    /*\n    This test asserts that if zkController.publishAndWaitForDownStates uses only core name to check if all local\n    cores are down then the method will return immediately but if it uses coreNodeName (as it does after SOLR-6665 then\n    the method will timeout).\n    We setup the cluster state in such a way that two replicas with same core name exist on non-existent nodes\n    and core container also has a dummy core that has the same core name. The publishAndWaitForDownStates before SOLR-6665\n    would only check the core names and therefore return immediately but after SOLR-6665 it should time out.\n     */\n\n    assumeWorkingMockito();\n    final String collectionName = \"testPublishAndWaitForDownStates\";\n    String zkDir = createTempDir(collectionName).toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    String nodeName = \"127.0.0.1:8983_solr\";\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      cc = new MockCoreContainer()  {\n        @Override\n        public List<CoreDescriptor> getCoreDescriptors() {\n          CoreDescriptor descriptor = new CoreDescriptor(collectionName, TEST_PATH(), Collections.emptyMap(), new Properties(), true);\n          // non-existent coreNodeName, this will cause zkController.publishAndWaitForDownStates to wait indefinitely\n          // when using coreNodeName but usage of core name alone will return immediately\n          descriptor.getCloudDescriptor().setCoreNodeName(\"core_node0\");\n          return Collections.singletonList(descriptor);\n        }\n      };\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPathRoot(collectionName), new byte[0], CreateMode.PERSISTENT, true);\n\n        ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,\n            CollectionParams.CollectionAction.CREATE.toLower(), ZkStateReader.NODE_NAME_PROP, nodeName, ZkStateReader.NUM_SHARDS_PROP, \"1\",\n            \"name\", collectionName, DocCollection.STATE_FORMAT, \"2\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(m));\n\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host1\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"active\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host2\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"down\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        zkController.getZkStateReader().forciblyRefreshAllClusterStateSlow();\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(5, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates(5);\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","sourceOld":"  @Slow\n  @LogLevel(value = \"org.apache.solr.cloud=DEBUG;org.apache.solr.cloud.overseer=DEBUG\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n\n    /*\n    This test asserts that if zkController.publishAndWaitForDownStates uses only core name to check if all local\n    cores are down then the method will return immediately but if it uses coreNodeName (as it does after SOLR-6665 then\n    the method will timeout).\n    We setup the cluster state in such a way that two replicas with same core name exist on non-existent nodes\n    and core container also has a dummy core that has the same core name. The publishAndWaitForDownStates before SOLR-6665\n    would only check the core names and therefore return immediately but after SOLR-6665 it should time out.\n     */\n\n    assumeWorkingMockito();\n    final String collectionName = \"testPublishAndWaitForDownStates\";\n    String zkDir = createTempDir(collectionName).toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    String nodeName = \"127.0.0.1:8983_solr\";\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AbstractZkTestCase.tryCleanSolrZkNode(server.getZkHost());\n      AbstractZkTestCase.makeSolrZkNode(server.getZkHost());\n\n      cc = new MockCoreContainer()  {\n        @Override\n        public List<CoreDescriptor> getCoreDescriptors() {\n          CoreDescriptor descriptor = new CoreDescriptor(collectionName, TEST_PATH(), Collections.emptyMap(), new Properties(), true);\n          // non-existent coreNodeName, this will cause zkController.publishAndWaitForDownStates to wait indefinitely\n          // when using coreNodeName but usage of core name alone will return immediately\n          descriptor.getCloudDescriptor().setCoreNodeName(\"core_node0\");\n          return Collections.singletonList(descriptor);\n        }\n      };\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPathRoot(collectionName), new byte[0], CreateMode.PERSISTENT, true);\n\n        ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,\n            CollectionParams.CollectionAction.CREATE.toLower(), ZkStateReader.NODE_NAME_PROP, nodeName, ZkStateReader.NUM_SHARDS_PROP, \"1\",\n            \"name\", collectionName, DocCollection.STATE_FORMAT, \"2\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(m));\n\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host1\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"active\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host2\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"down\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        zkController.getZkStateReader().forciblyRefreshAllClusterStateSlow();\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(ZkController.WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates();\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","bugFix":["e11b7252d34d00665befca520dee82fd64aed3c2"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1778938cb7fb298e6e07a43e2d5acaf552d61518","date":1559609435,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","sourceNew":"  @Slow\n  @LogLevel(value = \"org.apache.solr.cloud=DEBUG;org.apache.solr.cloud.overseer=DEBUG\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n\n    /*\n    This test asserts that if zkController.publishAndWaitForDownStates uses only core name to check if all local\n    cores are down then the method will return immediately but if it uses coreNodeName (as it does after SOLR-6665 then\n    the method will timeout).\n    We setup the cluster state in such a way that two replicas with same core name exist on non-existent nodes\n    and core container also has a dummy core that has the same core name. The publishAndWaitForDownStates before SOLR-6665\n    would only check the core names and therefore return immediately but after SOLR-6665 it should time out.\n     */\n\n    assumeWorkingMockito();\n    final String collectionName = \"testPublishAndWaitForDownStates\";\n    Path zkDir = createTempDir(collectionName);\n    CoreContainer cc = null;\n\n    String nodeName = \"127.0.0.1:8983_solr\";\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      cc = new MockCoreContainer()  {\n        @Override\n        public List<CoreDescriptor> getCoreDescriptors() {\n          CoreDescriptor descriptor = new CoreDescriptor(collectionName, TEST_PATH(), Collections.emptyMap(), new Properties(), true);\n          // non-existent coreNodeName, this will cause zkController.publishAndWaitForDownStates to wait indefinitely\n          // when using coreNodeName but usage of core name alone will return immediately\n          descriptor.getCloudDescriptor().setCoreNodeName(\"core_node0\");\n          return Collections.singletonList(descriptor);\n        }\n      };\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPathRoot(collectionName), new byte[0], CreateMode.PERSISTENT, true);\n\n        ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,\n            CollectionParams.CollectionAction.CREATE.toLower(), ZkStateReader.NODE_NAME_PROP, nodeName, ZkStateReader.NUM_SHARDS_PROP, \"1\",\n            \"name\", collectionName, DocCollection.STATE_FORMAT, \"2\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(m));\n\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host1\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"active\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host2\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"down\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        zkController.getZkStateReader().forciblyRefreshAllClusterStateSlow();\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(5, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates(5);\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","sourceOld":"  @Slow\n  @LogLevel(value = \"org.apache.solr.cloud=DEBUG;org.apache.solr.cloud.overseer=DEBUG\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n\n    /*\n    This test asserts that if zkController.publishAndWaitForDownStates uses only core name to check if all local\n    cores are down then the method will return immediately but if it uses coreNodeName (as it does after SOLR-6665 then\n    the method will timeout).\n    We setup the cluster state in such a way that two replicas with same core name exist on non-existent nodes\n    and core container also has a dummy core that has the same core name. The publishAndWaitForDownStates before SOLR-6665\n    would only check the core names and therefore return immediately but after SOLR-6665 it should time out.\n     */\n\n    assumeWorkingMockito();\n    final String collectionName = \"testPublishAndWaitForDownStates\";\n    String zkDir = createTempDir(collectionName).toFile().getAbsolutePath();\n    CoreContainer cc = null;\n\n    String nodeName = \"127.0.0.1:8983_solr\";\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      cc = new MockCoreContainer()  {\n        @Override\n        public List<CoreDescriptor> getCoreDescriptors() {\n          CoreDescriptor descriptor = new CoreDescriptor(collectionName, TEST_PATH(), Collections.emptyMap(), new Properties(), true);\n          // non-existent coreNodeName, this will cause zkController.publishAndWaitForDownStates to wait indefinitely\n          // when using coreNodeName but usage of core name alone will return immediately\n          descriptor.getCloudDescriptor().setCoreNodeName(\"core_node0\");\n          return Collections.singletonList(descriptor);\n        }\n      };\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPathRoot(collectionName), new byte[0], CreateMode.PERSISTENT, true);\n\n        ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,\n            CollectionParams.CollectionAction.CREATE.toLower(), ZkStateReader.NODE_NAME_PROP, nodeName, ZkStateReader.NUM_SHARDS_PROP, \"1\",\n            \"name\", collectionName, DocCollection.STATE_FORMAT, \"2\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(m));\n\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host1\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"active\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host2\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"down\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        zkController.getZkStateReader().forciblyRefreshAllClusterStateSlow();\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(5, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates(5);\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3e4fb176991e13ab85dfe62dceeb287dde115745","date":1579630717,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","sourceNew":"  @Slow\n  @LogLevel(value = \"org.apache.solr.cloud=DEBUG;org.apache.solr.cloud.overseer=DEBUG\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n\n    /*\n    This test asserts that if zkController.publishAndWaitForDownStates uses only core name to check if all local\n    cores are down then the method will return immediately but if it uses coreNodeName (as it does after SOLR-6665 then\n    the method will timeout).\n    We setup the cluster state in such a way that two replicas with same core name exist on non-existent nodes\n    and core container also has a dummy core that has the same core name. The publishAndWaitForDownStates before SOLR-6665\n    would only check the core names and therefore return immediately but after SOLR-6665 it should time out.\n     */\n\n    assumeWorkingMockito();\n    final String collectionName = \"testPublishAndWaitForDownStates\";\n    Path zkDir = createTempDir(collectionName);\n    CoreContainer cc = null;\n\n    String nodeName = \"127.0.0.1:8983_solr\";\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AtomicReference<ZkController> zkControllerRef = new AtomicReference<>();\n      cc = new MockCoreContainer()  {\n        @Override\n        public List<CoreDescriptor> getCoreDescriptors() {\n          CoreDescriptor descriptor = new CoreDescriptor(collectionName, TEST_PATH(), Collections.emptyMap(), new Properties(), zkControllerRef.get());\n          // non-existent coreNodeName, this will cause zkController.publishAndWaitForDownStates to wait indefinitely\n          // when using coreNodeName but usage of core name alone will return immediately\n          descriptor.getCloudDescriptor().setCoreNodeName(\"core_node0\");\n          return Collections.singletonList(descriptor);\n        }\n      };\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n        zkControllerRef.set(zkController);\n\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPathRoot(collectionName), new byte[0], CreateMode.PERSISTENT, true);\n\n        ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,\n            CollectionParams.CollectionAction.CREATE.toLower(), ZkStateReader.NODE_NAME_PROP, nodeName, ZkStateReader.NUM_SHARDS_PROP, \"1\",\n            \"name\", collectionName, DocCollection.STATE_FORMAT, \"2\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(m));\n\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host1\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"active\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host2\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"down\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        zkController.getZkStateReader().forciblyRefreshAllClusterStateSlow();\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(5, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates(5);\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","sourceOld":"  @Slow\n  @LogLevel(value = \"org.apache.solr.cloud=DEBUG;org.apache.solr.cloud.overseer=DEBUG\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n\n    /*\n    This test asserts that if zkController.publishAndWaitForDownStates uses only core name to check if all local\n    cores are down then the method will return immediately but if it uses coreNodeName (as it does after SOLR-6665 then\n    the method will timeout).\n    We setup the cluster state in such a way that two replicas with same core name exist on non-existent nodes\n    and core container also has a dummy core that has the same core name. The publishAndWaitForDownStates before SOLR-6665\n    would only check the core names and therefore return immediately but after SOLR-6665 it should time out.\n     */\n\n    assumeWorkingMockito();\n    final String collectionName = \"testPublishAndWaitForDownStates\";\n    Path zkDir = createTempDir(collectionName);\n    CoreContainer cc = null;\n\n    String nodeName = \"127.0.0.1:8983_solr\";\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      cc = new MockCoreContainer()  {\n        @Override\n        public List<CoreDescriptor> getCoreDescriptors() {\n          CoreDescriptor descriptor = new CoreDescriptor(collectionName, TEST_PATH(), Collections.emptyMap(), new Properties(), true);\n          // non-existent coreNodeName, this will cause zkController.publishAndWaitForDownStates to wait indefinitely\n          // when using coreNodeName but usage of core name alone will return immediately\n          descriptor.getCloudDescriptor().setCoreNodeName(\"core_node0\");\n          return Collections.singletonList(descriptor);\n        }\n      };\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPathRoot(collectionName), new byte[0], CreateMode.PERSISTENT, true);\n\n        ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,\n            CollectionParams.CollectionAction.CREATE.toLower(), ZkStateReader.NODE_NAME_PROP, nodeName, ZkStateReader.NUM_SHARDS_PROP, \"1\",\n            \"name\", collectionName, DocCollection.STATE_FORMAT, \"2\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(m));\n\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host1\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"active\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host2\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"down\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        zkController.getZkStateReader().forciblyRefreshAllClusterStateSlow();\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(5, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates(5);\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1c560208bc8842ee884b76b08784ccb132f05b48","date":1585344697,"type":3,"author":"Mike","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","sourceNew":"  @Slow\n  @LogLevel(value = \"org.apache.solr.cloud=DEBUG;org.apache.solr.cloud.overseer=DEBUG\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n\n    /*\n    This test asserts that if zkController.publishAndWaitForDownStates uses only core name to check if all local\n    cores are down then the method will return immediately but if it uses coreNodeName (as it does after SOLR-6665 then\n    the method will timeout).\n    We setup the cluster state in such a way that two replicas with same core name exist on non-existent nodes\n    and core container also has a dummy core that has the same core name. The publishAndWaitForDownStates before SOLR-6665\n    would only check the core names and therefore return immediately but after SOLR-6665 it should time out.\n     */\n\n    assumeWorkingMockito();\n    final String collectionName = \"testPublishAndWaitForDownStates\";\n    Path zkDir = createTempDir(collectionName);\n    CoreContainer cc = null;\n\n    String nodeName = \"127.0.0.1:8983_solr\";\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AtomicReference<ZkController> zkControllerRef = new AtomicReference<>();\n      cc = new MockCoreContainer()  {\n        @Override\n        public List<CoreDescriptor> getCoreDescriptors() {\n          CoreDescriptor descriptor = new CoreDescriptor(collectionName, TEST_PATH(), Collections.emptyMap(), new Properties(), zkControllerRef.get());\n          // non-existent coreNodeName, this will cause zkController.publishAndWaitForDownStates to wait indefinitely\n          // when using coreNodeName but usage of core name alone will return immediately\n          descriptor.getCloudDescriptor().setCoreNodeName(\"core_node0\");\n          return Collections.singletonList(descriptor);\n        }\n      };\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, () -> null);\n        zkControllerRef.set(zkController);\n\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPathRoot(collectionName), new byte[0], CreateMode.PERSISTENT, true);\n\n        ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,\n            CollectionParams.CollectionAction.CREATE.toLower(), ZkStateReader.NODE_NAME_PROP, nodeName, ZkStateReader.NUM_SHARDS_PROP, \"1\",\n            \"name\", collectionName, DocCollection.STATE_FORMAT, \"2\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(m));\n\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host1\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"active\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host2\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"down\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        zkController.getZkStateReader().forciblyRefreshAllClusterStateSlow();\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(5, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates(5);\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","sourceOld":"  @Slow\n  @LogLevel(value = \"org.apache.solr.cloud=DEBUG;org.apache.solr.cloud.overseer=DEBUG\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n\n    /*\n    This test asserts that if zkController.publishAndWaitForDownStates uses only core name to check if all local\n    cores are down then the method will return immediately but if it uses coreNodeName (as it does after SOLR-6665 then\n    the method will timeout).\n    We setup the cluster state in such a way that two replicas with same core name exist on non-existent nodes\n    and core container also has a dummy core that has the same core name. The publishAndWaitForDownStates before SOLR-6665\n    would only check the core names and therefore return immediately but after SOLR-6665 it should time out.\n     */\n\n    assumeWorkingMockito();\n    final String collectionName = \"testPublishAndWaitForDownStates\";\n    Path zkDir = createTempDir(collectionName);\n    CoreContainer cc = null;\n\n    String nodeName = \"127.0.0.1:8983_solr\";\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AtomicReference<ZkController> zkControllerRef = new AtomicReference<>();\n      cc = new MockCoreContainer()  {\n        @Override\n        public List<CoreDescriptor> getCoreDescriptors() {\n          CoreDescriptor descriptor = new CoreDescriptor(collectionName, TEST_PATH(), Collections.emptyMap(), new Properties(), zkControllerRef.get());\n          // non-existent coreNodeName, this will cause zkController.publishAndWaitForDownStates to wait indefinitely\n          // when using coreNodeName but usage of core name alone will return immediately\n          descriptor.getCloudDescriptor().setCoreNodeName(\"core_node0\");\n          return Collections.singletonList(descriptor);\n        }\n      };\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, new CurrentCoreDescriptorProvider() {\n\n          @Override\n          public List<CoreDescriptor> getCurrentDescriptors() {\n            // do nothing\n            return null;\n          }\n        });\n        zkControllerRef.set(zkController);\n\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPathRoot(collectionName), new byte[0], CreateMode.PERSISTENT, true);\n\n        ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,\n            CollectionParams.CollectionAction.CREATE.toLower(), ZkStateReader.NODE_NAME_PROP, nodeName, ZkStateReader.NUM_SHARDS_PROP, \"1\",\n            \"name\", collectionName, DocCollection.STATE_FORMAT, \"2\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(m));\n\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host1\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"active\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host2\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"down\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        zkController.getZkStateReader().forciblyRefreshAllClusterStateSlow();\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(5, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates(5);\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5ad9c35f926b4bf8da0336d1300efc709c8d5a56","date":1591729157,"type":3,"author":"murblanc","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/ZkControllerTest#testPublishAndWaitForDownStates().mjava","sourceNew":"  @Slow\n  @LogLevel(value = \"org.apache.solr.cloud=DEBUG;org.apache.solr.cloud.overseer=DEBUG\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n\n    /*\n    This test asserts that if zkController.publishAndWaitForDownStates uses only core name to check if all local\n    cores are down then the method will return immediately but if it uses coreNodeName (as it does after SOLR-6665 then\n    the method will timeout).\n    We setup the cluster state in such a way that two replicas with same core name exist on non-existent nodes\n    and core container also has a dummy core that has the same core name. The publishAndWaitForDownStates before SOLR-6665\n    would only check the core names and therefore return immediately but after SOLR-6665 it should time out.\n     */\n\n    assumeWorkingMockito();\n    final String collectionName = \"testPublishAndWaitForDownStates\";\n    Path zkDir = createTempDir(collectionName);\n    CoreContainer cc = null;\n\n    String nodeName = \"127.0.0.1:8983_solr\";\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AtomicReference<ZkController> zkControllerRef = new AtomicReference<>();\n      cc = new MockCoreContainer()  {\n        @Override\n        public List<CoreDescriptor> getCoreDescriptors() {\n          CoreDescriptor descriptor = new CoreDescriptor(collectionName, TEST_PATH(), Collections.emptyMap(), new Properties(), zkControllerRef.get());\n          // non-existent coreNodeName, this will cause zkController.publishAndWaitForDownStates to wait indefinitely\n          // when using coreNodeName but usage of core name alone will return immediately\n          descriptor.getCloudDescriptor().setCoreNodeName(\"core_node0\");\n          return Collections.singletonList(descriptor);\n        }\n      };\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, () -> null);\n        zkControllerRef.set(zkController);\n\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPathRoot(collectionName), new byte[0], CreateMode.PERSISTENT, true);\n\n        ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,\n            CollectionParams.CollectionAction.CREATE.toLower(), ZkStateReader.NODE_NAME_PROP, nodeName, ZkStateReader.NUM_SHARDS_PROP, \"1\",\n            \"name\", collectionName);\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(m));\n\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host1\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"active\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host2\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"down\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        zkController.getZkStateReader().forciblyRefreshAllClusterStateSlow();\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(5, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates(5);\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","sourceOld":"  @Slow\n  @LogLevel(value = \"org.apache.solr.cloud=DEBUG;org.apache.solr.cloud.overseer=DEBUG\")\n  public void testPublishAndWaitForDownStates() throws Exception  {\n\n    /*\n    This test asserts that if zkController.publishAndWaitForDownStates uses only core name to check if all local\n    cores are down then the method will return immediately but if it uses coreNodeName (as it does after SOLR-6665 then\n    the method will timeout).\n    We setup the cluster state in such a way that two replicas with same core name exist on non-existent nodes\n    and core container also has a dummy core that has the same core name. The publishAndWaitForDownStates before SOLR-6665\n    would only check the core names and therefore return immediately but after SOLR-6665 it should time out.\n     */\n\n    assumeWorkingMockito();\n    final String collectionName = \"testPublishAndWaitForDownStates\";\n    Path zkDir = createTempDir(collectionName);\n    CoreContainer cc = null;\n\n    String nodeName = \"127.0.0.1:8983_solr\";\n\n    ZkTestServer server = new ZkTestServer(zkDir);\n    try {\n      server.run();\n\n      AtomicReference<ZkController> zkControllerRef = new AtomicReference<>();\n      cc = new MockCoreContainer()  {\n        @Override\n        public List<CoreDescriptor> getCoreDescriptors() {\n          CoreDescriptor descriptor = new CoreDescriptor(collectionName, TEST_PATH(), Collections.emptyMap(), new Properties(), zkControllerRef.get());\n          // non-existent coreNodeName, this will cause zkController.publishAndWaitForDownStates to wait indefinitely\n          // when using coreNodeName but usage of core name alone will return immediately\n          descriptor.getCloudDescriptor().setCoreNodeName(\"core_node0\");\n          return Collections.singletonList(descriptor);\n        }\n      };\n      ZkController zkController = null;\n\n      try {\n        CloudConfig cloudConfig = new CloudConfig.CloudConfigBuilder(\"127.0.0.1\", 8983, \"solr\").build();\n        zkController = new ZkController(cc, server.getZkAddress(), TIMEOUT, cloudConfig, () -> null);\n        zkControllerRef.set(zkController);\n\n        zkController.getZkClient().makePath(ZkStateReader.getCollectionPathRoot(collectionName), new byte[0], CreateMode.PERSISTENT, true);\n\n        ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,\n            CollectionParams.CollectionAction.CREATE.toLower(), ZkStateReader.NODE_NAME_PROP, nodeName, ZkStateReader.NUM_SHARDS_PROP, \"1\",\n            \"name\", collectionName, DocCollection.STATE_FORMAT, \"2\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(m));\n\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host1\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"active\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, ADDREPLICA.toLower());\n        propMap.put(COLLECTION_PROP, collectionName);\n        propMap.put(SHARD_ID_PROP, \"shard1\");\n        propMap.put(ZkStateReader.NODE_NAME_PROP, \"non_existent_host2\");\n        propMap.put(ZkStateReader.CORE_NAME_PROP, collectionName);\n        propMap.put(ZkStateReader.STATE_PROP, \"down\");\n        zkController.getOverseerJobQueue().offer(Utils.toJSON(propMap));\n\n        zkController.getZkStateReader().forciblyRefreshAllClusterStateSlow();\n\n        long now = System.nanoTime();\n        long timeout = now + TimeUnit.NANOSECONDS.convert(5, TimeUnit.SECONDS);\n        zkController.publishAndWaitForDownStates(5);\n        assertTrue(\"The ZkController.publishAndWaitForDownStates should have timed out but it didn't\", System.nanoTime() >= timeout);\n      } finally {\n        if (zkController != null)\n          zkController.close();\n      }\n    } finally {\n      if (cc != null) {\n        cc.shutdown();\n      }\n      server.shutdown();\n    }\n  }\n\n","bugFix":["a92d3a78193c351661c38ed287536e76ebf2a852"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"920467eb07043f217d3793ecdaa61740984b013d":["ac55fed957ade417f7bf7a9f3aaa3d69ab294b05"],"5ad9c35f926b4bf8da0336d1300efc709c8d5a56":["1c560208bc8842ee884b76b08784ccb132f05b48"],"ff5e25fb60ccc8574bcbd65396786ae9163f0149":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f"],"1c560208bc8842ee884b76b08784ccb132f05b48":["3e4fb176991e13ab85dfe62dceeb287dde115745"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7"],"3e4fb176991e13ab85dfe62dceeb287dde115745":["1778938cb7fb298e6e07a43e2d5acaf552d61518"],"102da6baafc0f534a59f31729343dbab9d3b9e9a":["b693a83132c9e45afcd564fd65a25b60ed80388b"],"b693a83132c9e45afcd564fd65a25b60ed80388b":["920467eb07043f217d3793ecdaa61740984b013d"],"d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7":["d0e2a782a06f40ec809b5e18df859c8c42d444be","a92d3a78193c351661c38ed287536e76ebf2a852"],"a92d3a78193c351661c38ed287536e76ebf2a852":["d0e2a782a06f40ec809b5e18df859c8c42d444be"],"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f":["102da6baafc0f534a59f31729343dbab9d3b9e9a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0e2a782a06f40ec809b5e18df859c8c42d444be":["ff5e25fb60ccc8574bcbd65396786ae9163f0149"],"ac55fed957ade417f7bf7a9f3aaa3d69ab294b05":["e11b7252d34d00665befca520dee82fd64aed3c2"],"1778938cb7fb298e6e07a43e2d5acaf552d61518":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"e11b7252d34d00665befca520dee82fd64aed3c2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56"]},"commit2Childs":{"920467eb07043f217d3793ecdaa61740984b013d":["b693a83132c9e45afcd564fd65a25b60ed80388b"],"5ad9c35f926b4bf8da0336d1300efc709c8d5a56":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ff5e25fb60ccc8574bcbd65396786ae9163f0149":["d0e2a782a06f40ec809b5e18df859c8c42d444be"],"1c560208bc8842ee884b76b08784ccb132f05b48":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["1778938cb7fb298e6e07a43e2d5acaf552d61518"],"3e4fb176991e13ab85dfe62dceeb287dde115745":["1c560208bc8842ee884b76b08784ccb132f05b48"],"102da6baafc0f534a59f31729343dbab9d3b9e9a":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f"],"d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"b693a83132c9e45afcd564fd65a25b60ed80388b":["102da6baafc0f534a59f31729343dbab9d3b9e9a"],"a92d3a78193c351661c38ed287536e76ebf2a852":["d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7"],"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f":["ff5e25fb60ccc8574bcbd65396786ae9163f0149"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e11b7252d34d00665befca520dee82fd64aed3c2"],"d0e2a782a06f40ec809b5e18df859c8c42d444be":["d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7","a92d3a78193c351661c38ed287536e76ebf2a852"],"ac55fed957ade417f7bf7a9f3aaa3d69ab294b05":["920467eb07043f217d3793ecdaa61740984b013d"],"1778938cb7fb298e6e07a43e2d5acaf552d61518":["3e4fb176991e13ab85dfe62dceeb287dde115745"],"e11b7252d34d00665befca520dee82fd64aed3c2":["ac55fed957ade417f7bf7a9f3aaa3d69ab294b05"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}