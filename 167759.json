{"path":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","sourceNew":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          bytesWriter.writeVInt(suffix);\n          bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          bytesWriter2.writeVInt(term.stats.docFreq);\n          if (fieldInfo.indexOptions != IndexOptions.DOCS_ONLY) {\n            assert term.stats.totalTermFreq >= term.stats.docFreq;\n            bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n          }\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt(suffix<<1);\n            bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            bytesWriter2.writeVInt(term.stats.docFreq);\n            if (fieldInfo.indexOptions != IndexOptions.DOCS_ONLY) {\n              assert term.stats.totalTermFreq >= term.stats.docFreq;\n              bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n            }\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt((suffix<<1)|1);\n            bytesWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            bytesWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (bytesWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) bytesWriter2.getFilePointer());\n      bytesWriter2.writeTo(out);\n      bytesWriter2.reset();\n\n      // Have postings writer write block\n      postingsWriter.flushTermsBlock(futureTermCount+termCount, termCount);\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","sourceOld":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          bytesWriter.writeVInt(suffix);\n          bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          bytesWriter2.writeVInt(term.stats.docFreq);\n          if (fieldInfo.indexOptions != IndexOptions.DOCS_ONLY) {\n            assert term.stats.totalTermFreq >= term.stats.docFreq;\n            bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n          }\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt(suffix<<1);\n            bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            bytesWriter2.writeVInt(term.stats.docFreq);\n            if (fieldInfo.indexOptions != IndexOptions.DOCS_ONLY) {\n              assert term.stats.totalTermFreq >= term.stats.docFreq;\n              bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n            }\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt((suffix<<1)|1);\n            bytesWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            bytesWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (bytesWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) bytesWriter2.getFilePointer());\n      bytesWriter2.writeTo(out);\n      bytesWriter2.reset();\n\n      // Have postings writer write block\n      postingsWriter.flushTermsBlock(futureTermCount+termCount, termCount);\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"76923f6a33f2c4bec7f584e3f251261afe7ea276","date":1337149711,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","sourceNew":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          bytesWriter.writeVInt(suffix);\n          bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          bytesWriter2.writeVInt(term.stats.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert term.stats.totalTermFreq >= term.stats.docFreq;\n            bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n          }\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt(suffix<<1);\n            bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            bytesWriter2.writeVInt(term.stats.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert term.stats.totalTermFreq >= term.stats.docFreq;\n              bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n            }\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt((suffix<<1)|1);\n            bytesWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            bytesWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (bytesWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) bytesWriter2.getFilePointer());\n      bytesWriter2.writeTo(out);\n      bytesWriter2.reset();\n\n      // Have postings writer write block\n      postingsWriter.flushTermsBlock(futureTermCount+termCount, termCount);\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","sourceOld":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          bytesWriter.writeVInt(suffix);\n          bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          bytesWriter2.writeVInt(term.stats.docFreq);\n          if (fieldInfo.indexOptions != IndexOptions.DOCS_ONLY) {\n            assert term.stats.totalTermFreq >= term.stats.docFreq;\n            bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n          }\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt(suffix<<1);\n            bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            bytesWriter2.writeVInt(term.stats.docFreq);\n            if (fieldInfo.indexOptions != IndexOptions.DOCS_ONLY) {\n              assert term.stats.totalTermFreq >= term.stats.docFreq;\n              bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n            }\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt((suffix<<1)|1);\n            bytesWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            bytesWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (bytesWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) bytesWriter2.getFilePointer());\n      bytesWriter2.writeTo(out);\n      bytesWriter2.reset();\n\n      // Have postings writer write block\n      postingsWriter.flushTermsBlock(futureTermCount+termCount, termCount);\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","sourceNew":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          bytesWriter.writeVInt(suffix);\n          bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          bytesWriter2.writeVInt(term.stats.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert term.stats.totalTermFreq >= term.stats.docFreq;\n            bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n          }\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt(suffix<<1);\n            bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            bytesWriter2.writeVInt(term.stats.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert term.stats.totalTermFreq >= term.stats.docFreq;\n              bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n            }\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt((suffix<<1)|1);\n            bytesWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            bytesWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (bytesWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) bytesWriter2.getFilePointer());\n      bytesWriter2.writeTo(out);\n      bytesWriter2.reset();\n\n      // Have postings writer write block\n      postingsWriter.flushTermsBlock(futureTermCount+termCount, termCount);\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","sourceOld":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          bytesWriter.writeVInt(suffix);\n          bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          bytesWriter2.writeVInt(term.stats.docFreq);\n          if (fieldInfo.indexOptions != IndexOptions.DOCS_ONLY) {\n            assert term.stats.totalTermFreq >= term.stats.docFreq;\n            bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n          }\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt(suffix<<1);\n            bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            bytesWriter2.writeVInt(term.stats.docFreq);\n            if (fieldInfo.indexOptions != IndexOptions.DOCS_ONLY) {\n              assert term.stats.totalTermFreq >= term.stats.docFreq;\n              bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n            }\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt((suffix<<1)|1);\n            bytesWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            bytesWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (bytesWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) bytesWriter2.getFilePointer());\n      bytesWriter2.writeTo(out);\n      bytesWriter2.reset();\n\n      // Have postings writer write block\n      postingsWriter.flushTermsBlock(futureTermCount+termCount, termCount);\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e885d2b1e112b1d9db6a2dae82b3b493dfba1df1","date":1342716838,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","sourceNew":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          bytesWriter.writeVInt(suffix);\n          bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          bytesWriter2.writeVInt(term.stats.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert term.stats.totalTermFreq >= term.stats.docFreq: term.stats.totalTermFreq + \" vs \" + term.stats.docFreq;\n            bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n          }\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt(suffix<<1);\n            bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            bytesWriter2.writeVInt(term.stats.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert term.stats.totalTermFreq >= term.stats.docFreq;\n              bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n            }\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt((suffix<<1)|1);\n            bytesWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            bytesWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (bytesWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) bytesWriter2.getFilePointer());\n      bytesWriter2.writeTo(out);\n      bytesWriter2.reset();\n\n      // Have postings writer write block\n      postingsWriter.flushTermsBlock(futureTermCount+termCount, termCount);\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","sourceOld":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          bytesWriter.writeVInt(suffix);\n          bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          bytesWriter2.writeVInt(term.stats.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert term.stats.totalTermFreq >= term.stats.docFreq;\n            bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n          }\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt(suffix<<1);\n            bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            bytesWriter2.writeVInt(term.stats.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert term.stats.totalTermFreq >= term.stats.docFreq;\n              bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n            }\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt((suffix<<1)|1);\n            bytesWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            bytesWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (bytesWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) bytesWriter2.getFilePointer());\n      bytesWriter2.writeTo(out);\n      bytesWriter2.reset();\n\n      // Have postings writer write block\n      postingsWriter.flushTermsBlock(futureTermCount+termCount, termCount);\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8615860cb50aefb8eebca1d1b3893dbe21cf126","date":1345550448,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","sourceNew":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          bytesWriter.writeVInt(suffix);\n          bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          bytesWriter2.writeVInt(term.stats.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert term.stats.totalTermFreq >= term.stats.docFreq: term.stats.totalTermFreq + \" vs \" + term.stats.docFreq;\n            bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n          }\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt(suffix<<1);\n            bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            bytesWriter2.writeVInt(term.stats.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert term.stats.totalTermFreq >= term.stats.docFreq;\n              bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n            }\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt((suffix<<1)|1);\n            bytesWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            bytesWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (bytesWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) bytesWriter2.getFilePointer());\n      bytesWriter2.writeTo(out);\n      bytesWriter2.reset();\n\n      // Have postings writer write block\n      postingsWriter.flushTermsBlock(futureTermCount+termCount, termCount);\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","sourceOld":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          bytesWriter.writeVInt(suffix);\n          bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          bytesWriter2.writeVInt(term.stats.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert term.stats.totalTermFreq >= term.stats.docFreq;\n            bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n          }\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt(suffix<<1);\n            bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            bytesWriter2.writeVInt(term.stats.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert term.stats.totalTermFreq >= term.stats.docFreq;\n              bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n            }\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt((suffix<<1)|1);\n            bytesWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            bytesWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (bytesWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) bytesWriter2.getFilePointer());\n      bytesWriter2.writeTo(out);\n      bytesWriter2.reset();\n\n      // Have postings writer write block\n      postingsWriter.flushTermsBlock(futureTermCount+termCount, termCount);\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"001b25b42373b22a52f399dbf072f1224632e8e6","date":1345889167,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","sourceNew":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          bytesWriter.writeVInt(suffix);\n          bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          bytesWriter2.writeVInt(term.stats.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert term.stats.totalTermFreq >= term.stats.docFreq: term.stats.totalTermFreq + \" vs \" + term.stats.docFreq;\n            bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n          }\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt(suffix<<1);\n            bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            bytesWriter2.writeVInt(term.stats.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert term.stats.totalTermFreq >= term.stats.docFreq;\n              bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n            }\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt((suffix<<1)|1);\n            bytesWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            bytesWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (bytesWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) bytesWriter2.getFilePointer());\n      bytesWriter2.writeTo(out);\n      bytesWriter2.reset();\n\n      // Have postings writer write block\n      postingsWriter.flushTermsBlock(futureTermCount+termCount, termCount);\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","sourceOld":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          bytesWriter.writeVInt(suffix);\n          bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          bytesWriter2.writeVInt(term.stats.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert term.stats.totalTermFreq >= term.stats.docFreq;\n            bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n          }\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt(suffix<<1);\n            bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            bytesWriter2.writeVInt(term.stats.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert term.stats.totalTermFreq >= term.stats.docFreq;\n              bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n            }\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt((suffix<<1)|1);\n            bytesWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            bytesWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (bytesWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) bytesWriter2.getFilePointer());\n      bytesWriter2.writeTo(out);\n      bytesWriter2.reset();\n\n      // Have postings writer write block\n      postingsWriter.flushTermsBlock(futureTermCount+termCount, termCount);\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1a88d7b0899b7d22dcbd4cf8ca35d9ec9850ab98","date":1377268487,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","sourceNew":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n\n      long[] longs = new long[longsSize];\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          BlockTermState state = term.state;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            BlockTermState state = term.state;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","sourceOld":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          bytesWriter.writeVInt(suffix);\n          bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          bytesWriter2.writeVInt(term.stats.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert term.stats.totalTermFreq >= term.stats.docFreq: term.stats.totalTermFreq + \" vs \" + term.stats.docFreq;\n            bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n          }\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt(suffix<<1);\n            bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            bytesWriter2.writeVInt(term.stats.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert term.stats.totalTermFreq >= term.stats.docFreq;\n              bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n            }\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt((suffix<<1)|1);\n            bytesWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            bytesWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (bytesWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) bytesWriter2.getFilePointer());\n      bytesWriter2.writeTo(out);\n      bytesWriter2.reset();\n\n      // Have postings writer write block\n      postingsWriter.flushTermsBlock(futureTermCount+termCount, termCount);\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2f948dd442d23baa6cbb28daf77c8db78b351329","date":1378742876,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","sourceNew":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n\n      long[] longs = new long[longsSize];\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          BlockTermState state = term.state;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            BlockTermState state = term.state;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","sourceOld":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          bytesWriter.writeVInt(suffix);\n          bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          bytesWriter2.writeVInt(term.stats.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert term.stats.totalTermFreq >= term.stats.docFreq: term.stats.totalTermFreq + \" vs \" + term.stats.docFreq;\n            bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n          }\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt(suffix<<1);\n            bytesWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            bytesWriter2.writeVInt(term.stats.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert term.stats.totalTermFreq >= term.stats.docFreq;\n              bytesWriter2.writeVLong(term.stats.totalTermFreq - term.stats.docFreq);\n            }\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            bytesWriter.writeVInt((suffix<<1)|1);\n            bytesWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            bytesWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (bytesWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      bytesWriter.writeTo(out);\n      bytesWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) bytesWriter2.getFilePointer());\n      bytesWriter2.writeTo(out);\n      bytesWriter2.reset();\n\n      // Have postings writer write block\n      postingsWriter.flushTermsBlock(futureTermCount+termCount, termCount);\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","sourceNew":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n\n      long[] longs = new long[longsSize];\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          BlockTermState state = term.state;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            BlockTermState state = term.state;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","sourceOld":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n\n      long[] longs = new long[longsSize];\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          BlockTermState state = term.state;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<FST<BytesRef>>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            BlockTermState state = term.state;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5ad80176d91a6f70fe93880e43dfd697dc4e63ed","date":1400176913,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","sourceNew":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n\n      long[] longs = new long[longsSize];\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          BlockTermState state = term.state;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            BlockTermState state = term.state;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","sourceOld":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n\n      long[] longs = new long[longsSize];\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          BlockTermState state = term.state;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            BlockTermState state = term.state;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4d637064d608752565d4f9f41b2497dfdfdde50e","date":1400798123,"type":5,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/blocktree/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsWriter.TermsWriter#writeBlock(IntsRef,int,int,int,int,int,boolean,int,boolean).mjava","sourceNew":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n\n      long[] longs = new long[longsSize];\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          BlockTermState state = term.state;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            BlockTermState state = term.state;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","sourceOld":"    // Writes all entries in the pending slice as a single\n    // block: \n    private PendingBlock writeBlock(IntsRef prevTerm, int prefixLength, int indexPrefixLength, int startBackwards, int length,\n                                    int futureTermCount, boolean isFloor, int floorLeadByte, boolean isLastInFloor) throws IOException {\n\n      assert length > 0;\n\n      final int start = pending.size()-startBackwards;\n\n      assert start >= 0: \"pending.size()=\" + pending.size() + \" startBackwards=\" + startBackwards + \" length=\" + length;\n\n      final List<PendingEntry> slice = pending.subList(start, start + length);\n\n      final long startFP = out.getFilePointer();\n\n      final BytesRef prefix = new BytesRef(indexPrefixLength);\n      for(int m=0;m<indexPrefixLength;m++) {\n        prefix.bytes[m] = (byte) prevTerm.ints[m];\n      }\n      prefix.length = indexPrefixLength;\n\n      // Write block header:\n      out.writeVInt((length<<1)|(isLastInFloor ? 1:0));\n\n      // if (DEBUG) {\n      //   System.out.println(\"  writeBlock \" + (isFloor ? \"(floor) \" : \"\") + \"seg=\" + segment + \" pending.size()=\" + pending.size() + \" prefixLength=\" + prefixLength + \" indexPrefix=\" + toString(prefix) + \" entCount=\" + length + \" startFP=\" + startFP + \" futureTermCount=\" + futureTermCount + (isFloor ? (\" floorLeadByte=\" + Integer.toHexString(floorLeadByte&0xff)) : \"\") + \" isLastInFloor=\" + isLastInFloor);\n      // }\n\n      // 1st pass: pack term suffix bytes into byte[] blob\n      // TODO: cutover to bulk int codec... simple64?\n\n      final boolean isLeafBlock;\n      if (lastBlockIndex < start) {\n        // This block definitely does not contain sub-blocks:\n        isLeafBlock = true;\n        //System.out.println(\"no scan true isFloor=\" + isFloor);\n      } else if (!isFloor) {\n        // This block definitely does contain at least one sub-block:\n        isLeafBlock = false;\n        //System.out.println(\"no scan false \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n      } else {\n        // Must scan up-front to see if there is a sub-block\n        boolean v = true;\n        //System.out.println(\"scan \" + lastBlockIndex + \" vs start=\" + start + \" len=\" + length);\n        for (PendingEntry ent : slice) {\n          if (!ent.isTerm) {\n            v = false;\n            break;\n          }\n        }\n        isLeafBlock = v;\n      }\n\n      final List<FST<BytesRef>> subIndices;\n\n      int termCount;\n\n      long[] longs = new long[longsSize];\n      boolean absolute = true;\n\n      if (isLeafBlock) {\n        subIndices = null;\n        for (PendingEntry ent : slice) {\n          assert ent.isTerm;\n          PendingTerm term = (PendingTerm) ent;\n          BlockTermState state = term.state;\n          final int suffix = term.term.length - prefixLength;\n          // if (DEBUG) {\n          //   BytesRef suffixBytes = new BytesRef(suffix);\n          //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n          //   suffixBytes.length = suffix;\n          //   System.out.println(\"    write term suffix=\" + suffixBytes);\n          // }\n          // For leaf block we write suffix straight\n          suffixWriter.writeVInt(suffix);\n          suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n          // Write term stats, to separate byte[] blob:\n          statsWriter.writeVInt(state.docFreq);\n          if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n            assert state.totalTermFreq >= state.docFreq: state.totalTermFreq + \" vs \" + state.docFreq;\n            statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n          }\n\n          // Write term meta data\n          postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n          for (int pos = 0; pos < longsSize; pos++) {\n            assert longs[pos] >= 0;\n            metaWriter.writeVLong(longs[pos]);\n          }\n          bytesWriter.writeTo(metaWriter);\n          bytesWriter.reset();\n          absolute = false;\n        }\n        termCount = length;\n      } else {\n        subIndices = new ArrayList<>();\n        termCount = 0;\n        for (PendingEntry ent : slice) {\n          if (ent.isTerm) {\n            PendingTerm term = (PendingTerm) ent;\n            BlockTermState state = term.state;\n            final int suffix = term.term.length - prefixLength;\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(term.term.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write term suffix=\" + suffixBytes);\n            // }\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt(suffix<<1);\n            suffixWriter.writeBytes(term.term.bytes, prefixLength, suffix);\n\n            // Write term stats, to separate byte[] blob:\n            statsWriter.writeVInt(state.docFreq);\n            if (fieldInfo.getIndexOptions() != IndexOptions.DOCS_ONLY) {\n              assert state.totalTermFreq >= state.docFreq;\n              statsWriter.writeVLong(state.totalTermFreq - state.docFreq);\n            }\n\n            // TODO: now that terms dict \"sees\" these longs,\n            // we can explore better column-stride encodings\n            // to encode all long[0]s for this block at\n            // once, all long[1]s, etc., e.g. using\n            // Simple64.  Alternatively, we could interleave\n            // stats + meta ... no reason to have them\n            // separate anymore:\n\n            // Write term meta data\n            postingsWriter.encodeTerm(longs, bytesWriter, fieldInfo, state, absolute);\n            for (int pos = 0; pos < longsSize; pos++) {\n              assert longs[pos] >= 0;\n              metaWriter.writeVLong(longs[pos]);\n            }\n            bytesWriter.writeTo(metaWriter);\n            bytesWriter.reset();\n            absolute = false;\n\n            termCount++;\n          } else {\n            PendingBlock block = (PendingBlock) ent;\n            final int suffix = block.prefix.length - prefixLength;\n\n            assert suffix > 0;\n\n            // For non-leaf block we borrow 1 bit to record\n            // if entry is term or sub-block\n            suffixWriter.writeVInt((suffix<<1)|1);\n            suffixWriter.writeBytes(block.prefix.bytes, prefixLength, suffix);\n            assert block.fp < startFP;\n\n            // if (DEBUG) {\n            //   BytesRef suffixBytes = new BytesRef(suffix);\n            //   System.arraycopy(block.prefix.bytes, prefixLength, suffixBytes.bytes, 0, suffix);\n            //   suffixBytes.length = suffix;\n            //   System.out.println(\"    write sub-block suffix=\" + toString(suffixBytes) + \" subFP=\" + block.fp + \" subCode=\" + (startFP-block.fp) + \" floor=\" + block.isFloor);\n            // }\n\n            suffixWriter.writeVLong(startFP - block.fp);\n            subIndices.add(block.index);\n          }\n        }\n\n        assert subIndices.size() != 0;\n      }\n\n      // TODO: we could block-write the term suffix pointers;\n      // this would take more space but would enable binary\n      // search on lookup\n\n      // Write suffixes byte[] blob to terms dict output:\n      out.writeVInt((int) (suffixWriter.getFilePointer() << 1) | (isLeafBlock ? 1:0));\n      suffixWriter.writeTo(out);\n      suffixWriter.reset();\n\n      // Write term stats byte[] blob\n      out.writeVInt((int) statsWriter.getFilePointer());\n      statsWriter.writeTo(out);\n      statsWriter.reset();\n\n      // Write term meta data byte[] blob\n      out.writeVInt((int) metaWriter.getFilePointer());\n      metaWriter.writeTo(out);\n      metaWriter.reset();\n\n      // Remove slice replaced by block:\n      slice.clear();\n\n      if (lastBlockIndex >= start) {\n        if (lastBlockIndex < start+length) {\n          lastBlockIndex = start;\n        } else {\n          lastBlockIndex -= length;\n        }\n      }\n\n      // if (DEBUG) {\n      //   System.out.println(\"      fpEnd=\" + out.getFilePointer());\n      // }\n\n      return new PendingBlock(prefix, startFP, termCount != 0, isFloor, floorLeadByte, subIndices);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"001b25b42373b22a52f399dbf072f1224632e8e6":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","f8615860cb50aefb8eebca1d1b3893dbe21cf126"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["2f948dd442d23baa6cbb28daf77c8db78b351329"],"5ad80176d91a6f70fe93880e43dfd697dc4e63ed":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f8615860cb50aefb8eebca1d1b3893dbe21cf126":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","e885d2b1e112b1d9db6a2dae82b3b493dfba1df1"],"76923f6a33f2c4bec7f584e3f251261afe7ea276":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"1a88d7b0899b7d22dcbd4cf8ca35d9ec9850ab98":["f8615860cb50aefb8eebca1d1b3893dbe21cf126"],"4d637064d608752565d4f9f41b2497dfdfdde50e":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","5ad80176d91a6f70fe93880e43dfd697dc4e63ed"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","76923f6a33f2c4bec7f584e3f251261afe7ea276"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e885d2b1e112b1d9db6a2dae82b3b493dfba1df1":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"2f948dd442d23baa6cbb28daf77c8db78b351329":["f8615860cb50aefb8eebca1d1b3893dbe21cf126","1a88d7b0899b7d22dcbd4cf8ca35d9ec9850ab98"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4d637064d608752565d4f9f41b2497dfdfdde50e"]},"commit2Childs":{"001b25b42373b22a52f399dbf072f1224632e8e6":[],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["5ad80176d91a6f70fe93880e43dfd697dc4e63ed","4d637064d608752565d4f9f41b2497dfdfdde50e"],"5ad80176d91a6f70fe93880e43dfd697dc4e63ed":["4d637064d608752565d4f9f41b2497dfdfdde50e"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["76923f6a33f2c4bec7f584e3f251261afe7ea276","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"f8615860cb50aefb8eebca1d1b3893dbe21cf126":["001b25b42373b22a52f399dbf072f1224632e8e6","1a88d7b0899b7d22dcbd4cf8ca35d9ec9850ab98","2f948dd442d23baa6cbb28daf77c8db78b351329"],"76923f6a33f2c4bec7f584e3f251261afe7ea276":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"1a88d7b0899b7d22dcbd4cf8ca35d9ec9850ab98":["2f948dd442d23baa6cbb28daf77c8db78b351329"],"4d637064d608752565d4f9f41b2497dfdfdde50e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["001b25b42373b22a52f399dbf072f1224632e8e6","f8615860cb50aefb8eebca1d1b3893dbe21cf126","e885d2b1e112b1d9db6a2dae82b3b493dfba1df1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"e885d2b1e112b1d9db6a2dae82b3b493dfba1df1":["f8615860cb50aefb8eebca1d1b3893dbe21cf126"],"2f948dd442d23baa6cbb28daf77c8db78b351329":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["001b25b42373b22a52f399dbf072f1224632e8e6","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}