{"path":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","commits":[{"id":"1d6179f9c4237a7e5d423f4e4b439a94e967efc9","date":1304382587,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(startOffset, endOffset);\n        return true;\n      }\n    }\n    return false;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["089745617a0f9c49f3719652025f61c07e5ce4ae","fcbc12aa8147f5203ca283e7252ba4280d6ffd16"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4","date":1305207152,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(startOffset, endOffset);\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(startOffset, endOffset);\n        return true;\n      }\n    }\n    return false;\n  }\n\n","bugFix":null,"bugIntro":["089745617a0f9c49f3719652025f61c07e5ce4ae"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(startOffset, endOffset);\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fcbc12aa8147f5203ca283e7252ba4280d6ffd16","date":1305663400,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(correctOffset(startOffset), correctOffset(endOffset));\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(startOffset, endOffset);\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","bugFix":["1d6179f9c4237a7e5d423f4e4b439a94e967efc9"],"bugIntro":["b8851e523e638323ef17b2c8e44eb34ba16365e0"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c3a8a449466c1ff7ce2274fe73dab487256964b4","date":1305735867,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(correctOffset(startOffset), correctOffset(endOffset));\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(startOffset, endOffset);\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84fc017ed7c9f13d0cb96bce55a5909f7d6161b6","date":1306073935,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          if (termAtt.length() >= maxTokenLength) {\n            break;\n          }\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(correctOffset(startOffset), correctOffset(endOffset));\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(correctOffset(startOffset), correctOffset(endOffset));\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          if (termAtt.length() >= maxTokenLength) {\n            break;\n          }\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(correctOffset(startOffset), correctOffset(endOffset));\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a","date":1306150983,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          if (termAtt.length() >= maxTokenLength) {\n            break;\n          }\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(correctOffset(startOffset), correctOffset(endOffset));\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(correctOffset(startOffset), correctOffset(endOffset));\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test-framework/java/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","pathOld":"lucene/src/test-framework/org/apache/lucene/analysis/MockTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          if (termAtt.length() >= maxTokenLength) {\n            break;\n          }\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(correctOffset(startOffset), correctOffset(endOffset));\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    assert !enableChecks || (streamState == State.RESET || streamState == State.INCREMENT) \n                            : \"incrementToken() called while in wrong state: \" + streamState;\n    clearAttributes();\n    for (;;) {\n      int startOffset = off;\n      int cp = readCodePoint();\n      if (cp < 0) {\n        break;\n      } else if (isTokenChar(cp)) {\n        int endOffset;\n        do {\n          char chars[] = Character.toChars(normalize(cp));\n          for (int i = 0; i < chars.length; i++)\n            termAtt.append(chars[i]);\n          endOffset = off;\n          if (termAtt.length() >= maxTokenLength) {\n            break;\n          }\n          cp = readCodePoint();\n        } while (cp >= 0 && isTokenChar(cp));\n        offsetAtt.setOffset(correctOffset(startOffset), correctOffset(endOffset));\n        streamState = State.INCREMENT;\n        return true;\n      }\n    }\n    streamState = State.INCREMENT_FALSE;\n    return false;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"7b91922b55d15444d554721b352861d028eb8278":["84fc017ed7c9f13d0cb96bce55a5909f7d6161b6"],"fcbc12aa8147f5203ca283e7252ba4280d6ffd16":["e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4"],"5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a":["c3a8a449466c1ff7ce2274fe73dab487256964b4","84fc017ed7c9f13d0cb96bce55a5909f7d6161b6"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb","fcbc12aa8147f5203ca283e7252ba4280d6ffd16"],"e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4":["1d6179f9c4237a7e5d423f4e4b439a94e967efc9"],"1d6179f9c4237a7e5d423f4e4b439a94e967efc9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","84fc017ed7c9f13d0cb96bce55a5909f7d6161b6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4"],"84fc017ed7c9f13d0cb96bce55a5909f7d6161b6":["fcbc12aa8147f5203ca283e7252ba4280d6ffd16"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7b91922b55d15444d554721b352861d028eb8278"]},"commit2Childs":{"7b91922b55d15444d554721b352861d028eb8278":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fcbc12aa8147f5203ca283e7252ba4280d6ffd16":["c3a8a449466c1ff7ce2274fe73dab487256964b4","84fc017ed7c9f13d0cb96bce55a5909f7d6161b6"],"5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a":[],"c3a8a449466c1ff7ce2274fe73dab487256964b4":["5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a"],"e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4":["fcbc12aa8147f5203ca283e7252ba4280d6ffd16","c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"1d6179f9c4237a7e5d423f4e4b439a94e967efc9":["e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1d6179f9c4237a7e5d423f4e4b439a94e967efc9","a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["c3a8a449466c1ff7ce2274fe73dab487256964b4"],"84fc017ed7c9f13d0cb96bce55a5909f7d6161b6":["7b91922b55d15444d554721b352861d028eb8278","5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a","a3776dccca01c11e7046323cfad46a3b4a471233"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}