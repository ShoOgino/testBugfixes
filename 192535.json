{"path":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/VarSortedBytesImpl.Writer#finishInternal(int).mjava","commits":[{"id":"f9efc72acdea22f5285be0a808f8bba51bb8e367","date":1323217280,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/VarSortedBytesImpl.Writer#finishInternal(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/values/VarSortedBytesImpl.Writer#finishInternal(int).mjava","sourceNew":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int count = hash.size();\n      final IndexOutput datOut = getOrCreateDataOut();\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      long offset = 0;\n      final int[] index = new int[count];\n      final int[] sortedEntries = hash.sort(comp);\n      // total bytes of data\n      idxOut.writeLong(maxBytes);\n      PackedInts.Writer offsetWriter = PackedInts.getWriter(idxOut, count+1,\n          PackedInts.bitsRequired(maxBytes));\n      // first dump bytes data, recording index & write offset as\n      // we go\n      final BytesRef spare = new BytesRef();\n      for (int i = 0; i < count; i++) {\n        final int e = sortedEntries[i];\n        offsetWriter.add(offset);\n        index[e] = i;\n        final BytesRef bytes = hash.get(e, spare);\n        // TODO: we could prefix code...\n        datOut.writeBytes(bytes.bytes, bytes.offset, bytes.length);\n        offset += bytes.length;\n      }\n      // write sentinel\n      offsetWriter.add(offset);\n      offsetWriter.finish();\n      // write index\n      writeIndex(idxOut, docCount, count, index, docToEntry);\n\n    }\n\n","sourceOld":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int count = hash.size();\n      final IndexOutput datOut = getOrCreateDataOut();\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      long offset = 0;\n      final int[] index = new int[count];\n      final int[] sortedEntries = hash.sort(comp);\n      // total bytes of data\n      idxOut.writeLong(maxBytes);\n      PackedInts.Writer offsetWriter = PackedInts.getWriter(idxOut, count+1,\n          PackedInts.bitsRequired(maxBytes));\n      // first dump bytes data, recording index & write offset as\n      // we go\n      final BytesRef spare = new BytesRef();\n      for (int i = 0; i < count; i++) {\n        final int e = sortedEntries[i];\n        offsetWriter.add(offset);\n        index[e] = i;\n        final BytesRef bytes = hash.get(e, spare);\n        // TODO: we could prefix code...\n        datOut.writeBytes(bytes.bytes, bytes.offset, bytes.length);\n        offset += bytes.length;\n      }\n      // write sentinel\n      offsetWriter.add(offset);\n      offsetWriter.finish();\n      // write index\n      writeIndex(idxOut, docCount, count, index, docToEntry);\n\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d638301ad1cfcae567b681b893bc8781f0ee48a5","date":1323801546,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/VarSortedBytesImpl.Writer#finishInternal(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/values/VarSortedBytesImpl.Writer#finishInternal(int).mjava","sourceNew":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int count = hash.size();\n      final IndexOutput datOut = getOrCreateDataOut();\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      long offset = 0;\n      final int[] index = new int[count];\n      final int[] sortedEntries = hash.sort(comp);\n      // total bytes of data\n      idxOut.writeLong(maxBytes);\n      PackedInts.Writer offsetWriter = PackedInts.getWriter(idxOut, count+1,\n          PackedInts.bitsRequired(maxBytes));\n      // first dump bytes data, recording index & write offset as\n      // we go\n      final BytesRef spare = new BytesRef();\n      for (int i = 0; i < count; i++) {\n        final int e = sortedEntries[i];\n        offsetWriter.add(offset);\n        index[e] = i;\n        final BytesRef bytes = hash.get(e, spare);\n        // TODO: we could prefix code...\n        datOut.writeBytes(bytes.bytes, bytes.offset, bytes.length);\n        offset += bytes.length;\n      }\n      // write sentinel\n      offsetWriter.add(offset);\n      offsetWriter.finish();\n      // write index\n      writeIndex(idxOut, docCount, count, index, docToEntry);\n\n    }\n\n","sourceOld":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int count = hash.size();\n      final IndexOutput datOut = getOrCreateDataOut();\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      long offset = 0;\n      final int[] index = new int[count];\n      final int[] sortedEntries = hash.sort(comp);\n      // total bytes of data\n      idxOut.writeLong(maxBytes);\n      PackedInts.Writer offsetWriter = PackedInts.getWriter(idxOut, count+1,\n          PackedInts.bitsRequired(maxBytes));\n      // first dump bytes data, recording index & write offset as\n      // we go\n      final BytesRef spare = new BytesRef();\n      for (int i = 0; i < count; i++) {\n        final int e = sortedEntries[i];\n        offsetWriter.add(offset);\n        index[e] = i;\n        final BytesRef bytes = hash.get(e, spare);\n        // TODO: we could prefix code...\n        datOut.writeBytes(bytes.bytes, bytes.offset, bytes.length);\n        offset += bytes.length;\n      }\n      // write sentinel\n      offsetWriter.add(offset);\n      offsetWriter.finish();\n      // write index\n      writeIndex(idxOut, docCount, count, index, docToEntry);\n\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene40/values/VarSortedBytesImpl.Writer#finishInternal(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/VarSortedBytesImpl.Writer#finishInternal(int).mjava","sourceNew":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int count = hash.size();\n      final IndexOutput datOut = getOrCreateDataOut();\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      long offset = 0;\n      final int[] index = new int[count];\n      final int[] sortedEntries = hash.sort(comp);\n      // total bytes of data\n      idxOut.writeLong(maxBytes);\n      PackedInts.Writer offsetWriter = PackedInts.getWriter(idxOut, count+1,\n          PackedInts.bitsRequired(maxBytes));\n      // first dump bytes data, recording index & write offset as\n      // we go\n      final BytesRef spare = new BytesRef();\n      for (int i = 0; i < count; i++) {\n        final int e = sortedEntries[i];\n        offsetWriter.add(offset);\n        index[e] = i;\n        final BytesRef bytes = hash.get(e, spare);\n        // TODO: we could prefix code...\n        datOut.writeBytes(bytes.bytes, bytes.offset, bytes.length);\n        offset += bytes.length;\n      }\n      // write sentinel\n      offsetWriter.add(offset);\n      offsetWriter.finish();\n      // write index\n      writeIndex(idxOut, docCount, count, index, docToEntry);\n\n    }\n\n","sourceOld":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int count = hash.size();\n      final IndexOutput datOut = getOrCreateDataOut();\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      long offset = 0;\n      final int[] index = new int[count];\n      final int[] sortedEntries = hash.sort(comp);\n      // total bytes of data\n      idxOut.writeLong(maxBytes);\n      PackedInts.Writer offsetWriter = PackedInts.getWriter(idxOut, count+1,\n          PackedInts.bitsRequired(maxBytes));\n      // first dump bytes data, recording index & write offset as\n      // we go\n      final BytesRef spare = new BytesRef();\n      for (int i = 0; i < count; i++) {\n        final int e = sortedEntries[i];\n        offsetWriter.add(offset);\n        index[e] = i;\n        final BytesRef bytes = hash.get(e, spare);\n        // TODO: we could prefix code...\n        datOut.writeBytes(bytes.bytes, bytes.offset, bytes.length);\n        offset += bytes.length;\n      }\n      // write sentinel\n      offsetWriter.add(offset);\n      offsetWriter.finish();\n      // write index\n      writeIndex(idxOut, docCount, count, index, docToEntry);\n\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f9efc72acdea22f5285be0a808f8bba51bb8e367":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["d638301ad1cfcae567b681b893bc8781f0ee48a5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"d638301ad1cfcae567b681b893bc8781f0ee48a5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f9efc72acdea22f5285be0a808f8bba51bb8e367"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f9efc72acdea22f5285be0a808f8bba51bb8e367","d638301ad1cfcae567b681b893bc8781f0ee48a5"],"f9efc72acdea22f5285be0a808f8bba51bb8e367":["d638301ad1cfcae567b681b893bc8781f0ee48a5"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d638301ad1cfcae567b681b893bc8781f0ee48a5":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}