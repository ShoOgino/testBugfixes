{"path":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknowQueryAfterRewrite().mjava","commits":[{"id":"081b68cb9e8f4b5405b40bfb223fd7c587171aa1","date":1360072766,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknowQueryAfterRewrite().mjava","pathOld":"/dev/null","sourceNew":"  public void testHighlightUnknowQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n      \n    };\n    \n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    \n    searcher = new IndexSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    StoredDocument doc = searcher.doc(hits.scoreDocs[0].doc);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = TokenSources.getAnyTokenStream(searcher\n        .getIndexReader(), hits.scoreDocs[0].doc, FIELD_NAME, doc, analyzer);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello <B>this</B> is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n    \n    doc = searcher.doc(hits.scoreDocs[1].doc);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = TokenSources.getAnyTokenStream(searcher\n        .getIndexReader(), hits.scoreDocs[1].doc, FIELD_NAME, doc, analyzer);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"<B>This</B> piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e4d4ec39bf5396230748ca859ff05ab024b6fc5","date":1360112310,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknowQueryAfterRewrite().mjava","pathOld":"/dev/null","sourceNew":"  public void testHighlightUnknowQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n      \n    };\n    \n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    \n    searcher = new IndexSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    StoredDocument doc = searcher.doc(hits.scoreDocs[0].doc);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = TokenSources.getAnyTokenStream(searcher\n        .getIndexReader(), hits.scoreDocs[0].doc, FIELD_NAME, doc, analyzer);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello <B>this</B> is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n    \n    doc = searcher.doc(hits.scoreDocs[1].doc);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = TokenSources.getAnyTokenStream(searcher\n        .getIndexReader(), hits.scoreDocs[1].doc, FIELD_NAME, doc, analyzer);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"<B>This</B> piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad1f7eb1a6bbf19f3d32b3baf2dee3db844eccdc","date":1366056945,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknowQueryAfterRewrite().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknowQueryAfterRewrite().mjava","sourceNew":"  public void testHighlightUnknowQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return 31 * super.hashCode();\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return super.equals(obj);\n      }\n    };\n    \n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    \n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    StoredDocument doc = searcher.doc(hits.scoreDocs[0].doc);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = TokenSources.getAnyTokenStream(searcher\n        .getIndexReader(), hits.scoreDocs[0].doc, FIELD_NAME, doc, analyzer);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello <B>this</B> is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n    \n    doc = searcher.doc(hits.scoreDocs[1].doc);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = TokenSources.getAnyTokenStream(searcher\n        .getIndexReader(), hits.scoreDocs[1].doc, FIELD_NAME, doc, analyzer);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"<B>This</B> piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","sourceOld":"  public void testHighlightUnknowQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n      \n    };\n    \n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    \n    searcher = new IndexSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    StoredDocument doc = searcher.doc(hits.scoreDocs[0].doc);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = TokenSources.getAnyTokenStream(searcher\n        .getIndexReader(), hits.scoreDocs[0].doc, FIELD_NAME, doc, analyzer);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello <B>this</B> is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n    \n    doc = searcher.doc(hits.scoreDocs[1].doc);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = TokenSources.getAnyTokenStream(searcher\n        .getIndexReader(), hits.scoreDocs[1].doc, FIELD_NAME, doc, analyzer);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"<B>This</B> piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aeebe27bce18b879b80f68494c52cda1021b5705","date":1417792137,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknowQueryAfterRewrite().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknowQueryAfterRewrite().mjava","sourceNew":"  public void testHighlightUnknowQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return 31 * super.hashCode();\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return super.equals(obj);\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    StoredDocument doc = searcher.doc(hits.scoreDocs[0].doc);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = TokenSources.getAnyTokenStream(searcher\n        .getIndexReader(), hits.scoreDocs[0].doc, FIELD_NAME, doc, analyzer);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n    \n    doc = searcher.doc(hits.scoreDocs[1].doc);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = TokenSources.getAnyTokenStream(searcher\n        .getIndexReader(), hits.scoreDocs[1].doc, FIELD_NAME, doc, analyzer);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","sourceOld":"  public void testHighlightUnknowQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return 31 * super.hashCode();\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return super.equals(obj);\n      }\n    };\n    \n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);\n    \n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    StoredDocument doc = searcher.doc(hits.scoreDocs[0].doc);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = TokenSources.getAnyTokenStream(searcher\n        .getIndexReader(), hits.scoreDocs[0].doc, FIELD_NAME, doc, analyzer);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello <B>this</B> is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n    \n    doc = searcher.doc(hits.scoreDocs[1].doc);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = TokenSources.getAnyTokenStream(searcher\n        .getIndexReader(), hits.scoreDocs[1].doc, FIELD_NAME, doc, analyzer);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"<B>This</B> piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d62e4938659e263e96ae8188e11aea8a940aea5","date":1430230314,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknowQueryAfterRewrite().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknowQueryAfterRewrite().mjava","sourceNew":"  public void testHighlightUnknowQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return 31 * super.hashCode();\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return super.equals(obj);\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    StoredDocument doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","sourceOld":"  public void testHighlightUnknowQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return 31 * super.hashCode();\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return super.equals(obj);\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    StoredDocument doc = searcher.doc(hits.scoreDocs[0].doc);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = TokenSources.getAnyTokenStream(searcher\n        .getIndexReader(), hits.scoreDocs[0].doc, FIELD_NAME, doc, analyzer);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n    \n    doc = searcher.doc(hits.scoreDocs[1].doc);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = TokenSources.getAnyTokenStream(searcher\n        .getIndexReader(), hits.scoreDocs[1].doc, FIELD_NAME, doc, analyzer);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknowQueryAfterRewrite().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknowQueryAfterRewrite().mjava","sourceNew":"  public void testHighlightUnknowQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return 31 * super.hashCode();\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return super.equals(obj);\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    Document doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","sourceOld":"  public void testHighlightUnknowQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return 31 * super.hashCode();\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return super.equals(obj);\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    StoredDocument doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e7bc21595222ae4f75509300fbb7726691f387f","date":1464078795,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknownQueryAfterRewrite().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknowQueryAfterRewrite().mjava","sourceNew":"  public void testHighlightUnknownQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return System.identityHashCode(this);\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return obj == this;\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    Document doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","sourceOld":"  public void testHighlightUnknowQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return 31 * super.hashCode();\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return super.equals(obj);\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    Document doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#testHighlightUnknowQueryAfterRewrite().mjava","sourceNew":null,"sourceOld":"  public void testHighlightUnknowQueryAfterRewrite() throws IOException, InvalidTokenOffsetsException {\n    Query query = new Query() {\n      \n      @Override\n      public Query rewrite(IndexReader reader) throws IOException {\n        CommonTermsQuery query = new CommonTermsQuery(Occur.MUST, Occur.SHOULD, 3);\n        query.add(new Term(FIELD_NAME, \"this\"));//stop-word\n        query.add(new Term(FIELD_NAME, \"long\"));\n        query.add(new Term(FIELD_NAME, \"very\"));\n        return query;\n      }\n\n      @Override\n      public String toString(String field) {\n        return null;\n      }\n\n      @Override\n      public int hashCode() {\n        return 31 * super.hashCode();\n      }\n\n      @Override\n      public boolean equals(Object obj) {\n        return super.equals(obj);\n      }\n    };\n\n    searcher = newSearcher(reader);\n    TopDocs hits = searcher.search(query, 10);\n    assertEquals(2, hits.totalHits);\n    QueryScorer scorer = new QueryScorer(query, FIELD_NAME);\n    Highlighter highlighter = new Highlighter(scorer);\n\n    final int docId0 = hits.scoreDocs[0].doc;\n    Document doc = searcher.doc(docId0);\n    String storedField = doc.get(FIELD_NAME);\n\n    TokenStream stream = getAnyTokenStream(FIELD_NAME, docId0);\n    Fragmenter fragmenter = new SimpleSpanFragmenter(scorer);\n    highlighter.setTextFragmenter(fragmenter);\n    String fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"Hello this is a piece of text that is <B>very</B> <B>long</B> and contains too much preamble and the meat is really here which says kennedy has been shot\", fragment);\n\n    final int docId1 = hits.scoreDocs[1].doc;\n    doc = searcher.doc(docId1);\n    storedField = doc.get(FIELD_NAME);\n\n    stream = getAnyTokenStream(FIELD_NAME, docId1);\n    highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));\n    fragment = highlighter.getBestFragment(stream, storedField);\n    assertEquals(\"This piece of text refers to Kennedy at the beginning then has a longer piece of text that is <B>very</B>\", fragment);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"081b68cb9e8f4b5405b40bfb223fd7c587171aa1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3e4d4ec39bf5396230748ca859ff05ab024b6fc5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","081b68cb9e8f4b5405b40bfb223fd7c587171aa1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0e7bc21595222ae4f75509300fbb7726691f387f":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"5d62e4938659e263e96ae8188e11aea8a940aea5":["aeebe27bce18b879b80f68494c52cda1021b5705"],"ad1f7eb1a6bbf19f3d32b3baf2dee3db844eccdc":["081b68cb9e8f4b5405b40bfb223fd7c587171aa1"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","0e7bc21595222ae4f75509300fbb7726691f387f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0e7bc21595222ae4f75509300fbb7726691f387f"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["5d62e4938659e263e96ae8188e11aea8a940aea5"],"aeebe27bce18b879b80f68494c52cda1021b5705":["ad1f7eb1a6bbf19f3d32b3baf2dee3db844eccdc"]},"commit2Childs":{"081b68cb9e8f4b5405b40bfb223fd7c587171aa1":["3e4d4ec39bf5396230748ca859ff05ab024b6fc5","ad1f7eb1a6bbf19f3d32b3baf2dee3db844eccdc"],"3e4d4ec39bf5396230748ca859ff05ab024b6fc5":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["081b68cb9e8f4b5405b40bfb223fd7c587171aa1","3e4d4ec39bf5396230748ca859ff05ab024b6fc5"],"0e7bc21595222ae4f75509300fbb7726691f387f":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5d62e4938659e263e96ae8188e11aea8a940aea5":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"ad1f7eb1a6bbf19f3d32b3baf2dee3db844eccdc":["aeebe27bce18b879b80f68494c52cda1021b5705"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["0e7bc21595222ae4f75509300fbb7726691f387f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"aeebe27bce18b879b80f68494c52cda1021b5705":["5d62e4938659e263e96ae8188e11aea8a940aea5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3e4d4ec39bf5396230748ca859ff05ab024b6fc5","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}