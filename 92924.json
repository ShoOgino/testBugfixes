{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter#testChain().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter#testChain().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter#testChain().mjava","sourceNew":"  //           11111111112222222222333333333\n  // 012345678901234567890123456789012345678\n  //  a bb - ccc . --- bb a . ccc ccc bb\n  //  aa b - c . --- b aa . c c b\n  public void testChain() throws IOException {\n    final String BLOCK = \" a bb - ccc . --- bb a . ccc ccc bb\";\n    CharStream cs = new PatternReplaceCharFilter( pattern(\"a\"), \"aa\",\n        CharReader.get( new StringReader( BLOCK ) ) );\n    cs = new PatternReplaceCharFilter( pattern(\"bb\"), \"b\", cs );\n    cs = new PatternReplaceCharFilter( pattern(\"ccc\"), \"c\", cs );\n    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);\n    assertTokenStreamContents(ts,\n        new String[] { \"aa\", \"b\", \"-\", \"c\", \".\", \"---\", \"b\", \"aa\", \".\", \"c\", \"c\", \"b\" },\n        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },\n        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 },\n        BLOCK.length());\n  }\n\n","sourceOld":"  //           11111111112222222222333333333\n  // 012345678901234567890123456789012345678\n  //  a bb - ccc . --- bb a . ccc ccc bb\n  //  aa b - c . --- b aa . c c b\n  public void testChain() throws IOException {\n    final String BLOCK = \" a bb - ccc . --- bb a . ccc ccc bb\";\n    CharStream cs = new PatternReplaceCharFilter( pattern(\"a\"), \"aa\",\n        CharReader.get( new StringReader( BLOCK ) ) );\n    cs = new PatternReplaceCharFilter( pattern(\"bb\"), \"b\", cs );\n    cs = new PatternReplaceCharFilter( pattern(\"ccc\"), \"c\", cs );\n    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);\n    assertTokenStreamContents(ts,\n        new String[] { \"aa\", \"b\", \"-\", \"c\", \".\", \"---\", \"b\", \"aa\", \".\", \"c\", \"c\", \"b\" },\n        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },\n        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 },\n        BLOCK.length());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc706b1e03a539d44d99998108feb684bb44cbb2","date":1342522408,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter#testChain().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter#testChain().mjava","sourceNew":"  //           11111111112222222222333333333\n  // 012345678901234567890123456789012345678\n  //  a bb - ccc . --- bb a . ccc ccc bb\n  //  aa b - c . --- b aa . c c b\n  public void testChain() throws IOException {\n    final String BLOCK = \" a bb - ccc . --- bb a . ccc ccc bb\";\n    CharFilter cs = new PatternReplaceCharFilter( pattern(\"a\"), \"aa\",\n        new StringReader( BLOCK ) );\n    cs = new PatternReplaceCharFilter( pattern(\"bb\"), \"b\", cs );\n    cs = new PatternReplaceCharFilter( pattern(\"ccc\"), \"c\", cs );\n    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);\n    assertTokenStreamContents(ts,\n        new String[] { \"aa\", \"b\", \"-\", \"c\", \".\", \"---\", \"b\", \"aa\", \".\", \"c\", \"c\", \"b\" },\n        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },\n        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 },\n        BLOCK.length());\n  }\n\n","sourceOld":"  //           11111111112222222222333333333\n  // 012345678901234567890123456789012345678\n  //  a bb - ccc . --- bb a . ccc ccc bb\n  //  aa b - c . --- b aa . c c b\n  public void testChain() throws IOException {\n    final String BLOCK = \" a bb - ccc . --- bb a . ccc ccc bb\";\n    CharStream cs = new PatternReplaceCharFilter( pattern(\"a\"), \"aa\",\n        CharReader.get( new StringReader( BLOCK ) ) );\n    cs = new PatternReplaceCharFilter( pattern(\"bb\"), \"b\", cs );\n    cs = new PatternReplaceCharFilter( pattern(\"ccc\"), \"c\", cs );\n    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);\n    assertTokenStreamContents(ts,\n        new String[] { \"aa\", \"b\", \"-\", \"c\", \".\", \"---\", \"b\", \"aa\", \".\", \"c\", \"c\", \"b\" },\n        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },\n        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 },\n        BLOCK.length());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter#testChain().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter#testChain().mjava","sourceNew":"  //           11111111112222222222333333333\n  // 012345678901234567890123456789012345678\n  //  a bb - ccc . --- bb a . ccc ccc bb\n  //  aa b - c . --- b aa . c c b\n  public void testChain() throws IOException {\n    final String BLOCK = \" a bb - ccc . --- bb a . ccc ccc bb\";\n    CharFilter cs = new PatternReplaceCharFilter( pattern(\"a\"), \"aa\",\n        new StringReader( BLOCK ) );\n    cs = new PatternReplaceCharFilter( pattern(\"bb\"), \"b\", cs );\n    cs = new PatternReplaceCharFilter( pattern(\"ccc\"), \"c\", cs );\n    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);\n    assertTokenStreamContents(ts,\n        new String[] { \"aa\", \"b\", \"-\", \"c\", \".\", \"---\", \"b\", \"aa\", \".\", \"c\", \"c\", \"b\" },\n        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },\n        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 },\n        BLOCK.length());\n  }\n\n","sourceOld":"  //           11111111112222222222333333333\n  // 012345678901234567890123456789012345678\n  //  a bb - ccc . --- bb a . ccc ccc bb\n  //  aa b - c . --- b aa . c c b\n  public void testChain() throws IOException {\n    final String BLOCK = \" a bb - ccc . --- bb a . ccc ccc bb\";\n    CharStream cs = new PatternReplaceCharFilter( pattern(\"a\"), \"aa\",\n        CharReader.get( new StringReader( BLOCK ) ) );\n    cs = new PatternReplaceCharFilter( pattern(\"bb\"), \"b\", cs );\n    cs = new PatternReplaceCharFilter( pattern(\"ccc\"), \"c\", cs );\n    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);\n    assertTokenStreamContents(ts,\n        new String[] { \"aa\", \"b\", \"-\", \"c\", \".\", \"---\", \"b\", \"aa\", \".\", \"c\", \"c\", \"b\" },\n        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },\n        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 },\n        BLOCK.length());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter#testChain().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter#testChain().mjava","sourceNew":"  //           11111111112222222222333333333\n  // 012345678901234567890123456789012345678\n  //  a bb - ccc . --- bb a . ccc ccc bb\n  //  aa b - c . --- b aa . c c b\n  public void testChain() throws IOException {\n    final String BLOCK = \" a bb - ccc . --- bb a . ccc ccc bb\";\n    CharFilter cs = new PatternReplaceCharFilter( pattern(\"a\"), \"aa\",\n        new StringReader( BLOCK ) );\n    cs = new PatternReplaceCharFilter( pattern(\"bb\"), \"b\", cs );\n    cs = new PatternReplaceCharFilter( pattern(\"ccc\"), \"c\", cs );\n    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);\n    assertTokenStreamContents(ts,\n        new String[] { \"aa\", \"b\", \"-\", \"c\", \".\", \"---\", \"b\", \"aa\", \".\", \"c\", \"c\", \"b\" },\n        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },\n        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 },\n        BLOCK.length());\n  }\n\n","sourceOld":"  //           11111111112222222222333333333\n  // 012345678901234567890123456789012345678\n  //  a bb - ccc . --- bb a . ccc ccc bb\n  //  aa b - c . --- b aa . c c b\n  public void testChain() throws IOException {\n    final String BLOCK = \" a bb - ccc . --- bb a . ccc ccc bb\";\n    CharStream cs = new PatternReplaceCharFilter( pattern(\"a\"), \"aa\",\n        CharReader.get( new StringReader( BLOCK ) ) );\n    cs = new PatternReplaceCharFilter( pattern(\"bb\"), \"b\", cs );\n    cs = new PatternReplaceCharFilter( pattern(\"ccc\"), \"c\", cs );\n    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);\n    assertTokenStreamContents(ts,\n        new String[] { \"aa\", \"b\", \"-\", \"c\", \".\", \"---\", \"b\", \"aa\", \".\", \"c\", \"c\", \"b\" },\n        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },\n        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 },\n        BLOCK.length());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter#testChain().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter#testChain().mjava","sourceNew":"  //           11111111112222222222333333333\n  // 012345678901234567890123456789012345678\n  //  a bb - ccc . --- bb a . ccc ccc bb\n  //  aa b - c . --- b aa . c c b\n  public void testChain() throws IOException {\n    final String BLOCK = \" a bb - ccc . --- bb a . ccc ccc bb\";\n    CharFilter cs = new PatternReplaceCharFilter( pattern(\"a\"), \"aa\",\n        new StringReader( BLOCK ) );\n    cs = new PatternReplaceCharFilter( pattern(\"bb\"), \"b\", cs );\n    cs = new PatternReplaceCharFilter( pattern(\"ccc\"), \"c\", cs );\n    TokenStream ts = whitespaceMockTokenizer(cs);\n    assertTokenStreamContents(ts,\n        new String[] { \"aa\", \"b\", \"-\", \"c\", \".\", \"---\", \"b\", \"aa\", \".\", \"c\", \"c\", \"b\" },\n        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },\n        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 },\n        BLOCK.length());\n  }\n\n","sourceOld":"  //           11111111112222222222333333333\n  // 012345678901234567890123456789012345678\n  //  a bb - ccc . --- bb a . ccc ccc bb\n  //  aa b - c . --- b aa . c c b\n  public void testChain() throws IOException {\n    final String BLOCK = \" a bb - ccc . --- bb a . ccc ccc bb\";\n    CharFilter cs = new PatternReplaceCharFilter( pattern(\"a\"), \"aa\",\n        new StringReader( BLOCK ) );\n    cs = new PatternReplaceCharFilter( pattern(\"bb\"), \"b\", cs );\n    cs = new PatternReplaceCharFilter( pattern(\"ccc\"), \"c\", cs );\n    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);\n    assertTokenStreamContents(ts,\n        new String[] { \"aa\", \"b\", \"-\", \"c\", \".\", \"---\", \"b\", \"aa\", \".\", \"c\", \"c\", \"b\" },\n        new int[] { 1, 3, 6, 8, 12, 14, 18, 21, 23, 25, 29, 33 },\n        new int[] { 2, 5, 7, 11, 13, 17, 20, 22, 24, 28, 32, 35 },\n        BLOCK.length());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"aba371508186796cc6151d8223a5b4e16d02e26e":["b89678825b68eccaf09e6ab71675fc0b0af1e099","fc706b1e03a539d44d99998108feb684bb44cbb2"],"fc706b1e03a539d44d99998108feb684bb44cbb2":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["fc706b1e03a539d44d99998108feb684bb44cbb2"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["b89678825b68eccaf09e6ab71675fc0b0af1e099","fc706b1e03a539d44d99998108feb684bb44cbb2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["aba371508186796cc6151d8223a5b4e16d02e26e","fc706b1e03a539d44d99998108feb684bb44cbb2","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"aba371508186796cc6151d8223a5b4e16d02e26e":[],"fc706b1e03a539d44d99998108feb684bb44cbb2":["aba371508186796cc6151d8223a5b4e16d02e26e","ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["aba371508186796cc6151d8223a5b4e16d02e26e","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}