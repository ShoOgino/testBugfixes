{"path":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapper#createWeight(IndexSearcher,boolean).mjava","commits":[{"id":"2713584a660051cd646423be682771e3bbd99985","date":1425046322,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapper#createWeight(IndexSearcher,boolean).mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new ConstantScoreWeight(this) {\n        @Override\n        Scorer scorer(LeafReaderContext context, Bits acceptDocs, float score) throws IOException {\n          final SortedSetDocValues fcsi = DocValues.getSortedSet(context.reader(), query.field);\n          TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n            \n            @Override\n            public TermsEnum iterator(TermsEnum reuse) {\n              return fcsi.termsEnum();\n            }\n\n            @Override\n            public long getSumTotalTermFreq() {\n              return -1;\n            }\n\n            @Override\n            public long getSumDocFreq() {\n              return -1;\n            }\n\n            @Override\n            public int getDocCount() {\n              return -1;\n            }\n\n            @Override\n            public long size() {\n              return -1;\n            }\n\n            @Override\n            public boolean hasFreqs() {\n              return false;\n            }\n\n            @Override\n            public boolean hasOffsets() {\n              return false;\n            }\n\n            @Override\n            public boolean hasPositions() {\n              return false;\n            }\n            \n            @Override\n            public boolean hasPayloads() {\n              return false;\n            }\n          });\n          \n          assert termsEnum != null;\n          if (termsEnum.next() == null) {\n            // no matching terms\n            return null;\n          }\n          // fill into a bitset\n          // Cannot use FixedBitSet because we require long index (ord):\n          final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n          do {\n            long ord = termsEnum.ord();\n            if (ord >= 0) {\n              termSet.set(ord);\n            }\n          } while (termsEnum.next() != null);\n          \n          final DocIdSetIterator approximation = DocIdSetIterator.all(context.reader().maxDoc());\n          final TwoPhaseIterator twoPhaseIterator = new TwoPhaseIterator() {\n            @Override\n            public DocIdSetIterator approximation() {\n              return approximation;\n            }\n            @Override\n            public boolean matches() throws IOException {\n              final int doc = approximation.docID();\n              if (acceptDocs != null && acceptDocs.get(doc) == false) {\n                return false;\n              }\n              fcsi.setDocument(doc);\n              for (long ord = fcsi.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = fcsi.nextOrd()) {\n                if (termSet.get(ord)) {\n                  return true;\n                }\n              }\n              return false;\n            }\n          };\n          final DocIdSetIterator disi = TwoPhaseIterator.asDocIdSetIterator(twoPhaseIterator);\n          return new Scorer(this) {\n\n            @Override\n            public TwoPhaseIterator asTwoPhaseIterator() {\n              return twoPhaseIterator;\n            }\n\n            @Override\n            public float score() throws IOException {\n              return score;\n            }\n\n            @Override\n            public int freq() throws IOException {\n              return 1;\n            }\n\n            @Override\n            public int docID() {\n              return disi.docID();\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              return disi.nextDoc();\n            }\n\n            @Override\n            public int advance(int target) throws IOException {\n              return disi.advance(target);\n            }\n\n            @Override\n            public long cost() {\n              return disi.cost();\n            }\n\n          };\n        }\n      };\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a6b1be5d2b36d6a30913778ef61374103d55e33","date":1427303640,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapper#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapper#createWeight(IndexSearcher,boolean).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new ConstantScoreWeight(this) {\n        @Override\n        Scorer scorer(LeafReaderContext context, Bits acceptDocs, float score) throws IOException {\n          final SortedSetDocValues fcsi = DocValues.getSortedSet(context.reader(), query.field);\n          TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n            \n            @Override\n            public TermsEnum iterator(TermsEnum reuse) {\n              return fcsi.termsEnum();\n            }\n\n            @Override\n            public long getSumTotalTermFreq() {\n              return -1;\n            }\n\n            @Override\n            public long getSumDocFreq() {\n              return -1;\n            }\n\n            @Override\n            public int getDocCount() {\n              return -1;\n            }\n\n            @Override\n            public long size() {\n              return -1;\n            }\n\n            @Override\n            public boolean hasFreqs() {\n              return false;\n            }\n\n            @Override\n            public boolean hasOffsets() {\n              return false;\n            }\n\n            @Override\n            public boolean hasPositions() {\n              return false;\n            }\n            \n            @Override\n            public boolean hasPayloads() {\n              return false;\n            }\n          });\n          \n          assert termsEnum != null;\n          if (termsEnum.next() == null) {\n            // no matching terms\n            return null;\n          }\n          // fill into a bitset\n          // Cannot use FixedBitSet because we require long index (ord):\n          final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n          do {\n            long ord = termsEnum.ord();\n            if (ord >= 0) {\n              termSet.set(ord);\n            }\n          } while (termsEnum.next() != null);\n          \n          final DocIdSetIterator approximation = DocIdSetIterator.all(context.reader().maxDoc());\n          final TwoPhaseIterator twoPhaseIterator = new TwoPhaseIterator(approximation) {\n            @Override\n            public boolean matches() throws IOException {\n              final int doc = approximation.docID();\n              if (acceptDocs != null && acceptDocs.get(doc) == false) {\n                return false;\n              }\n              fcsi.setDocument(doc);\n              for (long ord = fcsi.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = fcsi.nextOrd()) {\n                if (termSet.get(ord)) {\n                  return true;\n                }\n              }\n              return false;\n            }\n          };\n          final DocIdSetIterator disi = TwoPhaseIterator.asDocIdSetIterator(twoPhaseIterator);\n          return new Scorer(this) {\n\n            @Override\n            public TwoPhaseIterator asTwoPhaseIterator() {\n              return twoPhaseIterator;\n            }\n\n            @Override\n            public float score() throws IOException {\n              return score;\n            }\n\n            @Override\n            public int freq() throws IOException {\n              return 1;\n            }\n\n            @Override\n            public int docID() {\n              return disi.docID();\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              return disi.nextDoc();\n            }\n\n            @Override\n            public int advance(int target) throws IOException {\n              return disi.advance(target);\n            }\n\n            @Override\n            public long cost() {\n              return disi.cost();\n            }\n\n          };\n        }\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new ConstantScoreWeight(this) {\n        @Override\n        Scorer scorer(LeafReaderContext context, Bits acceptDocs, float score) throws IOException {\n          final SortedSetDocValues fcsi = DocValues.getSortedSet(context.reader(), query.field);\n          TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n            \n            @Override\n            public TermsEnum iterator(TermsEnum reuse) {\n              return fcsi.termsEnum();\n            }\n\n            @Override\n            public long getSumTotalTermFreq() {\n              return -1;\n            }\n\n            @Override\n            public long getSumDocFreq() {\n              return -1;\n            }\n\n            @Override\n            public int getDocCount() {\n              return -1;\n            }\n\n            @Override\n            public long size() {\n              return -1;\n            }\n\n            @Override\n            public boolean hasFreqs() {\n              return false;\n            }\n\n            @Override\n            public boolean hasOffsets() {\n              return false;\n            }\n\n            @Override\n            public boolean hasPositions() {\n              return false;\n            }\n            \n            @Override\n            public boolean hasPayloads() {\n              return false;\n            }\n          });\n          \n          assert termsEnum != null;\n          if (termsEnum.next() == null) {\n            // no matching terms\n            return null;\n          }\n          // fill into a bitset\n          // Cannot use FixedBitSet because we require long index (ord):\n          final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n          do {\n            long ord = termsEnum.ord();\n            if (ord >= 0) {\n              termSet.set(ord);\n            }\n          } while (termsEnum.next() != null);\n          \n          final DocIdSetIterator approximation = DocIdSetIterator.all(context.reader().maxDoc());\n          final TwoPhaseIterator twoPhaseIterator = new TwoPhaseIterator() {\n            @Override\n            public DocIdSetIterator approximation() {\n              return approximation;\n            }\n            @Override\n            public boolean matches() throws IOException {\n              final int doc = approximation.docID();\n              if (acceptDocs != null && acceptDocs.get(doc) == false) {\n                return false;\n              }\n              fcsi.setDocument(doc);\n              for (long ord = fcsi.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = fcsi.nextOrd()) {\n                if (termSet.get(ord)) {\n                  return true;\n                }\n              }\n              return false;\n            }\n          };\n          final DocIdSetIterator disi = TwoPhaseIterator.asDocIdSetIterator(twoPhaseIterator);\n          return new Scorer(this) {\n\n            @Override\n            public TwoPhaseIterator asTwoPhaseIterator() {\n              return twoPhaseIterator;\n            }\n\n            @Override\n            public float score() throws IOException {\n              return score;\n            }\n\n            @Override\n            public int freq() throws IOException {\n              return 1;\n            }\n\n            @Override\n            public int docID() {\n              return disi.docID();\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              return disi.nextDoc();\n            }\n\n            @Override\n            public int advance(int target) throws IOException {\n              return disi.advance(target);\n            }\n\n            @Override\n            public long cost() {\n              return disi.cost();\n            }\n\n          };\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":0,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapper#createWeight(IndexSearcher,boolean).mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new ConstantScoreWeight(this) {\n        @Override\n        Scorer scorer(LeafReaderContext context, Bits acceptDocs, float score) throws IOException {\n          final SortedSetDocValues fcsi = DocValues.getSortedSet(context.reader(), query.field);\n          TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n            \n            @Override\n            public TermsEnum iterator(TermsEnum reuse) {\n              return fcsi.termsEnum();\n            }\n\n            @Override\n            public long getSumTotalTermFreq() {\n              return -1;\n            }\n\n            @Override\n            public long getSumDocFreq() {\n              return -1;\n            }\n\n            @Override\n            public int getDocCount() {\n              return -1;\n            }\n\n            @Override\n            public long size() {\n              return -1;\n            }\n\n            @Override\n            public boolean hasFreqs() {\n              return false;\n            }\n\n            @Override\n            public boolean hasOffsets() {\n              return false;\n            }\n\n            @Override\n            public boolean hasPositions() {\n              return false;\n            }\n            \n            @Override\n            public boolean hasPayloads() {\n              return false;\n            }\n          });\n          \n          assert termsEnum != null;\n          if (termsEnum.next() == null) {\n            // no matching terms\n            return null;\n          }\n          // fill into a bitset\n          // Cannot use FixedBitSet because we require long index (ord):\n          final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n          do {\n            long ord = termsEnum.ord();\n            if (ord >= 0) {\n              termSet.set(ord);\n            }\n          } while (termsEnum.next() != null);\n          \n          final DocIdSetIterator approximation = DocIdSetIterator.all(context.reader().maxDoc());\n          final TwoPhaseIterator twoPhaseIterator = new TwoPhaseIterator(approximation) {\n            @Override\n            public boolean matches() throws IOException {\n              final int doc = approximation.docID();\n              if (acceptDocs != null && acceptDocs.get(doc) == false) {\n                return false;\n              }\n              fcsi.setDocument(doc);\n              for (long ord = fcsi.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = fcsi.nextOrd()) {\n                if (termSet.get(ord)) {\n                  return true;\n                }\n              }\n              return false;\n            }\n          };\n          final DocIdSetIterator disi = TwoPhaseIterator.asDocIdSetIterator(twoPhaseIterator);\n          return new Scorer(this) {\n\n            @Override\n            public TwoPhaseIterator asTwoPhaseIterator() {\n              return twoPhaseIterator;\n            }\n\n            @Override\n            public float score() throws IOException {\n              return score;\n            }\n\n            @Override\n            public int freq() throws IOException {\n              return 1;\n            }\n\n            @Override\n            public int docID() {\n              return disi.docID();\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              return disi.nextDoc();\n            }\n\n            @Override\n            public int advance(int target) throws IOException {\n              return disi.advance(target);\n            }\n\n            @Override\n            public long cost() {\n              return disi.cost();\n            }\n\n          };\n        }\n      };\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapper#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapper#createWeight(IndexSearcher,boolean).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new ConstantScoreWeight(this) {\n        @Override\n        Scorer scorer(LeafReaderContext context, Bits acceptDocs, float score) throws IOException {\n          final SortedSetDocValues fcsi = DocValues.getSortedSet(context.reader(), query.field);\n          TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n            \n            @Override\n            public TermsEnum iterator() {\n              return fcsi.termsEnum();\n            }\n\n            @Override\n            public long getSumTotalTermFreq() {\n              return -1;\n            }\n\n            @Override\n            public long getSumDocFreq() {\n              return -1;\n            }\n\n            @Override\n            public int getDocCount() {\n              return -1;\n            }\n\n            @Override\n            public long size() {\n              return -1;\n            }\n\n            @Override\n            public boolean hasFreqs() {\n              return false;\n            }\n\n            @Override\n            public boolean hasOffsets() {\n              return false;\n            }\n\n            @Override\n            public boolean hasPositions() {\n              return false;\n            }\n            \n            @Override\n            public boolean hasPayloads() {\n              return false;\n            }\n          });\n          \n          assert termsEnum != null;\n          if (termsEnum.next() == null) {\n            // no matching terms\n            return null;\n          }\n          // fill into a bitset\n          // Cannot use FixedBitSet because we require long index (ord):\n          final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n          do {\n            long ord = termsEnum.ord();\n            if (ord >= 0) {\n              termSet.set(ord);\n            }\n          } while (termsEnum.next() != null);\n          \n          final DocIdSetIterator approximation = DocIdSetIterator.all(context.reader().maxDoc());\n          final TwoPhaseIterator twoPhaseIterator = new TwoPhaseIterator(approximation) {\n            @Override\n            public boolean matches() throws IOException {\n              final int doc = approximation.docID();\n              if (acceptDocs != null && acceptDocs.get(doc) == false) {\n                return false;\n              }\n              fcsi.setDocument(doc);\n              for (long ord = fcsi.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = fcsi.nextOrd()) {\n                if (termSet.get(ord)) {\n                  return true;\n                }\n              }\n              return false;\n            }\n          };\n          final DocIdSetIterator disi = TwoPhaseIterator.asDocIdSetIterator(twoPhaseIterator);\n          return new Scorer(this) {\n\n            @Override\n            public TwoPhaseIterator asTwoPhaseIterator() {\n              return twoPhaseIterator;\n            }\n\n            @Override\n            public float score() throws IOException {\n              return score;\n            }\n\n            @Override\n            public int freq() throws IOException {\n              return 1;\n            }\n\n            @Override\n            public int docID() {\n              return disi.docID();\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              return disi.nextDoc();\n            }\n\n            @Override\n            public int advance(int target) throws IOException {\n              return disi.advance(target);\n            }\n\n            @Override\n            public long cost() {\n              return disi.cost();\n            }\n\n          };\n        }\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new ConstantScoreWeight(this) {\n        @Override\n        Scorer scorer(LeafReaderContext context, Bits acceptDocs, float score) throws IOException {\n          final SortedSetDocValues fcsi = DocValues.getSortedSet(context.reader(), query.field);\n          TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n            \n            @Override\n            public TermsEnum iterator(TermsEnum reuse) {\n              return fcsi.termsEnum();\n            }\n\n            @Override\n            public long getSumTotalTermFreq() {\n              return -1;\n            }\n\n            @Override\n            public long getSumDocFreq() {\n              return -1;\n            }\n\n            @Override\n            public int getDocCount() {\n              return -1;\n            }\n\n            @Override\n            public long size() {\n              return -1;\n            }\n\n            @Override\n            public boolean hasFreqs() {\n              return false;\n            }\n\n            @Override\n            public boolean hasOffsets() {\n              return false;\n            }\n\n            @Override\n            public boolean hasPositions() {\n              return false;\n            }\n            \n            @Override\n            public boolean hasPayloads() {\n              return false;\n            }\n          });\n          \n          assert termsEnum != null;\n          if (termsEnum.next() == null) {\n            // no matching terms\n            return null;\n          }\n          // fill into a bitset\n          // Cannot use FixedBitSet because we require long index (ord):\n          final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n          do {\n            long ord = termsEnum.ord();\n            if (ord >= 0) {\n              termSet.set(ord);\n            }\n          } while (termsEnum.next() != null);\n          \n          final DocIdSetIterator approximation = DocIdSetIterator.all(context.reader().maxDoc());\n          final TwoPhaseIterator twoPhaseIterator = new TwoPhaseIterator(approximation) {\n            @Override\n            public boolean matches() throws IOException {\n              final int doc = approximation.docID();\n              if (acceptDocs != null && acceptDocs.get(doc) == false) {\n                return false;\n              }\n              fcsi.setDocument(doc);\n              for (long ord = fcsi.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = fcsi.nextOrd()) {\n                if (termSet.get(ord)) {\n                  return true;\n                }\n              }\n              return false;\n            }\n          };\n          final DocIdSetIterator disi = TwoPhaseIterator.asDocIdSetIterator(twoPhaseIterator);\n          return new Scorer(this) {\n\n            @Override\n            public TwoPhaseIterator asTwoPhaseIterator() {\n              return twoPhaseIterator;\n            }\n\n            @Override\n            public float score() throws IOException {\n              return score;\n            }\n\n            @Override\n            public int freq() throws IOException {\n              return 1;\n            }\n\n            @Override\n            public int docID() {\n              return disi.docID();\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              return disi.nextDoc();\n            }\n\n            @Override\n            public int advance(int target) throws IOException {\n              return disi.advance(target);\n            }\n\n            @Override\n            public long cost() {\n              return disi.cost();\n            }\n\n          };\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29efba95465cc25f76d9f92aec35c9f71b1a55ca","date":1428692677,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapper#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapper#createWeight(IndexSearcher,boolean).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new ConstantScoreWeight(this) {\n        @Override\n        protected Scorer scorer(LeafReaderContext context, Bits acceptDocs, float score) throws IOException {\n          final SortedSetDocValues fcsi = DocValues.getSortedSet(context.reader(), query.field);\n          TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n            \n            @Override\n            public TermsEnum iterator() {\n              return fcsi.termsEnum();\n            }\n\n            @Override\n            public long getSumTotalTermFreq() {\n              return -1;\n            }\n\n            @Override\n            public long getSumDocFreq() {\n              return -1;\n            }\n\n            @Override\n            public int getDocCount() {\n              return -1;\n            }\n\n            @Override\n            public long size() {\n              return -1;\n            }\n\n            @Override\n            public boolean hasFreqs() {\n              return false;\n            }\n\n            @Override\n            public boolean hasOffsets() {\n              return false;\n            }\n\n            @Override\n            public boolean hasPositions() {\n              return false;\n            }\n            \n            @Override\n            public boolean hasPayloads() {\n              return false;\n            }\n          });\n          \n          assert termsEnum != null;\n          if (termsEnum.next() == null) {\n            // no matching terms\n            return null;\n          }\n          // fill into a bitset\n          // Cannot use FixedBitSet because we require long index (ord):\n          final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n          do {\n            long ord = termsEnum.ord();\n            if (ord >= 0) {\n              termSet.set(ord);\n            }\n          } while (termsEnum.next() != null);\n          \n          final DocIdSetIterator approximation = DocIdSetIterator.all(context.reader().maxDoc());\n          final TwoPhaseIterator twoPhaseIterator = new TwoPhaseIterator(approximation) {\n            @Override\n            public boolean matches() throws IOException {\n              final int doc = approximation.docID();\n              if (acceptDocs != null && acceptDocs.get(doc) == false) {\n                return false;\n              }\n              fcsi.setDocument(doc);\n              for (long ord = fcsi.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = fcsi.nextOrd()) {\n                if (termSet.get(ord)) {\n                  return true;\n                }\n              }\n              return false;\n            }\n          };\n          final DocIdSetIterator disi = TwoPhaseIterator.asDocIdSetIterator(twoPhaseIterator);\n          return new Scorer(this) {\n\n            @Override\n            public TwoPhaseIterator asTwoPhaseIterator() {\n              return twoPhaseIterator;\n            }\n\n            @Override\n            public float score() throws IOException {\n              return score;\n            }\n\n            @Override\n            public int freq() throws IOException {\n              return 1;\n            }\n\n            @Override\n            public int docID() {\n              return disi.docID();\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              return disi.nextDoc();\n            }\n\n            @Override\n            public int advance(int target) throws IOException {\n              return disi.advance(target);\n            }\n\n            @Override\n            public long cost() {\n              return disi.cost();\n            }\n\n          };\n        }\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new ConstantScoreWeight(this) {\n        @Override\n        Scorer scorer(LeafReaderContext context, Bits acceptDocs, float score) throws IOException {\n          final SortedSetDocValues fcsi = DocValues.getSortedSet(context.reader(), query.field);\n          TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n            \n            @Override\n            public TermsEnum iterator() {\n              return fcsi.termsEnum();\n            }\n\n            @Override\n            public long getSumTotalTermFreq() {\n              return -1;\n            }\n\n            @Override\n            public long getSumDocFreq() {\n              return -1;\n            }\n\n            @Override\n            public int getDocCount() {\n              return -1;\n            }\n\n            @Override\n            public long size() {\n              return -1;\n            }\n\n            @Override\n            public boolean hasFreqs() {\n              return false;\n            }\n\n            @Override\n            public boolean hasOffsets() {\n              return false;\n            }\n\n            @Override\n            public boolean hasPositions() {\n              return false;\n            }\n            \n            @Override\n            public boolean hasPayloads() {\n              return false;\n            }\n          });\n          \n          assert termsEnum != null;\n          if (termsEnum.next() == null) {\n            // no matching terms\n            return null;\n          }\n          // fill into a bitset\n          // Cannot use FixedBitSet because we require long index (ord):\n          final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n          do {\n            long ord = termsEnum.ord();\n            if (ord >= 0) {\n              termSet.set(ord);\n            }\n          } while (termsEnum.next() != null);\n          \n          final DocIdSetIterator approximation = DocIdSetIterator.all(context.reader().maxDoc());\n          final TwoPhaseIterator twoPhaseIterator = new TwoPhaseIterator(approximation) {\n            @Override\n            public boolean matches() throws IOException {\n              final int doc = approximation.docID();\n              if (acceptDocs != null && acceptDocs.get(doc) == false) {\n                return false;\n              }\n              fcsi.setDocument(doc);\n              for (long ord = fcsi.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = fcsi.nextOrd()) {\n                if (termSet.get(ord)) {\n                  return true;\n                }\n              }\n              return false;\n            }\n          };\n          final DocIdSetIterator disi = TwoPhaseIterator.asDocIdSetIterator(twoPhaseIterator);\n          return new Scorer(this) {\n\n            @Override\n            public TwoPhaseIterator asTwoPhaseIterator() {\n              return twoPhaseIterator;\n            }\n\n            @Override\n            public float score() throws IOException {\n              return score;\n            }\n\n            @Override\n            public int freq() throws IOException {\n              return 1;\n            }\n\n            @Override\n            public int docID() {\n              return disi.docID();\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              return disi.nextDoc();\n            }\n\n            @Override\n            public int advance(int target) throws IOException {\n              return disi.advance(target);\n            }\n\n            @Override\n            public long cost() {\n              return disi.cost();\n            }\n\n          };\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a7f94ff172f40ff68a926d112e25b96bc38e5a27","date":1431002360,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapper#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapper#createWeight(IndexSearcher,boolean).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new RandomAccessWeight(this) {\n        @Override\n        protected Bits getMatchingDocs(LeafReaderContext context) throws IOException {\n          final SortedSetDocValues fcsi = DocValues.getSortedSet(context.reader(), query.field);\n          TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n            \n            @Override\n            public TermsEnum iterator() {\n              return fcsi.termsEnum();\n            }\n\n            @Override\n            public long getSumTotalTermFreq() {\n              return -1;\n            }\n\n            @Override\n            public long getSumDocFreq() {\n              return -1;\n            }\n\n            @Override\n            public int getDocCount() {\n              return -1;\n            }\n\n            @Override\n            public long size() {\n              return -1;\n            }\n\n            @Override\n            public boolean hasFreqs() {\n              return false;\n            }\n\n            @Override\n            public boolean hasOffsets() {\n              return false;\n            }\n\n            @Override\n            public boolean hasPositions() {\n              return false;\n            }\n            \n            @Override\n            public boolean hasPayloads() {\n              return false;\n            }\n          });\n          \n          assert termsEnum != null;\n          if (termsEnum.next() == null) {\n            // no matching terms\n            return null;\n          }\n          // fill into a bitset\n          // Cannot use FixedBitSet because we require long index (ord):\n          final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n          do {\n            long ord = termsEnum.ord();\n            if (ord >= 0) {\n              termSet.set(ord);\n            }\n          } while (termsEnum.next() != null);\n\n          return new Bits() {\n\n            @Override\n            public boolean get(int doc) {\n              fcsi.setDocument(doc);\n              for (long ord = fcsi.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = fcsi.nextOrd()) {\n                if (termSet.get(ord)) {\n                  return true;\n                }\n              }\n              return false;\n            }\n\n            @Override\n            public int length() {\n              return context.reader().maxDoc();\n            }\n\n          };\n        }\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new ConstantScoreWeight(this) {\n        @Override\n        protected Scorer scorer(LeafReaderContext context, Bits acceptDocs, float score) throws IOException {\n          final SortedSetDocValues fcsi = DocValues.getSortedSet(context.reader(), query.field);\n          TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n            \n            @Override\n            public TermsEnum iterator() {\n              return fcsi.termsEnum();\n            }\n\n            @Override\n            public long getSumTotalTermFreq() {\n              return -1;\n            }\n\n            @Override\n            public long getSumDocFreq() {\n              return -1;\n            }\n\n            @Override\n            public int getDocCount() {\n              return -1;\n            }\n\n            @Override\n            public long size() {\n              return -1;\n            }\n\n            @Override\n            public boolean hasFreqs() {\n              return false;\n            }\n\n            @Override\n            public boolean hasOffsets() {\n              return false;\n            }\n\n            @Override\n            public boolean hasPositions() {\n              return false;\n            }\n            \n            @Override\n            public boolean hasPayloads() {\n              return false;\n            }\n          });\n          \n          assert termsEnum != null;\n          if (termsEnum.next() == null) {\n            // no matching terms\n            return null;\n          }\n          // fill into a bitset\n          // Cannot use FixedBitSet because we require long index (ord):\n          final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n          do {\n            long ord = termsEnum.ord();\n            if (ord >= 0) {\n              termSet.set(ord);\n            }\n          } while (termsEnum.next() != null);\n          \n          final DocIdSetIterator approximation = DocIdSetIterator.all(context.reader().maxDoc());\n          final TwoPhaseIterator twoPhaseIterator = new TwoPhaseIterator(approximation) {\n            @Override\n            public boolean matches() throws IOException {\n              final int doc = approximation.docID();\n              if (acceptDocs != null && acceptDocs.get(doc) == false) {\n                return false;\n              }\n              fcsi.setDocument(doc);\n              for (long ord = fcsi.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = fcsi.nextOrd()) {\n                if (termSet.get(ord)) {\n                  return true;\n                }\n              }\n              return false;\n            }\n          };\n          final DocIdSetIterator disi = TwoPhaseIterator.asDocIdSetIterator(twoPhaseIterator);\n          return new Scorer(this) {\n\n            @Override\n            public TwoPhaseIterator asTwoPhaseIterator() {\n              return twoPhaseIterator;\n            }\n\n            @Override\n            public float score() throws IOException {\n              return score;\n            }\n\n            @Override\n            public int freq() throws IOException {\n              return 1;\n            }\n\n            @Override\n            public int docID() {\n              return disi.docID();\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              return disi.nextDoc();\n            }\n\n            @Override\n            public int advance(int target) throws IOException {\n              return disi.advance(target);\n            }\n\n            @Override\n            public long cost() {\n              return disi.cost();\n            }\n\n          };\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"02e175abd2c4c1611c5a9647486ae8ba249a94c1","date":1468327116,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapper#createWeight(IndexSearcher,boolean,float).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapper#createWeight(IndexSearcher,boolean).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n      return new RandomAccessWeight(this, boost) {\n        @Override\n        protected Bits getMatchingDocs(LeafReaderContext context) throws IOException {\n          final SortedSetDocValues fcsi = DocValues.getSortedSet(context.reader(), query.field);\n          TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n            \n            @Override\n            public TermsEnum iterator() {\n              return fcsi.termsEnum();\n            }\n\n            @Override\n            public long getSumTotalTermFreq() {\n              return -1;\n            }\n\n            @Override\n            public long getSumDocFreq() {\n              return -1;\n            }\n\n            @Override\n            public int getDocCount() {\n              return -1;\n            }\n\n            @Override\n            public long size() {\n              return -1;\n            }\n\n            @Override\n            public boolean hasFreqs() {\n              return false;\n            }\n\n            @Override\n            public boolean hasOffsets() {\n              return false;\n            }\n\n            @Override\n            public boolean hasPositions() {\n              return false;\n            }\n            \n            @Override\n            public boolean hasPayloads() {\n              return false;\n            }\n          });\n          \n          assert termsEnum != null;\n          if (termsEnum.next() == null) {\n            // no matching terms\n            return null;\n          }\n          // fill into a bitset\n          // Cannot use FixedBitSet because we require long index (ord):\n          final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n          do {\n            long ord = termsEnum.ord();\n            if (ord >= 0) {\n              termSet.set(ord);\n            }\n          } while (termsEnum.next() != null);\n\n          return new Bits() {\n\n            @Override\n            public boolean get(int doc) {\n              fcsi.setDocument(doc);\n              for (long ord = fcsi.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = fcsi.nextOrd()) {\n                if (termSet.get(ord)) {\n                  return true;\n                }\n              }\n              return false;\n            }\n\n            @Override\n            public int length() {\n              return context.reader().maxDoc();\n            }\n\n          };\n        }\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new RandomAccessWeight(this) {\n        @Override\n        protected Bits getMatchingDocs(LeafReaderContext context) throws IOException {\n          final SortedSetDocValues fcsi = DocValues.getSortedSet(context.reader(), query.field);\n          TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n            \n            @Override\n            public TermsEnum iterator() {\n              return fcsi.termsEnum();\n            }\n\n            @Override\n            public long getSumTotalTermFreq() {\n              return -1;\n            }\n\n            @Override\n            public long getSumDocFreq() {\n              return -1;\n            }\n\n            @Override\n            public int getDocCount() {\n              return -1;\n            }\n\n            @Override\n            public long size() {\n              return -1;\n            }\n\n            @Override\n            public boolean hasFreqs() {\n              return false;\n            }\n\n            @Override\n            public boolean hasOffsets() {\n              return false;\n            }\n\n            @Override\n            public boolean hasPositions() {\n              return false;\n            }\n            \n            @Override\n            public boolean hasPayloads() {\n              return false;\n            }\n          });\n          \n          assert termsEnum != null;\n          if (termsEnum.next() == null) {\n            // no matching terms\n            return null;\n          }\n          // fill into a bitset\n          // Cannot use FixedBitSet because we require long index (ord):\n          final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n          do {\n            long ord = termsEnum.ord();\n            if (ord >= 0) {\n              termSet.set(ord);\n            }\n          } while (termsEnum.next() != null);\n\n          return new Bits() {\n\n            @Override\n            public boolean get(int doc) {\n              fcsi.setDocument(doc);\n              for (long ord = fcsi.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = fcsi.nextOrd()) {\n                if (termSet.get(ord)) {\n                  return true;\n                }\n              }\n              return false;\n            }\n\n            @Override\n            public int length() {\n              return context.reader().maxDoc();\n            }\n\n          };\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/search/DocValuesRewriteMethod.MultiTermQueryDocValuesWrapper#createWeight(IndexSearcher,boolean).mjava","sourceNew":null,"sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new RandomAccessWeight(this) {\n        @Override\n        protected Bits getMatchingDocs(LeafReaderContext context) throws IOException {\n          final SortedSetDocValues fcsi = DocValues.getSortedSet(context.reader(), query.field);\n          TermsEnum termsEnum = query.getTermsEnum(new Terms() {\n            \n            @Override\n            public TermsEnum iterator() {\n              return fcsi.termsEnum();\n            }\n\n            @Override\n            public long getSumTotalTermFreq() {\n              return -1;\n            }\n\n            @Override\n            public long getSumDocFreq() {\n              return -1;\n            }\n\n            @Override\n            public int getDocCount() {\n              return -1;\n            }\n\n            @Override\n            public long size() {\n              return -1;\n            }\n\n            @Override\n            public boolean hasFreqs() {\n              return false;\n            }\n\n            @Override\n            public boolean hasOffsets() {\n              return false;\n            }\n\n            @Override\n            public boolean hasPositions() {\n              return false;\n            }\n            \n            @Override\n            public boolean hasPayloads() {\n              return false;\n            }\n          });\n          \n          assert termsEnum != null;\n          if (termsEnum.next() == null) {\n            // no matching terms\n            return null;\n          }\n          // fill into a bitset\n          // Cannot use FixedBitSet because we require long index (ord):\n          final LongBitSet termSet = new LongBitSet(fcsi.getValueCount());\n          do {\n            long ord = termsEnum.ord();\n            if (ord >= 0) {\n              termSet.set(ord);\n            }\n          } while (termsEnum.next() != null);\n\n          return new Bits() {\n\n            @Override\n            public boolean get(int doc) {\n              fcsi.setDocument(doc);\n              for (long ord = fcsi.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = fcsi.nextOrd()) {\n                if (termSet.get(ord)) {\n                  return true;\n                }\n              }\n              return false;\n            }\n\n            @Override\n            public int length() {\n              return context.reader().maxDoc();\n            }\n\n          };\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["7a6b1be5d2b36d6a30913778ef61374103d55e33"],"29efba95465cc25f76d9f92aec35c9f71b1a55ca":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"7a6b1be5d2b36d6a30913778ef61374103d55e33":["2713584a660051cd646423be682771e3bbd99985"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","7a6b1be5d2b36d6a30913778ef61374103d55e33"],"a7f94ff172f40ff68a926d112e25b96bc38e5a27":["29efba95465cc25f76d9f92aec35c9f71b1a55ca"],"2713584a660051cd646423be682771e3bbd99985":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"02e175abd2c4c1611c5a9647486ae8ba249a94c1":["a7f94ff172f40ff68a926d112e25b96bc38e5a27"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a7f94ff172f40ff68a926d112e25b96bc38e5a27","02e175abd2c4c1611c5a9647486ae8ba249a94c1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["02e175abd2c4c1611c5a9647486ae8ba249a94c1"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["29efba95465cc25f76d9f92aec35c9f71b1a55ca"],"7a6b1be5d2b36d6a30913778ef61374103d55e33":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"29efba95465cc25f76d9f92aec35c9f71b1a55ca":["a7f94ff172f40ff68a926d112e25b96bc38e5a27"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"a7f94ff172f40ff68a926d112e25b96bc38e5a27":["02e175abd2c4c1611c5a9647486ae8ba249a94c1","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"2713584a660051cd646423be682771e3bbd99985":["7a6b1be5d2b36d6a30913778ef61374103d55e33"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","2713584a660051cd646423be682771e3bbd99985"],"02e175abd2c4c1611c5a9647486ae8ba249a94c1":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}