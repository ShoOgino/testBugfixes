{"path":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","commits":[{"id":"c784b25e28b81ddedff2b97738c8286773f00f15","date":1352150231,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","pathOld":"/dev/null","sourceNew":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1);\n\n    suggester.build(new TermFreqArrayIterator(new TermFreq[] {\n          new TermFreq(\"a a\", 50),\n          new TermFreq(\"a b\", 50),\n        }));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ada2f7352a7f964fe49bccd13227c4ec38563d39","date":1381659982,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","sourceNew":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1);\n\n    suggester.build(new TermFreqPayloadArrayIterator(new TermFreqPayload[] {\n          new TermFreqPayload(\"a a\", 50),\n          new TermFreqPayload(\"a b\", 50),\n        }));\n  }\n\n","sourceOld":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1);\n\n    suggester.build(new TermFreqArrayIterator(new TermFreq[] {\n          new TermFreq(\"a a\", 50),\n          new TermFreq(\"a b\", 50),\n        }));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"41aee74b5f91a096e3fd950f4a336bc763f0e7a7","date":1381772070,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","sourceNew":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n  }\n\n","sourceOld":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1);\n\n    suggester.build(new TermFreqPayloadArrayIterator(new TermFreqPayload[] {\n          new TermFreqPayload(\"a a\", 50),\n          new TermFreqPayload(\"a b\", 50),\n        }));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4e0095ef720d1b8e7406847147af69f19af3ab6","date":1383131477,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","sourceNew":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1, false);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n  }\n\n","sourceOld":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"33f87fe6faf49dfc1e66f45e841e24838c2f725c","date":1383142987,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","sourceNew":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1, true);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n  }\n\n","sourceOld":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1, false);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","sourceNew":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1, true);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n  }\n\n","sourceOld":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n          Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1, true);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a56958d7f71a28824f20031ffbb2e13502a0274e","date":1425573902,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","sourceNew":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1, true);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n    \n    a.close();\n  }\n\n","sourceOld":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1, true);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","sourceNew":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1, true);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n    \n    a.close();\n  }\n\n","sourceOld":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1, true);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"867e3d9153fb761456b54a9dcce566e1545c5ef6","date":1444903098,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","sourceNew":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    Directory tempDir = getDirectory();\n    AnalyzingSuggester suggester = new AnalyzingSuggester(tempDir, \"suggest\", a, a, 0, 256, -1, true);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n    \n    IOUtils.close(a, tempDir);\n  }\n\n","sourceOld":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    AnalyzingSuggester suggester = new AnalyzingSuggester(a, a, 0, 256, -1, true);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n    \n    a.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e859719dc778fb66d3d21e7be08cd408fc2bde98","date":1446717611,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","sourceNew":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) {\n            }\n          };\n        }\n      };\n\n    Directory tempDir = getDirectory();\n    AnalyzingSuggester suggester = new AnalyzingSuggester(tempDir, \"suggest\", a, a, 0, 256, -1, true);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n    \n    IOUtils.close(a, tempDir);\n  }\n\n","sourceOld":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) throws IOException {\n            }\n          };\n        }\n      };\n\n    Directory tempDir = getDirectory();\n    AnalyzingSuggester suggester = new AnalyzingSuggester(tempDir, \"suggest\", a, a, 0, 256, -1, true);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n    \n    IOUtils.close(a, tempDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fac252ef8e3d0bbff9303ffbf675e824a729dfaf","date":1537347776,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingSuggesterTest#test0ByteKeys().mjava","sourceNew":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new MultiCannedAnalyzer(true,\n        new CannedBinaryTokenStream(token(new BytesRef(new byte[] {0x0, 0x0, 0x0}))),\n        new CannedBinaryTokenStream(token(new BytesRef(new byte[] {0x0, 0x0}))),\n        new CannedBinaryTokenStream(token(new BytesRef(new byte[] {0x0, 0x0, 0x0}))),\n        new CannedBinaryTokenStream(token(new BytesRef(new byte[] {0x0, 0x0})))\n    );\n\n    Directory tempDir = getDirectory();\n    AnalyzingSuggester suggester = new AnalyzingSuggester(tempDir, \"suggest\", a, a, 0, 256, -1, true);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n    \n    IOUtils.close(a, tempDir);\n  }\n\n","sourceOld":"  public void test0ByteKeys() throws Exception {\n    final Analyzer a = new Analyzer() {\n        @Override\n        protected TokenStreamComponents createComponents(String fieldName) {\n          Tokenizer tokenizer = new MockTokenizer(MockTokenizer.SIMPLE, true);\n        \n          return new TokenStreamComponents(tokenizer) {\n            int tokenStreamCounter = 0;\n            final TokenStream[] tokenStreams = new TokenStream[] {\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0, 0x0})),\n                }),\n              new CannedBinaryTokenStream(new BinaryToken[] {\n                  token(new BytesRef(new byte[] {0x0, 0x0})),\n                }),\n            };\n\n            @Override\n            public TokenStream getTokenStream() {\n              TokenStream result = tokenStreams[tokenStreamCounter];\n              tokenStreamCounter++;\n              return result;\n            }\n         \n            @Override\n            protected void setReader(final Reader reader) {\n            }\n          };\n        }\n      };\n\n    Directory tempDir = getDirectory();\n    AnalyzingSuggester suggester = new AnalyzingSuggester(tempDir, \"suggest\", a, a, 0, 256, -1, true);\n\n    suggester.build(new InputArrayIterator(new Input[] {\n          new Input(\"a a\", 50),\n          new Input(\"a b\", 50),\n        }));\n    \n    IOUtils.close(a, tempDir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["ada2f7352a7f964fe49bccd13227c4ec38563d39"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["33f87fe6faf49dfc1e66f45e841e24838c2f725c"],"33f87fe6faf49dfc1e66f45e841e24838c2f725c":["d4e0095ef720d1b8e7406847147af69f19af3ab6"],"e859719dc778fb66d3d21e7be08cd408fc2bde98":["867e3d9153fb761456b54a9dcce566e1545c5ef6"],"c784b25e28b81ddedff2b97738c8286773f00f15":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","a56958d7f71a28824f20031ffbb2e13502a0274e"],"fac252ef8e3d0bbff9303ffbf675e824a729dfaf":["e859719dc778fb66d3d21e7be08cd408fc2bde98"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a56958d7f71a28824f20031ffbb2e13502a0274e":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"867e3d9153fb761456b54a9dcce566e1545c5ef6":["a56958d7f71a28824f20031ffbb2e13502a0274e"],"d4e0095ef720d1b8e7406847147af69f19af3ab6":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fac252ef8e3d0bbff9303ffbf675e824a729dfaf"],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["c784b25e28b81ddedff2b97738c8286773f00f15"]},"commit2Childs":{"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["d4e0095ef720d1b8e7406847147af69f19af3ab6"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","a56958d7f71a28824f20031ffbb2e13502a0274e"],"33f87fe6faf49dfc1e66f45e841e24838c2f725c":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"e859719dc778fb66d3d21e7be08cd408fc2bde98":["fac252ef8e3d0bbff9303ffbf675e824a729dfaf"],"c784b25e28b81ddedff2b97738c8286773f00f15":["ada2f7352a7f964fe49bccd13227c4ec38563d39"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"fac252ef8e3d0bbff9303ffbf675e824a729dfaf":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c784b25e28b81ddedff2b97738c8286773f00f15"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","867e3d9153fb761456b54a9dcce566e1545c5ef6"],"d4e0095ef720d1b8e7406847147af69f19af3ab6":["33f87fe6faf49dfc1e66f45e841e24838c2f725c"],"867e3d9153fb761456b54a9dcce566e1545c5ef6":["e859719dc778fb66d3d21e7be08cd408fc2bde98"],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}