{"path":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","commits":[{"id":"9d7f2f39556d99cecd24f152bdece2b6432458c3","date":1077651298,"type":0,"author":"Doug Cutting","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();          // store, index, token\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], true, false, false));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], false, true, true));\n\t\t\t\tdoc.add (new Field (\"int\",      data[i][2], false, true, false));\n\t\t\t\tdoc.add (new Field (\"float\",    data[i][3], false, true, false));\n\t\t\t\tdoc.add (new Field (\"string\",   data[i][4], false, true, false));\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"35c39157e8b6bc585e3a07e703d75db0f2ad56b2","date":1082672595,"type":3,"author":"Tim Jones","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();          // store, index, token\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], true, false, false));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], false, true, true));\n\t\t\t\tdoc.add (new Field (\"int\",      data[i][2], false, true, false));\n\t\t\t\tdoc.add (new Field (\"float\",    data[i][3], false, true, false));\n\t\t\t\tdoc.add (new Field (\"string\",   data[i][4], false, true, false));\n\t\t\t\tdoc.add (new Field (\"custom\",   data[i][5], false, true, false));\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","sourceOld":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();          // store, index, token\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], true, false, false));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], false, true, true));\n\t\t\t\tdoc.add (new Field (\"int\",      data[i][2], false, true, false));\n\t\t\t\tdoc.add (new Field (\"float\",    data[i][3], false, true, false));\n\t\t\t\tdoc.add (new Field (\"string\",   data[i][4], false, true, false));\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba534479820dee396d07f520ba2a55400a1b6e7d","date":1085439102,"type":3,"author":"Tim Jones","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();          // store, index, token\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], true, false, false));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], false, true, true));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], false, true, false));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], false, true, false));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], false, true, false));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], false, true, false));\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","sourceOld":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();          // store, index, token\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], true, false, false));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], false, true, true));\n\t\t\t\tdoc.add (new Field (\"int\",      data[i][2], false, true, false));\n\t\t\t\tdoc.add (new Field (\"float\",    data[i][3], false, true, false));\n\t\t\t\tdoc.add (new Field (\"string\",   data[i][4], false, true, false));\n\t\t\t\tdoc.add (new Field (\"custom\",   data[i][5], false, true, false));\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d569a3d5c35dabec1e74fffd00c00294d3e1fbd5","date":1093899135,"type":3,"author":"Daniel Naber","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.TOKENIZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","sourceOld":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();          // store, index, token\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], true, false, false));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], false, true, true));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], false, true, false));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], false, true, false));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], false, true, false));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], false, true, false));\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f5457736ee10c96b4fcd88997461006c8585ac24","date":1131568124,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.TOKENIZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","sourceOld":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.TOKENIZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2275c46fba03d235b53596f1b08c77ad11a24459","date":1144296129,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.TOKENIZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","sourceOld":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.TOKENIZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8408bef84cc9eadfe3d6bf05cac61d5cb5a71f04","date":1193794105,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.TOKENIZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","sourceOld":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.TOKENIZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a20974f34ae56da194b058e7307c8c52b32444d8","date":1201921568,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.TOKENIZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][8] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][8] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","sourceOld":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.TOKENIZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0018e7a0579df5d3de71d0bd878322a7abef04d9","date":1202242049,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.TOKENIZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][8] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][8] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","sourceOld":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.TOKENIZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][8] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][8] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a","date":1221082732,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","sourceOld":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.TOKENIZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.UN_TOKENIZED));\n\t\t\t\tif (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][8] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        if (data[i][8] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.UN_TOKENIZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3766097c9c41a30d67e9b548c62d017abf8e07ac","date":1228770465,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","sourceOld":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"63bc3238545c6012bd44f5d294077997f236bc4e","date":1233087321,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory ();\n    IndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    writer.setMaxBufferedDocs(2);\n    writer.setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    return new IndexSearcher (indexStore);\n  }\n\n","sourceOld":"\t// create an index of all the documents, or just the x, or just the y documents\n\tprivate Searcher getIndex (boolean even, boolean odd)\n\tthrows IOException {\n\t\tRAMDirectory indexStore = new RAMDirectory ();\n\t\tIndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n\t\tfor (int i=0; i<data.length; ++i) {\n\t\t\tif (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n\t\t\t\tDocument doc = new Document();\n\t\t\t\tdoc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n\t\t\t\tdoc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n\t\t\t\tif (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n\t\t\t\tif (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n\t\t\t\twriter.addDocument (doc);\n\t\t\t}\n\t\t}\n\t\twriter.optimize ();\n\t\twriter.close ();\n\t\treturn new IndexSearcher (indexStore);\n\t}\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3965529a7891904512492d9c6a0c4dc6323899bc","date":1243970180,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory ();\n    IndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    writer.setMaxBufferedDocs(2);\n    writer.setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    IndexSearcher s = new IndexSearcher (indexStore);\n    s.setDefaultFieldSortScoring(true, true);\n    return s;\n  }\n\n","sourceOld":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory ();\n    IndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    writer.setMaxBufferedDocs(2);\n    writer.setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    return new IndexSearcher (indexStore);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8ebf3b77e5581d3b403ec1799f461a9b46fc6bf8","date":1254593002,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory ();\n    IndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    writer.setMaxBufferedDocs(2);\n    writer.setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    IndexSearcher s = new IndexSearcher (indexStore, true);\n    s.setDefaultFieldSortScoring(true, true);\n    return s;\n  }\n\n","sourceOld":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory ();\n    IndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    writer.setMaxBufferedDocs(2);\n    writer.setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    IndexSearcher s = new IndexSearcher (indexStore);\n    s.setDefaultFieldSortScoring(true, true);\n    return s;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe0932c1d340f83fb0a611e5829b3046a1cc1152","date":1264946739,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory ();\n    IndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);\n    writer.setMaxBufferedDocs(2);\n    writer.setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    IndexSearcher s = new IndexSearcher (indexStore, true);\n    s.setDefaultFieldSortScoring(true, true);\n    return s;\n  }\n\n","sourceOld":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory ();\n    IndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.LIMITED);\n    writer.setMaxBufferedDocs(2);\n    writer.setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    IndexSearcher s = new IndexSearcher (indexStore, true);\n    s.setDefaultFieldSortScoring(true, true);\n    return s;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6","date":1265808957,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory ();\n    IndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);\n    writer.setMaxBufferedDocs(2);\n    writer.setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    IndexSearcher s = new IndexSearcher (indexStore, true);\n    s.setDefaultFieldSortScoring(true, true);\n    return s;\n  }\n\n","sourceOld":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory ();\n    IndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);\n    writer.setMaxBufferedDocs(2);\n    writer.setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    IndexSearcher s = new IndexSearcher (indexStore, true);\n    s.setDefaultFieldSortScoring(true, true);\n    return s;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1cedb00d2dd44640194401179358a2e3ba6051bf","date":1268243626,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT).setAnalyzer(new SimpleAnalyzer(\n        TEST_VERSION_CURRENT)).setMaxBufferedDocs(2));\n    ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    IndexSearcher s = new IndexSearcher (indexStore, true);\n    s.setDefaultFieldSortScoring(true, true);\n    return s;\n  }\n\n","sourceOld":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory ();\n    IndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);\n    writer.setMaxBufferedDocs(2);\n    writer.setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    IndexSearcher s = new IndexSearcher (indexStore, true);\n    s.setDefaultFieldSortScoring(true, true);\n    return s;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e52fea2c4081a1e552b98506691990be59503168","date":1268250331,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory ();\n    IndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);\n    writer.setMaxBufferedDocs(2);\n    writer.setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    IndexSearcher s = new IndexSearcher (indexStore, true);\n    s.setDefaultFieldSortScoring(true, true);\n    return s;\n  }\n\n","sourceOld":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT).setAnalyzer(new SimpleAnalyzer(\n        TEST_VERSION_CURRENT)).setMaxBufferedDocs(2));\n    ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    IndexSearcher s = new IndexSearcher (indexStore, true);\n    s.setDefaultFieldSortScoring(true, true);\n    return s;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8","date":1268494368,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new SimpleAnalyzer(\n        TEST_VERSION_CURRENT)).setMaxBufferedDocs(2));\n    ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    IndexSearcher s = new IndexSearcher (indexStore, true);\n    s.setDefaultFieldSortScoring(true, true);\n    return s;\n  }\n\n","sourceOld":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory ();\n    IndexWriter writer = new IndexWriter (indexStore, new SimpleAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.LIMITED);\n    writer.setMaxBufferedDocs(2);\n    writer.setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    IndexSearcher s = new IndexSearcher (indexStore, true);\n    s.setDefaultFieldSortScoring(true, true);\n    return s;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","pathOld":"src/test/org/apache/lucene/search/TestSort#getIndex(boolean,boolean).mjava","sourceNew":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new SimpleAnalyzer(\n        TEST_VERSION_CURRENT)).setMaxBufferedDocs(2));\n    ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    IndexSearcher s = new IndexSearcher (indexStore, true);\n    s.setDefaultFieldSortScoring(true, true);\n    return s;\n  }\n\n","sourceOld":"  // create an index of all the documents, or just the x, or just the y documents\n  private Searcher getIndex (boolean even, boolean odd)\n  throws IOException {\n    RAMDirectory indexStore = new RAMDirectory();\n    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new SimpleAnalyzer(\n        TEST_VERSION_CURRENT)).setMaxBufferedDocs(2));\n    ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(1000);\n    for (int i=0; i<data.length; ++i) {\n      if (((i%2)==0 && even) || ((i%2)==1 && odd)) {\n        Document doc = new Document();\n        doc.add (new Field (\"tracer\",   data[i][0], Field.Store.YES, Field.Index.NO));\n        doc.add (new Field (\"contents\", data[i][1], Field.Store.NO, Field.Index.ANALYZED));\n        if (data[i][2] != null) doc.add (new Field (\"int\",      data[i][2], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][3] != null) doc.add (new Field (\"float\",    data[i][3], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][4] != null) doc.add (new Field (\"string\",   data[i][4], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][5] != null) doc.add (new Field (\"custom\",   data[i][5], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][6] != null) doc.add (new Field (\"i18n\",     data[i][6], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][7] != null) doc.add (new Field (\"long\",     data[i][7], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][8] != null) doc.add (new Field (\"double\",     data[i][8], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][9] != null) doc.add (new Field (\"short\",     data[i][9], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][10] != null) doc.add (new Field (\"byte\",     data[i][10], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        if (data[i][11] != null) doc.add (new Field (\"parser\",     data[i][11], Field.Store.NO, Field.Index.NOT_ANALYZED));\n        doc.setBoost(2);  // produce some scores above 1.0\n        writer.addDocument (doc);\n      }\n    }\n    //writer.optimize ();\n    writer.close ();\n    IndexSearcher s = new IndexSearcher (indexStore, true);\n    s.setDefaultFieldSortScoring(true, true);\n    return s;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3965529a7891904512492d9c6a0c4dc6323899bc":["63bc3238545c6012bd44f5d294077997f236bc4e"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a":["0018e7a0579df5d3de71d0bd878322a7abef04d9"],"e52fea2c4081a1e552b98506691990be59503168":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"0018e7a0579df5d3de71d0bd878322a7abef04d9":["a20974f34ae56da194b058e7307c8c52b32444d8"],"f5457736ee10c96b4fcd88997461006c8585ac24":["d569a3d5c35dabec1e74fffd00c00294d3e1fbd5"],"9d7f2f39556d99cecd24f152bdece2b6432458c3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"63bc3238545c6012bd44f5d294077997f236bc4e":["3766097c9c41a30d67e9b548c62d017abf8e07ac"],"ba534479820dee396d07f520ba2a55400a1b6e7d":["35c39157e8b6bc585e3a07e703d75db0f2ad56b2"],"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["e52fea2c4081a1e552b98506691990be59503168"],"3766097c9c41a30d67e9b548c62d017abf8e07ac":["b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a"],"8408bef84cc9eadfe3d6bf05cac61d5cb5a71f04":["2275c46fba03d235b53596f1b08c77ad11a24459"],"35c39157e8b6bc585e3a07e703d75db0f2ad56b2":["9d7f2f39556d99cecd24f152bdece2b6432458c3"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["8ebf3b77e5581d3b403ec1799f461a9b46fc6bf8"],"a20974f34ae56da194b058e7307c8c52b32444d8":["8408bef84cc9eadfe3d6bf05cac61d5cb5a71f04"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8ebf3b77e5581d3b403ec1799f461a9b46fc6bf8":["3965529a7891904512492d9c6a0c4dc6323899bc"],"d569a3d5c35dabec1e74fffd00c00294d3e1fbd5":["ba534479820dee396d07f520ba2a55400a1b6e7d"],"2275c46fba03d235b53596f1b08c77ad11a24459":["f5457736ee10c96b4fcd88997461006c8585ac24"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"]},"commit2Childs":{"3965529a7891904512492d9c6a0c4dc6323899bc":["8ebf3b77e5581d3b403ec1799f461a9b46fc6bf8"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["e52fea2c4081a1e552b98506691990be59503168"],"b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a":["3766097c9c41a30d67e9b548c62d017abf8e07ac"],"0018e7a0579df5d3de71d0bd878322a7abef04d9":["b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a"],"e52fea2c4081a1e552b98506691990be59503168":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"],"f5457736ee10c96b4fcd88997461006c8585ac24":["2275c46fba03d235b53596f1b08c77ad11a24459"],"9d7f2f39556d99cecd24f152bdece2b6432458c3":["35c39157e8b6bc585e3a07e703d75db0f2ad56b2"],"63bc3238545c6012bd44f5d294077997f236bc4e":["3965529a7891904512492d9c6a0c4dc6323899bc"],"ba534479820dee396d07f520ba2a55400a1b6e7d":["d569a3d5c35dabec1e74fffd00c00294d3e1fbd5"],"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"3766097c9c41a30d67e9b548c62d017abf8e07ac":["63bc3238545c6012bd44f5d294077997f236bc4e"],"35c39157e8b6bc585e3a07e703d75db0f2ad56b2":["ba534479820dee396d07f520ba2a55400a1b6e7d"],"8408bef84cc9eadfe3d6bf05cac61d5cb5a71f04":["a20974f34ae56da194b058e7307c8c52b32444d8"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"a20974f34ae56da194b058e7307c8c52b32444d8":["0018e7a0579df5d3de71d0bd878322a7abef04d9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9d7f2f39556d99cecd24f152bdece2b6432458c3"],"8ebf3b77e5581d3b403ec1799f461a9b46fc6bf8":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"d569a3d5c35dabec1e74fffd00c00294d3e1fbd5":["f5457736ee10c96b4fcd88997461006c8585ac24"],"2275c46fba03d235b53596f1b08c77ad11a24459":["8408bef84cc9eadfe3d6bf05cac61d5cb5a71f04"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}