{"path":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorStream[FacetField]#process().mjava","commits":[{"id":"ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d","date":1426480823,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorStream[FacetField]#process().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void process() throws IOException {\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add( \"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":0,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorStream[FacetField]#process().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void process() throws IOException {\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add( \"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"faf1236ae092482293a7e0659e347d172185ef6f","date":1430314113,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorStream[FacetField]#process().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorStream[FacetField]#process().mjava","sourceNew":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add( \"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public void process() throws IOException {\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add( \"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"82240bc1acbd51dd0fb06c0cbc5056991bba8d2e","date":1445972879,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorStream[FacetField]#process().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorStream[FacetField]#process().mjava","sourceNew":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add( \"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79759974460bc59933cd169acc94f5c6b16368d5","date":1471318443,"type":5,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorStream[FacetField]#process().mjava","sourceNew":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorByEnumTermsStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6","date":1471496851,"type":5,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorStream[FacetField]#process().mjava","sourceNew":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorByEnumTermsStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"403d05f7f8d69b65659157eff1bc1d2717f04c66","date":1471692961,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByEnumTermsStream#process().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorStream[FacetField]#process().mjava","sourceNew":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorByEnumTermsStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","sourceOld":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorStream[FacetField]#process().mjava","sourceNew":null,"sourceOld":"  @Override\n  public void process() throws IOException {\n    super.process();\n\n    // We need to keep the fcontext open after processing is done (since we will be streaming in the response writer).\n    // But if the connection is broken, we want to clean up.\n    // fcontext.base.incref();  // OFF-HEAP\n    fcontext.qcontext.addCloseHook(this);\n\n    setup();\n    response = new SimpleOrderedMap<>();\n    response.add(\"buckets\", new Iterator() {\n      boolean retrieveNext = true;\n      Object val;\n\n      @Override\n      public boolean hasNext() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = false;\n        return val != null;\n      }\n\n      @Override\n      public Object next() {\n        if (retrieveNext) {\n          val = nextBucket();\n        }\n        retrieveNext = true;\n        if (val == null) {\n          // Last value, so clean up.  In the case that we are doing streaming facets within streaming facets,\n          // the number of close hooks could grow very large, so we want to remove ourselves.\n          boolean removed = fcontext.qcontext.removeCloseHook(FacetFieldProcessorStream.this);\n          assert removed;\n          try {\n            close();\n          } catch (IOException e) {\n            throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Error during facet streaming close\", e);\n          }\n        }\n        return val;\n      }\n\n      @Override\n      public void remove() {\n        throw new UnsupportedOperationException();\n      }\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["82240bc1acbd51dd0fb06c0cbc5056991bba8d2e","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"82240bc1acbd51dd0fb06c0cbc5056991bba8d2e":["faf1236ae092482293a7e0659e347d172185ef6f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["82240bc1acbd51dd0fb06c0cbc5056991bba8d2e","79759974460bc59933cd169acc94f5c6b16368d5"],"79759974460bc59933cd169acc94f5c6b16368d5":["82240bc1acbd51dd0fb06c0cbc5056991bba8d2e"],"faf1236ae092482293a7e0659e347d172185ef6f":["ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["82240bc1acbd51dd0fb06c0cbc5056991bba8d2e","403d05f7f8d69b65659157eff1bc1d2717f04c66"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["403d05f7f8d69b65659157eff1bc1d2717f04c66"]},"commit2Childs":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"82240bc1acbd51dd0fb06c0cbc5056991bba8d2e":["403d05f7f8d69b65659157eff1bc1d2717f04c66","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6","79759974460bc59933cd169acc94f5c6b16368d5","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d"],"ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","faf1236ae092482293a7e0659e347d172185ef6f"],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"79759974460bc59933cd169acc94f5c6b16368d5":["2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"faf1236ae092482293a7e0659e347d172185ef6f":["82240bc1acbd51dd0fb06c0cbc5056991bba8d2e"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}