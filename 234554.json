{"path":"src/java/org/apache/lucene/analysis/de/WordlistLoader#getWordSet(File).mjava","commits":[{"id":"4230eef3a047e2a85e989e7ced62bf7fd4a9f859","date":1080661498,"type":0,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/de/WordlistLoader#getWordSet(File).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Loads a text file and adds every line as an entry to a HashSet (omitting\n   * leading and trailing whitespace). Every line of the file should contain only \n   * one word. The words need to be in lowercase if you make use of an\n   * Analyzer which uses LowerCaseFilter (like GermanAnalyzer).\n   * \n   * @param wordfile File containing the wordlist\n   * @return A HashSet with the file's words\n   */\n  public static HashSet getWordSet(File wordfile) throws IOException {\n    HashSet result = new HashSet();\n    FileReader freader = null;\n    LineNumberReader lnr = null;\n    try {\n      freader = new FileReader(wordfile);\n      lnr = new LineNumberReader(freader);\n      String word = null;\n      while ((word = lnr.readLine()) != null) {\n        result.add(word.trim());\n        }\n      }\n    finally {\n      if (lnr != null)\n        lnr.close();\n      if (freader != null)\n        freader.close();\n    }\n    return result;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d195ac4f5f0fd16249e88707973706feb1214df0","date":1080662088,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/de/WordlistLoader#getWordSet(File).mjava","pathOld":"src/java/org/apache/lucene/analysis/de/WordlistLoader#getWordSet(File).mjava","sourceNew":"  /**\n   * Loads a text file and adds every line as an entry to a HashSet (omitting\n   * leading and trailing whitespace). Every line of the file should contain only \n   * one word. The words need to be in lowercase if you make use of an\n   * Analyzer which uses LowerCaseFilter (like GermanAnalyzer).\n   * \n   * @param wordfile File containing the wordlist\n   * @return A HashSet with the file's words\n   */\n  public static HashSet getWordSet(File wordfile) throws IOException {\n    HashSet result = new HashSet();\n    FileReader freader = null;\n    LineNumberReader lnr = null;\n    try {\n      freader = new FileReader(wordfile);\n      lnr = new LineNumberReader(freader);\n      String word = null;\n      while ((word = lnr.readLine()) != null) {\n        result.add(word.trim());\n      }\n    }\n    finally {\n      if (lnr != null)\n        lnr.close();\n      if (freader != null)\n        freader.close();\n    }\n    return result;\n  }\n\n","sourceOld":"  /**\n   * Loads a text file and adds every line as an entry to a HashSet (omitting\n   * leading and trailing whitespace). Every line of the file should contain only \n   * one word. The words need to be in lowercase if you make use of an\n   * Analyzer which uses LowerCaseFilter (like GermanAnalyzer).\n   * \n   * @param wordfile File containing the wordlist\n   * @return A HashSet with the file's words\n   */\n  public static HashSet getWordSet(File wordfile) throws IOException {\n    HashSet result = new HashSet();\n    FileReader freader = null;\n    LineNumberReader lnr = null;\n    try {\n      freader = new FileReader(wordfile);\n      lnr = new LineNumberReader(freader);\n      String word = null;\n      while ((word = lnr.readLine()) != null) {\n        result.add(word.trim());\n        }\n      }\n    finally {\n      if (lnr != null)\n        lnr.close();\n      if (freader != null)\n        freader.close();\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eb502dc71e908fb2c30e64b73e1f7e7b6238f5a2","date":1092688309,"type":4,"author":"Daniel Naber","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/analysis/de/WordlistLoader#getWordSet(File).mjava","sourceNew":null,"sourceOld":"  /**\n   * Loads a text file and adds every line as an entry to a HashSet (omitting\n   * leading and trailing whitespace). Every line of the file should contain only \n   * one word. The words need to be in lowercase if you make use of an\n   * Analyzer which uses LowerCaseFilter (like GermanAnalyzer).\n   * \n   * @param wordfile File containing the wordlist\n   * @return A HashSet with the file's words\n   */\n  public static HashSet getWordSet(File wordfile) throws IOException {\n    HashSet result = new HashSet();\n    FileReader freader = null;\n    LineNumberReader lnr = null;\n    try {\n      freader = new FileReader(wordfile);\n      lnr = new LineNumberReader(freader);\n      String word = null;\n      while ((word = lnr.readLine()) != null) {\n        result.add(word.trim());\n      }\n    }\n    finally {\n      if (lnr != null)\n        lnr.close();\n      if (freader != null)\n        freader.close();\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"266fc7afc9269ff0e59f58194b01d4b42784ba3a","date":1095708421,"type":0,"author":"Daniel Naber","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/de/WordlistLoader#getWordSet(File).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Loads a text file and adds every line as an entry to a HashSet (omitting\n   * leading and trailing whitespace). Every line of the file should contain only \n   * one word. The words need to be in lowercase if you make use of an\n   * Analyzer which uses LowerCaseFilter (like GermanAnalyzer).\n   * \n   * @param wordfile File containing the wordlist\n   * @return A HashSet with the file's words\n   */\n  public static HashSet getWordSet(File wordfile) throws IOException {\n    HashSet result = new HashSet();\n    FileReader freader = null;\n    LineNumberReader lnr = null;\n    try {\n      freader = new FileReader(wordfile);\n      lnr = new LineNumberReader(freader);\n      String word = null;\n      while ((word = lnr.readLine()) != null) {\n        result.add(word.trim());\n      }\n    }\n    finally {\n      if (lnr != null)\n        lnr.close();\n      if (freader != null)\n        freader.close();\n    }\n    return result;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c69e98ffd83f56083b99e5443ca713cd5783a2ae","date":1142955392,"type":4,"author":"Yonik Seeley","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/analysis/de/WordlistLoader#getWordSet(File).mjava","sourceNew":null,"sourceOld":"  /**\n   * Loads a text file and adds every line as an entry to a HashSet (omitting\n   * leading and trailing whitespace). Every line of the file should contain only \n   * one word. The words need to be in lowercase if you make use of an\n   * Analyzer which uses LowerCaseFilter (like GermanAnalyzer).\n   * \n   * @param wordfile File containing the wordlist\n   * @return A HashSet with the file's words\n   */\n  public static HashSet getWordSet(File wordfile) throws IOException {\n    HashSet result = new HashSet();\n    FileReader freader = null;\n    LineNumberReader lnr = null;\n    try {\n      freader = new FileReader(wordfile);\n      lnr = new LineNumberReader(freader);\n      String word = null;\n      while ((word = lnr.readLine()) != null) {\n        result.add(word.trim());\n      }\n    }\n    finally {\n      if (lnr != null)\n        lnr.close();\n      if (freader != null)\n        freader.close();\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"eb502dc71e908fb2c30e64b73e1f7e7b6238f5a2":["d195ac4f5f0fd16249e88707973706feb1214df0"],"4230eef3a047e2a85e989e7ced62bf7fd4a9f859":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c69e98ffd83f56083b99e5443ca713cd5783a2ae":["266fc7afc9269ff0e59f58194b01d4b42784ba3a"],"d195ac4f5f0fd16249e88707973706feb1214df0":["4230eef3a047e2a85e989e7ced62bf7fd4a9f859"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c69e98ffd83f56083b99e5443ca713cd5783a2ae"],"266fc7afc9269ff0e59f58194b01d4b42784ba3a":["eb502dc71e908fb2c30e64b73e1f7e7b6238f5a2"]},"commit2Childs":{"eb502dc71e908fb2c30e64b73e1f7e7b6238f5a2":["266fc7afc9269ff0e59f58194b01d4b42784ba3a"],"4230eef3a047e2a85e989e7ced62bf7fd4a9f859":["d195ac4f5f0fd16249e88707973706feb1214df0"],"c69e98ffd83f56083b99e5443ca713cd5783a2ae":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d195ac4f5f0fd16249e88707973706feb1214df0":["eb502dc71e908fb2c30e64b73e1f7e7b6238f5a2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4230eef3a047e2a85e989e7ced62bf7fd4a9f859"],"266fc7afc9269ff0e59f58194b01d4b42784ba3a":["c69e98ffd83f56083b99e5443ca713cd5783a2ae"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}