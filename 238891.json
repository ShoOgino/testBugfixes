{"path":"solr/src/java/org/apache/solr/search/SortedIntDocSet#intersectionSize(int[],int[]).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SortedIntDocSet#intersectionSize(int[],int[]).mjava","pathOld":"/dev/null","sourceNew":"  public static int intersectionSize(int[] smallerSortedList, int[] biggerSortedList) {\n    final int a[] = smallerSortedList;\n    final int b[] = biggerSortedList;\n\n    // The next doc we are looking for will be much closer to the last position we tried\n    // than it will be to the midpoint between last and high... so probe ahead using\n    // a function of the ratio of the sizes of the sets.\n    int step = (b.length/a.length)+1;\n\n    // Since the majority of probes should be misses, we'll already be above the last probe\n    // and shouldn't need to move larger than the step size on average to step over our target (and thus lower\n    // the high upper bound a lot.)... but if we don't go over our target, it's a big miss... so double it.\n    step = step + step;\n\n    // FUTURE: come up with a density such that target * density == likely position?\n    // then check step on one side or the other?\n    // (density could be cached in the DocSet)... length/maxDoc\n\n    // FUTURE: try partitioning like a sort algorithm.  Pick the midpoint of the big\n    // array, find where that should be in the small array, and then recurse with\n    // the top and bottom half of both arrays until they are small enough to use\n    // a fallback insersection method.\n    // NOTE: I tried this and it worked, but it was actually slower than this current\n    // highly optimized approach.\n\n    int icount = 0;\n    int low = 0;\n    int max = b.length-1;\n\n    for (int i=0; i<a.length; i++) {\n      int doca = a[i];\n\n      int high = max;\n\n      int probe = low + step;     // 40% improvement!\n\n      // short linear probe to see if we can drop the high pointer in one big jump.\n      if (probe<high) {\n        if (b[probe]>=doca) {\n          // success!  we cut down the upper bound by a lot in one step!\n          high=probe;\n        } else {\n          // relative failure... we get to move the low pointer, but not my much\n          low=probe+1;\n\n          // reprobe worth it? it appears so!\n          probe = low + step;\n          if (probe<high) {\n            if (b[probe]>=doca) {\n              high=probe;\n            } else {\n              low=probe+1;\n            }\n          }\n        }\n      }\n\n      // binary search the rest of the way\n      while (low <= high) {\n        int mid = (low+high) >>> 1;\n        int docb = b[mid];\n\n        if (docb < doca) {\n          low = mid+1;\n        }\n        else if (docb > doca) {\n          high = mid-1;\n        }\n        else {\n          icount++;\n          low = mid+1;  // found it, so start at next element\n          break;\n        }\n      }\n      // Didn't find it... low is now positioned on the insertion point,\n      // which is higher than what we were looking for, so continue using\n      // the same low point.\n    }\n\n    return icount;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/search/SortedIntDocSet#intersectionSize(int[],int[]).mjava","sourceNew":null,"sourceOld":"  public static int intersectionSize(int[] smallerSortedList, int[] biggerSortedList) {\n    final int a[] = smallerSortedList;\n    final int b[] = biggerSortedList;\n\n    // The next doc we are looking for will be much closer to the last position we tried\n    // than it will be to the midpoint between last and high... so probe ahead using\n    // a function of the ratio of the sizes of the sets.\n    int step = (b.length/a.length)+1;\n\n    // Since the majority of probes should be misses, we'll already be above the last probe\n    // and shouldn't need to move larger than the step size on average to step over our target (and thus lower\n    // the high upper bound a lot.)... but if we don't go over our target, it's a big miss... so double it.\n    step = step + step;\n\n    // FUTURE: come up with a density such that target * density == likely position?\n    // then check step on one side or the other?\n    // (density could be cached in the DocSet)... length/maxDoc\n\n    // FUTURE: try partitioning like a sort algorithm.  Pick the midpoint of the big\n    // array, find where that should be in the small array, and then recurse with\n    // the top and bottom half of both arrays until they are small enough to use\n    // a fallback insersection method.\n    // NOTE: I tried this and it worked, but it was actually slower than this current\n    // highly optimized approach.\n\n    int icount = 0;\n    int low = 0;\n    int max = b.length-1;\n\n    for (int i=0; i<a.length; i++) {\n      int doca = a[i];\n\n      int high = max;\n\n      int probe = low + step;     // 40% improvement!\n\n      // short linear probe to see if we can drop the high pointer in one big jump.\n      if (probe<high) {\n        if (b[probe]>=doca) {\n          // success!  we cut down the upper bound by a lot in one step!\n          high=probe;\n        } else {\n          // relative failure... we get to move the low pointer, but not my much\n          low=probe+1;\n\n          // reprobe worth it? it appears so!\n          probe = low + step;\n          if (probe<high) {\n            if (b[probe]>=doca) {\n              high=probe;\n            } else {\n              low=probe+1;\n            }\n          }\n        }\n      }\n\n      // binary search the rest of the way\n      while (low <= high) {\n        int mid = (low+high) >>> 1;\n        int docb = b[mid];\n\n        if (docb < doca) {\n          low = mid+1;\n        }\n        else if (docb > doca) {\n          high = mid-1;\n        }\n        else {\n          icount++;\n          low = mid+1;  // found it, so start at next element\n          break;\n        }\n      }\n      // Didn't find it... low is now positioned on the insertion point,\n      // which is higher than what we were looking for, so continue using\n      // the same low point.\n    }\n\n    return icount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SortedIntDocSet#intersectionSize(int[],int[]).mjava","pathOld":"src/java/org/apache/solr/search/SortedIntDocSet#intersectionSize(int[],int[]).mjava","sourceNew":"  public static int intersectionSize(int[] smallerSortedList, int[] biggerSortedList) {\n    final int a[] = smallerSortedList;\n    final int b[] = biggerSortedList;\n\n    // The next doc we are looking for will be much closer to the last position we tried\n    // than it will be to the midpoint between last and high... so probe ahead using\n    // a function of the ratio of the sizes of the sets.\n    int step = (b.length/a.length)+1;\n\n    // Since the majority of probes should be misses, we'll already be above the last probe\n    // and shouldn't need to move larger than the step size on average to step over our target (and thus lower\n    // the high upper bound a lot.)... but if we don't go over our target, it's a big miss... so double it.\n    step = step + step;\n\n    // FUTURE: come up with a density such that target * density == likely position?\n    // then check step on one side or the other?\n    // (density could be cached in the DocSet)... length/maxDoc\n\n    // FUTURE: try partitioning like a sort algorithm.  Pick the midpoint of the big\n    // array, find where that should be in the small array, and then recurse with\n    // the top and bottom half of both arrays until they are small enough to use\n    // a fallback insersection method.\n    // NOTE: I tried this and it worked, but it was actually slower than this current\n    // highly optimized approach.\n\n    int icount = 0;\n    int low = 0;\n    int max = b.length-1;\n\n    for (int i=0; i<a.length; i++) {\n      int doca = a[i];\n\n      int high = max;\n\n      int probe = low + step;     // 40% improvement!\n\n      // short linear probe to see if we can drop the high pointer in one big jump.\n      if (probe<high) {\n        if (b[probe]>=doca) {\n          // success!  we cut down the upper bound by a lot in one step!\n          high=probe;\n        } else {\n          // relative failure... we get to move the low pointer, but not my much\n          low=probe+1;\n\n          // reprobe worth it? it appears so!\n          probe = low + step;\n          if (probe<high) {\n            if (b[probe]>=doca) {\n              high=probe;\n            } else {\n              low=probe+1;\n            }\n          }\n        }\n      }\n\n      // binary search the rest of the way\n      while (low <= high) {\n        int mid = (low+high) >>> 1;\n        int docb = b[mid];\n\n        if (docb < doca) {\n          low = mid+1;\n        }\n        else if (docb > doca) {\n          high = mid-1;\n        }\n        else {\n          icount++;\n          low = mid+1;  // found it, so start at next element\n          break;\n        }\n      }\n      // Didn't find it... low is now positioned on the insertion point,\n      // which is higher than what we were looking for, so continue using\n      // the same low point.\n    }\n\n    return icount;\n  }\n\n","sourceOld":"  public static int intersectionSize(int[] smallerSortedList, int[] biggerSortedList) {\n    final int a[] = smallerSortedList;\n    final int b[] = biggerSortedList;\n\n    // The next doc we are looking for will be much closer to the last position we tried\n    // than it will be to the midpoint between last and high... so probe ahead using\n    // a function of the ratio of the sizes of the sets.\n    int step = (b.length/a.length)+1;\n\n    // Since the majority of probes should be misses, we'll already be above the last probe\n    // and shouldn't need to move larger than the step size on average to step over our target (and thus lower\n    // the high upper bound a lot.)... but if we don't go over our target, it's a big miss... so double it.\n    step = step + step;\n\n    // FUTURE: come up with a density such that target * density == likely position?\n    // then check step on one side or the other?\n    // (density could be cached in the DocSet)... length/maxDoc\n\n    // FUTURE: try partitioning like a sort algorithm.  Pick the midpoint of the big\n    // array, find where that should be in the small array, and then recurse with\n    // the top and bottom half of both arrays until they are small enough to use\n    // a fallback insersection method.\n    // NOTE: I tried this and it worked, but it was actually slower than this current\n    // highly optimized approach.\n\n    int icount = 0;\n    int low = 0;\n    int max = b.length-1;\n\n    for (int i=0; i<a.length; i++) {\n      int doca = a[i];\n\n      int high = max;\n\n      int probe = low + step;     // 40% improvement!\n\n      // short linear probe to see if we can drop the high pointer in one big jump.\n      if (probe<high) {\n        if (b[probe]>=doca) {\n          // success!  we cut down the upper bound by a lot in one step!\n          high=probe;\n        } else {\n          // relative failure... we get to move the low pointer, but not my much\n          low=probe+1;\n\n          // reprobe worth it? it appears so!\n          probe = low + step;\n          if (probe<high) {\n            if (b[probe]>=doca) {\n              high=probe;\n            } else {\n              low=probe+1;\n            }\n          }\n        }\n      }\n\n      // binary search the rest of the way\n      while (low <= high) {\n        int mid = (low+high) >>> 1;\n        int docb = b[mid];\n\n        if (docb < doca) {\n          low = mid+1;\n        }\n        else if (docb > doca) {\n          high = mid-1;\n        }\n        else {\n          icount++;\n          low = mid+1;  // found it, so start at next element\n          break;\n        }\n      }\n      // Didn't find it... low is now positioned on the insertion point,\n      // which is higher than what we were looking for, so continue using\n      // the same low point.\n    }\n\n    return icount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/search/SortedIntDocSet#intersectionSize(int[],int[]).mjava","pathOld":"/dev/null","sourceNew":"  public static int intersectionSize(int[] smallerSortedList, int[] biggerSortedList) {\n    final int a[] = smallerSortedList;\n    final int b[] = biggerSortedList;\n\n    // The next doc we are looking for will be much closer to the last position we tried\n    // than it will be to the midpoint between last and high... so probe ahead using\n    // a function of the ratio of the sizes of the sets.\n    int step = (b.length/a.length)+1;\n\n    // Since the majority of probes should be misses, we'll already be above the last probe\n    // and shouldn't need to move larger than the step size on average to step over our target (and thus lower\n    // the high upper bound a lot.)... but if we don't go over our target, it's a big miss... so double it.\n    step = step + step;\n\n    // FUTURE: come up with a density such that target * density == likely position?\n    // then check step on one side or the other?\n    // (density could be cached in the DocSet)... length/maxDoc\n\n    // FUTURE: try partitioning like a sort algorithm.  Pick the midpoint of the big\n    // array, find where that should be in the small array, and then recurse with\n    // the top and bottom half of both arrays until they are small enough to use\n    // a fallback insersection method.\n    // NOTE: I tried this and it worked, but it was actually slower than this current\n    // highly optimized approach.\n\n    int icount = 0;\n    int low = 0;\n    int max = b.length-1;\n\n    for (int i=0; i<a.length; i++) {\n      int doca = a[i];\n\n      int high = max;\n\n      int probe = low + step;     // 40% improvement!\n\n      // short linear probe to see if we can drop the high pointer in one big jump.\n      if (probe<high) {\n        if (b[probe]>=doca) {\n          // success!  we cut down the upper bound by a lot in one step!\n          high=probe;\n        } else {\n          // relative failure... we get to move the low pointer, but not my much\n          low=probe+1;\n\n          // reprobe worth it? it appears so!\n          probe = low + step;\n          if (probe<high) {\n            if (b[probe]>=doca) {\n              high=probe;\n            } else {\n              low=probe+1;\n            }\n          }\n        }\n      }\n\n      // binary search the rest of the way\n      while (low <= high) {\n        int mid = (low+high) >>> 1;\n        int docb = b[mid];\n\n        if (docb < doca) {\n          low = mid+1;\n        }\n        else if (docb > doca) {\n          high = mid-1;\n        }\n        else {\n          icount++;\n          low = mid+1;  // found it, so start at next element\n          break;\n        }\n      }\n      // Didn't find it... low is now positioned on the insertion point,\n      // which is higher than what we were looking for, so continue using\n      // the same low point.\n    }\n\n    return icount;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SortedIntDocSet#intersectionSize(int[],int[]).mjava","pathOld":"solr/src/java/org/apache/solr/search/SortedIntDocSet#intersectionSize(int[],int[]).mjava","sourceNew":"  public static int intersectionSize(int[] smallerSortedList, int[] biggerSortedList) {\n    final int a[] = smallerSortedList;\n    final int b[] = biggerSortedList;\n\n    // The next doc we are looking for will be much closer to the last position we tried\n    // than it will be to the midpoint between last and high... so probe ahead using\n    // a function of the ratio of the sizes of the sets.\n    int step = (b.length/a.length)+1;\n\n    // Since the majority of probes should be misses, we'll already be above the last probe\n    // and shouldn't need to move larger than the step size on average to step over our target (and thus lower\n    // the high upper bound a lot.)... but if we don't go over our target, it's a big miss... so double it.\n    step = step + step;\n\n    // FUTURE: come up with a density such that target * density == likely position?\n    // then check step on one side or the other?\n    // (density could be cached in the DocSet)... length/maxDoc\n\n    // FUTURE: try partitioning like a sort algorithm.  Pick the midpoint of the big\n    // array, find where that should be in the small array, and then recurse with\n    // the top and bottom half of both arrays until they are small enough to use\n    // a fallback insersection method.\n    // NOTE: I tried this and it worked, but it was actually slower than this current\n    // highly optimized approach.\n\n    int icount = 0;\n    int low = 0;\n    int max = b.length-1;\n\n    for (int i=0; i<a.length; i++) {\n      int doca = a[i];\n\n      int high = max;\n\n      int probe = low + step;     // 40% improvement!\n\n      // short linear probe to see if we can drop the high pointer in one big jump.\n      if (probe<high) {\n        if (b[probe]>=doca) {\n          // success!  we cut down the upper bound by a lot in one step!\n          high=probe;\n        } else {\n          // relative failure... we get to move the low pointer, but not my much\n          low=probe+1;\n\n          // reprobe worth it? it appears so!\n          probe = low + step;\n          if (probe<high) {\n            if (b[probe]>=doca) {\n              high=probe;\n            } else {\n              low=probe+1;\n            }\n          }\n        }\n      }\n\n      // binary search the rest of the way\n      while (low <= high) {\n        int mid = (low+high) >>> 1;\n        int docb = b[mid];\n\n        if (docb < doca) {\n          low = mid+1;\n        }\n        else if (docb > doca) {\n          high = mid-1;\n        }\n        else {\n          icount++;\n          low = mid+1;  // found it, so start at next element\n          break;\n        }\n      }\n      // Didn't find it... low is now positioned on the insertion point,\n      // which is higher than what we were looking for, so continue using\n      // the same low point.\n    }\n\n    return icount;\n  }\n\n","sourceOld":"  public static int intersectionSize(int[] smallerSortedList, int[] biggerSortedList) {\n    final int a[] = smallerSortedList;\n    final int b[] = biggerSortedList;\n\n    // The next doc we are looking for will be much closer to the last position we tried\n    // than it will be to the midpoint between last and high... so probe ahead using\n    // a function of the ratio of the sizes of the sets.\n    int step = (b.length/a.length)+1;\n\n    // Since the majority of probes should be misses, we'll already be above the last probe\n    // and shouldn't need to move larger than the step size on average to step over our target (and thus lower\n    // the high upper bound a lot.)... but if we don't go over our target, it's a big miss... so double it.\n    step = step + step;\n\n    // FUTURE: come up with a density such that target * density == likely position?\n    // then check step on one side or the other?\n    // (density could be cached in the DocSet)... length/maxDoc\n\n    // FUTURE: try partitioning like a sort algorithm.  Pick the midpoint of the big\n    // array, find where that should be in the small array, and then recurse with\n    // the top and bottom half of both arrays until they are small enough to use\n    // a fallback insersection method.\n    // NOTE: I tried this and it worked, but it was actually slower than this current\n    // highly optimized approach.\n\n    int icount = 0;\n    int low = 0;\n    int max = b.length-1;\n\n    for (int i=0; i<a.length; i++) {\n      int doca = a[i];\n\n      int high = max;\n\n      int probe = low + step;     // 40% improvement!\n\n      // short linear probe to see if we can drop the high pointer in one big jump.\n      if (probe<high) {\n        if (b[probe]>=doca) {\n          // success!  we cut down the upper bound by a lot in one step!\n          high=probe;\n        } else {\n          // relative failure... we get to move the low pointer, but not my much\n          low=probe+1;\n\n          // reprobe worth it? it appears so!\n          probe = low + step;\n          if (probe<high) {\n            if (b[probe]>=doca) {\n              high=probe;\n            } else {\n              low=probe+1;\n            }\n          }\n        }\n      }\n\n      // binary search the rest of the way\n      while (low <= high) {\n        int mid = (low+high) >>> 1;\n        int docb = b[mid];\n\n        if (docb < doca) {\n          low = mid+1;\n        }\n        else if (docb > doca) {\n          high = mid-1;\n        }\n        else {\n          icount++;\n          low = mid+1;  // found it, so start at next element\n          break;\n        }\n      }\n      // Didn't find it... low is now positioned on the insertion point,\n      // which is higher than what we were looking for, so continue using\n      // the same low point.\n    }\n\n    return icount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SortedIntDocSet#intersectionSize(int[],int[]).mjava","pathOld":"solr/src/java/org/apache/solr/search/SortedIntDocSet#intersectionSize(int[],int[]).mjava","sourceNew":"  public static int intersectionSize(int[] smallerSortedList, int[] biggerSortedList) {\n    final int a[] = smallerSortedList;\n    final int b[] = biggerSortedList;\n\n    // The next doc we are looking for will be much closer to the last position we tried\n    // than it will be to the midpoint between last and high... so probe ahead using\n    // a function of the ratio of the sizes of the sets.\n    int step = (b.length/a.length)+1;\n\n    // Since the majority of probes should be misses, we'll already be above the last probe\n    // and shouldn't need to move larger than the step size on average to step over our target (and thus lower\n    // the high upper bound a lot.)... but if we don't go over our target, it's a big miss... so double it.\n    step = step + step;\n\n    // FUTURE: come up with a density such that target * density == likely position?\n    // then check step on one side or the other?\n    // (density could be cached in the DocSet)... length/maxDoc\n\n    // FUTURE: try partitioning like a sort algorithm.  Pick the midpoint of the big\n    // array, find where that should be in the small array, and then recurse with\n    // the top and bottom half of both arrays until they are small enough to use\n    // a fallback insersection method.\n    // NOTE: I tried this and it worked, but it was actually slower than this current\n    // highly optimized approach.\n\n    int icount = 0;\n    int low = 0;\n    int max = b.length-1;\n\n    for (int i=0; i<a.length; i++) {\n      int doca = a[i];\n\n      int high = max;\n\n      int probe = low + step;     // 40% improvement!\n\n      // short linear probe to see if we can drop the high pointer in one big jump.\n      if (probe<high) {\n        if (b[probe]>=doca) {\n          // success!  we cut down the upper bound by a lot in one step!\n          high=probe;\n        } else {\n          // relative failure... we get to move the low pointer, but not my much\n          low=probe+1;\n\n          // reprobe worth it? it appears so!\n          probe = low + step;\n          if (probe<high) {\n            if (b[probe]>=doca) {\n              high=probe;\n            } else {\n              low=probe+1;\n            }\n          }\n        }\n      }\n\n      // binary search the rest of the way\n      while (low <= high) {\n        int mid = (low+high) >>> 1;\n        int docb = b[mid];\n\n        if (docb < doca) {\n          low = mid+1;\n        }\n        else if (docb > doca) {\n          high = mid-1;\n        }\n        else {\n          icount++;\n          low = mid+1;  // found it, so start at next element\n          break;\n        }\n      }\n      // Didn't find it... low is now positioned on the insertion point,\n      // which is higher than what we were looking for, so continue using\n      // the same low point.\n    }\n\n    return icount;\n  }\n\n","sourceOld":"  public static int intersectionSize(int[] smallerSortedList, int[] biggerSortedList) {\n    final int a[] = smallerSortedList;\n    final int b[] = biggerSortedList;\n\n    // The next doc we are looking for will be much closer to the last position we tried\n    // than it will be to the midpoint between last and high... so probe ahead using\n    // a function of the ratio of the sizes of the sets.\n    int step = (b.length/a.length)+1;\n\n    // Since the majority of probes should be misses, we'll already be above the last probe\n    // and shouldn't need to move larger than the step size on average to step over our target (and thus lower\n    // the high upper bound a lot.)... but if we don't go over our target, it's a big miss... so double it.\n    step = step + step;\n\n    // FUTURE: come up with a density such that target * density == likely position?\n    // then check step on one side or the other?\n    // (density could be cached in the DocSet)... length/maxDoc\n\n    // FUTURE: try partitioning like a sort algorithm.  Pick the midpoint of the big\n    // array, find where that should be in the small array, and then recurse with\n    // the top and bottom half of both arrays until they are small enough to use\n    // a fallback insersection method.\n    // NOTE: I tried this and it worked, but it was actually slower than this current\n    // highly optimized approach.\n\n    int icount = 0;\n    int low = 0;\n    int max = b.length-1;\n\n    for (int i=0; i<a.length; i++) {\n      int doca = a[i];\n\n      int high = max;\n\n      int probe = low + step;     // 40% improvement!\n\n      // short linear probe to see if we can drop the high pointer in one big jump.\n      if (probe<high) {\n        if (b[probe]>=doca) {\n          // success!  we cut down the upper bound by a lot in one step!\n          high=probe;\n        } else {\n          // relative failure... we get to move the low pointer, but not my much\n          low=probe+1;\n\n          // reprobe worth it? it appears so!\n          probe = low + step;\n          if (probe<high) {\n            if (b[probe]>=doca) {\n              high=probe;\n            } else {\n              low=probe+1;\n            }\n          }\n        }\n      }\n\n      // binary search the rest of the way\n      while (low <= high) {\n        int mid = (low+high) >>> 1;\n        int docb = b[mid];\n\n        if (docb < doca) {\n          low = mid+1;\n        }\n        else if (docb > doca) {\n          high = mid-1;\n        }\n        else {\n          icount++;\n          low = mid+1;  // found it, so start at next element\n          break;\n        }\n      }\n      // Didn't find it... low is now positioned on the insertion point,\n      // which is higher than what we were looking for, so continue using\n      // the same low point.\n    }\n\n    return icount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SortedIntDocSet#intersectionSize(int[],int[]).mjava","pathOld":"solr/src/java/org/apache/solr/search/SortedIntDocSet#intersectionSize(int[],int[]).mjava","sourceNew":"  public static int intersectionSize(int[] smallerSortedList, int[] biggerSortedList) {\n    final int a[] = smallerSortedList;\n    final int b[] = biggerSortedList;\n\n    // The next doc we are looking for will be much closer to the last position we tried\n    // than it will be to the midpoint between last and high... so probe ahead using\n    // a function of the ratio of the sizes of the sets.\n    int step = (b.length/a.length)+1;\n\n    // Since the majority of probes should be misses, we'll already be above the last probe\n    // and shouldn't need to move larger than the step size on average to step over our target (and thus lower\n    // the high upper bound a lot.)... but if we don't go over our target, it's a big miss... so double it.\n    step = step + step;\n\n    // FUTURE: come up with a density such that target * density == likely position?\n    // then check step on one side or the other?\n    // (density could be cached in the DocSet)... length/maxDoc\n\n    // FUTURE: try partitioning like a sort algorithm.  Pick the midpoint of the big\n    // array, find where that should be in the small array, and then recurse with\n    // the top and bottom half of both arrays until they are small enough to use\n    // a fallback insersection method.\n    // NOTE: I tried this and it worked, but it was actually slower than this current\n    // highly optimized approach.\n\n    int icount = 0;\n    int low = 0;\n    int max = b.length-1;\n\n    for (int i=0; i<a.length; i++) {\n      int doca = a[i];\n\n      int high = max;\n\n      int probe = low + step;     // 40% improvement!\n\n      // short linear probe to see if we can drop the high pointer in one big jump.\n      if (probe<high) {\n        if (b[probe]>=doca) {\n          // success!  we cut down the upper bound by a lot in one step!\n          high=probe;\n        } else {\n          // relative failure... we get to move the low pointer, but not my much\n          low=probe+1;\n\n          // reprobe worth it? it appears so!\n          probe = low + step;\n          if (probe<high) {\n            if (b[probe]>=doca) {\n              high=probe;\n            } else {\n              low=probe+1;\n            }\n          }\n        }\n      }\n\n      // binary search the rest of the way\n      while (low <= high) {\n        int mid = (low+high) >>> 1;\n        int docb = b[mid];\n\n        if (docb < doca) {\n          low = mid+1;\n        }\n        else if (docb > doca) {\n          high = mid-1;\n        }\n        else {\n          icount++;\n          low = mid+1;  // found it, so start at next element\n          break;\n        }\n      }\n      // Didn't find it... low is now positioned on the insertion point,\n      // which is higher than what we were looking for, so continue using\n      // the same low point.\n    }\n\n    return icount;\n  }\n\n","sourceOld":"  public static int intersectionSize(int[] smallerSortedList, int[] biggerSortedList) {\n    final int a[] = smallerSortedList;\n    final int b[] = biggerSortedList;\n\n    // The next doc we are looking for will be much closer to the last position we tried\n    // than it will be to the midpoint between last and high... so probe ahead using\n    // a function of the ratio of the sizes of the sets.\n    int step = (b.length/a.length)+1;\n\n    // Since the majority of probes should be misses, we'll already be above the last probe\n    // and shouldn't need to move larger than the step size on average to step over our target (and thus lower\n    // the high upper bound a lot.)... but if we don't go over our target, it's a big miss... so double it.\n    step = step + step;\n\n    // FUTURE: come up with a density such that target * density == likely position?\n    // then check step on one side or the other?\n    // (density could be cached in the DocSet)... length/maxDoc\n\n    // FUTURE: try partitioning like a sort algorithm.  Pick the midpoint of the big\n    // array, find where that should be in the small array, and then recurse with\n    // the top and bottom half of both arrays until they are small enough to use\n    // a fallback insersection method.\n    // NOTE: I tried this and it worked, but it was actually slower than this current\n    // highly optimized approach.\n\n    int icount = 0;\n    int low = 0;\n    int max = b.length-1;\n\n    for (int i=0; i<a.length; i++) {\n      int doca = a[i];\n\n      int high = max;\n\n      int probe = low + step;     // 40% improvement!\n\n      // short linear probe to see if we can drop the high pointer in one big jump.\n      if (probe<high) {\n        if (b[probe]>=doca) {\n          // success!  we cut down the upper bound by a lot in one step!\n          high=probe;\n        } else {\n          // relative failure... we get to move the low pointer, but not my much\n          low=probe+1;\n\n          // reprobe worth it? it appears so!\n          probe = low + step;\n          if (probe<high) {\n            if (b[probe]>=doca) {\n              high=probe;\n            } else {\n              low=probe+1;\n            }\n          }\n        }\n      }\n\n      // binary search the rest of the way\n      while (low <= high) {\n        int mid = (low+high) >>> 1;\n        int docb = b[mid];\n\n        if (docb < doca) {\n          low = mid+1;\n        }\n        else if (docb > doca) {\n          high = mid-1;\n        }\n        else {\n          icount++;\n          low = mid+1;  // found it, so start at next element\n          break;\n        }\n      }\n      // Didn't find it... low is now positioned on the insertion point,\n      // which is higher than what we were looking for, so continue using\n      // the same low point.\n    }\n\n    return icount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["1da8d55113b689b06716246649de6f62430f15c0"],"c26f00b574427b55127e869b935845554afde1fa":["1da8d55113b689b06716246649de6f62430f15c0","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["1da8d55113b689b06716246649de6f62430f15c0"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"1da8d55113b689b06716246649de6f62430f15c0":["c903c3d15906a3da96b8c0c2fb704491005fdbdb","c26f00b574427b55127e869b935845554afde1fa","a258fbb26824fd104ed795e5d9033d2d040049ee"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}