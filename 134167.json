{"path":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","pathOld":"modules/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","sourceNew":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    QueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<String>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      Document doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","sourceOld":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    QueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<String>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      Document doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a7e4907084808af8fdb14b9809e6dceaccf6867b","date":1343473006,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","sourceNew":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    QueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<String>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      StoredDocument doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","sourceOld":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    QueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<String>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      Document doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","sourceNew":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    QueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<String>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      StoredDocument doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","sourceOld":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    QueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<String>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      Document doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","sourceNew":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    QueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      StoredDocument doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","sourceOld":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    QueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<String>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      StoredDocument doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","bugFix":null,"bugIntro":["de299b6017d29ce89b72c3ef9cfb99ca50d433cf"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e2eb9920ac302f8d2a4cd14e42eba6935f84fe0d","date":1394988844,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","sourceNew":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    ComplexPhraseQueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setInOrder(inOrder);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      StoredDocument doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","sourceOld":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    QueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      StoredDocument doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","bugFix":["a9ac13b5f0ce5ef1b2ce168367d993a79594b23a"],"bugIntro":["de299b6017d29ce89b72c3ef9cfb99ca50d433cf"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ff4227bb146f97aabae888091c19e48c88dbb0db","date":1406758576,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","sourceNew":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    ComplexPhraseQueryParser qp = new ComplexPhraseQueryParser(defaultFieldName, analyzer);\n    qp.setInOrder(inOrder);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      StoredDocument doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","sourceOld":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    ComplexPhraseQueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setInOrder(inOrder);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      StoredDocument doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cdab62f058ea765dd33deb05b4f19b7d626c801","date":1406803479,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","sourceNew":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    ComplexPhraseQueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setInOrder(inOrder);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      StoredDocument doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","sourceOld":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    ComplexPhraseQueryParser qp = new ComplexPhraseQueryParser(defaultFieldName, analyzer);\n    qp.setInOrder(inOrder);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      StoredDocument doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"379db3ad24c4f0214f30a122265a6d6be003a99d","date":1407537768,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","sourceNew":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    ComplexPhraseQueryParser qp = new ComplexPhraseQueryParser(defaultFieldName, analyzer);\n    qp.setInOrder(inOrder);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      StoredDocument doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","sourceOld":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    ComplexPhraseQueryParser qp = new ComplexPhraseQueryParser(TEST_VERSION_CURRENT, defaultFieldName, analyzer);\n    qp.setInOrder(inOrder);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      StoredDocument doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","bugFix":null,"bugIntro":["de299b6017d29ce89b72c3ef9cfb99ca50d433cf"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","sourceNew":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    ComplexPhraseQueryParser qp = new ComplexPhraseQueryParser(defaultFieldName, analyzer);\n    qp.setInOrder(inOrder);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      Document doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","sourceOld":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    ComplexPhraseQueryParser qp = new ComplexPhraseQueryParser(defaultFieldName, analyzer);\n    qp.setInOrder(inOrder);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      StoredDocument doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","bugFix":null,"bugIntro":["de299b6017d29ce89b72c3ef9cfb99ca50d433cf"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"de299b6017d29ce89b72c3ef9cfb99ca50d433cf","date":1488961235,"type":3,"author":"Mikhail Khludnev","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/complexPhrase/TestComplexPhraseQuery#checkMatches(String,String).mjava","sourceNew":"  private void checkMatches(String qString, String expectedVals)\n  throws Exception {\n    checkMatches(qString, expectedVals, analyzer);\n  }\n\n","sourceOld":"  private void checkMatches(String qString, String expectedVals)\n      throws Exception {\n    ComplexPhraseQueryParser qp = new ComplexPhraseQueryParser(defaultFieldName, analyzer);\n    qp.setInOrder(inOrder);\n    qp.setFuzzyPrefixLength(1); // usually a good idea\n\n    Query q = qp.parse(qString);\n\n    HashSet<String> expecteds = new HashSet<>();\n    String[] vals = expectedVals.split(\",\");\n    for (int i = 0; i < vals.length; i++) {\n      if (vals[i].length() > 0)\n        expecteds.add(vals[i]);\n    }\n\n    TopDocs td = searcher.search(q, 10);\n    ScoreDoc[] sd = td.scoreDocs;\n    for (int i = 0; i < sd.length; i++) {\n      Document doc = searcher.doc(sd[i].doc);\n      String id = doc.get(\"id\");\n      assertTrue(qString + \"matched doc#\" + id + \" not expected\", expecteds\n          .contains(id));\n      expecteds.remove(id);\n    }\n\n    assertEquals(qString + \" missing some matches \", 0, expecteds.size());\n\n  }\n\n","bugFix":["0107b7f49bcfde8f333685f53b37608815ca889b","634f330c54fd3f9f491d52036dc3f40b4f4d8934","379db3ad24c4f0214f30a122265a6d6be003a99d","6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","e2eb9920ac302f8d2a4cd14e42eba6935f84fe0d"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ff4227bb146f97aabae888091c19e48c88dbb0db":["e2eb9920ac302f8d2a4cd14e42eba6935f84fe0d"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["1d028314cced5858683a1bb4741423d0f934257b"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1d028314cced5858683a1bb4741423d0f934257b":["b89678825b68eccaf09e6ab71675fc0b0af1e099","a7e4907084808af8fdb14b9809e6dceaccf6867b"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e2eb9920ac302f8d2a4cd14e42eba6935f84fe0d":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"de299b6017d29ce89b72c3ef9cfb99ca50d433cf":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["ff4227bb146f97aabae888091c19e48c88dbb0db"],"a7e4907084808af8fdb14b9809e6dceaccf6867b":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["de299b6017d29ce89b72c3ef9cfb99ca50d433cf"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["379db3ad24c4f0214f30a122265a6d6be003a99d"]},"commit2Childs":{"ff4227bb146f97aabae888091c19e48c88dbb0db":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["e2eb9920ac302f8d2a4cd14e42eba6935f84fe0d"],"1d028314cced5858683a1bb4741423d0f934257b":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["1d028314cced5858683a1bb4741423d0f934257b","a7e4907084808af8fdb14b9809e6dceaccf6867b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"e2eb9920ac302f8d2a4cd14e42eba6935f84fe0d":["ff4227bb146f97aabae888091c19e48c88dbb0db"],"de299b6017d29ce89b72c3ef9cfb99ca50d433cf":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"a7e4907084808af8fdb14b9809e6dceaccf6867b":["1d028314cced5858683a1bb4741423d0f934257b"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["de299b6017d29ce89b72c3ef9cfb99ca50d433cf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}