{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","commits":[{"id":"0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793","date":1408030244,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","pathOld":"/dev/null","sourceNew":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6a3823714ed5de938fb4f3fc814824fe0f95e1a","date":1413422458,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","sourceNew":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","sourceOld":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6a3823714ed5de938fb4f3fc814824fe0f95e1a","date":1413422458,"type":6,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","sourceNew":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","sourceOld":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","sourceNew":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","sourceOld":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db68c63cbfaa8698b9c4475f75ed2b9c9696d238","date":1414118621,"type":6,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene410/Lucene410DocValuesConsumer#addReverseTermIndex(FieldInfo,Iterable[BytesRef],int).mjava","sourceNew":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","sourceOld":"  // writes reverse term index: used for binary searching a term into a range of 64 blocks\n  // for every 64 blocks (1024 terms) we store a term, trimming any suffix unnecessary for comparison\n  // terms are written as a contiguous byte[], but never spanning 2^15 byte boundaries.\n  private void addReverseTermIndex(FieldInfo field, final Iterable<BytesRef> values, int maxLength) throws IOException {\n    long count = 0;\n    BytesRefBuilder priorTerm = new BytesRefBuilder();\n    priorTerm.grow(maxLength);\n    BytesRef indexTerm = new BytesRef();\n    long startFP = data.getFilePointer();\n    PagedBytes pagedBytes = new PagedBytes(15);\n    MonotonicBlockPackedWriter addresses = new MonotonicBlockPackedWriter(data, BLOCK_SIZE);\n    \n    for (BytesRef b : values) {\n      int termPosition = (int) (count & REVERSE_INTERVAL_MASK);\n      if (termPosition == 0) {\n        int len = StringHelper.sortKeyLength(priorTerm.get(), b);\n        indexTerm.bytes = b.bytes;\n        indexTerm.offset = b.offset;\n        indexTerm.length = len;\n        addresses.add(pagedBytes.copyUsingLengthPrefix(indexTerm));\n      } else if (termPosition == REVERSE_INTERVAL_MASK) {\n        priorTerm.copyBytes(b);\n      }\n      count++;\n    }\n    addresses.finish();\n    long numBytes = pagedBytes.getPointer();\n    pagedBytes.freeze(true);\n    PagedBytesDataInput in = pagedBytes.getDataInput();\n    meta.writeLong(startFP);\n    data.writeVLong(numBytes);\n    data.copyBytes(in, numBytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793","d6a3823714ed5de938fb4f3fc814824fe0f95e1a"],"0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"d6a3823714ed5de938fb4f3fc814824fe0f95e1a":["0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793"],"db68c63cbfaa8698b9c4475f75ed2b9c9696d238":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0ce5e7f280a7b3f0f96f2623d9f0ce70f742b793":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238","d6a3823714ed5de938fb4f3fc814824fe0f95e1a"],"d6a3823714ed5de938fb4f3fc814824fe0f95e1a":["db68c63cbfaa8698b9c4475f75ed2b9c9696d238"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}