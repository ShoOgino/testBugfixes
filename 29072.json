{"path":"solr/core/src/test/org/apache/solr/core/CoreSorterTest#integrationTest().mjava","commits":[{"id":"919b9b89b8d44ea491f18a92e6d52efcf5f7a065","date":1585280660,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/core/CoreSorterTest#integrationTest().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void integrationTest() {\n    assumeWorkingMockito();\n\n    List<CountsForEachShard> perShardCounts = new ArrayList<>(inputCounts);\n    Collections.shuffle(perShardCounts, random());\n\n    // compute nodes, some live, some down\n    final int maxNodesOfAType = perShardCounts.stream() // not too important how many we have, but lets have plenty\n        .mapToInt(c -> c.totalReplicasInLiveNodes + c.totalReplicasInDownNodes + c.myReplicas).max().getAsInt();\n    List<String> liveNodes = IntStream.range(0, maxNodesOfAType).mapToObj(i -> \"192.168.0.\" + i + \"_8983\").collect(Collectors.toList());\n    Collections.shuffle(liveNodes, random());\n    String thisNode = liveNodes.get(0);\n    List<String> otherLiveNodes = liveNodes.subList(1, liveNodes.size());\n    List<String> downNodes = IntStream.range(0, maxNodesOfAType).mapToObj(i -> \"192.168.1.\" + i + \"_8983\").collect(Collectors.toList());\n\n    // divide into two collections\n    int numCol1 = random().nextInt(perShardCounts.size());\n    Map<String,List<CountsForEachShard>> collToCounts = new HashMap<>();\n    collToCounts.put(\"col1\", perShardCounts.subList(0, numCol1));\n    collToCounts.put(\"col2\", perShardCounts.subList(numCol1, perShardCounts.size()));\n\n    Map<String,DocCollection> collToState = new HashMap<>();\n    Map<CountsForEachShard, List<CoreDescriptor>> myCountsToDescs = new HashMap<>();\n    for (Map.Entry<String, List<CountsForEachShard>> entry : collToCounts.entrySet()) {\n      String collection = entry.getKey();\n      List<CountsForEachShard> collCounts = entry.getValue();\n      Map<String, Slice> sliceMap = new HashMap<>(collCounts.size());\n      for (CountsForEachShard shardCounts : collCounts) {\n        String slice = \"s\" + shardCounts.hashCode();\n        List<Replica> replicas = new ArrayList<>();\n        for (int myRepNum = 0; myRepNum < shardCounts.myReplicas; myRepNum++) {\n          addNewReplica(replicas, collection, slice, Collections.singletonList(thisNode));\n          // save this mapping for later\n          myCountsToDescs.put(shardCounts, replicas.stream().map(this::newCoreDescriptor).collect(Collectors.toList()));\n        }\n        for (int myRepNum = 0; myRepNum < shardCounts.totalReplicasInLiveNodes; myRepNum++) {\n          addNewReplica(replicas, collection, slice, otherLiveNodes);\n        }\n        for (int myRepNum = 0; myRepNum < shardCounts.totalReplicasInDownNodes; myRepNum++) {\n          addNewReplica(replicas, collection, slice, downNodes);\n        }\n        Map<String, Replica> replicaMap = replicas.stream().collect(Collectors.toMap(Replica::getName, Function.identity()));\n        sliceMap.put(slice, new Slice(slice, replicaMap, map(), collection));\n      }\n      DocCollection col = new DocCollection(collection, sliceMap, map(), DocRouter.DEFAULT);\n      collToState.put(collection, col);\n    }\n    // reverse map\n    Map<CoreDescriptor, CountsForEachShard> myDescsToCounts = new HashMap<>();\n    for (Map.Entry<CountsForEachShard, List<CoreDescriptor>> entry : myCountsToDescs.entrySet()) {\n      for (CoreDescriptor descriptor : entry.getValue()) {\n        CountsForEachShard prev = myDescsToCounts.put(descriptor, entry.getKey());\n        assert prev == null; // sanity check\n      }\n    }\n\n    assert myCountsToDescs.size() == perShardCounts.size(); // just a sanity check\n\n    CoreContainer mockCC = mock(CoreContainer.class);\n    {\n      when(mockCC.isZooKeeperAware()).thenReturn(true);\n\n      ZkController mockZKC = mock(ZkController.class);\n      when(mockCC.getZkController()).thenReturn(mockZKC);\n      {\n        ClusterState mockClusterState = mock(ClusterState.class);\n        when(mockZKC.getClusterState()).thenReturn(mockClusterState);\n        {\n          when(mockClusterState.getLiveNodes()).thenReturn(new HashSet<>(liveNodes));\n          for (Map.Entry<String, DocCollection> entry : collToState.entrySet()) {\n            when(mockClusterState.getCollectionOrNull(entry.getKey())).thenReturn(entry.getValue());\n          }\n        }\n      }\n\n      NodeConfig mockNodeConfig = mock(NodeConfig.class);\n      when(mockNodeConfig.getNodeName()).thenReturn(thisNode);\n      when(mockCC.getNodeConfig()).thenReturn(mockNodeConfig);\n\n    }\n\n    List<CoreDescriptor> myDescs = new ArrayList<>(myDescsToCounts.keySet());\n    for (int i = 0; i < 10; i++) {\n      Collections.shuffle(myDescs, random());\n\n      List<CoreDescriptor> resultDescs = CoreSorter.sortCores(mockCC, myDescs);\n      // map descriptors back to counts, removing consecutive duplicates\n      List<CountsForEachShard> resultCounts = new ArrayList<>();\n      CountsForEachShard lastCounts = null;\n      for (CoreDescriptor resultDesc : resultDescs) {\n        CountsForEachShard counts = myDescsToCounts.get(resultDesc);\n        if (counts != lastCounts) {\n          resultCounts.add(counts);\n        }\n        lastCounts = counts;\n      }\n      assertEquals(expectedCounts, resultCounts);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e98520789adb1d5ad05afb4956eca0944a929688","date":1592430701,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/core/CoreSorterTest#integrationTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/core/CoreSorterTest#integrationTest().mjava","sourceNew":"  @Test\n  @SuppressWarnings({\"unchecked\"})\n  public void integrationTest() {\n    assumeWorkingMockito();\n\n    List<CountsForEachShard> perShardCounts = new ArrayList<>(inputCounts);\n    Collections.shuffle(perShardCounts, random());\n\n    // compute nodes, some live, some down\n    final int maxNodesOfAType = perShardCounts.stream() // not too important how many we have, but lets have plenty\n        .mapToInt(c -> c.totalReplicasInLiveNodes + c.totalReplicasInDownNodes + c.myReplicas).max().getAsInt();\n    List<String> liveNodes = IntStream.range(0, maxNodesOfAType).mapToObj(i -> \"192.168.0.\" + i + \"_8983\").collect(Collectors.toList());\n    Collections.shuffle(liveNodes, random());\n    String thisNode = liveNodes.get(0);\n    List<String> otherLiveNodes = liveNodes.subList(1, liveNodes.size());\n    List<String> downNodes = IntStream.range(0, maxNodesOfAType).mapToObj(i -> \"192.168.1.\" + i + \"_8983\").collect(Collectors.toList());\n\n    // divide into two collections\n    int numCol1 = random().nextInt(perShardCounts.size());\n    Map<String,List<CountsForEachShard>> collToCounts = new HashMap<>();\n    collToCounts.put(\"col1\", perShardCounts.subList(0, numCol1));\n    collToCounts.put(\"col2\", perShardCounts.subList(numCol1, perShardCounts.size()));\n\n    Map<String,DocCollection> collToState = new HashMap<>();\n    Map<CountsForEachShard, List<CoreDescriptor>> myCountsToDescs = new HashMap<>();\n    for (Map.Entry<String, List<CountsForEachShard>> entry : collToCounts.entrySet()) {\n      String collection = entry.getKey();\n      List<CountsForEachShard> collCounts = entry.getValue();\n      Map<String, Slice> sliceMap = new HashMap<>(collCounts.size());\n      for (CountsForEachShard shardCounts : collCounts) {\n        String slice = \"s\" + shardCounts.hashCode();\n        List<Replica> replicas = new ArrayList<>();\n        for (int myRepNum = 0; myRepNum < shardCounts.myReplicas; myRepNum++) {\n          addNewReplica(replicas, collection, slice, Collections.singletonList(thisNode));\n          // save this mapping for later\n          myCountsToDescs.put(shardCounts, replicas.stream().map(this::newCoreDescriptor).collect(Collectors.toList()));\n        }\n        for (int myRepNum = 0; myRepNum < shardCounts.totalReplicasInLiveNodes; myRepNum++) {\n          addNewReplica(replicas, collection, slice, otherLiveNodes);\n        }\n        for (int myRepNum = 0; myRepNum < shardCounts.totalReplicasInDownNodes; myRepNum++) {\n          addNewReplica(replicas, collection, slice, downNodes);\n        }\n        Map<String, Replica> replicaMap = replicas.stream().collect(Collectors.toMap(Replica::getName, Function.identity()));\n        sliceMap.put(slice, new Slice(slice, replicaMap, map(), collection));\n      }\n      @SuppressWarnings({\"unchecked\"})\n      DocCollection col = new DocCollection(collection, sliceMap, map(), DocRouter.DEFAULT);\n      collToState.put(collection, col);\n    }\n    // reverse map\n    Map<CoreDescriptor, CountsForEachShard> myDescsToCounts = new HashMap<>();\n    for (Map.Entry<CountsForEachShard, List<CoreDescriptor>> entry : myCountsToDescs.entrySet()) {\n      for (CoreDescriptor descriptor : entry.getValue()) {\n        CountsForEachShard prev = myDescsToCounts.put(descriptor, entry.getKey());\n        assert prev == null; // sanity check\n      }\n    }\n\n    assert myCountsToDescs.size() == perShardCounts.size(); // just a sanity check\n\n    CoreContainer mockCC = mock(CoreContainer.class);\n    {\n      when(mockCC.isZooKeeperAware()).thenReturn(true);\n\n      ZkController mockZKC = mock(ZkController.class);\n      when(mockCC.getZkController()).thenReturn(mockZKC);\n      {\n        ClusterState mockClusterState = mock(ClusterState.class);\n        when(mockZKC.getClusterState()).thenReturn(mockClusterState);\n        {\n          when(mockClusterState.getLiveNodes()).thenReturn(new HashSet<>(liveNodes));\n          for (Map.Entry<String, DocCollection> entry : collToState.entrySet()) {\n            when(mockClusterState.getCollectionOrNull(entry.getKey())).thenReturn(entry.getValue());\n          }\n        }\n      }\n\n      NodeConfig mockNodeConfig = mock(NodeConfig.class);\n      when(mockNodeConfig.getNodeName()).thenReturn(thisNode);\n      when(mockCC.getNodeConfig()).thenReturn(mockNodeConfig);\n\n    }\n\n    List<CoreDescriptor> myDescs = new ArrayList<>(myDescsToCounts.keySet());\n    for (int i = 0; i < 10; i++) {\n      Collections.shuffle(myDescs, random());\n\n      List<CoreDescriptor> resultDescs = CoreSorter.sortCores(mockCC, myDescs);\n      // map descriptors back to counts, removing consecutive duplicates\n      List<CountsForEachShard> resultCounts = new ArrayList<>();\n      CountsForEachShard lastCounts = null;\n      for (CoreDescriptor resultDesc : resultDescs) {\n        CountsForEachShard counts = myDescsToCounts.get(resultDesc);\n        if (counts != lastCounts) {\n          resultCounts.add(counts);\n        }\n        lastCounts = counts;\n      }\n      assertEquals(expectedCounts, resultCounts);\n    }\n  }\n\n","sourceOld":"  @Test\n  public void integrationTest() {\n    assumeWorkingMockito();\n\n    List<CountsForEachShard> perShardCounts = new ArrayList<>(inputCounts);\n    Collections.shuffle(perShardCounts, random());\n\n    // compute nodes, some live, some down\n    final int maxNodesOfAType = perShardCounts.stream() // not too important how many we have, but lets have plenty\n        .mapToInt(c -> c.totalReplicasInLiveNodes + c.totalReplicasInDownNodes + c.myReplicas).max().getAsInt();\n    List<String> liveNodes = IntStream.range(0, maxNodesOfAType).mapToObj(i -> \"192.168.0.\" + i + \"_8983\").collect(Collectors.toList());\n    Collections.shuffle(liveNodes, random());\n    String thisNode = liveNodes.get(0);\n    List<String> otherLiveNodes = liveNodes.subList(1, liveNodes.size());\n    List<String> downNodes = IntStream.range(0, maxNodesOfAType).mapToObj(i -> \"192.168.1.\" + i + \"_8983\").collect(Collectors.toList());\n\n    // divide into two collections\n    int numCol1 = random().nextInt(perShardCounts.size());\n    Map<String,List<CountsForEachShard>> collToCounts = new HashMap<>();\n    collToCounts.put(\"col1\", perShardCounts.subList(0, numCol1));\n    collToCounts.put(\"col2\", perShardCounts.subList(numCol1, perShardCounts.size()));\n\n    Map<String,DocCollection> collToState = new HashMap<>();\n    Map<CountsForEachShard, List<CoreDescriptor>> myCountsToDescs = new HashMap<>();\n    for (Map.Entry<String, List<CountsForEachShard>> entry : collToCounts.entrySet()) {\n      String collection = entry.getKey();\n      List<CountsForEachShard> collCounts = entry.getValue();\n      Map<String, Slice> sliceMap = new HashMap<>(collCounts.size());\n      for (CountsForEachShard shardCounts : collCounts) {\n        String slice = \"s\" + shardCounts.hashCode();\n        List<Replica> replicas = new ArrayList<>();\n        for (int myRepNum = 0; myRepNum < shardCounts.myReplicas; myRepNum++) {\n          addNewReplica(replicas, collection, slice, Collections.singletonList(thisNode));\n          // save this mapping for later\n          myCountsToDescs.put(shardCounts, replicas.stream().map(this::newCoreDescriptor).collect(Collectors.toList()));\n        }\n        for (int myRepNum = 0; myRepNum < shardCounts.totalReplicasInLiveNodes; myRepNum++) {\n          addNewReplica(replicas, collection, slice, otherLiveNodes);\n        }\n        for (int myRepNum = 0; myRepNum < shardCounts.totalReplicasInDownNodes; myRepNum++) {\n          addNewReplica(replicas, collection, slice, downNodes);\n        }\n        Map<String, Replica> replicaMap = replicas.stream().collect(Collectors.toMap(Replica::getName, Function.identity()));\n        sliceMap.put(slice, new Slice(slice, replicaMap, map(), collection));\n      }\n      DocCollection col = new DocCollection(collection, sliceMap, map(), DocRouter.DEFAULT);\n      collToState.put(collection, col);\n    }\n    // reverse map\n    Map<CoreDescriptor, CountsForEachShard> myDescsToCounts = new HashMap<>();\n    for (Map.Entry<CountsForEachShard, List<CoreDescriptor>> entry : myCountsToDescs.entrySet()) {\n      for (CoreDescriptor descriptor : entry.getValue()) {\n        CountsForEachShard prev = myDescsToCounts.put(descriptor, entry.getKey());\n        assert prev == null; // sanity check\n      }\n    }\n\n    assert myCountsToDescs.size() == perShardCounts.size(); // just a sanity check\n\n    CoreContainer mockCC = mock(CoreContainer.class);\n    {\n      when(mockCC.isZooKeeperAware()).thenReturn(true);\n\n      ZkController mockZKC = mock(ZkController.class);\n      when(mockCC.getZkController()).thenReturn(mockZKC);\n      {\n        ClusterState mockClusterState = mock(ClusterState.class);\n        when(mockZKC.getClusterState()).thenReturn(mockClusterState);\n        {\n          when(mockClusterState.getLiveNodes()).thenReturn(new HashSet<>(liveNodes));\n          for (Map.Entry<String, DocCollection> entry : collToState.entrySet()) {\n            when(mockClusterState.getCollectionOrNull(entry.getKey())).thenReturn(entry.getValue());\n          }\n        }\n      }\n\n      NodeConfig mockNodeConfig = mock(NodeConfig.class);\n      when(mockNodeConfig.getNodeName()).thenReturn(thisNode);\n      when(mockCC.getNodeConfig()).thenReturn(mockNodeConfig);\n\n    }\n\n    List<CoreDescriptor> myDescs = new ArrayList<>(myDescsToCounts.keySet());\n    for (int i = 0; i < 10; i++) {\n      Collections.shuffle(myDescs, random());\n\n      List<CoreDescriptor> resultDescs = CoreSorter.sortCores(mockCC, myDescs);\n      // map descriptors back to counts, removing consecutive duplicates\n      List<CountsForEachShard> resultCounts = new ArrayList<>();\n      CountsForEachShard lastCounts = null;\n      for (CoreDescriptor resultDesc : resultDescs) {\n        CountsForEachShard counts = myDescsToCounts.get(resultDesc);\n        if (counts != lastCounts) {\n          resultCounts.add(counts);\n        }\n        lastCounts = counts;\n      }\n      assertEquals(expectedCounts, resultCounts);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"919b9b89b8d44ea491f18a92e6d52efcf5f7a065":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e98520789adb1d5ad05afb4956eca0944a929688"],"e98520789adb1d5ad05afb4956eca0944a929688":["919b9b89b8d44ea491f18a92e6d52efcf5f7a065"]},"commit2Childs":{"919b9b89b8d44ea491f18a92e6d52efcf5f7a065":["e98520789adb1d5ad05afb4956eca0944a929688"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["919b9b89b8d44ea491f18a92e6d52efcf5f7a065"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"e98520789adb1d5ad05afb4956eca0944a929688":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}