{"path":"lucene/core/src/test/org/apache/lucene/search/TestFieldSortOptimizationSkipping#testLongSortOptimization().mjava","commits":[{"id":"e18fac0122568cb02eb2c92608ca703a723bbbd6","date":1592942698,"type":0,"author":"Mayya Sharipova","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldSortOptimizationSkipping#testLongSortOptimization().mjava","pathOld":"/dev/null","sourceNew":"  public void testLongSortOptimization() throws IOException {\n\n    final Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig());\n    final int numDocs = atLeast(10000);\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = new Document();\n      doc.add(new NumericDocValuesField(\"my_field\", i));\n      doc.add(new LongPoint(\"my_field\", i));\n      writer.addDocument(doc);\n      if (i == 7000) writer.flush(); // two segments\n    }\n    final IndexReader reader = DirectoryReader.open(writer);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    final SortField sortField = new SortField(\"my_field\", SortField.Type.LONG);\n    final Sort sort = new Sort(sortField);\n    final int numHits = 3;\n    final int totalHitsThreshold = 3;\n\n    { // simple sort\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, null, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      for (int i = 0; i < numHits; i++) {\n        FieldDoc fieldDoc = (FieldDoc) topDocs.scoreDocs[i];\n        assertEquals(i, ((Long) fieldDoc.fields[0]).intValue());\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < numDocs);\n    }\n\n    { // paging sort with after\n      long afterValue = 2;\n      FieldDoc after = new FieldDoc(2, Float.NaN, new Long[] {afterValue});\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, after, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      for (int i = 0; i < numHits; i++) {\n        FieldDoc fieldDoc = (FieldDoc) topDocs.scoreDocs[i];\n        assertEquals(afterValue + 1 + i, fieldDoc.fields[0]);\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < numDocs);\n    }\n\n    { // test that if there is the secondary sort on _score, scores are filled correctly\n      final TopFieldCollector collector = TopFieldCollector.create(new Sort(sortField, FIELD_SCORE), numHits, null, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      for (int i = 0; i < numHits; i++) {\n        FieldDoc fieldDoc = (FieldDoc) topDocs.scoreDocs[i];\n        assertEquals(i, ((Long) fieldDoc.fields[0]).intValue());\n        float score = (float) fieldDoc.fields[1];\n        assertEquals(1.0, score, 0.001);\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < numDocs);\n    }\n\n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e3d1c24d2bbe79dcf77ffcb104706e42ae3c9241","date":1599588987,"type":3,"author":"Mayya Sharipova","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldSortOptimizationSkipping#testLongSortOptimization().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldSortOptimizationSkipping#testLongSortOptimization().mjava","sourceNew":"  public void testLongSortOptimization() throws IOException {\n\n    final Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig());\n    final int numDocs = atLeast(10000);\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = new Document();\n      doc.add(new NumericDocValuesField(\"my_field\", i));\n      doc.add(new LongPoint(\"my_field\", i));\n      writer.addDocument(doc);\n      if (i == 7000) writer.flush(); // two segments\n    }\n    final IndexReader reader = DirectoryReader.open(writer);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    final SortField sortField = new SortField(\"my_field\", SortField.Type.LONG);\n    final Sort sort = new Sort(sortField);\n    final int numHits = 3;\n    final int totalHitsThreshold = 3;\n\n    { // simple sort\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, null, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      for (int i = 0; i < numHits; i++) {\n        FieldDoc fieldDoc = (FieldDoc) topDocs.scoreDocs[i];\n        assertEquals(i, ((Long) fieldDoc.fields[0]).intValue());\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < numDocs);\n    }\n\n    { // paging sort with after\n      long afterValue = 2;\n      FieldDoc after = new FieldDoc(2, Float.NaN, new Long[] {afterValue});\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, after, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      for (int i = 0; i < numHits; i++) {\n        FieldDoc fieldDoc = (FieldDoc) topDocs.scoreDocs[i];\n        assertEquals(afterValue + 1 + i, fieldDoc.fields[0]);\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < numDocs);\n    }\n\n    { // test that if there is the secondary sort on _score, scores are filled correctly\n      final TopFieldCollector collector = TopFieldCollector.create(new Sort(sortField, FIELD_SCORE), numHits, null, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      for (int i = 0; i < numHits; i++) {\n        FieldDoc fieldDoc = (FieldDoc) topDocs.scoreDocs[i];\n        assertEquals(i, ((Long) fieldDoc.fields[0]).intValue());\n        float score = (float) fieldDoc.fields[1];\n        assertEquals(1.0, score, 0.001);\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < numDocs);\n    }\n\n    { // test that if numeric field is a secondary sort, no optimization is run\n      final TopFieldCollector collector = TopFieldCollector.create(new Sort(FIELD_SCORE, sortField), numHits, null, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      assertEquals(topDocs.totalHits.value, numDocs); // assert that all documents were collected => optimization was not run\n    }\n\n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testLongSortOptimization() throws IOException {\n\n    final Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig());\n    final int numDocs = atLeast(10000);\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = new Document();\n      doc.add(new NumericDocValuesField(\"my_field\", i));\n      doc.add(new LongPoint(\"my_field\", i));\n      writer.addDocument(doc);\n      if (i == 7000) writer.flush(); // two segments\n    }\n    final IndexReader reader = DirectoryReader.open(writer);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    final SortField sortField = new SortField(\"my_field\", SortField.Type.LONG);\n    final Sort sort = new Sort(sortField);\n    final int numHits = 3;\n    final int totalHitsThreshold = 3;\n\n    { // simple sort\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, null, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      for (int i = 0; i < numHits; i++) {\n        FieldDoc fieldDoc = (FieldDoc) topDocs.scoreDocs[i];\n        assertEquals(i, ((Long) fieldDoc.fields[0]).intValue());\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < numDocs);\n    }\n\n    { // paging sort with after\n      long afterValue = 2;\n      FieldDoc after = new FieldDoc(2, Float.NaN, new Long[] {afterValue});\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, after, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      for (int i = 0; i < numHits; i++) {\n        FieldDoc fieldDoc = (FieldDoc) topDocs.scoreDocs[i];\n        assertEquals(afterValue + 1 + i, fieldDoc.fields[0]);\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < numDocs);\n    }\n\n    { // test that if there is the secondary sort on _score, scores are filled correctly\n      final TopFieldCollector collector = TopFieldCollector.create(new Sort(sortField, FIELD_SCORE), numHits, null, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      for (int i = 0; i < numHits; i++) {\n        FieldDoc fieldDoc = (FieldDoc) topDocs.scoreDocs[i];\n        assertEquals(i, ((Long) fieldDoc.fields[0]).intValue());\n        float score = (float) fieldDoc.fields[1];\n        assertEquals(1.0, score, 0.001);\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < numDocs);\n    }\n\n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e977a403f93a917f75266c88727eadb89e4f64fc","date":1600866583,"type":3,"author":"Mayya Sharipova","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestFieldSortOptimizationSkipping#testLongSortOptimization().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestFieldSortOptimizationSkipping#testLongSortOptimization().mjava","sourceNew":"  public void testLongSortOptimization() throws IOException {\n\n    final Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig());\n    final int numDocs = atLeast(10000);\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = new Document();\n      doc.add(new NumericDocValuesField(\"my_field\", i));\n      doc.add(new LongPoint(\"my_field\", i));\n      writer.addDocument(doc);\n      if (i == 7000) writer.flush(); // two segments\n    }\n    final IndexReader reader = DirectoryReader.open(writer);\n    writer.close();\n    IndexSearcher searcher = new IndexSearcher(reader);\n    final SortField sortField = new SortField(\"my_field\", SortField.Type.LONG);\n    final Sort sort = new Sort(sortField);\n    final int numHits = 3;\n    final int totalHitsThreshold = 3;\n\n    { // simple sort\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, null, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      for (int i = 0; i < numHits; i++) {\n        FieldDoc fieldDoc = (FieldDoc) topDocs.scoreDocs[i];\n        assertEquals(i, ((Long) fieldDoc.fields[0]).intValue());\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < numDocs);\n    }\n\n    { // paging sort with after\n      long afterValue = 2;\n      FieldDoc after = new FieldDoc(2, Float.NaN, new Long[] {afterValue});\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, after, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      for (int i = 0; i < numHits; i++) {\n        FieldDoc fieldDoc = (FieldDoc) topDocs.scoreDocs[i];\n        assertEquals(afterValue + 1 + i, fieldDoc.fields[0]);\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < numDocs);\n    }\n\n    { // test that if there is the secondary sort on _score, scores are filled correctly\n      final TopFieldCollector collector = TopFieldCollector.create(new Sort(sortField, FIELD_SCORE), numHits, null, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      for (int i = 0; i < numHits; i++) {\n        FieldDoc fieldDoc = (FieldDoc) topDocs.scoreDocs[i];\n        assertEquals(i, ((Long) fieldDoc.fields[0]).intValue());\n        float score = (float) fieldDoc.fields[1];\n        assertEquals(1.0, score, 0.001);\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < numDocs);\n    }\n\n    { // test that if numeric field is a secondary sort, no optimization is run\n      final TopFieldCollector collector = TopFieldCollector.create(new Sort(FIELD_SCORE, sortField), numHits, null, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      assertEquals(topDocs.totalHits.value, numDocs); // assert that all documents were collected => optimization was not run\n    }\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testLongSortOptimization() throws IOException {\n\n    final Directory dir = newDirectory();\n    final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig());\n    final int numDocs = atLeast(10000);\n    for (int i = 0; i < numDocs; ++i) {\n      final Document doc = new Document();\n      doc.add(new NumericDocValuesField(\"my_field\", i));\n      doc.add(new LongPoint(\"my_field\", i));\n      writer.addDocument(doc);\n      if (i == 7000) writer.flush(); // two segments\n    }\n    final IndexReader reader = DirectoryReader.open(writer);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    final SortField sortField = new SortField(\"my_field\", SortField.Type.LONG);\n    final Sort sort = new Sort(sortField);\n    final int numHits = 3;\n    final int totalHitsThreshold = 3;\n\n    { // simple sort\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, null, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      for (int i = 0; i < numHits; i++) {\n        FieldDoc fieldDoc = (FieldDoc) topDocs.scoreDocs[i];\n        assertEquals(i, ((Long) fieldDoc.fields[0]).intValue());\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < numDocs);\n    }\n\n    { // paging sort with after\n      long afterValue = 2;\n      FieldDoc after = new FieldDoc(2, Float.NaN, new Long[] {afterValue});\n      final TopFieldCollector collector = TopFieldCollector.create(sort, numHits, after, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      for (int i = 0; i < numHits; i++) {\n        FieldDoc fieldDoc = (FieldDoc) topDocs.scoreDocs[i];\n        assertEquals(afterValue + 1 + i, fieldDoc.fields[0]);\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < numDocs);\n    }\n\n    { // test that if there is the secondary sort on _score, scores are filled correctly\n      final TopFieldCollector collector = TopFieldCollector.create(new Sort(sortField, FIELD_SCORE), numHits, null, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      for (int i = 0; i < numHits; i++) {\n        FieldDoc fieldDoc = (FieldDoc) topDocs.scoreDocs[i];\n        assertEquals(i, ((Long) fieldDoc.fields[0]).intValue());\n        float score = (float) fieldDoc.fields[1];\n        assertEquals(1.0, score, 0.001);\n      }\n      assertTrue(collector.isEarlyTerminated());\n      assertTrue(topDocs.totalHits.value < numDocs);\n    }\n\n    { // test that if numeric field is a secondary sort, no optimization is run\n      final TopFieldCollector collector = TopFieldCollector.create(new Sort(FIELD_SCORE, sortField), numHits, null, totalHitsThreshold);\n      searcher.search(new MatchAllDocsQuery(), collector);\n      TopDocs topDocs = collector.topDocs();\n      assertEquals(topDocs.scoreDocs.length, numHits);\n      assertEquals(topDocs.totalHits.value, numDocs); // assert that all documents were collected => optimization was not run\n    }\n\n    writer.close();\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e977a403f93a917f75266c88727eadb89e4f64fc":["e3d1c24d2bbe79dcf77ffcb104706e42ae3c9241"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e18fac0122568cb02eb2c92608ca703a723bbbd6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e977a403f93a917f75266c88727eadb89e4f64fc"],"e3d1c24d2bbe79dcf77ffcb104706e42ae3c9241":["e18fac0122568cb02eb2c92608ca703a723bbbd6"]},"commit2Childs":{"e977a403f93a917f75266c88727eadb89e4f64fc":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e18fac0122568cb02eb2c92608ca703a723bbbd6"],"e18fac0122568cb02eb2c92608ca703a723bbbd6":["e3d1c24d2bbe79dcf77ffcb104706e42ae3c9241"],"e3d1c24d2bbe79dcf77ffcb104706e42ae3c9241":["e977a403f93a917f75266c88727eadb89e4f64fc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}