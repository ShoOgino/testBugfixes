{"path":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","commits":[{"id":"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be","date":1204801324,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean).mjava","sourceNew":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    if (autoCommit)\n      flushDeletes = true;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            docWriter.abort(null);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile);\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      if (flushDocs)\n        checkpoint();\n\n      doAfterFlush();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    flushCount++;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      // Always flush deletes if there are any delete terms.\n      // TODO: when autoCommit=false we don't have to flush\n      // deletes with every flushed segment; we can save\n      // CPU/IO by buffering longer & flushing deletes only\n      // when they are full or writer is being closed.  We\n      // have to fix the \"applyDeletesSelectively\" logic to\n      // apply to more than just the last flushed segment\n      boolean flushDeletes = docWriter.hasDeletes();\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            docWriter.abort(null);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile);\n      }\n\n      if (flushDeletes) {\n        try {\n          SegmentInfos rollback = (SegmentInfos) segmentInfos.clone();\n\n          boolean success = false;\n          try {\n            // we should be able to change this so we can\n            // buffer deletes longer and then flush them to\n            // multiple flushed segments only when a commit()\n            // finally happens\n            applyDeletes(newSegment);\n            success = true;\n          } finally {\n            if (!success) {\n              if (infoStream != null)\n                message(\"hit exception flushing deletes\");\n                \n              // Carefully remove any partially written .del\n              // files\n              final int size = rollback.size();\n              for(int i=0;i<size;i++) {\n                final String newDelFileName = segmentInfos.info(i).getDelFileName();\n                final String delFileName = rollback.info(i).getDelFileName();\n                if (newDelFileName != null && !newDelFileName.equals(delFileName))\n                  deleter.deleteFile(newDelFileName);\n              }\n\n              // Remove just flushed segment\n              deleter.refresh(segment);\n\n              // Fully replace the segmentInfos since flushed\n              // deletes could have changed any of the\n              // SegmentInfo instances:\n              segmentInfos.clear();\n              segmentInfos.addAll(rollback);\n            }              \n          }\n        } finally {\n          // Regardless of success of failure in flushing\n          // deletes, we must clear them from our buffer:\n          docWriter.clearBufferedDeletes();\n        }\n      }\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDocs || flushDeletes)\n        checkpoint();\n\n      doAfterFlush();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n      \n      return flushDocs || flushDeletes;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ab2938d01fe23337bcad36c5ad7207deb33a6a4","date":1205259391,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","sourceNew":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    if (autoCommit)\n      flushDeletes = true;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            docWriter.abort(null);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile);\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    if (autoCommit)\n      flushDeletes = true;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            docWriter.abort(null);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile);\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      if (flushDocs)\n        checkpoint();\n\n      doAfterFlush();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":["e82780afe6097066eb5befb86e9432f077667e3d"],"bugIntro":["cd488f50316362b01a7f67b11a96796b9652e3e5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"455aeff4fef915340c5b19d71d5e147034e83093","date":1210099270,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","sourceNew":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    flushDeletes |= autoCommit;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            docWriter.abort(null);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile);\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    if (autoCommit)\n      flushDeletes = true;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            docWriter.abort(null);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile);\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":null,"bugIntro":["cd488f50316362b01a7f67b11a96796b9652e3e5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5350389bf83287111f7760b9e3db3af8e3648474","date":1216372812,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","sourceNew":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    flushDeletes |= autoCommit;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile);\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    flushDeletes |= autoCommit;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            docWriter.abort(null);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile);\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"902ba79f4590a41c663c447756d2e5041cbbdda9","date":1217956662,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","sourceNew":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    flushDeletes |= autoCommit;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile,    \n                                     docWriter.hasProx());\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    flushDeletes |= autoCommit;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile);\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":null,"bugIntro":["cd488f50316362b01a7f67b11a96796b9652e3e5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2586f96f60332eb97ecd2934b0763791462568b2","date":1220116589,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","sourceNew":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    ensureOpen(false);\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    // Make sure no threads are actively adding a document\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    flushDeletes |= autoCommit;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile,    \n                                     docWriter.hasProx());\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    // Make sure no threads are actively adding a document\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    flushDeletes |= autoCommit;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile,    \n                                     docWriter.hasProx());\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":null,"bugIntro":["cd488f50316362b01a7f67b11a96796b9652e3e5","df2e19759ba573689671d3ed4451ede4d92e479a"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c7b6cdc70e097da94da79a655ed8f94477ff69f5","date":1220815360,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","sourceNew":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    ensureOpen(false);\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    // Make sure no threads are actively adding a document\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    flushDeletes |= autoCommit;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile,    \n                                     docWriter.hasProx());\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.add(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    ensureOpen(false);\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    // Make sure no threads are actively adding a document\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    flushDeletes |= autoCommit;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile,    \n                                     docWriter.hasProx());\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.addElement(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":null,"bugIntro":["cd488f50316362b01a7f67b11a96796b9652e3e5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"df2e19759ba573689671d3ed4451ede4d92e479a","date":1235439035,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","sourceNew":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    ensureOpen(false);\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    flushDeletes |= autoCommit;\n\n    // Make sure no threads are actively adding a document.\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile,    \n                                     docWriter.hasProx());\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.add(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    ensureOpen(false);\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    // Make sure no threads are actively adding a document\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    flushDeletes |= autoCommit;\n\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile,    \n                                     docWriter.hasProx());\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.add(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":["2586f96f60332eb97ecd2934b0763791462568b2"],"bugIntro":["cd488f50316362b01a7f67b11a96796b9652e3e5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c4ff8864209d2e972cb4393600c26082f9a6533d","date":1239297466,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","sourceNew":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    ensureOpen(false);\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    flushDeletes |= autoCommit;\n\n    // Make sure no threads are actively adding a document.\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n\n      assert docStoreSegment != null || numDocs == 0;\n\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile,    \n                                     docWriter.hasProx());\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.add(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","sourceOld":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    ensureOpen(false);\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    flushDeletes |= autoCommit;\n\n    // Make sure no threads are actively adding a document.\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile,    \n                                     docWriter.hasProx());\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.add(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":null,"bugIntro":["cd488f50316362b01a7f67b11a96796b9652e3e5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cd488f50316362b01a7f67b11a96796b9652e3e5","date":1241121034,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","sourceNew":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n    try {\n      return doFlushInternal(flushDocStores, flushDeletes);\n    } finally {\n      docWriter.clearFlushPending();\n    }\n  }\n\n","sourceOld":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n\n    ensureOpen(false);\n\n    assert testPoint(\"startDoFlush\");\n\n    flushCount++;\n\n    flushDeletes |= docWriter.deletesFull();\n\n    // When autoCommit=true we must always flush deletes\n    // when flushing a segment; otherwise deletes may become\n    // visible before their corresponding added document\n    // from an updateDocument call\n    flushDeletes |= autoCommit;\n\n    // Make sure no threads are actively adding a document.\n    // Returns true if docWriter is currently aborting, in\n    // which case we skip flushing this segment\n    if (docWriter.pauseAllThreads()) {\n      docWriter.resumeAllThreads();\n      return false;\n    }\n\n    try {\n\n      SegmentInfo newSegment = null;\n\n      final int numDocs = docWriter.getNumDocsInRAM();\n\n      // Always flush docs if there are any\n      boolean flushDocs = numDocs > 0;\n\n      // With autoCommit=true we always must flush the doc\n      // stores when we flush\n      flushDocStores |= autoCommit;\n      String docStoreSegment = docWriter.getDocStoreSegment();\n\n      assert docStoreSegment != null || numDocs == 0;\n\n      if (docStoreSegment == null)\n        flushDocStores = false;\n\n      int docStoreOffset = docWriter.getDocStoreOffset();\n\n      // docStoreOffset should only be non-zero when\n      // autoCommit == false\n      assert !autoCommit || 0 == docStoreOffset;\n\n      boolean docStoreIsCompoundFile = false;\n\n      if (infoStream != null) {\n        message(\"  flush: segment=\" + docWriter.getSegment() +\n                \" docStoreSegment=\" + docWriter.getDocStoreSegment() +\n                \" docStoreOffset=\" + docStoreOffset +\n                \" flushDocs=\" + flushDocs +\n                \" flushDeletes=\" + flushDeletes +\n                \" flushDocStores=\" + flushDocStores +\n                \" numDocs=\" + numDocs +\n                \" numBufDelTerms=\" + docWriter.getNumBufferedDeleteTerms());\n        message(\"  index before flush \" + segString());\n      }\n\n      // Check if the doc stores must be separately flushed\n      // because other segments, besides the one we are about\n      // to flush, reference it\n      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {\n        // We must separately flush the doc store\n        if (infoStream != null)\n          message(\"  flush shared docStore segment \" + docStoreSegment);\n      \n        docStoreIsCompoundFile = flushDocStores();\n        flushDocStores = false;\n      }\n\n      String segment = docWriter.getSegment();\n\n      // If we are flushing docs, segment must not be null:\n      assert segment != null || !flushDocs;\n\n      if (flushDocs) {\n\n        boolean success = false;\n        final int flushedDocCount;\n\n        try {\n          flushedDocCount = docWriter.flush(flushDocStores);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception flushing segment \" + segment);\n            deleter.refresh(segment);\n          }\n        }\n        \n        if (0 == docStoreOffset && flushDocStores) {\n          // This means we are flushing private doc stores\n          // with this segment, so it will not be shared\n          // with other segments\n          assert docStoreSegment != null;\n          assert docStoreSegment.equals(segment);\n          docStoreOffset = -1;\n          docStoreIsCompoundFile = false;\n          docStoreSegment = null;\n        }\n\n        // Create new SegmentInfo, but do not add to our\n        // segmentInfos until deletes are flushed\n        // successfully.\n        newSegment = new SegmentInfo(segment,\n                                     flushedDocCount,\n                                     directory, false, true,\n                                     docStoreOffset, docStoreSegment,\n                                     docStoreIsCompoundFile,    \n                                     docWriter.hasProx());\n      }\n\n      docWriter.pushDeletes();\n\n      if (flushDocs)\n        segmentInfos.add(newSegment);\n\n      if (flushDeletes) {\n        flushDeletesCount++;\n        applyDeletes();\n      }\n      \n      doAfterFlush();\n\n      if (flushDocs)\n        checkpoint();\n\n      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          docWriter.createCompoundFile(segment);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null)\n              message(\"hit exception creating compound file for newly flushed segment \" + segment);\n            deleter.deleteFile(segment + \".\" + IndexFileNames.COMPOUND_FILE_EXTENSION);\n          }\n        }\n\n        newSegment.setUseCompoundFile(true);\n        checkpoint();\n      }\n\n      return flushDocs;\n\n    } catch (OutOfMemoryError oom) {\n      hitOOM = true;\n      throw oom;\n    } finally {\n      docWriter.clearFlushPending();\n      docWriter.resumeAllThreads();\n    }\n  }\n\n","bugFix":["c7b6cdc70e097da94da79a655ed8f94477ff69f5","01deb9e9fb9dbd5fddce32a5fcd952bbb611fe63","b1405362241b561f5590ff4a87d5d6e173bcd9cf","2586f96f60332eb97ecd2934b0763791462568b2","c4ff8864209d2e972cb4393600c26082f9a6533d","83bbb041887bbef07b8a98d08a0e1713ce137039","902ba79f4590a41c663c447756d2e5041cbbdda9","455aeff4fef915340c5b19d71d5e147034e83093","df2e19759ba573689671d3ed4451ede4d92e479a","4ab2938d01fe23337bcad36c5ad7207deb33a6a4","1fd1f3c5c06036aebe90bc6da756a37d03f63884","e82780afe6097066eb5befb86e9432f077667e3d","a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#doFlush(boolean,boolean).mjava","sourceNew":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n    try {\n      return doFlushInternal(flushDocStores, flushDeletes);\n    } finally {\n      docWriter.clearFlushPending();\n    }\n  }\n\n","sourceOld":"  // TODO: this method should not have to be entirely\n  // synchronized, ie, merges should be allowed to commit\n  // even while a flush is happening\n  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {\n    try {\n      return doFlushInternal(flushDocStores, flushDeletes);\n    } finally {\n      docWriter.clearFlushPending();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"455aeff4fef915340c5b19d71d5e147034e83093":["4ab2938d01fe23337bcad36c5ad7207deb33a6a4"],"c4ff8864209d2e972cb4393600c26082f9a6533d":["df2e19759ba573689671d3ed4451ede4d92e479a"],"902ba79f4590a41c663c447756d2e5041cbbdda9":["5350389bf83287111f7760b9e3db3af8e3648474"],"c7b6cdc70e097da94da79a655ed8f94477ff69f5":["2586f96f60332eb97ecd2934b0763791462568b2"],"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4ab2938d01fe23337bcad36c5ad7207deb33a6a4":["a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be"],"cd488f50316362b01a7f67b11a96796b9652e3e5":["c4ff8864209d2e972cb4393600c26082f9a6533d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"df2e19759ba573689671d3ed4451ede4d92e479a":["c7b6cdc70e097da94da79a655ed8f94477ff69f5"],"2586f96f60332eb97ecd2934b0763791462568b2":["902ba79f4590a41c663c447756d2e5041cbbdda9"],"5350389bf83287111f7760b9e3db3af8e3648474":["455aeff4fef915340c5b19d71d5e147034e83093"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd488f50316362b01a7f67b11a96796b9652e3e5"]},"commit2Childs":{"455aeff4fef915340c5b19d71d5e147034e83093":["5350389bf83287111f7760b9e3db3af8e3648474"],"c4ff8864209d2e972cb4393600c26082f9a6533d":["cd488f50316362b01a7f67b11a96796b9652e3e5"],"902ba79f4590a41c663c447756d2e5041cbbdda9":["2586f96f60332eb97ecd2934b0763791462568b2"],"c7b6cdc70e097da94da79a655ed8f94477ff69f5":["df2e19759ba573689671d3ed4451ede4d92e479a"],"a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be":["4ab2938d01fe23337bcad36c5ad7207deb33a6a4"],"4ab2938d01fe23337bcad36c5ad7207deb33a6a4":["455aeff4fef915340c5b19d71d5e147034e83093"],"cd488f50316362b01a7f67b11a96796b9652e3e5":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a2fc4b864a5dc2c630bb1fa94091e89e69f8f8be"],"df2e19759ba573689671d3ed4451ede4d92e479a":["c4ff8864209d2e972cb4393600c26082f9a6533d"],"2586f96f60332eb97ecd2934b0763791462568b2":["c7b6cdc70e097da94da79a655ed8f94477ff69f5"],"5350389bf83287111f7760b9e3db3af8e3648474":["902ba79f4590a41c663c447756d2e5041cbbdda9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}