{"path":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n\n    FieldCache.DocTermsIndex si = null;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    FieldFacetStats all = new FieldFacetStats( \"all\", si, ft, 0 );\n    StatsValues allstats = new StatsValues();\n    if ( all.nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if the no documents match...\n    int i=0;\n    final FieldFacetStats[] finfo = new FieldFacetStats[facet.length];\n    for( String f : facet ) {\n      ft = searcher.getSchema().getFieldType(f);\n      try {\n        si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), f);\n      } \n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"+f, e );\n      }\n      finfo[i++] = new FieldFacetStats( f, si, ft, 0 );\n    }\n    final CharsRef spare = new CharsRef();\n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = all.getTermText(docID, tempBR);\n      Double v = null;\n      if( raw != null ) {\n        v = Double.parseDouble(all.ft.indexedToReadable(raw, spare).toString());\n        allstats.accumulate(v);\n      }\n      else {\n        allstats.missing++;\n      }\n      \n      // now check the facets\n      for( FieldFacetStats f : finfo ) {\n        f.facet(docID, v);\n      }\n    }\n    \n    if( finfo.length > 0 ) {\n      allstats.facets = new HashMap<String, Map<String,StatsValues>>();\n      for( FieldFacetStats f : finfo ) {\n        allstats.facets.put( f.name, f.facetStatsValues );\n      }\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n\n    FieldCache.DocTermsIndex si = null;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    FieldFacetStats all = new FieldFacetStats( \"all\", si, ft, 0 );\n    StatsValues allstats = new StatsValues();\n    if ( all.nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if the no documents match...\n    int i=0;\n    final FieldFacetStats[] finfo = new FieldFacetStats[facet.length];\n    for( String f : facet ) {\n      ft = searcher.getSchema().getFieldType(f);\n      try {\n        si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), f);\n      } \n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"+f, e );\n      }\n      finfo[i++] = new FieldFacetStats( f, si, ft, 0 );\n    }\n    final CharsRef spare = new CharsRef();\n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = all.getTermText(docID, tempBR);\n      Double v = null;\n      if( raw != null ) {\n        v = Double.parseDouble(all.ft.indexedToReadable(raw, spare).toString());\n        allstats.accumulate(v);\n      }\n      else {\n        allstats.missing++;\n      }\n      \n      // now check the facets\n      for( FieldFacetStats f : finfo ) {\n        f.facet(docID, v);\n      }\n    }\n    \n    if( finfo.length > 0 ) {\n      allstats.facets = new HashMap<String, Map<String,StatsValues>>();\n      for( FieldFacetStats f : finfo ) {\n        allstats.facets.put( f.name, f.facetStatsValues );\n      }\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n\n    FieldCache.DocTermsIndex si = null;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    FieldFacetStats all = new FieldFacetStats( \"all\", si, ft, 0 );\n    StatsValues allstats = new StatsValues();\n    if ( all.nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if the no documents match...\n    int i=0;\n    final FieldFacetStats[] finfo = new FieldFacetStats[facet.length];\n    for( String f : facet ) {\n      ft = searcher.getSchema().getFieldType(f);\n      try {\n        si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), f);\n      } \n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"+f, e );\n      }\n      finfo[i++] = new FieldFacetStats( f, si, ft, 0 );\n    }\n    final CharsRef spare = new CharsRef();\n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = all.getTermText(docID, tempBR);\n      Double v = null;\n      if( raw != null ) {\n        v = Double.parseDouble(all.ft.indexedToReadable(raw, spare).toString());\n        allstats.accumulate(v);\n      }\n      else {\n        allstats.missing++;\n      }\n      \n      // now check the facets\n      for( FieldFacetStats f : finfo ) {\n        f.facet(docID, v);\n      }\n    }\n    \n    if( finfo.length > 0 ) {\n      allstats.facets = new HashMap<String, Map<String,StatsValues>>();\n      for( FieldFacetStats f : finfo ) {\n        allstats.facets.put( f.name, f.facetStatsValues );\n      }\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n\n    FieldCache.DocTermsIndex si = null;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    FieldFacetStats all = new FieldFacetStats( \"all\", si, ft, 0 );\n    StatsValues allstats = new StatsValues();\n    if ( all.nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if the no documents match...\n    int i=0;\n    final FieldFacetStats[] finfo = new FieldFacetStats[facet.length];\n    for( String f : facet ) {\n      ft = searcher.getSchema().getFieldType(f);\n      try {\n        si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), f);\n      } \n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"+f, e );\n      }\n      finfo[i++] = new FieldFacetStats( f, si, ft, 0 );\n    }\n    final CharsRef spare = new CharsRef();\n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = all.getTermText(docID, tempBR);\n      Double v = null;\n      if( raw != null ) {\n        v = Double.parseDouble(all.ft.indexedToReadable(raw, spare).toString());\n        allstats.accumulate(v);\n      }\n      else {\n        allstats.missing++;\n      }\n      \n      // now check the facets\n      for( FieldFacetStats f : finfo ) {\n        f.facet(docID, v);\n      }\n    }\n    \n    if( finfo.length > 0 ) {\n      allstats.facets = new HashMap<String, Map<String,StatsValues>>();\n      for( FieldFacetStats f : finfo ) {\n        allstats.facets.put( f.name, f.facetStatsValues );\n      }\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n\n    FieldCache.DocTermsIndex si = null;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    FieldFacetStats all = new FieldFacetStats( \"all\", si, ft, 0 );\n    StatsValues allstats = new StatsValues();\n    if ( all.nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if the no documents match...\n    int i=0;\n    final FieldFacetStats[] finfo = new FieldFacetStats[facet.length];\n    for( String f : facet ) {\n      ft = searcher.getSchema().getFieldType(f);\n      try {\n        si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), f);\n      } \n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"+f, e );\n      }\n      finfo[i++] = new FieldFacetStats( f, si, ft, 0 );\n    }\n    final CharsRef spare = new CharsRef();\n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = all.getTermText(docID, tempBR);\n      Double v = null;\n      if( raw != null ) {\n        v = Double.parseDouble(all.ft.indexedToReadable(raw, spare).toString());\n        allstats.accumulate(v);\n      }\n      else {\n        allstats.missing++;\n      }\n      \n      // now check the facets\n      for( FieldFacetStats f : finfo ) {\n        f.facet(docID, v);\n      }\n    }\n    \n    if( finfo.length > 0 ) {\n      allstats.facets = new HashMap<String, Map<String,StatsValues>>();\n      for( FieldFacetStats f : finfo ) {\n        allstats.facets.put( f.name, f.facetStatsValues );\n      }\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n\n    FieldCache.DocTermsIndex si = null;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    FieldFacetStats all = new FieldFacetStats( \"all\", si, ft, 0 );\n    StatsValues allstats = new StatsValues();\n    if ( all.nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if the no documents match...\n    int i=0;\n    final FieldFacetStats[] finfo = new FieldFacetStats[facet.length];\n    for( String f : facet ) {\n      ft = searcher.getSchema().getFieldType(f);\n      try {\n        si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), f);\n      } \n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"+f, e );\n      }\n      finfo[i++] = new FieldFacetStats( f, si, ft, 0 );\n    }\n    final CharsRef spare = new CharsRef();\n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = all.getTermText(docID, tempBR);\n      Double v = null;\n      if( raw != null ) {\n        v = Double.parseDouble(all.ft.indexedToReadable(raw, spare).toString());\n        allstats.accumulate(v);\n      }\n      else {\n        allstats.missing++;\n      }\n      \n      // now check the facets\n      for( FieldFacetStats f : finfo ) {\n        f.facet(docID, v);\n      }\n    }\n    \n    if( finfo.length > 0 ) {\n      allstats.facets = new HashMap<String, Map<String,StatsValues>>();\n      for( FieldFacetStats f : finfo ) {\n        allstats.facets.put( f.name, f.facetStatsValues );\n      }\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"11982a7b6834a8571852448312db4624c32990b5","date":1321300684,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      FieldType facetFieldType = fsf.getType();\n\n      if (facetFieldType.isTokenized() || facetFieldType.isMultiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField\n          + \"[\" + facetFieldType + \"]\");\n        }\n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = si.lookup(si.getOrd(docID), tempBR);\n      if( raw.length > 0 ) {\n        allstats.accumulate(raw);\n      } else {\n        allstats.missing();\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n\n    FieldCache.DocTermsIndex si = null;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    FieldFacetStats all = new FieldFacetStats( \"all\", si, ft, 0 );\n    StatsValues allstats = new StatsValues();\n    if ( all.nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if the no documents match...\n    int i=0;\n    final FieldFacetStats[] finfo = new FieldFacetStats[facet.length];\n    for( String f : facet ) {\n      ft = searcher.getSchema().getFieldType(f);\n      try {\n        si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), f);\n      } \n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"+f, e );\n      }\n      finfo[i++] = new FieldFacetStats( f, si, ft, 0 );\n    }\n    final CharsRef spare = new CharsRef();\n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = all.getTermText(docID, tempBR);\n      Double v = null;\n      if( raw != null ) {\n        v = Double.parseDouble(all.ft.indexedToReadable(raw, spare).toString());\n        allstats.accumulate(v);\n      }\n      else {\n        allstats.missing++;\n      }\n      \n      // now check the facets\n      for( FieldFacetStats f : finfo ) {\n        f.facet(docID, v);\n      }\n    }\n    \n    if( finfo.length > 0 ) {\n      allstats.facets = new HashMap<String, Map<String,StatsValues>>();\n      for( FieldFacetStats f : finfo ) {\n        allstats.facets.put( f.name, f.facetStatsValues );\n      }\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4","e0781eeef93647a16405c13e217b095865562dd1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2dd6ecb8250c497ed227653279d6a4f470bfbb31","date":1326814483,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(new SlowMultiReaderWrapper(searcher.getIndexReader()), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      FieldType facetFieldType = fsf.getType();\n\n      if (facetFieldType.isTokenized() || facetFieldType.isMultiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField\n          + \"[\" + facetFieldType + \"]\");\n        }\n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(new SlowMultiReaderWrapper(searcher.getIndexReader()), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = si.lookup(si.getOrd(docID), tempBR);\n      if( raw.length > 0 ) {\n        allstats.accumulate(raw);\n      } else {\n        allstats.missing();\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      FieldType facetFieldType = fsf.getType();\n\n      if (facetFieldType.isTokenized() || facetFieldType.isMultiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField\n          + \"[\" + facetFieldType + \"]\");\n        }\n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getIndexReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = si.lookup(si.getOrd(docID), tempBR);\n      if( raw.length > 0 ) {\n        allstats.accumulate(raw);\n      } else {\n        allstats.missing();\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"96d207426bd26fa5c1014e26d21d87603aea68b7","date":1327944562,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      FieldType facetFieldType = fsf.getType();\n\n      if (facetFieldType.isTokenized() || facetFieldType.isMultiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField\n          + \"[\" + facetFieldType + \"]\");\n        }\n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = si.lookup(si.getOrd(docID), tempBR);\n      if( raw.length > 0 ) {\n        allstats.accumulate(raw);\n      } else {\n        allstats.missing();\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(new SlowMultiReaderWrapper(searcher.getIndexReader()), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      FieldType facetFieldType = fsf.getType();\n\n      if (facetFieldType.isTokenized() || facetFieldType.isMultiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField\n          + \"[\" + facetFieldType + \"]\");\n        }\n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(new SlowMultiReaderWrapper(searcher.getIndexReader()), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = si.lookup(si.getOrd(docID), tempBR);\n      if( raw.length > 0 ) {\n        allstats.accumulate(raw);\n      } else {\n        allstats.missing();\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      FieldType facetFieldType = fsf.getType();\n\n      if (facetFieldType.isTokenized() || facetFieldType.isMultiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField\n          + \"[\" + facetFieldType + \"]\");\n        }\n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = si.lookup(si.getOrd(docID), tempBR);\n      if( raw.length > 0 ) {\n        allstats.accumulate(raw);\n      } else {\n        allstats.missing();\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(new SlowMultiReaderWrapper(searcher.getIndexReader()), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      FieldType facetFieldType = fsf.getType();\n\n      if (facetFieldType.isTokenized() || facetFieldType.isMultiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField\n          + \"[\" + facetFieldType + \"]\");\n        }\n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(new SlowMultiReaderWrapper(searcher.getIndexReader()), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = si.lookup(si.getOrd(docID), tempBR);\n      if( raw.length > 0 ) {\n        allstats.accumulate(raw);\n      } else {\n        allstats.missing();\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e0781eeef93647a16405c13e217b095865562dd1","date":1342733291,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n\n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = si.lookup(si.getOrd(docID), tempBR);\n      if( raw.length > 0 ) {\n        allstats.accumulate(raw);\n      } else {\n        allstats.missing();\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      FieldType facetFieldType = fsf.getType();\n\n      if (facetFieldType.isTokenized() || facetFieldType.isMultiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField\n          + \"[\" + facetFieldType + \"]\");\n        }\n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = si.lookup(si.getOrd(docID), tempBR);\n      if( raw.length > 0 ) {\n        allstats.accumulate(raw);\n      } else {\n        allstats.missing();\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":["11982a7b6834a8571852448312db4624c32990b5"],"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","date":1343059585,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n\n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = si.lookup(si.getOrd(docID), tempBR);\n      if( raw.length > 0 ) {\n        allstats.accumulate(raw);\n      } else {\n        allstats.missing();\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      FieldType facetFieldType = fsf.getType();\n\n      if (facetFieldType.isTokenized() || facetFieldType.isMultiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField\n          + \"[\" + facetFieldType + \"]\");\n        }\n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = si.lookup(si.getOrd(docID), tempBR);\n      if( raw.length > 0 ) {\n        allstats.accumulate(raw);\n      } else {\n        allstats.missing();\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n\n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = si.lookup(si.getOrd(docID), tempBR);\n      if( raw.length > 0 ) {\n        allstats.accumulate(raw);\n      } else {\n        allstats.missing();\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n      FieldType facetFieldType = fsf.getType();\n\n      if (facetFieldType.isTokenized() || facetFieldType.isMultiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField\n          + \"[\" + facetFieldType + \"]\");\n        }\n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = si.lookup(si.getOrd(docID), tempBR);\n      if( raw.length > 0 ) {\n        allstats.accumulate(raw);\n      } else {\n        allstats.missing();\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6e2893fd5349134af382d33ccc3d84840394c6c1","date":1353682567,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      int docOrd = si.getOrd(docID);\n      BytesRef raw;\n      if (docOrd == -1) {\n        allstats.missing();\n        tempBR.length = 0;\n        raw = tempBR;\n      } else {\n        raw = si.lookup(docOrd, tempBR);\n        if( raw.length > 0 ) {\n          allstats.accumulate(raw);\n        } else {\n          allstats.missing();\n        }\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n\n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = si.lookup(si.getOrd(docID), tempBR);\n      if( raw.length > 0 ) {\n        allstats.accumulate(raw);\n      } else {\n        allstats.missing();\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9d7e5f3aa5935964617824d1f9b2599ddb334464","date":1353762831,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    SortedDocValues si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.getValueCount();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    SortedDocValues facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      int docOrd = si.getOrd(docID);\n      BytesRef raw;\n      if (docOrd == -1) {\n        allstats.missing();\n        tempBR.length = 0;\n        raw = tempBR;\n      } else {\n        raw = tempBR;\n        si.lookupOrd(docOrd, tempBR);\n        if( tempBR.length > 0 ) {\n          allstats.accumulate(tempBR);\n        } else {\n          allstats.missing();\n        }\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      int docOrd = si.getOrd(docID);\n      BytesRef raw;\n      if (docOrd == -1) {\n        allstats.missing();\n        tempBR.length = 0;\n        raw = tempBR;\n      } else {\n        raw = si.lookup(docOrd, tempBR);\n        if( raw.length > 0 ) {\n          allstats.accumulate(raw);\n        } else {\n          allstats.missing();\n        }\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    SortedDocValues si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.getValueCount();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    SortedDocValues facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      int docOrd = si.getOrd(docID);\n      BytesRef raw;\n      if (docOrd == -1) {\n        allstats.missing();\n        tempBR.length = 0;\n        raw = tempBR;\n      } else {\n        raw = tempBR;\n        si.lookupOrd(docOrd, tempBR);\n        if( tempBR.length > 0 ) {\n          allstats.accumulate(tempBR);\n        } else {\n          allstats.missing();\n        }\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    FieldCache.DocTermsIndex si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.numOrd();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    FieldCache.DocTermsIndex facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n\n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      BytesRef raw = si.lookup(si.getOrd(docID), tempBR);\n      if( raw.length > 0 ) {\n        allstats.accumulate(raw);\n      } else {\n        allstats.missing();\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":["11982a7b6834a8571852448312db4624c32990b5","e0781eeef93647a16405c13e217b095865562dd1"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"73bb5a57dc75b54a39494f99986599cae7dff417","date":1361040620,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet) throws IOException {\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n\n    final StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n\n      facetStats.add(new FieldFacetStats(searcher, facetField, sf, fsf));\n    }\n\n    final Iterator<AtomicReaderContext> ctxIt = searcher.getIndexReader().leaves().iterator();\n    AtomicReaderContext ctx = null;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        // advance\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n\n        // propagate the context among accumulators.\n        allstats.setNextReader(ctx);\n        for (FieldFacetStats f : facetStats) {\n          f.setNextReader(ctx);\n        }\n      }\n\n      // accumulate\n      allstats.accumulate(doc - ctx.docBase);\n      for (FieldFacetStats f : facetStats) {\n        f.facet(doc - ctx.docBase);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    SortedDocValues si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.getValueCount();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    SortedDocValues facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      int docOrd = si.getOrd(docID);\n      BytesRef raw;\n      if (docOrd == -1) {\n        allstats.missing();\n        tempBR.length = 0;\n        raw = tempBR;\n      } else {\n        raw = tempBR;\n        si.lookupOrd(docOrd, tempBR);\n        if( tempBR.length > 0 ) {\n          allstats.accumulate(tempBR);\n        } else {\n          allstats.missing();\n        }\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"95303ff3749680c743b9425f9cf99e6e4065e8a8","date":1361061922,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet) throws IOException {\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n\n    final StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n\n      facetStats.add(new FieldFacetStats(searcher, facetField, sf, fsf));\n    }\n\n    final Iterator<AtomicReaderContext> ctxIt = searcher.getIndexReader().leaves().iterator();\n    AtomicReaderContext ctx = null;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        // advance\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n\n        // propagate the context among accumulators.\n        allstats.setNextReader(ctx);\n        for (FieldFacetStats f : facetStats) {\n          f.setNextReader(ctx);\n        }\n      }\n\n      // accumulate\n      allstats.accumulate(doc - ctx.docBase);\n      for (FieldFacetStats f : facetStats) {\n        f.facet(doc - ctx.docBase);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  // why does this use a top-level field cache?\n  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet ) {\n    SchemaField sf = searcher.getSchema().getField(fieldName);\n    \n    SortedDocValues si;\n    try {\n      si = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), fieldName);\n    } \n    catch (IOException e) {\n      throw new RuntimeException( \"failed to open field cache for: \"+fieldName, e );\n    }\n    StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n    final int nTerms = si.getValueCount();\n    if ( nTerms <= 0 || docs.size() <= 0 ) return allstats.getStatsValues();\n\n    // don't worry about faceting if no documents match...\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    SortedDocValues facetTermsIndex;\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n      \n      try {\n        facetTermsIndex = FieldCache.DEFAULT.getTermsIndex(searcher.getAtomicReader(), facetField);\n      }\n      catch (IOException e) {\n        throw new RuntimeException( \"failed to open field cache for: \"\n          + facetField, e );\n      }\n      facetStats.add(new FieldFacetStats(facetField, facetTermsIndex, sf, fsf, nTerms));\n    }\n    \n    final BytesRef tempBR = new BytesRef();\n    DocIterator iter = docs.iterator();\n    while (iter.hasNext()) {\n      int docID = iter.nextDoc();\n      int docOrd = si.getOrd(docID);\n      BytesRef raw;\n      if (docOrd == -1) {\n        allstats.missing();\n        tempBR.length = 0;\n        raw = tempBR;\n      } else {\n        raw = tempBR;\n        si.lookupOrd(docOrd, tempBR);\n        if( tempBR.length > 0 ) {\n          allstats.accumulate(tempBR);\n        } else {\n          allstats.missing();\n        }\n      }\n\n      // now update the facets\n      for (FieldFacetStats f : facetStats) {\n        f.facet(docID, raw);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"08970e5b8411182a29412c177eff67ec1110095b","date":1366640815,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet) throws IOException {\n    IndexSchema schema = searcher.getSchema();\n    final SchemaField sf = schema.getField(fieldName);\n\n    final StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    for( String facetField : facet ) {\n      SchemaField fsf = schema.getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n\n      facetStats.add(new FieldFacetStats(searcher, facetField, sf, fsf));\n    }\n\n    final Iterator<AtomicReaderContext> ctxIt = searcher.getIndexReader().leaves().iterator();\n    AtomicReaderContext ctx = null;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        // advance\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n\n        // propagate the context among accumulators.\n        allstats.setNextReader(ctx);\n        for (FieldFacetStats f : facetStats) {\n          f.setNextReader(ctx);\n        }\n      }\n\n      // accumulate\n      allstats.accumulate(doc - ctx.docBase);\n      for (FieldFacetStats f : facetStats) {\n        f.facet(doc - ctx.docBase);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet) throws IOException {\n    final SchemaField sf = searcher.getSchema().getField(fieldName);\n\n    final StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    for( String facetField : facet ) {\n      SchemaField fsf = searcher.getSchema().getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n\n      facetStats.add(new FieldFacetStats(searcher, facetField, sf, fsf));\n    }\n\n    final Iterator<AtomicReaderContext> ctxIt = searcher.getIndexReader().leaves().iterator();\n    AtomicReaderContext ctx = null;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        // advance\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n\n        // propagate the context among accumulators.\n        allstats.setNextReader(ctx);\n        for (FieldFacetStats f : facetStats) {\n          f.setNextReader(ctx);\n        }\n      }\n\n      // accumulate\n      allstats.accumulate(doc - ctx.docBase);\n      for (FieldFacetStats f : facetStats) {\n        f.facet(doc - ctx.docBase);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bf795ee457272965bd751f513787065bbf0a650a","date":1385015231,"type":5,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,boolean,String[]).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":"  public NamedList<?> getFieldCacheStats(String fieldName, boolean calcDistinct, String[] facet) throws IOException {\n    IndexSchema schema = searcher.getSchema();\n    final SchemaField sf = schema.getField(fieldName);\n\n    final StatsValues allstats = StatsValuesFactory.createStatsValues(sf, calcDistinct);\n\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    for( String facetField : facet ) {\n      SchemaField fsf = schema.getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n\n      facetStats.add(new FieldFacetStats(searcher, facetField, sf, fsf, calcDistinct));\n    }\n\n    final Iterator<AtomicReaderContext> ctxIt = searcher.getIndexReader().leaves().iterator();\n    AtomicReaderContext ctx = null;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        // advance\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n\n        // propagate the context among accumulators.\n        allstats.setNextReader(ctx);\n        for (FieldFacetStats f : facetStats) {\n          f.setNextReader(ctx);\n        }\n      }\n\n      // accumulate\n      allstats.accumulate(doc - ctx.docBase);\n      for (FieldFacetStats f : facetStats) {\n        f.facet(doc - ctx.docBase);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","sourceOld":"  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet) throws IOException {\n    IndexSchema schema = searcher.getSchema();\n    final SchemaField sf = schema.getField(fieldName);\n\n    final StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    for( String facetField : facet ) {\n      SchemaField fsf = schema.getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n\n      facetStats.add(new FieldFacetStats(searcher, facetField, sf, fsf));\n    }\n\n    final Iterator<AtomicReaderContext> ctxIt = searcher.getIndexReader().leaves().iterator();\n    AtomicReaderContext ctx = null;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        // advance\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n\n        // propagate the context among accumulators.\n        allstats.setNextReader(ctx);\n        for (FieldFacetStats f : facetStats) {\n          f.setNextReader(ctx);\n        }\n      }\n\n      // accumulate\n      allstats.accumulate(doc - ctx.docBase);\n      for (FieldFacetStats f : facetStats) {\n        f.facet(doc - ctx.docBase);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":4,"author":"Michael McCandless","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/handler/component/SimpleStats[StatsComponent]#getFieldCacheStats(String,String[]).mjava","sourceNew":null,"sourceOld":"  public NamedList<?> getFieldCacheStats(String fieldName, String[] facet) throws IOException {\n    IndexSchema schema = searcher.getSchema();\n    final SchemaField sf = schema.getField(fieldName);\n\n    final StatsValues allstats = StatsValuesFactory.createStatsValues(sf);\n\n    List<FieldFacetStats> facetStats = new ArrayList<FieldFacetStats>();\n    for( String facetField : facet ) {\n      SchemaField fsf = schema.getField(facetField);\n\n      if ( fsf.multiValued()) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n          \"Stats can only facet on single-valued fields, not: \" + facetField );\n      }\n\n      facetStats.add(new FieldFacetStats(searcher, facetField, sf, fsf));\n    }\n\n    final Iterator<AtomicReaderContext> ctxIt = searcher.getIndexReader().leaves().iterator();\n    AtomicReaderContext ctx = null;\n    for (DocIterator docsIt = docs.iterator(); docsIt.hasNext(); ) {\n      final int doc = docsIt.nextDoc();\n      if (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc()) {\n        // advance\n        do {\n          ctx = ctxIt.next();\n        } while (ctx == null || doc >= ctx.docBase + ctx.reader().maxDoc());\n        assert doc >= ctx.docBase;\n\n        // propagate the context among accumulators.\n        allstats.setNextReader(ctx);\n        for (FieldFacetStats f : facetStats) {\n          f.setNextReader(ctx);\n        }\n      }\n\n      // accumulate\n      allstats.accumulate(doc - ctx.docBase);\n      for (FieldFacetStats f : facetStats) {\n        f.facet(doc - ctx.docBase);\n      }\n    }\n\n    for (FieldFacetStats f : facetStats) {\n      allstats.addFacet(f.name, f.facetStatsValues);\n    }\n    return allstats.getStatsValues();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6e2893fd5349134af382d33ccc3d84840394c6c1":["e0781eeef93647a16405c13e217b095865562dd1"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"96d207426bd26fa5c1014e26d21d87603aea68b7":["2dd6ecb8250c497ed227653279d6a4f470bfbb31"],"e0781eeef93647a16405c13e217b095865562dd1":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"bf795ee457272965bd751f513787065bbf0a650a":["08970e5b8411182a29412c177eff67ec1110095b"],"2dd6ecb8250c497ed227653279d6a4f470bfbb31":["11982a7b6834a8571852448312db4624c32990b5"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["2dd6ecb8250c497ed227653279d6a4f470bfbb31","96d207426bd26fa5c1014e26d21d87603aea68b7"],"08970e5b8411182a29412c177eff67ec1110095b":["73bb5a57dc75b54a39494f99986599cae7dff417"],"aba371508186796cc6151d8223a5b4e16d02e26e":["5cab9a86bd67202d20b6adc463008c8e982b070a","e0781eeef93647a16405c13e217b095865562dd1"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["e0781eeef93647a16405c13e217b095865562dd1","9d7e5f3aa5935964617824d1f9b2599ddb334464"],"95303ff3749680c743b9425f9cf99e6e4065e8a8":["d4d69c535930b5cce125cff868d40f6373dc27d4","73bb5a57dc75b54a39494f99986599cae7dff417"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9d7e5f3aa5935964617824d1f9b2599ddb334464":["6e2893fd5349134af382d33ccc3d84840394c6c1"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["08970e5b8411182a29412c177eff67ec1110095b","bf795ee457272965bd751f513787065bbf0a650a"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":["5cab9a86bd67202d20b6adc463008c8e982b070a","e0781eeef93647a16405c13e217b095865562dd1"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bf795ee457272965bd751f513787065bbf0a650a"],"73bb5a57dc75b54a39494f99986599cae7dff417":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"11982a7b6834a8571852448312db4624c32990b5":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"6e2893fd5349134af382d33ccc3d84840394c6c1":["9d7e5f3aa5935964617824d1f9b2599ddb334464"],"c26f00b574427b55127e869b935845554afde1fa":["11982a7b6834a8571852448312db4624c32990b5"],"96d207426bd26fa5c1014e26d21d87603aea68b7":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"e0781eeef93647a16405c13e217b095865562dd1":["6e2893fd5349134af382d33ccc3d84840394c6c1","aba371508186796cc6151d8223a5b4e16d02e26e","d4d69c535930b5cce125cff868d40f6373dc27d4","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7"],"bf795ee457272965bd751f513787065bbf0a650a":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2dd6ecb8250c497ed227653279d6a4f470bfbb31":["96d207426bd26fa5c1014e26d21d87603aea68b7","5cab9a86bd67202d20b6adc463008c8e982b070a"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["e0781eeef93647a16405c13e217b095865562dd1","aba371508186796cc6151d8223a5b4e16d02e26e","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7"],"08970e5b8411182a29412c177eff67ec1110095b":["bf795ee457272965bd751f513787065bbf0a650a","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"aba371508186796cc6151d8223a5b4e16d02e26e":[],"d4d69c535930b5cce125cff868d40f6373dc27d4":["95303ff3749680c743b9425f9cf99e6e4065e8a8","73bb5a57dc75b54a39494f99986599cae7dff417"],"95303ff3749680c743b9425f9cf99e6e4065e8a8":[],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"9d7e5f3aa5935964617824d1f9b2599ddb334464":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"11982a7b6834a8571852448312db4624c32990b5":["2dd6ecb8250c497ed227653279d6a4f470bfbb31"],"73bb5a57dc75b54a39494f99986599cae7dff417":["08970e5b8411182a29412c177eff67ec1110095b","95303ff3749680c743b9425f9cf99e6e4065e8a8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["aba371508186796cc6151d8223a5b4e16d02e26e","95303ff3749680c743b9425f9cf99e6e4065e8a8","74f45af4339b0daf7a95c820ab88c1aea74fbce0","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}