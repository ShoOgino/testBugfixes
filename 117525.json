{"path":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) throws IOException {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) throws IOException {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4d3e8520fd031bab31fd0e4d480e55958bc45efe","date":1340901565,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) throws IOException {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","bugFix":["60ba444201d2570214b6fcf1d15600dc1a01f548","744486748bc5bee772100e49230e5bca39bac99a"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) throws IOException {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dcc555744b1a581a4beccd0b75f8d3fe49735a2f","date":1367588265,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5","date":1379624229,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","bugFix":null,"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","bugFix":["60ba444201d2570214b6fcf1d15600dc1a01f548","e6e919043fa85ee891123768dd655a98edbbf63c","744486748bc5bee772100e49230e5bca39bac99a","519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9f7c14f40c65357617cada58ca9b026ab9f81c24","date":1432120112,"type":3,"author":"Mark Harwood","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n    \n    adjustScoreTerms(reader, scoreTerms);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","bugFix":["60ba444201d2570214b6fcf1d15600dc1a01f548"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f68d01cf19df971dcdcb05e30247f4ad7ec9747","date":1434611645,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final B b = getTopLevelBuilder();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n    \n    adjustScoreTerms(reader, scoreTerms);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      addClause(b, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return build(b);\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n    \n    adjustScoreTerms(reader, scoreTerms);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2e0b693f44c4d48acb66e289f04ec7309118a1a","date":1437989791,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final B b = getTopLevelBuilder();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      addClause(b, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return build(b);\n  }\n\n","sourceOld":"  @Override\n  public final Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final B b = getTopLevelBuilder();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n    \n    adjustScoreTerms(reader, scoreTerms);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      addClause(b, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return build(b);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2dfdf766e55e943d942055d7de53c7ad6bc45283","date":1441632886,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final B b = getTopLevelBuilder();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      addClause(b, term, st.termState.docFreq(), st.boost, st.termState); // add to query\n    }\n    return build(b);\n  }\n\n","sourceOld":"  @Override\n  public final Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final B b = getTopLevelBuilder();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      addClause(b, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return build(b);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7d3dec8619cc5a67c810bd49ad697d0170a32637","date":1473965066,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final B b = getTopLevelBuilder();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      // We allow negative term scores (fuzzy query does this, for example) while collecting the terms,\n      // but truncate such boosts to 0.0f when building the query:\n      addClause(b, term, st.termState.docFreq(), Math.max(0.0f, st.boost), st.termState); // add to query\n    }\n    return build(b);\n  }\n\n","sourceOld":"  @Override\n  public final Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final B b = getTopLevelBuilder();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      addClause(b, term, st.termState.docFreq(), st.boost, st.termState); // add to query\n    }\n    return build(b);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final B b = getTopLevelBuilder();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      // We allow negative term scores (fuzzy query does this, for example) while collecting the terms,\n      // but truncate such boosts to 0.0f when building the query:\n      addClause(b, term, st.termState.docFreq(), Math.max(0.0f, st.boost), st.termState); // add to query\n    }\n    return build(b);\n  }\n\n","sourceOld":"  @Override\n  public final Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final B b = getTopLevelBuilder();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      addClause(b, term, st.termState.docFreq(), st.boost, st.termState); // add to query\n    }\n    return build(b);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final B b = getTopLevelBuilder();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      // We allow negative term scores (fuzzy query does this, for example) while collecting the terms,\n      // but truncate such boosts to 0.0f when building the query:\n      addClause(b, term, st.termState.docFreq(), Math.max(0.0f, st.boost), st.termState); // add to query\n    }\n    return build(b);\n  }\n\n","sourceOld":"  @Override\n  public final Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final B b = getTopLevelBuilder();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      addClause(b, term, st.termState.docFreq(), st.boost, st.termState); // add to query\n    }\n    return build(b);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a6e9f769521480a623f897c0d59089b919fa4239","date":1515161835,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermStates(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermStates(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final B b = getTopLevelBuilder();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      // We allow negative term scores (fuzzy query does this, for example) while collecting the terms,\n      // but truncate such boosts to 0.0f when building the query:\n      addClause(b, term, st.termState.docFreq(), Math.max(0.0f, st.boost), st.termState); // add to query\n    }\n    return build(b);\n  }\n\n","sourceOld":"  @Override\n  public final Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final B b = getTopLevelBuilder();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      // We allow negative term scores (fuzzy query does this, for example) while collecting the terms,\n      // but truncate such boosts to 0.0f when building the query:\n      addClause(b, term, st.termState.docFreq(), Math.max(0.0f, st.boost), st.termState); // add to query\n    }\n    return build(b);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermStates(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermStates(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final B b = getTopLevelBuilder();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      // We allow negative term scores (fuzzy query does this, for example) while collecting the terms,\n      // but truncate such boosts to 0.0f when building the query:\n      addClause(b, term, st.termState.docFreq(), Math.max(0.0f, st.boost), st.termState); // add to query\n    }\n    return build(b);\n  }\n\n","sourceOld":"  @Override\n  public final Query rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<>();\n      \n      private TermsEnum termsEnum;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) {\n        this.termsEnum = termsEnum;\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRefBuilder lastTerm;\n      private boolean compareToLastTerm(BytesRef t) {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRefBuilder();\n          lastTerm.append(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert lastTerm.get().compareTo(t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && bytes.compareTo(t.bytes.get()) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes.get(), st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes.get());\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes.get());\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final B b = getTopLevelBuilder();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.timSort(scoreTerms, scoreTermSortByTermComp);\n\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes.toBytesRef());\n      // We allow negative term scores (fuzzy query does this, for example) while collecting the terms,\n      // but truncate such boosts to 0.0f when building the query:\n      addClause(b, term, st.termState.docFreq(), Math.max(0.0f, st.boost), st.termState); // add to query\n    }\n    return build(b);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5"],"b94236357aaa22b76c10629851fe4e376e0cea82":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","a6e9f769521480a623f897c0d59089b919fa4239"],"9f7c14f40c65357617cada58ca9b026ab9f81c24":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"7d3dec8619cc5a67c810bd49ad697d0170a32637":["2dfdf766e55e943d942055d7de53c7ad6bc45283"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2dfdf766e55e943d942055d7de53c7ad6bc45283":["f2e0b693f44c4d48acb66e289f04ec7309118a1a"],"f2e0b693f44c4d48acb66e289f04ec7309118a1a":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["2dfdf766e55e943d942055d7de53c7ad6bc45283","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["9f7c14f40c65357617cada58ca9b026ab9f81c24"],"a6e9f769521480a623f897c0d59089b919fa4239":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5":["dcc555744b1a581a4beccd0b75f8d3fe49735a2f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["2dfdf766e55e943d942055d7de53c7ad6bc45283","7d3dec8619cc5a67c810bd49ad697d0170a32637"],"dcc555744b1a581a4beccd0b75f8d3fe49735a2f":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b94236357aaa22b76c10629851fe4e376e0cea82"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"b94236357aaa22b76c10629851fe4e376e0cea82":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9f7c14f40c65357617cada58ca9b026ab9f81c24":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"],"7d3dec8619cc5a67c810bd49ad697d0170a32637":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["fe33227f6805edab2036cbb80645cc4e2d1fa424","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"2dfdf766e55e943d942055d7de53c7ad6bc45283":["7d3dec8619cc5a67c810bd49ad697d0170a32637","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["9f7c14f40c65357617cada58ca9b026ab9f81c24"],"f2e0b693f44c4d48acb66e289f04ec7309118a1a":["2dfdf766e55e943d942055d7de53c7ad6bc45283"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["f2e0b693f44c4d48acb66e289f04ec7309118a1a"],"a6e9f769521480a623f897c0d59089b919fa4239":["b94236357aaa22b76c10629851fe4e376e0cea82"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["b94236357aaa22b76c10629851fe4e376e0cea82","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","a6e9f769521480a623f897c0d59089b919fa4239"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"dcc555744b1a581a4beccd0b75f8d3fe49735a2f":["519bac5f6a2dc1779d2fe8e51d9e1762ec94b4a5"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["fe33227f6805edab2036cbb80645cc4e2d1fa424","dcc555744b1a581a4beccd0b75f8d3fe49735a2f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}