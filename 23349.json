{"path":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","commits":[{"id":"02a71af6b0525092e8cdc9e3649fa77150cc7814","date":1115339520,"type":1,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","pathOld":"contrib/wordnetlc/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","sourceNew":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param field optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString field,\n\t\t\t\t\t\t\t\tfloat boost)\n\t\tthrows IOException\n\t{\n\t\tSet already = new HashSet(); // avoid dups \n\t\tList top = new LinkedList(); // needs to be separately listed..\n\t\tif ( field == null) field = \"contents\";\n\t\tif ( a == null) a = new StandardAnalyzer();\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\torg.apache.lucene.analysis.Token t;\n\t\twhile ( (t = ts.next()) != null)\n\t\t{\n\t\t\tString word = t.termText();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tBooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\t// [2b] add in unique synonums\n\t\t\tHits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));\n\t\t\tfor (int i = 0; i < hits.length(); i++)\n\t\t\t{\n\t\t\t\tDocument doc = hits.doc(i);\n\t\t\t\tString[] values = doc.getValues( Syns2Index.F_SYN);\n\t\t\t\tfor ( int j = 0; j < values.length; j++)\n\t\t\t\t{\n\t\t\t\t\tString syn = values[ j];\n\t\t\t\t\tif ( already.add( syn)) // avoid dups of top level words and synonyms\n\t\t\t\t\t{\n\t\t\t\t\t\ttq = new TermQuery( new Term( field, syn));\n\t\t\t\t\t\tif ( boost > 0) // else keep normal 1.0\n\t\t\t\t\t\t\ttq.setBoost( boost);\n\t\t\t\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD); \n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","sourceOld":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param field optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString field,\n\t\t\t\t\t\t\t\tfloat boost)\n\t\tthrows IOException\n\t{\n\t\tSet already = new HashSet(); // avoid dups \n\t\tList top = new LinkedList(); // needs to be separately listed..\n\t\tif ( field == null) field = \"contents\";\n\t\tif ( a == null) a = new StandardAnalyzer();\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\torg.apache.lucene.analysis.Token t;\n\t\twhile ( (t = ts.next()) != null)\n\t\t{\n\t\t\tString word = t.termText();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tBooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\t// [2b] add in unique synonums\n\t\t\tHits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));\n\t\t\tfor (int i = 0; i < hits.length(); i++)\n\t\t\t{\n\t\t\t\tDocument doc = hits.doc(i);\n\t\t\t\tString[] values = doc.getValues( Syns2Index.F_SYN);\n\t\t\t\tfor ( int j = 0; j < values.length; j++)\n\t\t\t\t{\n\t\t\t\t\tString syn = values[ j];\n\t\t\t\t\tif ( already.add( syn)) // avoid dups of top level words and synonyms\n\t\t\t\t\t{\n\t\t\t\t\t\ttq = new TermQuery( new Term( field, syn));\n\t\t\t\t\t\tif ( boost > 0) // else keep normal 1.0\n\t\t\t\t\t\t\ttq.setBoost( boost);\n\t\t\t\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD); \n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e2cb543b41c145f33390f460ee743d6693c9c6c","date":1219243087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","pathOld":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","sourceNew":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param field optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString field,\n\t\t\t\t\t\t\t\tfloat boost)\n\t\tthrows IOException\n\t{\n\t\tSet already = new HashSet(); // avoid dups \n\t\tList top = new LinkedList(); // needs to be separately listed..\n\t\tif ( field == null) field = \"contents\";\n\t\tif ( a == null) a = new StandardAnalyzer();\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n                \n                final Token reusableToken = new Token();\n\t\tfor (Token nextToken = ts.next(reusableToken); nextToken != null; nextToken = ts.next(reusableToken)) {\n\t\t\tString word = nextToken.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tBooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\t// [2b] add in unique synonums\n\t\t\tHits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));\n\t\t\tfor (int i = 0; i < hits.length(); i++)\n\t\t\t{\n\t\t\t\tDocument doc = hits.doc(i);\n\t\t\t\tString[] values = doc.getValues( Syns2Index.F_SYN);\n\t\t\t\tfor ( int j = 0; j < values.length; j++)\n\t\t\t\t{\n\t\t\t\t\tString syn = values[ j];\n\t\t\t\t\tif ( already.add( syn)) // avoid dups of top level words and synonyms\n\t\t\t\t\t{\n\t\t\t\t\t\ttq = new TermQuery( new Term( field, syn));\n\t\t\t\t\t\tif ( boost > 0) // else keep normal 1.0\n\t\t\t\t\t\t\ttq.setBoost( boost);\n\t\t\t\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD); \n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","sourceOld":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param field optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString field,\n\t\t\t\t\t\t\t\tfloat boost)\n\t\tthrows IOException\n\t{\n\t\tSet already = new HashSet(); // avoid dups \n\t\tList top = new LinkedList(); // needs to be separately listed..\n\t\tif ( field == null) field = \"contents\";\n\t\tif ( a == null) a = new StandardAnalyzer();\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\torg.apache.lucene.analysis.Token t;\n\t\twhile ( (t = ts.next()) != null)\n\t\t{\n\t\t\tString word = t.termText();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tBooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\t// [2b] add in unique synonums\n\t\t\tHits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));\n\t\t\tfor (int i = 0; i < hits.length(); i++)\n\t\t\t{\n\t\t\t\tDocument doc = hits.doc(i);\n\t\t\t\tString[] values = doc.getValues( Syns2Index.F_SYN);\n\t\t\t\tfor ( int j = 0; j < values.length; j++)\n\t\t\t\t{\n\t\t\t\t\tString syn = values[ j];\n\t\t\t\t\tif ( already.add( syn)) // avoid dups of top level words and synonyms\n\t\t\t\t\t{\n\t\t\t\t\t\ttq = new TermQuery( new Term( field, syn));\n\t\t\t\t\t\tif ( boost > 0) // else keep normal 1.0\n\t\t\t\t\t\t\ttq.setBoost( boost);\n\t\t\t\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD); \n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9b5756469957918cac40a831acec9cf01c8c2bb3","date":1249167152,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","pathOld":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","sourceNew":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param field optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString field,\n\t\t\t\t\t\t\t\tfloat boost)\n\t\tthrows IOException\n\t{\n\t\tSet already = new HashSet(); // avoid dups \n\t\tList top = new LinkedList(); // needs to be separately listed..\n\t\tif ( field == null) field = \"contents\";\n\t\tif ( a == null) a = new StandardAnalyzer();\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\tTermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n\t\t\n\t\twhile (ts.incrementToken()) {\n\t\t  String word = termAtt.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tBooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\t// [2b] add in unique synonums\n\t\t\tHits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));\n\t\t\tfor (int i = 0; i < hits.length(); i++)\n\t\t\t{\n\t\t\t\tDocument doc = hits.doc(i);\n\t\t\t\tString[] values = doc.getValues( Syns2Index.F_SYN);\n\t\t\t\tfor ( int j = 0; j < values.length; j++)\n\t\t\t\t{\n\t\t\t\t\tString syn = values[ j];\n\t\t\t\t\tif ( already.add( syn)) // avoid dups of top level words and synonyms\n\t\t\t\t\t{\n\t\t\t\t\t\ttq = new TermQuery( new Term( field, syn));\n\t\t\t\t\t\tif ( boost > 0) // else keep normal 1.0\n\t\t\t\t\t\t\ttq.setBoost( boost);\n\t\t\t\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD); \n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","sourceOld":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param field optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString field,\n\t\t\t\t\t\t\t\tfloat boost)\n\t\tthrows IOException\n\t{\n\t\tSet already = new HashSet(); // avoid dups \n\t\tList top = new LinkedList(); // needs to be separately listed..\n\t\tif ( field == null) field = \"contents\";\n\t\tif ( a == null) a = new StandardAnalyzer();\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n                \n                final Token reusableToken = new Token();\n\t\tfor (Token nextToken = ts.next(reusableToken); nextToken != null; nextToken = ts.next(reusableToken)) {\n\t\t\tString word = nextToken.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tBooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\t// [2b] add in unique synonums\n\t\t\tHits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));\n\t\t\tfor (int i = 0; i < hits.length(); i++)\n\t\t\t{\n\t\t\t\tDocument doc = hits.doc(i);\n\t\t\t\tString[] values = doc.getValues( Syns2Index.F_SYN);\n\t\t\t\tfor ( int j = 0; j < values.length; j++)\n\t\t\t\t{\n\t\t\t\t\tString syn = values[ j];\n\t\t\t\t\tif ( already.add( syn)) // avoid dups of top level words and synonyms\n\t\t\t\t\t{\n\t\t\t\t\t\ttq = new TermQuery( new Term( field, syn));\n\t\t\t\t\t\tif ( boost > 0) // else keep normal 1.0\n\t\t\t\t\t\t\ttq.setBoost( boost);\n\t\t\t\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD); \n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8d78f014fded44fbde905f4f84cdc21907b371e8","date":1254383623,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","pathOld":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","sourceNew":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param field optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString field,\n\t\t\t\t\t\t\t\tfloat boost)\n\t\tthrows IOException\n\t{\n\t\tSet already = new HashSet(); // avoid dups \n\t\tList top = new LinkedList(); // needs to be separately listed..\n\t\tif ( field == null) field = \"contents\";\n\t\tif ( a == null) a = new StandardAnalyzer();\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\tTermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n\t\t\n\t\twhile (ts.incrementToken()) {\n\t\t  String word = termAtt.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tBooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\t// [2b] add in unique synonums\n\t\t\tHits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));\n\t\t\tfor (int i = 0; i < hits.length(); i++)\n\t\t\t{\n\t\t\t\tDocument doc = hits.doc(i);\n\t\t\t\tString[] values = doc.getValues( Syns2Index.F_SYN);\n\t\t\t\tfor ( int j = 0; j < values.length; j++)\n\t\t\t\t{\n\t\t\t\t\tString syn = values[ j];\n\t\t\t\t\tif ( already.add( syn)) // avoid dups of top level words and synonyms\n\t\t\t\t\t{\n\t\t\t\t\t\ttq = new TermQuery( new Term( field, syn));\n\t\t\t\t\t\tif ( boost > 0) // else keep normal 1.0\n\t\t\t\t\t\t\ttq.setBoost( boost);\n\t\t\t\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD); \n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","sourceOld":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param field optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString field,\n\t\t\t\t\t\t\t\tfloat boost)\n\t\tthrows IOException\n\t{\n\t\tSet already = new HashSet(); // avoid dups \n\t\tList top = new LinkedList(); // needs to be separately listed..\n\t\tif ( field == null) field = \"contents\";\n\t\tif ( a == null) a = new StandardAnalyzer();\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\tTermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);\n\t\t\n\t\twhile (ts.incrementToken()) {\n\t\t  String word = termAtt.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tBooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\t// [2b] add in unique synonums\n\t\t\tHits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));\n\t\t\tfor (int i = 0; i < hits.length(); i++)\n\t\t\t{\n\t\t\t\tDocument doc = hits.doc(i);\n\t\t\t\tString[] values = doc.getValues( Syns2Index.F_SYN);\n\t\t\t\tfor ( int j = 0; j < values.length; j++)\n\t\t\t\t{\n\t\t\t\t\tString syn = values[ j];\n\t\t\t\t\tif ( already.add( syn)) // avoid dups of top level words and synonyms\n\t\t\t\t\t{\n\t\t\t\t\t\ttq = new TermQuery( new Term( field, syn));\n\t\t\t\t\t\tif ( boost > 0) // else keep normal 1.0\n\t\t\t\t\t\t\ttq.setBoost( boost);\n\t\t\t\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD); \n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f148c02ddd6ba981c65ca685d0e56c3a98368e1","date":1254892102,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","pathOld":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","sourceNew":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param field optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString f,\n\t\t\t\t\t\t\t\tfinal float boost)\n\t\tthrows IOException\n\t{\n\t\tfinal Set already = new HashSet(); // avoid dups \n\t\tList top = new LinkedList(); // needs to be separately listed..\n\t\tfinal String field = ( f == null) ? \"contents\" : f;\n\t\tif ( a == null) a = new StandardAnalyzer();\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\tTermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n\t\t\n\t\twhile (ts.incrementToken()) {\n\t\t  String word = termAtt.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tfinal BooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\tsyns.search(new TermQuery( new Term(Syns2Index.F_WORD, word)), new Collector() {\n\t\t\t  IndexReader reader;\n\t\t\t  \n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int doc) throws IOException {\n          Document d = reader.document(doc);\n          String[] values = d.getValues( Syns2Index.F_SYN);\n          for ( int j = 0; j < values.length; j++)\n          {\n            String syn = values[ j];\n            if ( already.add( syn)) // avoid dups of top level words and synonyms\n            {\n              TermQuery tq = new TermQuery( new Term( field, syn));\n              if ( boost > 0) // else keep normal 1.0\n                tq.setBoost( boost);\n              tmp.add( tq, BooleanClause.Occur.SHOULD); \n            }\n          }\n        }\n\n        @Override\n        public void setNextReader(IndexReader reader, int docBase)\n            throws IOException {\n          this.reader = reader;\n        }\n\n        @Override\n        public void setScorer(Scorer scorer) throws IOException {}\n\t\t\t});\n\t\t\t\n\t\t\t// [2b] add in unique synonums\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","sourceOld":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param field optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString field,\n\t\t\t\t\t\t\t\tfloat boost)\n\t\tthrows IOException\n\t{\n\t\tSet already = new HashSet(); // avoid dups \n\t\tList top = new LinkedList(); // needs to be separately listed..\n\t\tif ( field == null) field = \"contents\";\n\t\tif ( a == null) a = new StandardAnalyzer();\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\tTermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n\t\t\n\t\twhile (ts.incrementToken()) {\n\t\t  String word = termAtt.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tBooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\t// [2b] add in unique synonums\n\t\t\tHits hits = syns.search( new TermQuery( new Term(Syns2Index.F_WORD, word)));\n\t\t\tfor (int i = 0; i < hits.length(); i++)\n\t\t\t{\n\t\t\t\tDocument doc = hits.doc(i);\n\t\t\t\tString[] values = doc.getValues( Syns2Index.F_SYN);\n\t\t\t\tfor ( int j = 0; j < values.length; j++)\n\t\t\t\t{\n\t\t\t\t\tString syn = values[ j];\n\t\t\t\t\tif ( already.add( syn)) // avoid dups of top level words and synonyms\n\t\t\t\t\t{\n\t\t\t\t\t\ttq = new TermQuery( new Term( field, syn));\n\t\t\t\t\t\tif ( boost > 0) // else keep normal 1.0\n\t\t\t\t\t\t\ttq.setBoost( boost);\n\t\t\t\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD); \n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b41b991de69ba7b72d5e90cfcee25699a1a7fc9","date":1256127131,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","pathOld":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","sourceNew":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param field optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString f,\n\t\t\t\t\t\t\t\tfinal float boost)\n\t\tthrows IOException\n\t{\n\t\tfinal Set already = new HashSet(); // avoid dups \n\t\tList top = new LinkedList(); // needs to be separately listed..\n\t\tfinal String field = ( f == null) ? \"contents\" : f;\n\t\tif ( a == null) a = new StandardAnalyzer(Version.LUCENE_CURRENT);\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\tTermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n\t\t\n\t\twhile (ts.incrementToken()) {\n\t\t  String word = termAtt.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tfinal BooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\tsyns.search(new TermQuery( new Term(Syns2Index.F_WORD, word)), new Collector() {\n\t\t\t  IndexReader reader;\n\t\t\t  \n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int doc) throws IOException {\n          Document d = reader.document(doc);\n          String[] values = d.getValues( Syns2Index.F_SYN);\n          for ( int j = 0; j < values.length; j++)\n          {\n            String syn = values[ j];\n            if ( already.add( syn)) // avoid dups of top level words and synonyms\n            {\n              TermQuery tq = new TermQuery( new Term( field, syn));\n              if ( boost > 0) // else keep normal 1.0\n                tq.setBoost( boost);\n              tmp.add( tq, BooleanClause.Occur.SHOULD); \n            }\n          }\n        }\n\n        @Override\n        public void setNextReader(IndexReader reader, int docBase)\n            throws IOException {\n          this.reader = reader;\n        }\n\n        @Override\n        public void setScorer(Scorer scorer) throws IOException {}\n\t\t\t});\n\t\t\t\n\t\t\t// [2b] add in unique synonums\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","sourceOld":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param field optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString f,\n\t\t\t\t\t\t\t\tfinal float boost)\n\t\tthrows IOException\n\t{\n\t\tfinal Set already = new HashSet(); // avoid dups \n\t\tList top = new LinkedList(); // needs to be separately listed..\n\t\tfinal String field = ( f == null) ? \"contents\" : f;\n\t\tif ( a == null) a = new StandardAnalyzer();\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\tTermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n\t\t\n\t\twhile (ts.incrementToken()) {\n\t\t  String word = termAtt.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tfinal BooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\tsyns.search(new TermQuery( new Term(Syns2Index.F_WORD, word)), new Collector() {\n\t\t\t  IndexReader reader;\n\t\t\t  \n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int doc) throws IOException {\n          Document d = reader.document(doc);\n          String[] values = d.getValues( Syns2Index.F_SYN);\n          for ( int j = 0; j < values.length; j++)\n          {\n            String syn = values[ j];\n            if ( already.add( syn)) // avoid dups of top level words and synonyms\n            {\n              TermQuery tq = new TermQuery( new Term( field, syn));\n              if ( boost > 0) // else keep normal 1.0\n                tq.setBoost( boost);\n              tmp.add( tq, BooleanClause.Occur.SHOULD); \n            }\n          }\n        }\n\n        @Override\n        public void setNextReader(IndexReader reader, int docBase)\n            throws IOException {\n          this.reader = reader;\n        }\n\n        @Override\n        public void setScorer(Scorer scorer) throws IOException {}\n\t\t\t});\n\t\t\t\n\t\t\t// [2b] add in unique synonums\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d68e5c46e6a5ebdf4dafec4a123344092b915cc0","date":1256752193,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","pathOld":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","sourceNew":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param f optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString f,\n\t\t\t\t\t\t\t\tfinal float boost)\n\t\tthrows IOException\n\t{\n\t\tfinal Set already = new HashSet(); // avoid dups \n\t\tList top = new LinkedList(); // needs to be separately listed..\n\t\tfinal String field = ( f == null) ? \"contents\" : f;\n\t\tif ( a == null) a = new StandardAnalyzer(Version.LUCENE_CURRENT);\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\tTermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n\t\t\n\t\twhile (ts.incrementToken()) {\n\t\t  String word = termAtt.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tfinal BooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\tsyns.search(new TermQuery( new Term(Syns2Index.F_WORD, word)), new Collector() {\n\t\t\t  IndexReader reader;\n\t\t\t  \n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int doc) throws IOException {\n          Document d = reader.document(doc);\n          String[] values = d.getValues( Syns2Index.F_SYN);\n          for ( int j = 0; j < values.length; j++)\n          {\n            String syn = values[ j];\n            if ( already.add( syn)) // avoid dups of top level words and synonyms\n            {\n              TermQuery tq = new TermQuery( new Term( field, syn));\n              if ( boost > 0) // else keep normal 1.0\n                tq.setBoost( boost);\n              tmp.add( tq, BooleanClause.Occur.SHOULD); \n            }\n          }\n        }\n\n        @Override\n        public void setNextReader(IndexReader reader, int docBase)\n            throws IOException {\n          this.reader = reader;\n        }\n\n        @Override\n        public void setScorer(Scorer scorer) throws IOException {}\n\t\t\t});\n\t\t\t\n\t\t\t// [2b] add in unique synonums\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","sourceOld":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param field optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString f,\n\t\t\t\t\t\t\t\tfinal float boost)\n\t\tthrows IOException\n\t{\n\t\tfinal Set already = new HashSet(); // avoid dups \n\t\tList top = new LinkedList(); // needs to be separately listed..\n\t\tfinal String field = ( f == null) ? \"contents\" : f;\n\t\tif ( a == null) a = new StandardAnalyzer(Version.LUCENE_CURRENT);\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\tTermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n\t\t\n\t\twhile (ts.incrementToken()) {\n\t\t  String word = termAtt.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tfinal BooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\tsyns.search(new TermQuery( new Term(Syns2Index.F_WORD, word)), new Collector() {\n\t\t\t  IndexReader reader;\n\t\t\t  \n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int doc) throws IOException {\n          Document d = reader.document(doc);\n          String[] values = d.getValues( Syns2Index.F_SYN);\n          for ( int j = 0; j < values.length; j++)\n          {\n            String syn = values[ j];\n            if ( already.add( syn)) // avoid dups of top level words and synonyms\n            {\n              TermQuery tq = new TermQuery( new Term( field, syn));\n              if ( boost > 0) // else keep normal 1.0\n                tq.setBoost( boost);\n              tmp.add( tq, BooleanClause.Occur.SHOULD); \n            }\n          }\n        }\n\n        @Override\n        public void setNextReader(IndexReader reader, int docBase)\n            throws IOException {\n          this.reader = reader;\n        }\n\n        @Override\n        public void setScorer(Scorer scorer) throws IOException {}\n\t\t\t});\n\t\t\t\n\t\t\t// [2b] add in unique synonums\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c69d87d34a81230de56333f52f590caeb6d80667","date":1257848306,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","pathOld":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","sourceNew":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param f optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString f,\n\t\t\t\t\t\t\t\tfinal float boost)\n\t\tthrows IOException\n\t{\n\t\tfinal Set<String> already = new HashSet<String>(); // avoid dups \n\t\tList<String> top = new LinkedList<String>(); // needs to be separately listed..\n\t\tfinal String field = ( f == null) ? \"contents\" : f;\n\t\tif ( a == null) a = new StandardAnalyzer(Version.LUCENE_CURRENT);\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\tTermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n\t\t\n\t\twhile (ts.incrementToken()) {\n\t\t  String word = termAtt.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tfinal BooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator<String> it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\tsyns.search(new TermQuery( new Term(Syns2Index.F_WORD, word)), new Collector() {\n\t\t\t  IndexReader reader;\n\t\t\t  \n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int doc) throws IOException {\n          Document d = reader.document(doc);\n          String[] values = d.getValues( Syns2Index.F_SYN);\n          for ( int j = 0; j < values.length; j++)\n          {\n            String syn = values[ j];\n            if ( already.add( syn)) // avoid dups of top level words and synonyms\n            {\n              TermQuery tq = new TermQuery( new Term( field, syn));\n              if ( boost > 0) // else keep normal 1.0\n                tq.setBoost( boost);\n              tmp.add( tq, BooleanClause.Occur.SHOULD); \n            }\n          }\n        }\n\n        @Override\n        public void setNextReader(IndexReader reader, int docBase)\n            throws IOException {\n          this.reader = reader;\n        }\n\n        @Override\n        public void setScorer(Scorer scorer) throws IOException {}\n\t\t\t});\n\t\t\t\n\t\t\t// [2b] add in unique synonums\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","sourceOld":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param f optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString f,\n\t\t\t\t\t\t\t\tfinal float boost)\n\t\tthrows IOException\n\t{\n\t\tfinal Set already = new HashSet(); // avoid dups \n\t\tList top = new LinkedList(); // needs to be separately listed..\n\t\tfinal String field = ( f == null) ? \"contents\" : f;\n\t\tif ( a == null) a = new StandardAnalyzer(Version.LUCENE_CURRENT);\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\tTermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n\t\t\n\t\twhile (ts.incrementToken()) {\n\t\t  String word = termAtt.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tfinal BooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\tsyns.search(new TermQuery( new Term(Syns2Index.F_WORD, word)), new Collector() {\n\t\t\t  IndexReader reader;\n\t\t\t  \n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int doc) throws IOException {\n          Document d = reader.document(doc);\n          String[] values = d.getValues( Syns2Index.F_SYN);\n          for ( int j = 0; j < values.length; j++)\n          {\n            String syn = values[ j];\n            if ( already.add( syn)) // avoid dups of top level words and synonyms\n            {\n              TermQuery tq = new TermQuery( new Term( field, syn));\n              if ( boost > 0) // else keep normal 1.0\n                tq.setBoost( boost);\n              tmp.add( tq, BooleanClause.Occur.SHOULD); \n            }\n          }\n        }\n\n        @Override\n        public void setNextReader(IndexReader reader, int docBase)\n            throws IOException {\n          this.reader = reader;\n        }\n\n        @Override\n        public void setScorer(Scorer scorer) throws IOException {}\n\t\t\t});\n\t\t\t\n\t\t\t// [2b] add in unique synonums\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a","date":1267298041,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","pathOld":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","sourceNew":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param f optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString f,\n\t\t\t\t\t\t\t\tfinal float boost)\n\t\tthrows IOException\n\t{\n\t\tfinal Set<String> already = new HashSet<String>(); // avoid dups \n\t\tList<String> top = new LinkedList<String>(); // needs to be separately listed..\n\t\tfinal String field = ( f == null) ? \"contents\" : f;\n\t\tif ( a == null) a = new StandardAnalyzer(Version.LUCENE_CURRENT);\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\tTermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n\t\t\n\t\twhile (ts.incrementToken()) {\n\t\t  String word = termAtt.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tfinal BooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator<String> it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\tsyns.search(new TermQuery( new Term(Syns2Index.F_WORD, word)), new Collector() {\n\t\t\t  IndexReader reader;\n\t\t\t  \n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int doc) throws IOException {\n          Document d = reader.document(doc);\n          String[] values = d.getValues( Syns2Index.F_SYN);\n          for ( int j = 0; j < values.length; j++)\n          {\n            String syn = values[ j];\n            if ( already.add( syn)) // avoid dups of top level words and synonyms\n            {\n              TermQuery tq = new TermQuery( new Term( field, syn));\n              if ( boost > 0) // else keep normal 1.0\n                tq.setBoost( boost);\n              tmp.add( tq, BooleanClause.Occur.SHOULD); \n            }\n          }\n        }\n\n        @Override\n        public void setNextReader(IndexReader reader, int docBase)\n            throws IOException {\n          this.reader = reader;\n        }\n\n        @Override\n        public void setScorer(Scorer scorer) throws IOException {}\n\t\t\t});\n\t\t\t\n\t\t\t// [2b] add in unique synonums\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","sourceOld":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param f optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString f,\n\t\t\t\t\t\t\t\tfinal float boost)\n\t\tthrows IOException\n\t{\n\t\tfinal Set<String> already = new HashSet<String>(); // avoid dups \n\t\tList<String> top = new LinkedList<String>(); // needs to be separately listed..\n\t\tfinal String field = ( f == null) ? \"contents\" : f;\n\t\tif ( a == null) a = new StandardAnalyzer(Version.LUCENE_CURRENT);\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\tTermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n\t\t\n\t\twhile (ts.incrementToken()) {\n\t\t  String word = termAtt.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tfinal BooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator<String> it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = (String) it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\tsyns.search(new TermQuery( new Term(Syns2Index.F_WORD, word)), new Collector() {\n\t\t\t  IndexReader reader;\n\t\t\t  \n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int doc) throws IOException {\n          Document d = reader.document(doc);\n          String[] values = d.getValues( Syns2Index.F_SYN);\n          for ( int j = 0; j < values.length; j++)\n          {\n            String syn = values[ j];\n            if ( already.add( syn)) // avoid dups of top level words and synonyms\n            {\n              TermQuery tq = new TermQuery( new Term( field, syn));\n              if ( boost > 0) // else keep normal 1.0\n                tq.setBoost( boost);\n              tmp.add( tq, BooleanClause.Occur.SHOULD); \n            }\n          }\n        }\n\n        @Override\n        public void setNextReader(IndexReader reader, int docBase)\n            throws IOException {\n          this.reader = reader;\n        }\n\n        @Override\n        public void setScorer(Scorer scorer) throws IOException {}\n\t\t\t});\n\t\t\t\n\t\t\t// [2b] add in unique synonums\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","pathOld":"contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand#expand(String,Searcher,Analyzer,String,float).mjava","sourceNew":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param f optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString f,\n\t\t\t\t\t\t\t\tfinal float boost)\n\t\tthrows IOException\n\t{\n\t\tfinal Set<String> already = new HashSet<String>(); // avoid dups \n\t\tList<String> top = new LinkedList<String>(); // needs to be separately listed..\n\t\tfinal String field = ( f == null) ? \"contents\" : f;\n\t\tif ( a == null) a = new StandardAnalyzer(Version.LUCENE_CURRENT);\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\tTermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n\t\t\n\t\twhile (ts.incrementToken()) {\n\t\t  String word = termAtt.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tfinal BooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator<String> it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\tsyns.search(new TermQuery( new Term(Syns2Index.F_WORD, word)), new Collector() {\n\t\t\t  IndexReader reader;\n\t\t\t  \n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int doc) throws IOException {\n          Document d = reader.document(doc);\n          String[] values = d.getValues( Syns2Index.F_SYN);\n          for ( int j = 0; j < values.length; j++)\n          {\n            String syn = values[ j];\n            if ( already.add( syn)) // avoid dups of top level words and synonyms\n            {\n              TermQuery tq = new TermQuery( new Term( field, syn));\n              if ( boost > 0) // else keep normal 1.0\n                tq.setBoost( boost);\n              tmp.add( tq, BooleanClause.Occur.SHOULD); \n            }\n          }\n        }\n\n        @Override\n        public void setNextReader(IndexReader reader, int docBase)\n            throws IOException {\n          this.reader = reader;\n        }\n\n        @Override\n        public void setScorer(Scorer scorer) throws IOException {}\n\t\t\t});\n\t\t\t\n\t\t\t// [2b] add in unique synonums\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","sourceOld":"\t/**\n\t * Perform synonym expansion on a query.\n\t *\n\t * @param query users query that is assumed to not have any \"special\" query syntax, thus it should be just normal words, so \"big dog\" makes sense, but a query like \"title:foo^1.2\" doesn't as this should presumably be passed directly to the default query parser.\n\t *\n\t * @param syns a opened to the Lucene index you previously created with {@link Syns2Index}. The searcher is not closed or otherwise altered.\n\t *\n\t * @param a optional analyzer used to parse the users query else {@link StandardAnalyzer} is used\n\t *\n\t * @param f optional field name to search in or null if you want the default of \"contents\"\n\t *\n\t * @param boost optional boost applied to synonyms else no boost is applied\n\t *\n\t * @return the expanded Query\n\t */ \n\tpublic static Query expand( String query,\n\t\t\t\t\t\t\t\tSearcher syns,\n\t\t\t\t\t\t\t\tAnalyzer a,\n\t\t\t\t\t\t\t\tString f,\n\t\t\t\t\t\t\t\tfinal float boost)\n\t\tthrows IOException\n\t{\n\t\tfinal Set<String> already = new HashSet<String>(); // avoid dups \n\t\tList<String> top = new LinkedList<String>(); // needs to be separately listed..\n\t\tfinal String field = ( f == null) ? \"contents\" : f;\n\t\tif ( a == null) a = new StandardAnalyzer(Version.LUCENE_CURRENT);\n\n\t\t// [1] Parse query into separate words so that when we expand we can avoid dups\n\t\tTokenStream ts = a.tokenStream( field, new StringReader( query));\n\t\tTermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n\t\t\n\t\twhile (ts.incrementToken()) {\n\t\t  String word = termAtt.term();\n\t\t\tif ( already.add( word))\n\t\t\t\ttop.add( word);\n\t\t}\n\t\tfinal BooleanQuery tmp = new BooleanQuery();\n\t\t\n\t\t// [2] form query\n\t\tIterator<String> it = top.iterator();\n\t\twhile ( it.hasNext())\n\t\t{\n\t\t\t// [2a] add to level words in\n\t\t\tString word = it.next();\n\t\t\tTermQuery tq = new TermQuery( new Term( field, word));\n\t\t\ttmp.add( tq, BooleanClause.Occur.SHOULD);\n\n\t\t\tsyns.search(new TermQuery( new Term(Syns2Index.F_WORD, word)), new Collector() {\n\t\t\t  IndexReader reader;\n\t\t\t  \n        @Override\n        public boolean acceptsDocsOutOfOrder() {\n          return true;\n        }\n\n        @Override\n        public void collect(int doc) throws IOException {\n          Document d = reader.document(doc);\n          String[] values = d.getValues( Syns2Index.F_SYN);\n          for ( int j = 0; j < values.length; j++)\n          {\n            String syn = values[ j];\n            if ( already.add( syn)) // avoid dups of top level words and synonyms\n            {\n              TermQuery tq = new TermQuery( new Term( field, syn));\n              if ( boost > 0) // else keep normal 1.0\n                tq.setBoost( boost);\n              tmp.add( tq, BooleanClause.Occur.SHOULD); \n            }\n          }\n        }\n\n        @Override\n        public void setNextReader(IndexReader reader, int docBase)\n            throws IOException {\n          this.reader = reader;\n        }\n\n        @Override\n        public void setScorer(Scorer scorer) throws IOException {}\n\t\t\t});\n\t\t\t\n\t\t\t// [2b] add in unique synonums\n\t\t}\n\n\n\t\treturn tmp;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["02a71af6b0525092e8cdc9e3649fa77150cc7814"],"c69d87d34a81230de56333f52f590caeb6d80667":["d68e5c46e6a5ebdf4dafec4a123344092b915cc0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9b5756469957918cac40a831acec9cf01c8c2bb3":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"02a71af6b0525092e8cdc9e3649fa77150cc7814":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4b41b991de69ba7b72d5e90cfcee25699a1a7fc9":["0f148c02ddd6ba981c65ca685d0e56c3a98368e1"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["9b5756469957918cac40a831acec9cf01c8c2bb3"],"0f148c02ddd6ba981c65ca685d0e56c3a98368e1":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a":["c69d87d34a81230de56333f52f590caeb6d80667"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a9ac13b5f0ce5ef1b2ce168367d993a79594b23a"],"d68e5c46e6a5ebdf4dafec4a123344092b915cc0":["4b41b991de69ba7b72d5e90cfcee25699a1a7fc9"]},"commit2Childs":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["9b5756469957918cac40a831acec9cf01c8c2bb3"],"c69d87d34a81230de56333f52f590caeb6d80667":["a9ac13b5f0ce5ef1b2ce168367d993a79594b23a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["02a71af6b0525092e8cdc9e3649fa77150cc7814"],"02a71af6b0525092e8cdc9e3649fa77150cc7814":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"9b5756469957918cac40a831acec9cf01c8c2bb3":["8d78f014fded44fbde905f4f84cdc21907b371e8"],"4b41b991de69ba7b72d5e90cfcee25699a1a7fc9":["d68e5c46e6a5ebdf4dafec4a123344092b915cc0"],"8d78f014fded44fbde905f4f84cdc21907b371e8":["0f148c02ddd6ba981c65ca685d0e56c3a98368e1"],"0f148c02ddd6ba981c65ca685d0e56c3a98368e1":["4b41b991de69ba7b72d5e90cfcee25699a1a7fc9"],"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"d68e5c46e6a5ebdf4dafec4a123344092b915cc0":["c69d87d34a81230de56333f52f590caeb6d80667"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}