{"path":"solr/core/src/test/org/apache/solr/search/TestRecovery#testNewDBQAndDocMatchingOldDBQDuringLogReplay().mjava","commits":[{"id":"72b93de9124049bdac1d82afb795dd2a463b5b37","date":1484151664,"type":0,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testNewDBQAndDocMatchingOldDBQDuringLogReplay().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testNewDBQAndDocMatchingOldDBQDuringLogReplay() throws Exception {\n    try {\n\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      clearIndex();\n      assertU(commit());\n\n      // because we're sending updates during log replay, we can't emulate replica logic -- we need to use\n      // normal updates like a leader / single-node instance would get.\n      //\n      // (In SolrCloud mode, when a replica run recoverFromLog, replica in this time period will have state = DOWN,\n      // so It won't receive any updates.)\n      \n      updateJ(jsonAdd(sdoc(\"id\",\"B0\")),params());\n      updateJ(jsonAdd(sdoc(\"id\",\"B1\")),params()); // should be deleted by subsequent DBQ in tlog\n      updateJ(jsonAdd(sdoc(\"id\",\"B2\")),params()); // should be deleted by DBQ that arives during tlog replay\n      updateJ(jsonDelQ(\"id:B1 OR id:B3 OR id:B6\"),params());\n      updateJ(jsonAdd(sdoc(\"id\",\"B3\")),params()); // should *NOT* be deleted by previous DBQ in tlog\n      updateJ(jsonAdd(sdoc(\"id\",\"B4\")),params()); // should be deleted by DBQ that arives during tlog replay\n      updateJ(jsonAdd(sdoc(\"id\",\"B5\")),params());\n      \n      // sanity check no updates have been applied yet (just in tlog)\n      assertJQ(req(\"q\",\"*:*\"),\"/response/numFound==0\");\n\n      h.close();\n      createCore(); // (Attempts to) kick off recovery (which is currently blocked by semaphore)\n\n      // verify that previous close didn't do a commit & that recovery should be blocked by our hook\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==0\");\n\n      // begin recovery (first few items)\n      logReplay.release(TestUtil.nextInt(random(),1,6));\n      // ... but before recover is completely unblocked/finished, have a *new* DBQ arrive\n      // that should delete some items we either have just replayed, or are about to replay (or maybe both)...\n      updateJ(jsonDelQ(\"id:B2 OR id:B4\"),params());\n      // ...and re-add a doc that would have matched a DBQ already in the tlog\n      // (which may/may-not have been replayed yet)\n      updateJ(jsonAdd(sdoc(\"id\",\"B6\")),params()); // should *NOT* be deleted by DBQ from tlog\n      assertU(commit());\n\n      // now completely unblock recovery\n      logReplay.release(1000);\n\n      // wait until recovery has finished\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      // verify only the expected docs are found, even with out of order DBQ and DBQ that arived during recovery\n      assertJQ(req(\"q\", \"*:*\", \"fl\", \"id\", \"sort\", \"id asc\")\n               , \"/response/docs==[{'id':'B0'}, {'id':'B3'}, {'id':'B5'}, {'id':'B6'}]\");\n      \n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","date":1484239864,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testNewDBQAndDocMatchingOldDBQDuringLogReplay().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testNewDBQAndDocMatchingOldDBQDuringLogReplay() throws Exception {\n    try {\n\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      clearIndex();\n      assertU(commit());\n\n      // because we're sending updates during log replay, we can't emulate replica logic -- we need to use\n      // normal updates like a leader / single-node instance would get.\n      //\n      // (In SolrCloud mode, when a replica run recoverFromLog, replica in this time period will have state = DOWN,\n      // so It won't receive any updates.)\n      \n      updateJ(jsonAdd(sdoc(\"id\",\"B0\")),params());\n      updateJ(jsonAdd(sdoc(\"id\",\"B1\")),params()); // should be deleted by subsequent DBQ in tlog\n      updateJ(jsonAdd(sdoc(\"id\",\"B2\")),params()); // should be deleted by DBQ that arives during tlog replay\n      updateJ(jsonDelQ(\"id:B1 OR id:B3 OR id:B6\"),params());\n      updateJ(jsonAdd(sdoc(\"id\",\"B3\")),params()); // should *NOT* be deleted by previous DBQ in tlog\n      updateJ(jsonAdd(sdoc(\"id\",\"B4\")),params()); // should be deleted by DBQ that arives during tlog replay\n      updateJ(jsonAdd(sdoc(\"id\",\"B5\")),params());\n      \n      // sanity check no updates have been applied yet (just in tlog)\n      assertJQ(req(\"q\",\"*:*\"),\"/response/numFound==0\");\n\n      h.close();\n      createCore(); // (Attempts to) kick off recovery (which is currently blocked by semaphore)\n\n      // verify that previous close didn't do a commit & that recovery should be blocked by our hook\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==0\");\n\n      // begin recovery (first few items)\n      logReplay.release(TestUtil.nextInt(random(),1,6));\n      // ... but before recover is completely unblocked/finished, have a *new* DBQ arrive\n      // that should delete some items we either have just replayed, or are about to replay (or maybe both)...\n      updateJ(jsonDelQ(\"id:B2 OR id:B4\"),params());\n      // ...and re-add a doc that would have matched a DBQ already in the tlog\n      // (which may/may-not have been replayed yet)\n      updateJ(jsonAdd(sdoc(\"id\",\"B6\")),params()); // should *NOT* be deleted by DBQ from tlog\n      assertU(commit());\n\n      // now completely unblock recovery\n      logReplay.release(1000);\n\n      // wait until recovery has finished\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      // verify only the expected docs are found, even with out of order DBQ and DBQ that arived during recovery\n      assertJQ(req(\"q\", \"*:*\", \"fl\", \"id\", \"sort\", \"id asc\")\n               , \"/response/docs==[{'id':'B0'}, {'id':'B3'}, {'id':'B5'}, {'id':'B6'}]\");\n      \n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1","date":1579200426,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testNewDBQAndDocMatchingOldDBQDuringLogReplay().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testNewDBQAndDocMatchingOldDBQDuringLogReplay().mjava","sourceNew":"  @Test\n  public void testNewDBQAndDocMatchingOldDBQDuringLogReplay() throws Exception {\n    try {\n\n      TestInjection.skipIndexWriterCommitOnClose = true;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      clearIndex();\n      assertU(commit());\n\n      // because we're sending updates during log replay, we can't emulate replica logic -- we need to use\n      // normal updates like a leader / single-node instance would get.\n      //\n      // (In SolrCloud mode, when a replica run recoverFromLog, replica in this time period will have state = DOWN,\n      // so It won't receive any updates.)\n      \n      updateJ(jsonAdd(sdoc(\"id\",\"B0\")),params());\n      updateJ(jsonAdd(sdoc(\"id\",\"B1\")),params()); // should be deleted by subsequent DBQ in tlog\n      updateJ(jsonAdd(sdoc(\"id\",\"B2\")),params()); // should be deleted by DBQ that arives during tlog replay\n      updateJ(jsonDelQ(\"id:B1 OR id:B3 OR id:B6\"),params());\n      updateJ(jsonAdd(sdoc(\"id\",\"B3\")),params()); // should *NOT* be deleted by previous DBQ in tlog\n      updateJ(jsonAdd(sdoc(\"id\",\"B4\")),params()); // should be deleted by DBQ that arives during tlog replay\n      updateJ(jsonAdd(sdoc(\"id\",\"B5\")),params());\n      \n      // sanity check no updates have been applied yet (just in tlog)\n      assertJQ(req(\"q\",\"*:*\"),\"/response/numFound==0\");\n\n      h.close();\n      createCore(); // (Attempts to) kick off recovery (which is currently blocked by semaphore)\n\n      // verify that previous close didn't do a commit & that recovery should be blocked by our hook\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==0\");\n\n      // begin recovery (first few items)\n      logReplay.release(TestUtil.nextInt(random(),1,6));\n      // ... but before recover is completely unblocked/finished, have a *new* DBQ arrive\n      // that should delete some items we either have just replayed, or are about to replay (or maybe both)...\n      updateJ(jsonDelQ(\"id:B2 OR id:B4\"),params());\n      // ...and re-add a doc that would have matched a DBQ already in the tlog\n      // (which may/may-not have been replayed yet)\n      updateJ(jsonAdd(sdoc(\"id\",\"B6\")),params()); // should *NOT* be deleted by DBQ from tlog\n      assertU(commit());\n\n      // now completely unblock recovery\n      logReplay.release(1000);\n\n      // wait until recovery has finished\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      // verify only the expected docs are found, even with out of order DBQ and DBQ that arived during recovery\n      assertJQ(req(\"q\", \"*:*\", \"fl\", \"id\", \"sort\", \"id asc\")\n               , \"/response/docs==[{'id':'B0'}, {'id':'B3'}, {'id':'B5'}, {'id':'B6'}]\");\n      \n    } finally {\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testNewDBQAndDocMatchingOldDBQDuringLogReplay() throws Exception {\n    try {\n\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      clearIndex();\n      assertU(commit());\n\n      // because we're sending updates during log replay, we can't emulate replica logic -- we need to use\n      // normal updates like a leader / single-node instance would get.\n      //\n      // (In SolrCloud mode, when a replica run recoverFromLog, replica in this time period will have state = DOWN,\n      // so It won't receive any updates.)\n      \n      updateJ(jsonAdd(sdoc(\"id\",\"B0\")),params());\n      updateJ(jsonAdd(sdoc(\"id\",\"B1\")),params()); // should be deleted by subsequent DBQ in tlog\n      updateJ(jsonAdd(sdoc(\"id\",\"B2\")),params()); // should be deleted by DBQ that arives during tlog replay\n      updateJ(jsonDelQ(\"id:B1 OR id:B3 OR id:B6\"),params());\n      updateJ(jsonAdd(sdoc(\"id\",\"B3\")),params()); // should *NOT* be deleted by previous DBQ in tlog\n      updateJ(jsonAdd(sdoc(\"id\",\"B4\")),params()); // should be deleted by DBQ that arives during tlog replay\n      updateJ(jsonAdd(sdoc(\"id\",\"B5\")),params());\n      \n      // sanity check no updates have been applied yet (just in tlog)\n      assertJQ(req(\"q\",\"*:*\"),\"/response/numFound==0\");\n\n      h.close();\n      createCore(); // (Attempts to) kick off recovery (which is currently blocked by semaphore)\n\n      // verify that previous close didn't do a commit & that recovery should be blocked by our hook\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==0\");\n\n      // begin recovery (first few items)\n      logReplay.release(TestUtil.nextInt(random(),1,6));\n      // ... but before recover is completely unblocked/finished, have a *new* DBQ arrive\n      // that should delete some items we either have just replayed, or are about to replay (or maybe both)...\n      updateJ(jsonDelQ(\"id:B2 OR id:B4\"),params());\n      // ...and re-add a doc that would have matched a DBQ already in the tlog\n      // (which may/may-not have been replayed yet)\n      updateJ(jsonAdd(sdoc(\"id\",\"B6\")),params()); // should *NOT* be deleted by DBQ from tlog\n      assertU(commit());\n\n      // now completely unblock recovery\n      logReplay.release(1000);\n\n      // wait until recovery has finished\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      // verify only the expected docs are found, even with out of order DBQ and DBQ that arived during recovery\n      assertJQ(req(\"q\", \"*:*\", \"fl\", \"id\", \"sort\", \"id asc\")\n               , \"/response/docs==[{'id':'B0'}, {'id':'B3'}, {'id':'B5'}, {'id':'B6'}]\");\n      \n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"72b93de9124049bdac1d82afb795dd2a463b5b37":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","72b93de9124049bdac1d82afb795dd2a463b5b37"],"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1":["72b93de9124049bdac1d82afb795dd2a463b5b37"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1"]},"commit2Childs":{"72b93de9124049bdac1d82afb795dd2a463b5b37":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["72b93de9124049bdac1d82afb795dd2a463b5b37","09ab8ee44ca898536770d0106a7c0ee4be4f0eb7"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":[],"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}