{"path":"contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","commits":[{"id":"422a649a45aaa37e53615faeca74d891f876a139","date":1255445670,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new WhitespaceAnalyzer(),\n              true, MaxFieldLength.UNLIMITED);\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(new IndexReader[]{input});\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1cedb00d2dd44640194401179358a2e3ba6051bf","date":1268243626,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","pathOld":"contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(Version.LUCENE_CURRENT).setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(new IndexReader[]{input});\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new WhitespaceAnalyzer(),\n              true, MaxFieldLength.UNLIMITED);\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(new IndexReader[]{input});\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e52fea2c4081a1e552b98506691990be59503168","date":1268250331,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","pathOld":"contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new WhitespaceAnalyzer(),\n              true, MaxFieldLength.UNLIMITED);\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(new IndexReader[]{input});\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(Version.LUCENE_CURRENT).setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(new IndexReader[]{input});\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8","date":1268494368,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","pathOld":"contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          new WhitespaceAnalyzer(Version.LUCENE_CURRENT))\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(new IndexReader[]{input});\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new WhitespaceAnalyzer(),\n              true, MaxFieldLength.UNLIMITED);\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(new IndexReader[]{input});\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","pathOld":"contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter#split(IndexReader,Directory[],boolean).mjava","sourceNew":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          new WhitespaceAnalyzer(Version.LUCENE_CURRENT))\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(new IndexReader[]{input});\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","sourceOld":"  /**\n   * Split source index into multiple parts.\n   * @param input source index, can be read-only, can have deletions, can have\n   * multiple segments (or multiple readers).\n   * @param outputs list of directories where the output parts will be stored.\n   * @param seq if true, then the source index will be split into equal\n   * increasing ranges of document id-s. If false, source document id-s will be\n   * assigned in a deterministic round-robin fashion to one of the output splits.\n   * @throws IOException\n   */\n  public void split(IndexReader input, Directory[] outputs, boolean seq) throws IOException {\n    if (outputs == null || outputs.length < 2) {\n      throw new IOException(\"Invalid number of outputs.\");\n    }\n    if (input == null || input.numDocs() < 2) {\n      throw new IOException(\"Not enough documents for splitting\");\n    }\n    int numParts = outputs.length;\n    // wrap a potentially read-only input\n    // this way we don't have to preserve original deletions because neither\n    // deleteDocument(int) or undeleteAll() is applied to the wrapped input index.\n    input = new FakeDeleteIndexReader(input);\n    int maxDoc = input.maxDoc();\n    int partLen = maxDoc / numParts;\n    for (int i = 0; i < numParts; i++) {\n      input.undeleteAll();\n      if (seq) { // sequential range\n        int lo = partLen * i;\n        int hi = lo + partLen;\n        // below range\n        for (int j = 0; j < lo; j++) {\n          input.deleteDocument(j);\n        }\n        // above range - last part collects all id-s that remained due to\n        // integer rounding errors\n        if (i < numParts - 1) {\n          for (int j = hi; j < maxDoc; j++) {\n            input.deleteDocument(j);\n          }\n        }\n      } else {\n        // round-robin\n        for (int j = 0; j < maxDoc; j++) {\n          if ((j + numParts - i) % numParts != 0) {\n            input.deleteDocument(j);\n          }\n        }\n      }\n      IndexWriter w = new IndexWriter(outputs[i], new IndexWriterConfig(\n          Version.LUCENE_CURRENT,\n          new WhitespaceAnalyzer(Version.LUCENE_CURRENT))\n          .setOpenMode(OpenMode.CREATE));\n      System.err.println(\"Writing part \" + (i + 1) + \" ...\");\n      w.addIndexes(new IndexReader[]{input});\n      w.close();\n    }\n    System.err.println(\"Done.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["e52fea2c4081a1e552b98506691990be59503168"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1cedb00d2dd44640194401179358a2e3ba6051bf":["422a649a45aaa37e53615faeca74d891f876a139"],"e52fea2c4081a1e552b98506691990be59503168":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"422a649a45aaa37e53615faeca74d891f876a139":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"]},"commit2Childs":{"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["422a649a45aaa37e53615faeca74d891f876a139"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["e52fea2c4081a1e552b98506691990be59503168"],"e52fea2c4081a1e552b98506691990be59503168":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"],"422a649a45aaa37e53615faeca74d891f876a139":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}