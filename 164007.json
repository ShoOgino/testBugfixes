{"path":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","commits":[{"id":"05569170a222447d3aec8fad773feedf4429fdd5","date":1476800012,"type":0,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint. \n   * We can't use computeIfAbsent as caching is conditional (as described above) \n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   * @param searcher searcher that includes specified LeaderReaderContext\n   * @param ctx LeafReaderContext of a segment to compute fingerprint of \n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n      IndexFingerprint f = null;\n      f = perSegmentFingerprintCache.get(ctx.reader().getCoreCacheKey()) ; \n      // fingerprint is either not cached or \n      // we want fingerprint only up to a version less than maxVersionEncountered in the segment \n      if(f == null || (f.getMaxInHash() > maxVersion)) {\n        log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader() , ctx.reader().hashCode(), maxVersion);\n        f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n        // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint  \n        if(f.getMaxVersionEncountered() == f.getMaxInHash()) {\n          log.info(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n          perSegmentFingerprintCache.put(ctx.reader().getCoreCacheKey(), f);\n        }\n        \n      } else {\n        log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      }\n      log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n      return f;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b437b84da5e49daf1197c9cd533015490cdcb2c2","date":1476818430,"type":4,"author":"Noble Paul","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","sourceNew":null,"sourceOld":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint. \n   * We can't use computeIfAbsent as caching is conditional (as described above) \n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   * @param searcher searcher that includes specified LeaderReaderContext\n   * @param ctx LeafReaderContext of a segment to compute fingerprint of \n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n      IndexFingerprint f = null;\n      f = perSegmentFingerprintCache.get(ctx.reader().getCoreCacheKey()) ; \n      // fingerprint is either not cached or \n      // we want fingerprint only up to a version less than maxVersionEncountered in the segment \n      if(f == null || (f.getMaxInHash() > maxVersion)) {\n        log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader() , ctx.reader().hashCode(), maxVersion);\n        f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n        // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint  \n        if(f.getMaxVersionEncountered() == f.getMaxInHash()) {\n          log.info(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n          perSegmentFingerprintCache.put(ctx.reader().getCoreCacheKey(), f);\n        }\n        \n      } else {\n        log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      }\n      log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n      return f;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b11122ff28c20e6e4e02cb1366eaa029a92f69ce","date":1477307742,"type":0,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint.\n   * We can't use computeIfAbsent as caching is conditional (as described above)\n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   *\n   * @param searcher   searcher that includes specified LeaderReaderContext\n   * @param ctx        LeafReaderContext of a segment to compute fingerprint of\n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n    IndexFingerprint f = null;\n    f = perSegmentFingerprintCache.get(ctx.reader().getCoreCacheKey());\n    // fingerprint is either not cached or\n    // if we want fingerprint only up to a version less than maxVersionEncountered in the segment, or\n    // documents were deleted from segment for which fingerprint was cached\n    //\n    if (f == null || (f.getMaxInHash() > maxVersion) || (f.getNumDocs() != ctx.reader().numDocs())) {\n      log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n      // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint\n      if (f.getMaxVersionEncountered() == f.getMaxInHash()) {\n        log.info(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n        perSegmentFingerprintCache.put(ctx.reader().getCoreCacheKey(), f);\n      }\n\n    } else {\n      log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n    }\n    log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n    return f;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"80d0e6d59ae23f4a6f30eaf40bfb40742300287f","date":1477598926,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint.\n   * We can't use computeIfAbsent as caching is conditional (as described above)\n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   *\n   * @param searcher   searcher that includes specified LeaderReaderContext\n   * @param ctx        LeafReaderContext of a segment to compute fingerprint of\n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n    IndexFingerprint f = null;\n    f = perSegmentFingerprintCache.get(ctx.reader().getCoreCacheKey());\n    // fingerprint is either not cached or\n    // if we want fingerprint only up to a version less than maxVersionEncountered in the segment, or\n    // documents were deleted from segment for which fingerprint was cached\n    //\n    if (f == null || (f.getMaxInHash() > maxVersion) || (f.getNumDocs() != ctx.reader().numDocs())) {\n      log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n      // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint\n      if (f.getMaxVersionEncountered() == f.getMaxInHash()) {\n        log.info(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n        perSegmentFingerprintCache.put(ctx.reader().getCoreCacheKey(), f);\n      }\n\n    } else {\n      log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n    }\n    log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n    return f;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e2663d2ab6c608590fac0aa672e94a5a56744331","date":1483930986,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","sourceNew":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint.\n   * We can't use computeIfAbsent as caching is conditional (as described above)\n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   *\n   * @param searcher   searcher that includes specified LeaderReaderContext\n   * @param ctx        LeafReaderContext of a segment to compute fingerprint of\n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n    IndexFingerprint f = null;\n    f = perSegmentFingerprintCache.get(ctx.reader().getCombinedCoreAndDeletesKey());\n    // fingerprint is either not cached or\n    // if we want fingerprint only up to a version less than maxVersionEncountered in the segment, or\n    // documents were deleted from segment for which fingerprint was cached\n    //\n    if (f == null || (f.getMaxInHash() > maxVersion) || (f.getNumDocs() != ctx.reader().numDocs())) {\n      log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n      // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint\n      if (f.getMaxVersionEncountered() == f.getMaxInHash()) {\n        log.info(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n        perSegmentFingerprintCache.put(ctx.reader().getCombinedCoreAndDeletesKey(), f);\n      }\n\n    } else {\n      log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n    }\n    log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n    return f;\n  }\n\n","sourceOld":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint.\n   * We can't use computeIfAbsent as caching is conditional (as described above)\n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   *\n   * @param searcher   searcher that includes specified LeaderReaderContext\n   * @param ctx        LeafReaderContext of a segment to compute fingerprint of\n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n    IndexFingerprint f = null;\n    f = perSegmentFingerprintCache.get(ctx.reader().getCoreCacheKey());\n    // fingerprint is either not cached or\n    // if we want fingerprint only up to a version less than maxVersionEncountered in the segment, or\n    // documents were deleted from segment for which fingerprint was cached\n    //\n    if (f == null || (f.getMaxInHash() > maxVersion) || (f.getNumDocs() != ctx.reader().numDocs())) {\n      log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n      // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint\n      if (f.getMaxVersionEncountered() == f.getMaxInHash()) {\n        log.info(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n        perSegmentFingerprintCache.put(ctx.reader().getCoreCacheKey(), f);\n      }\n\n    } else {\n      log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n    }\n    log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n    return f;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","date":1484239864,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","sourceNew":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint.\n   * We can't use computeIfAbsent as caching is conditional (as described above)\n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   *\n   * @param searcher   searcher that includes specified LeaderReaderContext\n   * @param ctx        LeafReaderContext of a segment to compute fingerprint of\n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n    IndexFingerprint f = null;\n    f = perSegmentFingerprintCache.get(ctx.reader().getCombinedCoreAndDeletesKey());\n    // fingerprint is either not cached or\n    // if we want fingerprint only up to a version less than maxVersionEncountered in the segment, or\n    // documents were deleted from segment for which fingerprint was cached\n    //\n    if (f == null || (f.getMaxInHash() > maxVersion) || (f.getNumDocs() != ctx.reader().numDocs())) {\n      log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n      // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint\n      if (f.getMaxVersionEncountered() == f.getMaxInHash()) {\n        log.info(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n        perSegmentFingerprintCache.put(ctx.reader().getCombinedCoreAndDeletesKey(), f);\n      }\n\n    } else {\n      log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n    }\n    log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n    return f;\n  }\n\n","sourceOld":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint.\n   * We can't use computeIfAbsent as caching is conditional (as described above)\n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   *\n   * @param searcher   searcher that includes specified LeaderReaderContext\n   * @param ctx        LeafReaderContext of a segment to compute fingerprint of\n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n    IndexFingerprint f = null;\n    f = perSegmentFingerprintCache.get(ctx.reader().getCoreCacheKey());\n    // fingerprint is either not cached or\n    // if we want fingerprint only up to a version less than maxVersionEncountered in the segment, or\n    // documents were deleted from segment for which fingerprint was cached\n    //\n    if (f == null || (f.getMaxInHash() > maxVersion) || (f.getNumDocs() != ctx.reader().numDocs())) {\n      log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n      // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint\n      if (f.getMaxVersionEncountered() == f.getMaxInHash()) {\n        log.info(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n        perSegmentFingerprintCache.put(ctx.reader().getCoreCacheKey(), f);\n      }\n\n    } else {\n      log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n    }\n    log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n    return f;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d211216c83f01894810543d1c107160a9ae3650b","date":1488289605,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","sourceNew":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint.\n   * We can't use computeIfAbsent as caching is conditional (as described above)\n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   *\n   * @param searcher   searcher that includes specified LeaderReaderContext\n   * @param ctx        LeafReaderContext of a segment to compute fingerprint of\n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n    IndexReader.CacheHelper cacheHelper = ctx.reader().getReaderCacheHelper();\n    if (cacheHelper == null) {\n      log.debug(\"Cannot cache IndexFingerprint as reader does not support caching. searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      return IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n    }\n    \n    IndexFingerprint f = null;\n    f = perSegmentFingerprintCache.get(cacheHelper.getKey());\n    // fingerprint is either not cached or\n    // if we want fingerprint only up to a version less than maxVersionEncountered in the segment, or\n    // documents were deleted from segment for which fingerprint was cached\n    //\n    if (f == null || (f.getMaxInHash() > maxVersion) || (f.getNumDocs() != ctx.reader().numDocs())) {\n      log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n      // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint\n      if (f.getMaxVersionEncountered() == f.getMaxInHash()) {\n        log.info(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n        perSegmentFingerprintCache.put(cacheHelper.getKey(), f);\n      }\n\n    } else {\n      log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n    }\n    log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n    return f;\n  }\n\n","sourceOld":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint.\n   * We can't use computeIfAbsent as caching is conditional (as described above)\n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   *\n   * @param searcher   searcher that includes specified LeaderReaderContext\n   * @param ctx        LeafReaderContext of a segment to compute fingerprint of\n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n    IndexFingerprint f = null;\n    f = perSegmentFingerprintCache.get(ctx.reader().getCombinedCoreAndDeletesKey());\n    // fingerprint is either not cached or\n    // if we want fingerprint only up to a version less than maxVersionEncountered in the segment, or\n    // documents were deleted from segment for which fingerprint was cached\n    //\n    if (f == null || (f.getMaxInHash() > maxVersion) || (f.getNumDocs() != ctx.reader().numDocs())) {\n      log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n      // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint\n      if (f.getMaxVersionEncountered() == f.getMaxInHash()) {\n        log.info(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n        perSegmentFingerprintCache.put(ctx.reader().getCombinedCoreAndDeletesKey(), f);\n      }\n\n    } else {\n      log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n    }\n    log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n    return f;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"425c2986e128f9e4aadd629cdf3b04e7aacb7c80","date":1536202585,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","sourceNew":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint.\n   * We can't use computeIfAbsent as caching is conditional (as described above)\n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   *\n   * @param searcher   searcher that includes specified LeaderReaderContext\n   * @param ctx        LeafReaderContext of a segment to compute fingerprint of\n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n    IndexReader.CacheHelper cacheHelper = ctx.reader().getReaderCacheHelper();\n    if (cacheHelper == null) {\n      log.debug(\"Cannot cache IndexFingerprint as reader does not support caching. searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      return IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n    }\n    \n    IndexFingerprint f = null;\n    f = perSegmentFingerprintCache.get(cacheHelper.getKey());\n    // fingerprint is either not cached or\n    // if we want fingerprint only up to a version less than maxVersionEncountered in the segment, or\n    // documents were deleted from segment for which fingerprint was cached\n    //\n    if (f == null || (f.getMaxInHash() > maxVersion) || (f.getNumDocs() != ctx.reader().numDocs())) {\n      log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n      // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint\n      if (f.getMaxVersionEncountered() == f.getMaxInHash()) {\n        log.debug(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n        perSegmentFingerprintCache.put(cacheHelper.getKey(), f);\n      }\n\n    } else {\n      log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n    }\n    log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n    return f;\n  }\n\n","sourceOld":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint.\n   * We can't use computeIfAbsent as caching is conditional (as described above)\n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   *\n   * @param searcher   searcher that includes specified LeaderReaderContext\n   * @param ctx        LeafReaderContext of a segment to compute fingerprint of\n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n    IndexReader.CacheHelper cacheHelper = ctx.reader().getReaderCacheHelper();\n    if (cacheHelper == null) {\n      log.debug(\"Cannot cache IndexFingerprint as reader does not support caching. searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      return IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n    }\n    \n    IndexFingerprint f = null;\n    f = perSegmentFingerprintCache.get(cacheHelper.getKey());\n    // fingerprint is either not cached or\n    // if we want fingerprint only up to a version less than maxVersionEncountered in the segment, or\n    // documents were deleted from segment for which fingerprint was cached\n    //\n    if (f == null || (f.getMaxInHash() > maxVersion) || (f.getNumDocs() != ctx.reader().numDocs())) {\n      log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n      // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint\n      if (f.getMaxVersionEncountered() == f.getMaxInHash()) {\n        log.info(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n        perSegmentFingerprintCache.put(cacheHelper.getKey(), f);\n      }\n\n    } else {\n      log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n    }\n    log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n    return f;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2668c99990e4c94a78bac005aa682b7c5986d23a","date":1561446137,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","sourceNew":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint.\n   * We can't use computeIfAbsent as caching is conditional (as described above)\n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   *\n   * @param searcher   searcher that includes specified LeaderReaderContext\n   * @param ctx        LeafReaderContext of a segment to compute fingerprint of\n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n    IndexReader.CacheHelper cacheHelper = ctx.reader().getReaderCacheHelper();\n    if (cacheHelper == null) {\n      log.debug(\"Cannot cache IndexFingerprint as reader does not support caching. searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      return IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n    }\n\n    IndexFingerprint f = null;\n    f = perSegmentFingerprintCache.get(cacheHelper.getKey());\n    // fingerprint is either not cached or\n    // if we want fingerprint only up to a version less than maxVersionEncountered in the segment, or\n    // documents were deleted from segment for which fingerprint was cached\n    //\n    if (f == null || (f.getMaxInHash() > maxVersion) || (f.getNumDocs() != ctx.reader().numDocs())) {\n      log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n      // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint\n      if (f.getMaxVersionEncountered() == f.getMaxInHash()) {\n        log.debug(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n        perSegmentFingerprintCache.put(cacheHelper.getKey(), f);\n      }\n\n    } else {\n      log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n    }\n    log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n    return f;\n  }\n\n","sourceOld":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint.\n   * We can't use computeIfAbsent as caching is conditional (as described above)\n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   *\n   * @param searcher   searcher that includes specified LeaderReaderContext\n   * @param ctx        LeafReaderContext of a segment to compute fingerprint of\n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n    IndexReader.CacheHelper cacheHelper = ctx.reader().getReaderCacheHelper();\n    if (cacheHelper == null) {\n      log.debug(\"Cannot cache IndexFingerprint as reader does not support caching. searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      return IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n    }\n    \n    IndexFingerprint f = null;\n    f = perSegmentFingerprintCache.get(cacheHelper.getKey());\n    // fingerprint is either not cached or\n    // if we want fingerprint only up to a version less than maxVersionEncountered in the segment, or\n    // documents were deleted from segment for which fingerprint was cached\n    //\n    if (f == null || (f.getMaxInHash() > maxVersion) || (f.getNumDocs() != ctx.reader().numDocs())) {\n      log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n      // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint\n      if (f.getMaxVersionEncountered() == f.getMaxInHash()) {\n        log.debug(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n        perSegmentFingerprintCache.put(cacheHelper.getKey(), f);\n      }\n\n    } else {\n      log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n    }\n    log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n    return f;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"140be51d03394488536f4aacedace29f9b318347","date":1587170432,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#getIndexFingerprint(SolrIndexSearcher,LeafReaderContext,long).mjava","sourceNew":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint.\n   * We can't use computeIfAbsent as caching is conditional (as described above)\n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   *\n   * @param searcher   searcher that includes specified LeaderReaderContext\n   * @param ctx        LeafReaderContext of a segment to compute fingerprint of\n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n    IndexReader.CacheHelper cacheHelper = ctx.reader().getReaderCacheHelper();\n    if (cacheHelper == null) {\n      if (log.isDebugEnabled()) {\n        log.debug(\"Cannot cache IndexFingerprint as reader does not support caching. searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      }\n      return IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n    }\n\n    IndexFingerprint f = null;\n    f = perSegmentFingerprintCache.get(cacheHelper.getKey());\n    // fingerprint is either not cached or\n    // if we want fingerprint only up to a version less than maxVersionEncountered in the segment, or\n    // documents were deleted from segment for which fingerprint was cached\n    //\n    if (f == null || (f.getMaxInHash() > maxVersion) || (f.getNumDocs() != ctx.reader().numDocs())) {\n      if (log.isDebugEnabled()) {\n        log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      }\n      f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n      // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint\n      if (f.getMaxVersionEncountered() == f.getMaxInHash()) {\n        log.debug(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n        perSegmentFingerprintCache.put(cacheHelper.getKey(), f);\n      }\n\n    } else {\n      if (log.isDebugEnabled()) {\n        log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      }\n    }\n    if (log.isDebugEnabled()) {\n      log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n    }\n    return f;\n  }\n\n","sourceOld":"  /**\n   * Computes fingerprint of a segment and caches it only if all the version in segment are included in the fingerprint.\n   * We can't use computeIfAbsent as caching is conditional (as described above)\n   * There is chance that two threads may compute fingerprint on the same segment. It might be OK to do so rather than locking entire map.\n   *\n   * @param searcher   searcher that includes specified LeaderReaderContext\n   * @param ctx        LeafReaderContext of a segment to compute fingerprint of\n   * @param maxVersion maximum version number to consider for fingerprint computation\n   * @return IndexFingerprint of the segment\n   * @throws IOException Can throw IOException\n   */\n  public IndexFingerprint getIndexFingerprint(SolrIndexSearcher searcher, LeafReaderContext ctx, long maxVersion)\n      throws IOException {\n    IndexReader.CacheHelper cacheHelper = ctx.reader().getReaderCacheHelper();\n    if (cacheHelper == null) {\n      log.debug(\"Cannot cache IndexFingerprint as reader does not support caching. searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      return IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n    }\n\n    IndexFingerprint f = null;\n    f = perSegmentFingerprintCache.get(cacheHelper.getKey());\n    // fingerprint is either not cached or\n    // if we want fingerprint only up to a version less than maxVersionEncountered in the segment, or\n    // documents were deleted from segment for which fingerprint was cached\n    //\n    if (f == null || (f.getMaxInHash() > maxVersion) || (f.getNumDocs() != ctx.reader().numDocs())) {\n      log.debug(\"IndexFingerprint cache miss for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n      f = IndexFingerprint.getFingerprint(searcher, ctx, maxVersion);\n      // cache fingerprint for the segment only if all the versions in the segment are included in the fingerprint\n      if (f.getMaxVersionEncountered() == f.getMaxInHash()) {\n        log.debug(\"Caching fingerprint for searcher:{} leafReaderContext:{} mavVersion:{}\", searcher, ctx, maxVersion);\n        perSegmentFingerprintCache.put(cacheHelper.getKey(), f);\n      }\n\n    } else {\n      log.debug(\"IndexFingerprint cache hit for searcher:{} reader:{} readerHash:{} maxVersion:{}\", searcher, ctx.reader(), ctx.reader().hashCode(), maxVersion);\n    }\n    log.debug(\"Cache Size: {}, Segments Size:{}\", perSegmentFingerprintCache.size(), searcher.getTopReaderContext().leaves().size());\n    return f;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"425c2986e128f9e4aadd629cdf3b04e7aacb7c80":["d211216c83f01894810543d1c107160a9ae3650b"],"b11122ff28c20e6e4e02cb1366eaa029a92f69ce":["b437b84da5e49daf1197c9cd533015490cdcb2c2"],"b437b84da5e49daf1197c9cd533015490cdcb2c2":["05569170a222447d3aec8fad773feedf4429fdd5"],"2668c99990e4c94a78bac005aa682b7c5986d23a":["425c2986e128f9e4aadd629cdf3b04e7aacb7c80"],"140be51d03394488536f4aacedace29f9b318347":["2668c99990e4c94a78bac005aa682b7c5986d23a"],"d211216c83f01894810543d1c107160a9ae3650b":["e2663d2ab6c608590fac0aa672e94a5a56744331"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b11122ff28c20e6e4e02cb1366eaa029a92f69ce"],"e2663d2ab6c608590fac0aa672e94a5a56744331":["b11122ff28c20e6e4e02cb1366eaa029a92f69ce"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f","e2663d2ab6c608590fac0aa672e94a5a56744331"],"05569170a222447d3aec8fad773feedf4429fdd5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["140be51d03394488536f4aacedace29f9b318347"]},"commit2Childs":{"425c2986e128f9e4aadd629cdf3b04e7aacb7c80":["2668c99990e4c94a78bac005aa682b7c5986d23a"],"b11122ff28c20e6e4e02cb1366eaa029a92f69ce":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f","e2663d2ab6c608590fac0aa672e94a5a56744331"],"b437b84da5e49daf1197c9cd533015490cdcb2c2":["b11122ff28c20e6e4e02cb1366eaa029a92f69ce"],"2668c99990e4c94a78bac005aa682b7c5986d23a":["140be51d03394488536f4aacedace29f9b318347"],"d211216c83f01894810543d1c107160a9ae3650b":["425c2986e128f9e4aadd629cdf3b04e7aacb7c80"],"140be51d03394488536f4aacedace29f9b318347":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f","05569170a222447d3aec8fad773feedf4429fdd5"],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7"],"e2663d2ab6c608590fac0aa672e94a5a56744331":["d211216c83f01894810543d1c107160a9ae3650b","09ab8ee44ca898536770d0106a7c0ee4be4f0eb7"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":[],"05569170a222447d3aec8fad773feedf4429fdd5":["b437b84da5e49daf1197c9cd533015490cdcb2c2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}