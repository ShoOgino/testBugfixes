{"path":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#doTestSortedNumericBlocksOfVariousBitsPerValue(LongSupplier).mjava","commits":[{"id":"03e17b020972a0d6e8d6823f545571a66646a167","date":1547847724,"type":1,"author":"Toke Eskildsen","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#doTestSortedNumericBlocksOfVariousBitsPerValue(LongSupplier).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#doTestSortedNumericBlocksOfVariousBitsPerValue(LongSupplier).mjava","sourceNew":"  private void doTestSortedNumericBlocksOfVariousBitsPerValue(LongSupplier counts) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    conf.setMaxBufferedDocs(atLeast(Lucene70DocValuesFormat.NUMERIC_BLOCK_SIZE));\n    conf.setRAMBufferSizeMB(-1);\n    conf.setMergePolicy(newLogMergePolicy(random().nextBoolean()));\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final int numDocs = atLeast(Lucene70DocValuesFormat.NUMERIC_BLOCK_SIZE*3);\n    final LongSupplier values = blocksOfVariousBPV();\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      \n      int valueCount = (int) counts.getAsLong();\n      long valueArray[] = new long[valueCount];\n      for (int j = 0; j < valueCount; j++) {\n        long value = values.getAsLong();\n        valueArray[j] = value;\n        doc.add(new SortedNumericDocValuesField(\"dv\", value));\n      }\n      Arrays.sort(valueArray);\n      for (int j = 0; j < valueCount; j++) {\n        doc.add(new StoredField(\"stored\", Long.toString(valueArray[j])));\n      }\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    writer.forceMerge(1);\n\n    writer.close();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      SortedNumericDocValues docValues = DocValues.getSortedNumeric(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        if (i > docValues.docID()) {\n          docValues.nextDoc();\n        }\n        String expected[] = r.document(i).getValues(\"stored\");\n        if (i < docValues.docID()) {\n          assertEquals(0, expected.length);\n        } else {\n          String actual[] = new String[docValues.docValueCount()];\n          for (int j = 0; j < actual.length; j++) {\n            actual[j] = Long.toString(docValues.nextValue());\n          }\n          assertArrayEquals(expected, actual);\n        }\n      }\n    }\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  private void doTestSortedNumericBlocksOfVariousBitsPerValue(LongSupplier counts) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    conf.setMaxBufferedDocs(atLeast(Lucene70DocValuesFormat.NUMERIC_BLOCK_SIZE));\n    conf.setRAMBufferSizeMB(-1);\n    conf.setMergePolicy(newLogMergePolicy(random().nextBoolean()));\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final int numDocs = atLeast(Lucene70DocValuesFormat.NUMERIC_BLOCK_SIZE*3);\n    final LongSupplier values = blocksOfVariousBPV();\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      \n      int valueCount = (int) counts.getAsLong();\n      long valueArray[] = new long[valueCount];\n      for (int j = 0; j < valueCount; j++) {\n        long value = values.getAsLong();\n        valueArray[j] = value;\n        doc.add(new SortedNumericDocValuesField(\"dv\", value));\n      }\n      Arrays.sort(valueArray);\n      for (int j = 0; j < valueCount; j++) {\n        doc.add(new StoredField(\"stored\", Long.toString(valueArray[j])));\n      }\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    writer.forceMerge(1);\n\n    writer.close();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      SortedNumericDocValues docValues = DocValues.getSortedNumeric(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        if (i > docValues.docID()) {\n          docValues.nextDoc();\n        }\n        String expected[] = r.document(i).getValues(\"stored\");\n        if (i < docValues.docID()) {\n          assertEquals(0, expected.length);\n        } else {\n          String actual[] = new String[docValues.docValueCount()];\n          for (int j = 0; j < actual.length; j++) {\n            actual[j] = Long.toString(docValues.nextValue());\n          }\n          assertArrayEquals(expected, actual);\n        }\n      }\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c89f1ef80a9432f4eabaeda9a1e135cd72e60836","date":1547972642,"type":1,"author":"Tommaso Teofili","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#doTestSortedNumericBlocksOfVariousBitsPerValue(LongSupplier).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#doTestSortedNumericBlocksOfVariousBitsPerValue(LongSupplier).mjava","sourceNew":"  private void doTestSortedNumericBlocksOfVariousBitsPerValue(LongSupplier counts) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    conf.setMaxBufferedDocs(atLeast(Lucene70DocValuesFormat.NUMERIC_BLOCK_SIZE));\n    conf.setRAMBufferSizeMB(-1);\n    conf.setMergePolicy(newLogMergePolicy(random().nextBoolean()));\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final int numDocs = atLeast(Lucene70DocValuesFormat.NUMERIC_BLOCK_SIZE*3);\n    final LongSupplier values = blocksOfVariousBPV();\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      \n      int valueCount = (int) counts.getAsLong();\n      long valueArray[] = new long[valueCount];\n      for (int j = 0; j < valueCount; j++) {\n        long value = values.getAsLong();\n        valueArray[j] = value;\n        doc.add(new SortedNumericDocValuesField(\"dv\", value));\n      }\n      Arrays.sort(valueArray);\n      for (int j = 0; j < valueCount; j++) {\n        doc.add(new StoredField(\"stored\", Long.toString(valueArray[j])));\n      }\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    writer.forceMerge(1);\n\n    writer.close();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      SortedNumericDocValues docValues = DocValues.getSortedNumeric(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        if (i > docValues.docID()) {\n          docValues.nextDoc();\n        }\n        String expected[] = r.document(i).getValues(\"stored\");\n        if (i < docValues.docID()) {\n          assertEquals(0, expected.length);\n        } else {\n          String actual[] = new String[docValues.docValueCount()];\n          for (int j = 0; j < actual.length; j++) {\n            actual[j] = Long.toString(docValues.nextValue());\n          }\n          assertArrayEquals(expected, actual);\n        }\n      }\n    }\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  private void doTestSortedNumericBlocksOfVariousBitsPerValue(LongSupplier counts) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    conf.setMaxBufferedDocs(atLeast(Lucene70DocValuesFormat.NUMERIC_BLOCK_SIZE));\n    conf.setRAMBufferSizeMB(-1);\n    conf.setMergePolicy(newLogMergePolicy(random().nextBoolean()));\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final int numDocs = atLeast(Lucene70DocValuesFormat.NUMERIC_BLOCK_SIZE*3);\n    final LongSupplier values = blocksOfVariousBPV();\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      \n      int valueCount = (int) counts.getAsLong();\n      long valueArray[] = new long[valueCount];\n      for (int j = 0; j < valueCount; j++) {\n        long value = values.getAsLong();\n        valueArray[j] = value;\n        doc.add(new SortedNumericDocValuesField(\"dv\", value));\n      }\n      Arrays.sort(valueArray);\n      for (int j = 0; j < valueCount; j++) {\n        doc.add(new StoredField(\"stored\", Long.toString(valueArray[j])));\n      }\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    writer.forceMerge(1);\n\n    writer.close();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      SortedNumericDocValues docValues = DocValues.getSortedNumeric(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        if (i > docValues.docID()) {\n          docValues.nextDoc();\n        }\n        String expected[] = r.document(i).getValues(\"stored\");\n        if (i < docValues.docID()) {\n          assertEquals(0, expected.length);\n        } else {\n          String actual[] = new String[docValues.docValueCount()];\n          for (int j = 0; j < actual.length; j++) {\n            actual[j] = Long.toString(docValues.nextValue());\n          }\n          assertArrayEquals(expected, actual);\n        }\n      }\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57cb6df494f10aeb3fab477b1ce4a9187455a227","date":1574155024,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#doTestSortedNumericBlocksOfVariousBitsPerValue(LongSupplier).mjava","sourceNew":null,"sourceOld":"  private void doTestSortedNumericBlocksOfVariousBitsPerValue(LongSupplier counts) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    conf.setMaxBufferedDocs(atLeast(Lucene70DocValuesFormat.NUMERIC_BLOCK_SIZE));\n    conf.setRAMBufferSizeMB(-1);\n    conf.setMergePolicy(newLogMergePolicy(random().nextBoolean()));\n    IndexWriter writer = new IndexWriter(dir, conf);\n    \n    final int numDocs = atLeast(Lucene70DocValuesFormat.NUMERIC_BLOCK_SIZE*3);\n    final LongSupplier values = blocksOfVariousBPV();\n    for (int i = 0; i < numDocs; i++) {\n      Document doc = new Document();\n      \n      int valueCount = (int) counts.getAsLong();\n      long valueArray[] = new long[valueCount];\n      for (int j = 0; j < valueCount; j++) {\n        long value = values.getAsLong();\n        valueArray[j] = value;\n        doc.add(new SortedNumericDocValuesField(\"dv\", value));\n      }\n      Arrays.sort(valueArray);\n      for (int j = 0; j < valueCount; j++) {\n        doc.add(new StoredField(\"stored\", Long.toString(valueArray[j])));\n      }\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    writer.forceMerge(1);\n\n    writer.close();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      SortedNumericDocValues docValues = DocValues.getSortedNumeric(r, \"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        if (i > docValues.docID()) {\n          docValues.nextDoc();\n        }\n        String expected[] = r.document(i).getValues(\"stored\");\n        if (i < docValues.docID()) {\n          assertEquals(0, expected.length);\n        } else {\n          String actual[] = new String[docValues.docValueCount()];\n          for (int j = 0; j < actual.length; j++) {\n            actual[j] = Long.toString(docValues.nextValue());\n          }\n          assertArrayEquals(expected, actual);\n        }\n      }\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"03e17b020972a0d6e8d6823f545571a66646a167":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","03e17b020972a0d6e8d6823f545571a66646a167"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"57cb6df494f10aeb3fab477b1ce4a9187455a227":["03e17b020972a0d6e8d6823f545571a66646a167"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["57cb6df494f10aeb3fab477b1ce4a9187455a227"]},"commit2Childs":{"03e17b020972a0d6e8d6823f545571a66646a167":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","57cb6df494f10aeb3fab477b1ce4a9187455a227"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["03e17b020972a0d6e8d6823f545571a66646a167","c89f1ef80a9432f4eabaeda9a1e135cd72e60836"],"57cb6df494f10aeb3fab477b1ce4a9187455a227":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}