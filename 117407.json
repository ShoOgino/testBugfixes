{"path":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","commits":[{"id":"ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d","date":1426480823,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","pathOld":"/dev/null","sourceNew":"  // called from FieldFacetProcessor\n  // TODO: do a callback version that can be specialized!\n  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    DocSet docs = processor.fcontext.base;\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n\n    int uniqueTerms = 0;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        // handle the biggest terms\n        try ( DocSet intersection = searcher.getDocSet(new TermQuery(new Term(field, tt.term)), docs); )\n        {\n          int collected = processor.collect(intersection, tt.termNum - startTermIndex);\n          processor.countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      // TODO: handle facet.prefix here!!!\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              // should be impossible\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReader(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            processor.countAcc.incrementCount(arrIdx, 1);\n            processor.collect(segDoc, arrIdx);\n            if (processor.allBucketsSlot >= 0) {\n              processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n              processor.collect(segDoc, processor.allBucketsSlot);\n            }\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              processor.countAcc.incrementCount(arrIdx, 1);\n              processor.collect(segDoc, arrIdx);\n              if (processor.allBucketsSlot >= 0) {\n                processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n                processor.collect(segDoc, processor.allBucketsSlot);\n              }\n\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2fa33edb6216dc94f84690314f1ca005ab42cc99","date":1427399820,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","sourceNew":"  // called from FieldFacetProcessor\n  // TODO: do a callback version that can be specialized!\n  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    if (processor.accs.length==1 && processor.accs[0] instanceof CountSlotAcc)\n\n    use.incrementAndGet();\n\n    DocSet docs = processor.fcontext.base;\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n\n    int uniqueTerms = 0;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        // handle the biggest terms\n        try ( DocSet intersection = searcher.getDocSet(new TermQuery(new Term(field, tt.term)), docs); )\n        {\n          int collected = processor.collect(intersection, tt.termNum - startTermIndex);\n          processor.countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      // TODO: handle facet.prefix here!!!\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              // should be impossible\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReader(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            processor.countAcc.incrementCount(arrIdx, 1);\n            processor.collect(segDoc, arrIdx);\n            if (processor.allBucketsSlot >= 0) {\n              processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n              processor.collect(segDoc, processor.allBucketsSlot);\n            }\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              processor.countAcc.incrementCount(arrIdx, 1);\n              processor.collect(segDoc, arrIdx);\n              if (processor.allBucketsSlot >= 0) {\n                processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n                processor.collect(segDoc, processor.allBucketsSlot);\n              }\n\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n\n","sourceOld":"  // called from FieldFacetProcessor\n  // TODO: do a callback version that can be specialized!\n  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    DocSet docs = processor.fcontext.base;\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n\n    int uniqueTerms = 0;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        // handle the biggest terms\n        try ( DocSet intersection = searcher.getDocSet(new TermQuery(new Term(field, tt.term)), docs); )\n        {\n          int collected = processor.collect(intersection, tt.termNum - startTermIndex);\n          processor.countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      // TODO: handle facet.prefix here!!!\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              // should be impossible\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReader(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            processor.countAcc.incrementCount(arrIdx, 1);\n            processor.collect(segDoc, arrIdx);\n            if (processor.allBucketsSlot >= 0) {\n              processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n              processor.collect(segDoc, processor.allBucketsSlot);\n            }\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              processor.countAcc.incrementCount(arrIdx, 1);\n              processor.collect(segDoc, arrIdx);\n              if (processor.allBucketsSlot >= 0) {\n                processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n                processor.collect(segDoc, processor.allBucketsSlot);\n              }\n\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"16ade4f0c13fba30ca00e1117fbca16adffc6d58","date":1427399980,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","sourceNew":"  // called from FieldFacetProcessor\n  // TODO: do a callback version that can be specialized!\n  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    DocSet docs = processor.fcontext.base;\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n\n    int uniqueTerms = 0;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        // handle the biggest terms\n        try ( DocSet intersection = searcher.getDocSet(new TermQuery(new Term(field, tt.term)), docs); )\n        {\n          int collected = processor.collect(intersection, tt.termNum - startTermIndex);\n          processor.countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      // TODO: handle facet.prefix here!!!\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              // should be impossible\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReader(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            processor.countAcc.incrementCount(arrIdx, 1);\n            processor.collect(segDoc, arrIdx);\n            if (processor.allBucketsSlot >= 0) {\n              processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n              processor.collect(segDoc, processor.allBucketsSlot);\n            }\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              processor.countAcc.incrementCount(arrIdx, 1);\n              processor.collect(segDoc, arrIdx);\n              if (processor.allBucketsSlot >= 0) {\n                processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n                processor.collect(segDoc, processor.allBucketsSlot);\n              }\n\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n\n","sourceOld":"  // called from FieldFacetProcessor\n  // TODO: do a callback version that can be specialized!\n  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    if (processor.accs.length==1 && processor.accs[0] instanceof CountSlotAcc)\n\n    use.incrementAndGet();\n\n    DocSet docs = processor.fcontext.base;\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n\n    int uniqueTerms = 0;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        // handle the biggest terms\n        try ( DocSet intersection = searcher.getDocSet(new TermQuery(new Term(field, tt.term)), docs); )\n        {\n          int collected = processor.collect(intersection, tt.termNum - startTermIndex);\n          processor.countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      // TODO: handle facet.prefix here!!!\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              // should be impossible\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReader(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            processor.countAcc.incrementCount(arrIdx, 1);\n            processor.collect(segDoc, arrIdx);\n            if (processor.allBucketsSlot >= 0) {\n              processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n              processor.collect(segDoc, processor.allBucketsSlot);\n            }\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              processor.countAcc.incrementCount(arrIdx, 1);\n              processor.collect(segDoc, arrIdx);\n              if (processor.allBucketsSlot >= 0) {\n                processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n                processor.collect(segDoc, processor.allBucketsSlot);\n              }\n\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4a7c13535572b8e97cc477fc3388a57321a7751a","date":1427500960,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","sourceNew":"  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    if (processor.accs.length == 0 && processor.startTermIndex == 0 && processor.endTermIndex >= numTermsInField)\n    {\n      int[] arr = processor.countAcc.getCountArray();\n      getCountsInArray(processor, arr);\n\n      /*** debugging\n      int sz = processor.countAcc.getCountArray().length;\n      CountSlotAcc acc = processor.countAcc;\n      CountSlotAcc acc2 = new CountSlotAcc(processor.fcontext, sz);\n      processor.countAcc = acc2;\n      collectDocsGeneric(processor); // hopefully we can call this again?\n\n      for (int i=0; i<sz; i++) {\n        if (acc.getCount(i) != acc2.getCount(i)) {\n          System.out.println(\"ERROR! ERROR! i=\" + i + \" counts=\" + acc.getCount(i) + \" \" + acc2.getCount(i));\n          CountSlotAcc acc3 = new CountSlotAcc(processor.fcontext, sz);  // put breakpoint here and re-execute\n          processor.countAcc = acc3;\n          int[] arr3 = processor.countAcc.getCountArray();\n          getCountsInArray(processor, arr3);\n        }\n      }\n       ***/\n\n      return;\n    }\n\n    collectDocsGeneric(processor);\n  }\n\n","sourceOld":"  // called from FieldFacetProcessor\n  // TODO: do a callback version that can be specialized!\n  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    use.incrementAndGet();\n\n    DocSet docs = processor.fcontext.base;\n    int startTermIndex = processor.startTermIndex;\n    int endTermIndex = processor.endTermIndex;\n    int nTerms = processor.nTerms;\n\n    int uniqueTerms = 0;\n\n    for (TopTerm tt : bigTerms.values()) {\n      if (tt.termNum >= startTermIndex && tt.termNum < endTermIndex) {\n        // handle the biggest terms\n        try ( DocSet intersection = searcher.getDocSet(new TermQuery(new Term(field, tt.term)), docs); )\n        {\n          int collected = processor.collect(intersection, tt.termNum - startTermIndex);\n          processor.countAcc.incrementCount(tt.termNum - startTermIndex, collected);\n          if (collected > 0) {\n            uniqueTerms++;\n          }\n        }\n      }\n    }\n\n    if (termInstances > 0) {\n\n      final List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();\n      final Iterator<LeafReaderContext> ctxIt = leaves.iterator();\n      LeafReaderContext ctx = null;\n      int segBase = 0;\n      int segMax;\n      int adjustedMax = 0;\n\n\n      // TODO: handle facet.prefix here!!!\n\n      DocIterator iter = docs.iterator();\n      while (iter.hasNext()) {\n        int doc = iter.nextDoc();\n\n        if (doc >= adjustedMax) {\n          do {\n            ctx = ctxIt.next();\n            if (ctx == null) {\n              // should be impossible\n              throw new RuntimeException(\"INTERNAL FACET ERROR\");\n            }\n            segBase = ctx.docBase;\n            segMax = ctx.reader().maxDoc();\n            adjustedMax = segBase + segMax;\n          } while (doc >= adjustedMax);\n          assert doc >= ctx.docBase;\n          processor.setNextReader(ctx);\n        }\n        int segDoc = doc - segBase;\n\n\n        int code = index[doc];\n\n        if ((code & 0xff)==1) {\n          int pos = code>>>8;\n          int whichArray = (doc >>> 16) & 0xff;\n          byte[] arr = tnums[whichArray];\n          int tnum = 0;\n          for(;;) {\n            int delta = 0;\n            for(;;) {\n              byte b = arr[pos++];\n              delta = (delta << 7) | (b & 0x7f);\n              if ((b & 0x80) == 0) break;\n            }\n            if (delta == 0) break;\n            tnum += delta - TNUM_OFFSET;\n            int arrIdx = tnum - startTermIndex;\n            if (arrIdx < 0) continue;\n            if (arrIdx >= nTerms) break;\n            processor.countAcc.incrementCount(arrIdx, 1);\n            processor.collect(segDoc, arrIdx);\n            if (processor.allBucketsSlot >= 0) {\n              processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n              processor.collect(segDoc, processor.allBucketsSlot);\n            }\n          }\n        } else {\n          int tnum = 0;\n          int delta = 0;\n          for (;;) {\n            delta = (delta << 7) | (code & 0x7f);\n            if ((code & 0x80)==0) {\n              if (delta==0) break;\n              tnum += delta - TNUM_OFFSET;\n              int arrIdx = tnum - startTermIndex;\n              if (arrIdx < 0) continue;\n              if (arrIdx >= nTerms) break;\n              processor.countAcc.incrementCount(arrIdx, 1);\n              processor.collect(segDoc, arrIdx);\n              if (processor.allBucketsSlot >= 0) {\n                processor.countAcc.incrementCount(processor.allBucketsSlot, 1);\n                processor.collect(segDoc, processor.allBucketsSlot);\n              }\n\n              delta = 0;\n            }\n            code >>>= 8;\n          }\n        }\n      }\n    }\n\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":0,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","pathOld":"/dev/null","sourceNew":"  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    if (processor.accs.length == 0 && processor.startTermIndex == 0 && processor.endTermIndex >= numTermsInField)\n    {\n      int[] arr = processor.countAcc.getCountArray();\n      getCountsInArray(processor, arr);\n\n      /*** debugging\n      int sz = processor.countAcc.getCountArray().length;\n      CountSlotAcc acc = processor.countAcc;\n      CountSlotAcc acc2 = new CountSlotAcc(processor.fcontext, sz);\n      processor.countAcc = acc2;\n      collectDocsGeneric(processor); // hopefully we can call this again?\n\n      for (int i=0; i<sz; i++) {\n        if (acc.getCount(i) != acc2.getCount(i)) {\n          System.out.println(\"ERROR! ERROR! i=\" + i + \" counts=\" + acc.getCount(i) + \" \" + acc2.getCount(i));\n          CountSlotAcc acc3 = new CountSlotAcc(processor.fcontext, sz);  // put breakpoint here and re-execute\n          processor.countAcc = acc3;\n          int[] arr3 = processor.countAcc.getCountArray();\n          getCountsInArray(processor, arr3);\n        }\n      }\n       ***/\n\n      return;\n    }\n\n    collectDocsGeneric(processor);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"48a04370d92de1fba80afce42dd014d5a1e3aa52","date":1431204655,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","sourceNew":"  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    if (processor.accs.length == 0 && processor.startTermIndex == 0 && processor.endTermIndex >= numTermsInField)\n    {\n      getCounts(processor, processor.countAcc);\n\n      /*** debugging\n      int sz = processor.countAcc.getCountArray().length;\n      CountSlotAcc acc = processor.countAcc;\n      CountSlotAcc acc2 = new CountSlotAcc(processor.fcontext, sz);\n      processor.countAcc = acc2;\n      collectDocsGeneric(processor); // hopefully we can call this again?\n\n      for (int i=0; i<sz; i++) {\n        if (acc.getCount(i) != acc2.getCount(i)) {\n          System.out.println(\"ERROR! ERROR! i=\" + i + \" counts=\" + acc.getCount(i) + \" \" + acc2.getCount(i));\n          CountSlotAcc acc3 = new CountSlotAcc(processor.fcontext, sz);  // put breakpoint here and re-execute\n          processor.countAcc = acc3;\n          int[] arr3 = processor.countAcc.getCountArray();\n          getCountsInArray(processor, arr3);\n        }\n      }\n       ***/\n\n      return;\n    }\n\n    collectDocsGeneric(processor);\n  }\n\n","sourceOld":"  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    if (processor.accs.length == 0 && processor.startTermIndex == 0 && processor.endTermIndex >= numTermsInField)\n    {\n      int[] arr = processor.countAcc.getCountArray();\n      getCountsInArray(processor, arr);\n\n      /*** debugging\n      int sz = processor.countAcc.getCountArray().length;\n      CountSlotAcc acc = processor.countAcc;\n      CountSlotAcc acc2 = new CountSlotAcc(processor.fcontext, sz);\n      processor.countAcc = acc2;\n      collectDocsGeneric(processor); // hopefully we can call this again?\n\n      for (int i=0; i<sz; i++) {\n        if (acc.getCount(i) != acc2.getCount(i)) {\n          System.out.println(\"ERROR! ERROR! i=\" + i + \" counts=\" + acc.getCount(i) + \" \" + acc2.getCount(i));\n          CountSlotAcc acc3 = new CountSlotAcc(processor.fcontext, sz);  // put breakpoint here and re-execute\n          processor.countAcc = acc3;\n          int[] arr3 = processor.countAcc.getCountArray();\n          getCountsInArray(processor, arr3);\n        }\n      }\n       ***/\n\n      return;\n    }\n\n    collectDocsGeneric(processor);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9e13d0d4d8b6dc352cb304974502b9a36c153f78","date":1436492687,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","sourceNew":"  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    if (processor.collectAcc==null && processor.missingAcc == null && processor.allBucketsAcc == null && processor.startTermIndex == 0 && processor.endTermIndex >= numTermsInField) {\n      getCounts(processor, processor.countAcc);\n      return;\n    }\n\n    collectDocsGeneric(processor);\n  }\n\n","sourceOld":"  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    if (processor.accs.length == 0 && processor.startTermIndex == 0 && processor.endTermIndex >= numTermsInField)\n    {\n      getCounts(processor, processor.countAcc);\n\n      /*** debugging\n      int sz = processor.countAcc.getCountArray().length;\n      CountSlotAcc acc = processor.countAcc;\n      CountSlotAcc acc2 = new CountSlotAcc(processor.fcontext, sz);\n      processor.countAcc = acc2;\n      collectDocsGeneric(processor); // hopefully we can call this again?\n\n      for (int i=0; i<sz; i++) {\n        if (acc.getCount(i) != acc2.getCount(i)) {\n          System.out.println(\"ERROR! ERROR! i=\" + i + \" counts=\" + acc.getCount(i) + \" \" + acc2.getCount(i));\n          CountSlotAcc acc3 = new CountSlotAcc(processor.fcontext, sz);  // put breakpoint here and re-execute\n          processor.countAcc = acc3;\n          int[] arr3 = processor.countAcc.getCountArray();\n          getCountsInArray(processor, arr3);\n        }\n      }\n       ***/\n\n      return;\n    }\n\n    collectDocsGeneric(processor);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"168f749bbf9022a1ba5fea29c54baa1c00883d1d","date":1437587676,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","sourceNew":"  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    if (processor.collectAcc==null && processor.allBucketsAcc == null && processor.startTermIndex == 0 && processor.endTermIndex >= numTermsInField) {\n      getCounts(processor, processor.countAcc);\n      return;\n    }\n\n    collectDocsGeneric(processor);\n  }\n\n","sourceOld":"  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    if (processor.collectAcc==null && processor.missingAcc == null && processor.allBucketsAcc == null && processor.startTermIndex == 0 && processor.endTermIndex >= numTermsInField) {\n      getCounts(processor, processor.countAcc);\n      return;\n    }\n\n    collectDocsGeneric(processor);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79759974460bc59933cd169acc94f5c6b16368d5","date":1471318443,"type":5,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorByArrayUIF).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","sourceNew":"  public void collectDocs(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    if (processor.collectAcc==null && processor.allBucketsAcc == null && processor.startTermIndex == 0 && processor.endTermIndex >= numTermsInField) {\n      getCounts(processor, processor.countAcc);\n      return;\n    }\n\n    collectDocsGeneric(processor);\n  }\n\n","sourceOld":"  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    if (processor.collectAcc==null && processor.allBucketsAcc == null && processor.startTermIndex == 0 && processor.endTermIndex >= numTermsInField) {\n      getCounts(processor, processor.countAcc);\n      return;\n    }\n\n    collectDocsGeneric(processor);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6","date":1471496851,"type":5,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorByArrayUIF).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","sourceNew":"  public void collectDocs(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    if (processor.collectAcc==null && processor.allBucketsAcc == null && processor.startTermIndex == 0 && processor.endTermIndex >= numTermsInField) {\n      getCounts(processor, processor.countAcc);\n      return;\n    }\n\n    collectDocsGeneric(processor);\n  }\n\n","sourceOld":"  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    if (processor.collectAcc==null && processor.allBucketsAcc == null && processor.startTermIndex == 0 && processor.endTermIndex >= numTermsInField) {\n      getCounts(processor, processor.countAcc);\n      return;\n    }\n\n    collectDocsGeneric(processor);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"403d05f7f8d69b65659157eff1bc1d2717f04c66","date":1471692961,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorByArrayUIF).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","sourceNew":"  public void collectDocs(FacetFieldProcessorByArrayUIF processor) throws IOException {\n    if (processor.collectAcc==null && processor.allBucketsAcc == null && processor.startTermIndex == 0 && processor.endTermIndex >= numTermsInField) {\n      getCounts(processor, processor.countAcc);\n      return;\n    }\n\n    collectDocsGeneric(processor);\n  }\n\n","sourceOld":"  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    if (processor.collectAcc==null && processor.allBucketsAcc == null && processor.startTermIndex == 0 && processor.endTermIndex >= numTermsInField) {\n      getCounts(processor, processor.countAcc);\n      return;\n    }\n\n    collectDocsGeneric(processor);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/search/facet/UnInvertedField#collectDocs(FacetFieldProcessorUIF).mjava","sourceNew":null,"sourceOld":"  public void collectDocs(FacetFieldProcessorUIF processor) throws IOException {\n    if (processor.collectAcc==null && processor.allBucketsAcc == null && processor.startTermIndex == 0 && processor.endTermIndex >= numTermsInField) {\n      getCounts(processor, processor.countAcc);\n      return;\n    }\n\n    collectDocsGeneric(processor);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"403d05f7f8d69b65659157eff1bc1d2717f04c66":["168f749bbf9022a1ba5fea29c54baa1c00883d1d","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"2fa33edb6216dc94f84690314f1ca005ab42cc99":["ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d"],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["168f749bbf9022a1ba5fea29c54baa1c00883d1d","79759974460bc59933cd169acc94f5c6b16368d5"],"4a7c13535572b8e97cc477fc3388a57321a7751a":["16ade4f0c13fba30ca00e1117fbca16adffc6d58"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["168f749bbf9022a1ba5fea29c54baa1c00883d1d","403d05f7f8d69b65659157eff1bc1d2717f04c66"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4a7c13535572b8e97cc477fc3388a57321a7751a"],"9e13d0d4d8b6dc352cb304974502b9a36c153f78":["48a04370d92de1fba80afce42dd014d5a1e3aa52"],"16ade4f0c13fba30ca00e1117fbca16adffc6d58":["2fa33edb6216dc94f84690314f1ca005ab42cc99"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"48a04370d92de1fba80afce42dd014d5a1e3aa52":["4a7c13535572b8e97cc477fc3388a57321a7751a"],"79759974460bc59933cd169acc94f5c6b16368d5":["168f749bbf9022a1ba5fea29c54baa1c00883d1d"],"168f749bbf9022a1ba5fea29c54baa1c00883d1d":["9e13d0d4d8b6dc352cb304974502b9a36c153f78"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["403d05f7f8d69b65659157eff1bc1d2717f04c66"]},"commit2Childs":{"403d05f7f8d69b65659157eff1bc1d2717f04c66":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2fa33edb6216dc94f84690314f1ca005ab42cc99":["16ade4f0c13fba30ca00e1117fbca16adffc6d58"],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"4a7c13535572b8e97cc477fc3388a57321a7751a":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","48a04370d92de1fba80afce42dd014d5a1e3aa52"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"16ade4f0c13fba30ca00e1117fbca16adffc6d58":["4a7c13535572b8e97cc477fc3388a57321a7751a"],"9e13d0d4d8b6dc352cb304974502b9a36c153f78":["168f749bbf9022a1ba5fea29c54baa1c00883d1d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d"],"ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d":["2fa33edb6216dc94f84690314f1ca005ab42cc99"],"79759974460bc59933cd169acc94f5c6b16368d5":["2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"48a04370d92de1fba80afce42dd014d5a1e3aa52":["9e13d0d4d8b6dc352cb304974502b9a36c153f78"],"168f749bbf9022a1ba5fea29c54baa1c00883d1d":["403d05f7f8d69b65659157eff1bc1d2717f04c66","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","79759974460bc59933cd169acc94f5c6b16368d5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}