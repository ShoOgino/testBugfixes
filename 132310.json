{"path":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                TermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n                try\n                {\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.term());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","sourceOld":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                TermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n                try\n                {\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.term());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a7347509fad0711ac30cb15a746e9a3830a38ebd","date":1275388513,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n                try\n                {\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.toString());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","sourceOld":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                TermAttribute termAtt = ts.addAttribute(TermAttribute.class);\n                try\n                {\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.term());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4","date":1305207152,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n                try\n                {\n                  ts.reset();\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.toString());\n\t                }\n\t                ts.end();\n\t                ts.close();\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","sourceOld":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n                try\n                {\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.toString());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n                try\n                {\n                  ts.reset();\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.toString());\n\t                }\n\t                ts.end();\n\t                ts.close();\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","sourceOld":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n                try\n                {\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.toString());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"00746ad002a54281629e3b6f3eb39833a33f093e","date":1305306799,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                try\n                {\n                  TokenStream ts = analyzer.reusableTokenStream(fields[i],new StringReader(stopWords));\n                  CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n                  ts.reset();\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.toString());\n\t                }\n\t                ts.end();\n\t                ts.close();\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","sourceOld":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n                try\n                {\n                  ts.reset();\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.toString());\n\t                }\n\t                ts.end();\n\t                ts.close();\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c3a8a449466c1ff7ce2274fe73dab487256964b4","date":1305735867,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                try\n                {\n                  TokenStream ts = analyzer.reusableTokenStream(fields[i],new StringReader(stopWords));\n                  CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n                  ts.reset();\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.toString());\n\t                }\n\t                ts.end();\n\t                ts.close();\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","sourceOld":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n                try\n                {\n                  ts.reset();\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.toString());\n\t                }\n\t                ts.end();\n\t                ts.close();\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                try\n                {\n                  TokenStream ts = analyzer.reusableTokenStream(fields[i],new StringReader(stopWords));\n                  CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n                  ts.reset();\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.toString());\n\t                }\n\t                ts.end();\n\t                ts.close();\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","sourceOld":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));\n                CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n                try\n                {\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.toString());\n\t                }\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae46d105c94ea6ceb5201189bf9611bdef91b1b4","date":1310997409,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                try\n                {\n                  TokenStream ts = analyzer.reusableTokenStream(fields[i],new StringReader(stopWords));\n                  CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n                  ts.reset();\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.toString());\n\t                }\n\t                ts.end();\n\t                ts.close();\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer, fields[0]);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","sourceOld":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                try\n                {\n                  TokenStream ts = analyzer.reusableTokenStream(fields[i],new StringReader(stopWords));\n                  CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n                  ts.reset();\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.toString());\n\t                }\n\t                ts.end();\n\t                ts.close();\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","bugFix":["6a361a621b184d9b73c9c9a37323a9845b8f8260"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b68b0aeb05de4dd5b24fc5ffd51e2fbd5d571df2","date":1313460667,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"  /* (non-Javadoc)\n    * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n    */\n  public Query getQuery(Element e) throws ParserException {\n    String fieldsList = e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n    String fields[] = defaultFieldNames;\n    if ((fieldsList != null) && (fieldsList.trim().length() > 0)) {\n      fields = fieldsList.trim().split(\",\");\n      //trim the fieldnames\n      for (int i = 0; i < fields.length; i++) {\n        fields[i] = fields[i].trim();\n      }\n    }\n\n    //Parse any \"stopWords\" attribute\n    //TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then\n    //I use all analyzers/fields to generate multi-field compatible stop list\n    String stopWords = e.getAttribute(\"stopWords\");\n    Set<String> stopWordsSet = null;\n    if ((stopWords != null) && (fields != null)) {\n      stopWordsSet = new HashSet<String>();\n      for (String field : fields) {\n        try {\n          TokenStream ts = analyzer.reusableTokenStream(field, new StringReader(stopWords));\n          CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n          ts.reset();\n          while (ts.incrementToken()) {\n            stopWordsSet.add(termAtt.toString());\n          }\n          ts.end();\n          ts.close();\n        } catch (IOException ioe) {\n          throw new ParserException(\"IoException parsing stop words list in \"\n              + getClass().getName() + \":\" + ioe.getLocalizedMessage());\n        }\n      }\n    }\n\n\n    MoreLikeThisQuery mlt = new MoreLikeThisQuery(DOMUtils.getText(e), fields, analyzer, fields[0]);\n    mlt.setMaxQueryTerms(DOMUtils.getAttribute(e, \"maxQueryTerms\", DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMinTermFrequency(DOMUtils.getAttribute(e, \"minTermFrequency\", DEFAULT_MIN_TERM_FREQUENCY));\n    mlt.setPercentTermsToMatch(DOMUtils.getAttribute(e, \"percentTermsToMatch\", DEFAULT_PERCENT_TERMS_TO_MATCH) / 100);\n    mlt.setStopWords(stopWordsSet);\n    int minDocFreq = DOMUtils.getAttribute(e, \"minDocFreq\", -1);\n    if (minDocFreq >= 0) {\n      mlt.setMinDocFreq(minDocFreq);\n    }\n\n    mlt.setBoost(DOMUtils.getAttribute(e, \"boost\", 1.0f));\n\n    return mlt;\n  }\n\n","sourceOld":"\t/* (non-Javadoc)\n\t * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n\t */\n\tpublic Query getQuery(Element e) throws ParserException {\n\t\tString fieldsList=e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n\t\tString fields[]=defaultFieldNames;\n\t\tif((fieldsList!=null)&&(fieldsList.trim().length()>0))\n\t\t{\n\t\t\tfields=fieldsList.trim().split(\",\");\n\t\t\t//trim the fieldnames\n\t\t\tfor (int i = 0; i < fields.length; i++) {\n\t\t\t\tfields[i]=fields[i].trim();\n\t\t\t}\n\t\t}\n\t\t\n\t\t//Parse any \"stopWords\" attribute\n\t\t//TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then \n\t\t//I use all analyzers/fields to generate multi-field compatible stop list\n\t\tString stopWords=e.getAttribute(\"stopWords\");\n\t\tSet<String> stopWordsSet=null;\n\t\tif((stopWords!=null)&&(fields!=null))\n\t\t{\n\t\t    stopWordsSet=new HashSet<String>();\n\t\t    for (int i = 0; i < fields.length; i++)\n            {\n                try\n                {\n                  TokenStream ts = analyzer.reusableTokenStream(fields[i],new StringReader(stopWords));\n                  CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n                  ts.reset();\n\t                while(ts.incrementToken()) {\n\t                    stopWordsSet.add(termAtt.toString());\n\t                }\n\t                ts.end();\n\t                ts.close();\n                }\n                catch(IOException ioe)\n                {\n                    throw new ParserException(\"IoException parsing stop words list in \"\n                            +getClass().getName()+\":\"+ioe.getLocalizedMessage());\n                }\n            }\n\t\t}\n\t\t\n\t\t\n\t\tMoreLikeThisQuery mlt=new MoreLikeThisQuery(DOMUtils.getText(e),fields,analyzer, fields[0]);\n\t\tmlt.setMaxQueryTerms(DOMUtils.getAttribute(e,\"maxQueryTerms\",defaultMaxQueryTerms));\n\t\tmlt.setMinTermFrequency(DOMUtils.getAttribute(e,\"minTermFrequency\",defaultMinTermFrequency));\n\t\tmlt.setPercentTermsToMatch(DOMUtils.getAttribute(e,\"percentTermsToMatch\",defaultPercentTermsToMatch)/100);\n\t\tmlt.setStopWords(stopWordsSet);\n\t\tint minDocFreq=DOMUtils.getAttribute(e,\"minDocFreq\",-1);\n\t\tif(minDocFreq>=0)\n\t\t{\n\t\t\tmlt.setMinDocFreq(minDocFreq);\n\t\t}\n\n\t\tmlt.setBoost(DOMUtils.getAttribute(e,\"boost\",1.0f));\n\n\t\treturn mlt;\n\t}\n\n","bugFix":null,"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"251550f5d19b526a76f8c5126ae7bb2d22cf8935","date":1315202008,"type":5,"author":"Christopher John Male","isMerge":false,"pathNew":"modules/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/LikeThisQueryBuilder#getQuery(Element).mjava","pathOld":"lucene/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder#getQuery(Element).mjava","sourceNew":"  /* (non-Javadoc)\n    * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n    */\n  public Query getQuery(Element e) throws ParserException {\n    String fieldsList = e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n    String fields[] = defaultFieldNames;\n    if ((fieldsList != null) && (fieldsList.trim().length() > 0)) {\n      fields = fieldsList.trim().split(\",\");\n      //trim the fieldnames\n      for (int i = 0; i < fields.length; i++) {\n        fields[i] = fields[i].trim();\n      }\n    }\n\n    //Parse any \"stopWords\" attribute\n    //TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then\n    //I use all analyzers/fields to generate multi-field compatible stop list\n    String stopWords = e.getAttribute(\"stopWords\");\n    Set<String> stopWordsSet = null;\n    if ((stopWords != null) && (fields != null)) {\n      stopWordsSet = new HashSet<String>();\n      for (String field : fields) {\n        try {\n          TokenStream ts = analyzer.reusableTokenStream(field, new StringReader(stopWords));\n          CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n          ts.reset();\n          while (ts.incrementToken()) {\n            stopWordsSet.add(termAtt.toString());\n          }\n          ts.end();\n          ts.close();\n        } catch (IOException ioe) {\n          throw new ParserException(\"IoException parsing stop words list in \"\n              + getClass().getName() + \":\" + ioe.getLocalizedMessage());\n        }\n      }\n    }\n\n\n    MoreLikeThisQuery mlt = new MoreLikeThisQuery(DOMUtils.getText(e), fields, analyzer, fields[0]);\n    mlt.setMaxQueryTerms(DOMUtils.getAttribute(e, \"maxQueryTerms\", DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMinTermFrequency(DOMUtils.getAttribute(e, \"minTermFrequency\", DEFAULT_MIN_TERM_FREQUENCY));\n    mlt.setPercentTermsToMatch(DOMUtils.getAttribute(e, \"percentTermsToMatch\", DEFAULT_PERCENT_TERMS_TO_MATCH) / 100);\n    mlt.setStopWords(stopWordsSet);\n    int minDocFreq = DOMUtils.getAttribute(e, \"minDocFreq\", -1);\n    if (minDocFreq >= 0) {\n      mlt.setMinDocFreq(minDocFreq);\n    }\n\n    mlt.setBoost(DOMUtils.getAttribute(e, \"boost\", 1.0f));\n\n    return mlt;\n  }\n\n","sourceOld":"  /* (non-Javadoc)\n    * @see org.apache.lucene.xmlparser.QueryObjectBuilder#process(org.w3c.dom.Element)\n    */\n  public Query getQuery(Element e) throws ParserException {\n    String fieldsList = e.getAttribute(\"fieldNames\"); //a comma-delimited list of fields\n    String fields[] = defaultFieldNames;\n    if ((fieldsList != null) && (fieldsList.trim().length() > 0)) {\n      fields = fieldsList.trim().split(\",\");\n      //trim the fieldnames\n      for (int i = 0; i < fields.length; i++) {\n        fields[i] = fields[i].trim();\n      }\n    }\n\n    //Parse any \"stopWords\" attribute\n    //TODO MoreLikeThis needs to ideally have per-field stopWords lists - until then\n    //I use all analyzers/fields to generate multi-field compatible stop list\n    String stopWords = e.getAttribute(\"stopWords\");\n    Set<String> stopWordsSet = null;\n    if ((stopWords != null) && (fields != null)) {\n      stopWordsSet = new HashSet<String>();\n      for (String field : fields) {\n        try {\n          TokenStream ts = analyzer.reusableTokenStream(field, new StringReader(stopWords));\n          CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n          ts.reset();\n          while (ts.incrementToken()) {\n            stopWordsSet.add(termAtt.toString());\n          }\n          ts.end();\n          ts.close();\n        } catch (IOException ioe) {\n          throw new ParserException(\"IoException parsing stop words list in \"\n              + getClass().getName() + \":\" + ioe.getLocalizedMessage());\n        }\n      }\n    }\n\n\n    MoreLikeThisQuery mlt = new MoreLikeThisQuery(DOMUtils.getText(e), fields, analyzer, fields[0]);\n    mlt.setMaxQueryTerms(DOMUtils.getAttribute(e, \"maxQueryTerms\", DEFAULT_MAX_QUERY_TERMS));\n    mlt.setMinTermFrequency(DOMUtils.getAttribute(e, \"minTermFrequency\", DEFAULT_MIN_TERM_FREQUENCY));\n    mlt.setPercentTermsToMatch(DOMUtils.getAttribute(e, \"percentTermsToMatch\", DEFAULT_PERCENT_TERMS_TO_MATCH) / 100);\n    mlt.setStopWords(stopWordsSet);\n    int minDocFreq = DOMUtils.getAttribute(e, \"minDocFreq\", -1);\n    if (minDocFreq >= 0) {\n      mlt.setMinDocFreq(minDocFreq);\n    }\n\n    mlt.setBoost(DOMUtils.getAttribute(e, \"boost\", 1.0f));\n\n    return mlt;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b68b0aeb05de4dd5b24fc5ffd51e2fbd5d571df2":["ae46d105c94ea6ceb5201189bf9611bdef91b1b4"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb","00746ad002a54281629e3b6f3eb39833a33f093e"],"e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4":["a7347509fad0711ac30cb15a746e9a3830a38ebd"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a7347509fad0711ac30cb15a746e9a3830a38ebd","00746ad002a54281629e3b6f3eb39833a33f093e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"251550f5d19b526a76f8c5126ae7bb2d22cf8935":["b68b0aeb05de4dd5b24fc5ffd51e2fbd5d571df2"],"ae46d105c94ea6ceb5201189bf9611bdef91b1b4":["00746ad002a54281629e3b6f3eb39833a33f093e"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["a7347509fad0711ac30cb15a746e9a3830a38ebd","e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4"],"00746ad002a54281629e3b6f3eb39833a33f093e":["e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4"],"a7347509fad0711ac30cb15a746e9a3830a38ebd":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["251550f5d19b526a76f8c5126ae7bb2d22cf8935"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"b68b0aeb05de4dd5b24fc5ffd51e2fbd5d571df2":["251550f5d19b526a76f8c5126ae7bb2d22cf8935"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":[],"e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb","00746ad002a54281629e3b6f3eb39833a33f093e"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"ae46d105c94ea6ceb5201189bf9611bdef91b1b4":["b68b0aeb05de4dd5b24fc5ffd51e2fbd5d571df2"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["c3a8a449466c1ff7ce2274fe73dab487256964b4"],"251550f5d19b526a76f8c5126ae7bb2d22cf8935":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"00746ad002a54281629e3b6f3eb39833a33f093e":["c3a8a449466c1ff7ce2274fe73dab487256964b4","a3776dccca01c11e7046323cfad46a3b4a471233","ae46d105c94ea6ceb5201189bf9611bdef91b1b4"],"a7347509fad0711ac30cb15a746e9a3830a38ebd":["e2efdd13c0f37dbe4a292a6f98ddcf8e8f872ac4","a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a7347509fad0711ac30cb15a746e9a3830a38ebd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c3a8a449466c1ff7ce2274fe73dab487256964b4","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}