{"path":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter#testBehavingAsShingleFilter().mjava","commits":[{"id":"dd745d580729e528151b58aeda87ef82f1b95c9b","date":1248369082,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter#testBehavingAsShingleFilter().mjava","pathOld":"contrib/analyzers/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter#testBehavingAsShingleFilter().mjava","sourceNew":"  public void testBehavingAsShingleFilter() throws IOException {\n\n    ShingleMatrixFilter.defaultSettingsCodec = null;\n\n    TokenStream ts;\n\n    ts = new ShingleMatrixFilter(new EmptyTokenStream(), 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n    assertNull(ts.next(new Token()));\n\n    TokenListStream tls;\n    LinkedList tokens;\n\n    // test a plain old token stream with synonyms translated to rows.\n\n    tokens = new LinkedList();\n    tokens.add(createToken(\"please\", 0, 6));\n    tokens.add(createToken(\"divide\", 7, 13));\n    tokens.add(createToken(\"this\", 14, 18));\n    tokens.add(createToken(\"sentence\", 19, 27));\n    tokens.add(createToken(\"into\", 28, 32));\n    tokens.add(createToken(\"shingles\", 33, 39));\n\n    tls = new TokenListStream(tokens);\n\n    // bi-grams\n\n    ts = new ShingleMatrixFilter(tls, 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n\n    Token reusableToken = new Token();\n\n    assertNext(ts, reusableToken, \"please\", 0, 6);\n    assertNext(ts, reusableToken, \"please divide\", 0, 13);\n    assertNext(ts, reusableToken, \"divide\", 7, 13);\n    assertNext(ts, reusableToken, \"divide this\", 7, 18);\n    assertNext(ts, reusableToken, \"this\", 14, 18);\n    assertNext(ts, reusableToken, \"this sentence\", 14, 27);\n    assertNext(ts, reusableToken, \"sentence\", 19, 27);\n    assertNext(ts, reusableToken, \"sentence into\", 19, 32);\n    assertNext(ts, reusableToken, \"into\", 28, 32);\n    assertNext(ts, reusableToken, \"into shingles\", 28, 39);\n    assertNext(ts, reusableToken, \"shingles\", 33, 39);\n\n\n    assertNull(ts.next(reusableToken));\n\n  }\n\n","sourceOld":"  public void testBehavingAsShingleFilter() throws IOException {\n\n    ShingleMatrixFilter.defaultSettingsCodec = null;\n\n    TokenStream ts;\n\n    ts = new ShingleMatrixFilter(new EmptyTokenStream(), 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n    assertNull(ts.next(new Token()));\n\n    TokenListStream tls;\n    LinkedList tokens;\n\n    // test a plain old token stream with synonyms translated to rows.\n\n    tokens = new LinkedList();\n    tokens.add(createToken(\"please\", 0, 6));\n    tokens.add(createToken(\"divide\", 7, 13));\n    tokens.add(createToken(\"this\", 14, 18));\n    tokens.add(createToken(\"sentence\", 19, 27));\n    tokens.add(createToken(\"into\", 28, 32));\n    tokens.add(createToken(\"shingles\", 33, 39));\n\n    tls = new TokenListStream(tokens);\n\n    // bi-grams\n\n    ts = new ShingleMatrixFilter(tls, 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n\n    Token reusableToken = new Token();\n\n    assertNext(ts, reusableToken, \"please\", 0, 6);\n    assertNext(ts, reusableToken, \"please divide\", 0, 13);\n    assertNext(ts, reusableToken, \"divide\", 7, 13);\n    assertNext(ts, reusableToken, \"divide this\", 7, 18);\n    assertNext(ts, reusableToken, \"this\", 14, 18);\n    assertNext(ts, reusableToken, \"this sentence\", 14, 27);\n    assertNext(ts, reusableToken, \"sentence\", 19, 27);\n    assertNext(ts, reusableToken, \"sentence into\", 19, 32);\n    assertNext(ts, reusableToken, \"into\", 28, 32);\n    assertNext(ts, reusableToken, \"into shingles\", 28, 39);\n    assertNext(ts, reusableToken, \"shingles\", 33, 39);\n\n\n    assertNull(ts.next(reusableToken));\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0dda87e5ad7246b25d0da56a16ead95360499d86","date":1249273990,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter#testBehavingAsShingleFilter().mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter#testBehavingAsShingleFilter().mjava","sourceNew":"  public void testBehavingAsShingleFilter() throws IOException {\n\n    ShingleMatrixFilter.defaultSettingsCodec = null;\n\n    TokenStream ts;\n\n    ts = new ShingleMatrixFilter(new EmptyTokenStream(), 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n    assertFalse(ts.incrementToken());\n\n    TokenListStream tls;\n    LinkedList tokens;\n\n    // test a plain old token stream with synonyms translated to rows.\n\n    tokens = new LinkedList();\n    tokens.add(createToken(\"please\", 0, 6));\n    tokens.add(createToken(\"divide\", 7, 13));\n    tokens.add(createToken(\"this\", 14, 18));\n    tokens.add(createToken(\"sentence\", 19, 27));\n    tokens.add(createToken(\"into\", 28, 32));\n    tokens.add(createToken(\"shingles\", 33, 39));\n\n    tls = new TokenListStream(tokens);\n\n    // bi-grams\n\n    ts = new ShingleMatrixFilter(tls, 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n\n    Token reusableToken = new Token();\n\n    assertNext(ts, \"please\", 0, 6);\n    assertNext(ts, \"please divide\", 0, 13);\n    assertNext(ts, \"divide\", 7, 13);\n    assertNext(ts, \"divide this\", 7, 18);\n    assertNext(ts, \"this\", 14, 18);\n    assertNext(ts, \"this sentence\", 14, 27);\n    assertNext(ts, \"sentence\", 19, 27);\n    assertNext(ts, \"sentence into\", 19, 32);\n    assertNext(ts, \"into\", 28, 32);\n    assertNext(ts, \"into shingles\", 28, 39);\n    assertNext(ts, \"shingles\", 33, 39);\n\n\n    assertFalse(ts.incrementToken());\n\n  }\n\n","sourceOld":"  public void testBehavingAsShingleFilter() throws IOException {\n\n    ShingleMatrixFilter.defaultSettingsCodec = null;\n\n    TokenStream ts;\n\n    ts = new ShingleMatrixFilter(new EmptyTokenStream(), 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n    assertNull(ts.next(new Token()));\n\n    TokenListStream tls;\n    LinkedList tokens;\n\n    // test a plain old token stream with synonyms translated to rows.\n\n    tokens = new LinkedList();\n    tokens.add(createToken(\"please\", 0, 6));\n    tokens.add(createToken(\"divide\", 7, 13));\n    tokens.add(createToken(\"this\", 14, 18));\n    tokens.add(createToken(\"sentence\", 19, 27));\n    tokens.add(createToken(\"into\", 28, 32));\n    tokens.add(createToken(\"shingles\", 33, 39));\n\n    tls = new TokenListStream(tokens);\n\n    // bi-grams\n\n    ts = new ShingleMatrixFilter(tls, 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n\n    Token reusableToken = new Token();\n\n    assertNext(ts, reusableToken, \"please\", 0, 6);\n    assertNext(ts, reusableToken, \"please divide\", 0, 13);\n    assertNext(ts, reusableToken, \"divide\", 7, 13);\n    assertNext(ts, reusableToken, \"divide this\", 7, 18);\n    assertNext(ts, reusableToken, \"this\", 14, 18);\n    assertNext(ts, reusableToken, \"this sentence\", 14, 27);\n    assertNext(ts, reusableToken, \"sentence\", 19, 27);\n    assertNext(ts, reusableToken, \"sentence into\", 19, 32);\n    assertNext(ts, reusableToken, \"into\", 28, 32);\n    assertNext(ts, reusableToken, \"into shingles\", 28, 39);\n    assertNext(ts, reusableToken, \"shingles\", 33, 39);\n\n\n    assertNull(ts.next(reusableToken));\n\n  }\n\n","bugFix":null,"bugIntro":["360d15dc189fb48153cb62234f7d20819e4e292e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"054f92bb0a8ff8d94755c13351fbfc928e3e9760","date":1252294178,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter#testBehavingAsShingleFilter().mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter#testBehavingAsShingleFilter().mjava","sourceNew":"  public void testBehavingAsShingleFilter() throws IOException {\n\n    ShingleMatrixFilter.defaultSettingsCodec = null;\n\n    TokenStream ts;\n\n    ts = new ShingleMatrixFilter(new EmptyTokenStream(), 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n    assertFalse(ts.incrementToken());\n\n    TokenListStream tls;\n    LinkedList tokens;\n\n    // test a plain old token stream with synonyms translated to rows.\n\n    tokens = new LinkedList();\n    tokens.add(createToken(\"please\", 0, 6));\n    tokens.add(createToken(\"divide\", 7, 13));\n    tokens.add(createToken(\"this\", 14, 18));\n    tokens.add(createToken(\"sentence\", 19, 27));\n    tokens.add(createToken(\"into\", 28, 32));\n    tokens.add(createToken(\"shingles\", 33, 39));\n\n    tls = new TokenListStream(tokens);\n\n    // bi-grams\n\n    ts = new ShingleMatrixFilter(tls, 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n\n\n    assertNext(ts, \"please\", 0, 6);\n    assertNext(ts, \"please divide\", 0, 13);\n    assertNext(ts, \"divide\", 7, 13);\n    assertNext(ts, \"divide this\", 7, 18);\n    assertNext(ts, \"this\", 14, 18);\n    assertNext(ts, \"this sentence\", 14, 27);\n    assertNext(ts, \"sentence\", 19, 27);\n    assertNext(ts, \"sentence into\", 19, 32);\n    assertNext(ts, \"into\", 28, 32);\n    assertNext(ts, \"into shingles\", 28, 39);\n    assertNext(ts, \"shingles\", 33, 39);\n\n\n    assertFalse(ts.incrementToken());\n\n  }\n\n","sourceOld":"  public void testBehavingAsShingleFilter() throws IOException {\n\n    ShingleMatrixFilter.defaultSettingsCodec = null;\n\n    TokenStream ts;\n\n    ts = new ShingleMatrixFilter(new EmptyTokenStream(), 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n    assertFalse(ts.incrementToken());\n\n    TokenListStream tls;\n    LinkedList tokens;\n\n    // test a plain old token stream with synonyms translated to rows.\n\n    tokens = new LinkedList();\n    tokens.add(createToken(\"please\", 0, 6));\n    tokens.add(createToken(\"divide\", 7, 13));\n    tokens.add(createToken(\"this\", 14, 18));\n    tokens.add(createToken(\"sentence\", 19, 27));\n    tokens.add(createToken(\"into\", 28, 32));\n    tokens.add(createToken(\"shingles\", 33, 39));\n\n    tls = new TokenListStream(tokens);\n\n    // bi-grams\n\n    ts = new ShingleMatrixFilter(tls, 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n\n    Token reusableToken = new Token();\n\n    assertNext(ts, \"please\", 0, 6);\n    assertNext(ts, \"please divide\", 0, 13);\n    assertNext(ts, \"divide\", 7, 13);\n    assertNext(ts, \"divide this\", 7, 18);\n    assertNext(ts, \"this\", 14, 18);\n    assertNext(ts, \"this sentence\", 14, 27);\n    assertNext(ts, \"sentence\", 19, 27);\n    assertNext(ts, \"sentence into\", 19, 32);\n    assertNext(ts, \"into\", 28, 32);\n    assertNext(ts, \"into shingles\", 28, 39);\n    assertNext(ts, \"shingles\", 33, 39);\n\n\n    assertFalse(ts.incrementToken());\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"360d15dc189fb48153cb62234f7d20819e4e292e","date":1263562938,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter#testBehavingAsShingleFilter().mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter#testBehavingAsShingleFilter().mjava","sourceNew":"  public void testBehavingAsShingleFilter() throws IOException {\n\n    ShingleMatrixFilter.defaultSettingsCodec = null;\n\n    TokenStream ts;\n\n    ts = new ShingleMatrixFilter(new EmptyTokenStream(), 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n    assertFalse(ts.incrementToken());\n\n    TokenListStream tls;\n    LinkedList tokens;\n\n    // test a plain old token stream with synonyms translated to rows.\n\n    tokens = new LinkedList();\n    tokens.add(createToken(\"please\", 0, 6));\n    tokens.add(createToken(\"divide\", 7, 13));\n    tokens.add(createToken(\"this\", 14, 18));\n    tokens.add(createToken(\"sentence\", 19, 27));\n    tokens.add(createToken(\"into\", 28, 32));\n    tokens.add(createToken(\"shingles\", 33, 39));\n\n    tls = new TokenListStream(tokens);\n\n    // bi-grams\n\n    ts = new ShingleMatrixFilter(tls, 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n\n    assertTokenStreamContents(ts,\n      new String[] { \"please\", \"please divide\", \"divide\", \"divide this\",\n        \"this\", \"this sentence\", \"sentence\", \"sentence into\", \"into\",\n        \"into shingles\", \"shingles\" },\n      new int[] { 0, 0, 7, 7, 14, 14, 19, 19, 28, 28, 33 },\n      new int[] { 6, 13, 13, 18, 18, 27, 27, 32, 32, 39, 39 });\n  }\n\n","sourceOld":"  public void testBehavingAsShingleFilter() throws IOException {\n\n    ShingleMatrixFilter.defaultSettingsCodec = null;\n\n    TokenStream ts;\n\n    ts = new ShingleMatrixFilter(new EmptyTokenStream(), 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n    assertFalse(ts.incrementToken());\n\n    TokenListStream tls;\n    LinkedList tokens;\n\n    // test a plain old token stream with synonyms translated to rows.\n\n    tokens = new LinkedList();\n    tokens.add(createToken(\"please\", 0, 6));\n    tokens.add(createToken(\"divide\", 7, 13));\n    tokens.add(createToken(\"this\", 14, 18));\n    tokens.add(createToken(\"sentence\", 19, 27));\n    tokens.add(createToken(\"into\", 28, 32));\n    tokens.add(createToken(\"shingles\", 33, 39));\n\n    tls = new TokenListStream(tokens);\n\n    // bi-grams\n\n    ts = new ShingleMatrixFilter(tls, 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n\n\n    assertNext(ts, \"please\", 0, 6);\n    assertNext(ts, \"please divide\", 0, 13);\n    assertNext(ts, \"divide\", 7, 13);\n    assertNext(ts, \"divide this\", 7, 18);\n    assertNext(ts, \"this\", 14, 18);\n    assertNext(ts, \"this sentence\", 14, 27);\n    assertNext(ts, \"sentence\", 19, 27);\n    assertNext(ts, \"sentence into\", 19, 32);\n    assertNext(ts, \"into\", 28, 32);\n    assertNext(ts, \"into shingles\", 28, 39);\n    assertNext(ts, \"shingles\", 33, 39);\n\n\n    assertFalse(ts.incrementToken());\n\n  }\n\n","bugFix":["0dda87e5ad7246b25d0da56a16ead95360499d86","7e2cb543b41c145f33390f460ee743d6693c9c6c","660fdd379b3fe276cd3a63d9c5852cef6dd5d54f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a","date":1267298041,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter#testBehavingAsShingleFilter().mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter#testBehavingAsShingleFilter().mjava","sourceNew":"  public void testBehavingAsShingleFilter() throws IOException {\n\n    ShingleMatrixFilter.defaultSettingsCodec = null;\n\n    TokenStream ts;\n\n    ts = new ShingleMatrixFilter(new EmptyTokenStream(), 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n    assertFalse(ts.incrementToken());\n\n    TokenListStream tls;\n    LinkedList<Token> tokens;\n\n    // test a plain old token stream with synonyms translated to rows.\n\n    tokens = new LinkedList<Token>();\n    tokens.add(createToken(\"please\", 0, 6));\n    tokens.add(createToken(\"divide\", 7, 13));\n    tokens.add(createToken(\"this\", 14, 18));\n    tokens.add(createToken(\"sentence\", 19, 27));\n    tokens.add(createToken(\"into\", 28, 32));\n    tokens.add(createToken(\"shingles\", 33, 39));\n\n    tls = new TokenListStream(tokens);\n\n    // bi-grams\n\n    ts = new ShingleMatrixFilter(tls, 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n\n    assertTokenStreamContents(ts,\n      new String[] { \"please\", \"please divide\", \"divide\", \"divide this\",\n        \"this\", \"this sentence\", \"sentence\", \"sentence into\", \"into\",\n        \"into shingles\", \"shingles\" },\n      new int[] { 0, 0, 7, 7, 14, 14, 19, 19, 28, 28, 33 },\n      new int[] { 6, 13, 13, 18, 18, 27, 27, 32, 32, 39, 39 });\n  }\n\n","sourceOld":"  public void testBehavingAsShingleFilter() throws IOException {\n\n    ShingleMatrixFilter.defaultSettingsCodec = null;\n\n    TokenStream ts;\n\n    ts = new ShingleMatrixFilter(new EmptyTokenStream(), 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n    assertFalse(ts.incrementToken());\n\n    TokenListStream tls;\n    LinkedList tokens;\n\n    // test a plain old token stream with synonyms translated to rows.\n\n    tokens = new LinkedList();\n    tokens.add(createToken(\"please\", 0, 6));\n    tokens.add(createToken(\"divide\", 7, 13));\n    tokens.add(createToken(\"this\", 14, 18));\n    tokens.add(createToken(\"sentence\", 19, 27));\n    tokens.add(createToken(\"into\", 28, 32));\n    tokens.add(createToken(\"shingles\", 33, 39));\n\n    tls = new TokenListStream(tokens);\n\n    // bi-grams\n\n    ts = new ShingleMatrixFilter(tls, 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n\n    assertTokenStreamContents(ts,\n      new String[] { \"please\", \"please divide\", \"divide\", \"divide this\",\n        \"this\", \"this sentence\", \"sentence\", \"sentence into\", \"into\",\n        \"into shingles\", \"shingles\" },\n      new int[] { 0, 0, 7, 7, 14, 14, 19, 19, 28, 28, 33 },\n      new int[] { 6, 13, 13, 18, 18, 27, 27, 32, 32, 39, 39 });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter#testBehavingAsShingleFilter().mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter#testBehavingAsShingleFilter().mjava","sourceNew":"  public void testBehavingAsShingleFilter() throws IOException {\n\n    ShingleMatrixFilter.defaultSettingsCodec = null;\n\n    TokenStream ts;\n\n    ts = new ShingleMatrixFilter(new EmptyTokenStream(), 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n    assertFalse(ts.incrementToken());\n\n    TokenListStream tls;\n    LinkedList<Token> tokens;\n\n    // test a plain old token stream with synonyms translated to rows.\n\n    tokens = new LinkedList<Token>();\n    tokens.add(createToken(\"please\", 0, 6));\n    tokens.add(createToken(\"divide\", 7, 13));\n    tokens.add(createToken(\"this\", 14, 18));\n    tokens.add(createToken(\"sentence\", 19, 27));\n    tokens.add(createToken(\"into\", 28, 32));\n    tokens.add(createToken(\"shingles\", 33, 39));\n\n    tls = new TokenListStream(tokens);\n\n    // bi-grams\n\n    ts = new ShingleMatrixFilter(tls, 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n\n    assertTokenStreamContents(ts,\n      new String[] { \"please\", \"please divide\", \"divide\", \"divide this\",\n        \"this\", \"this sentence\", \"sentence\", \"sentence into\", \"into\",\n        \"into shingles\", \"shingles\" },\n      new int[] { 0, 0, 7, 7, 14, 14, 19, 19, 28, 28, 33 },\n      new int[] { 6, 13, 13, 18, 18, 27, 27, 32, 32, 39, 39 });\n  }\n\n","sourceOld":"  public void testBehavingAsShingleFilter() throws IOException {\n\n    ShingleMatrixFilter.defaultSettingsCodec = null;\n\n    TokenStream ts;\n\n    ts = new ShingleMatrixFilter(new EmptyTokenStream(), 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n    assertFalse(ts.incrementToken());\n\n    TokenListStream tls;\n    LinkedList<Token> tokens;\n\n    // test a plain old token stream with synonyms translated to rows.\n\n    tokens = new LinkedList<Token>();\n    tokens.add(createToken(\"please\", 0, 6));\n    tokens.add(createToken(\"divide\", 7, 13));\n    tokens.add(createToken(\"this\", 14, 18));\n    tokens.add(createToken(\"sentence\", 19, 27));\n    tokens.add(createToken(\"into\", 28, 32));\n    tokens.add(createToken(\"shingles\", 33, 39));\n\n    tls = new TokenListStream(tokens);\n\n    // bi-grams\n\n    ts = new ShingleMatrixFilter(tls, 1, 2, new Character(' '), false, new ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec());\n\n    assertTokenStreamContents(ts,\n      new String[] { \"please\", \"please divide\", \"divide\", \"divide this\",\n        \"this\", \"this sentence\", \"sentence\", \"sentence into\", \"into\",\n        \"into shingles\", \"shingles\" },\n      new int[] { 0, 0, 7, 7, 14, 14, 19, 19, 28, 28, 33 },\n      new int[] { 6, 13, 13, 18, 18, 27, 27, 32, 32, 39, 39 });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"dd745d580729e528151b58aeda87ef82f1b95c9b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0dda87e5ad7246b25d0da56a16ead95360499d86":["dd745d580729e528151b58aeda87ef82f1b95c9b"],"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a":["360d15dc189fb48153cb62234f7d20819e4e292e"],"054f92bb0a8ff8d94755c13351fbfc928e3e9760":["0dda87e5ad7246b25d0da56a16ead95360499d86"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a9ac13b5f0ce5ef1b2ce168367d993a79594b23a"],"360d15dc189fb48153cb62234f7d20819e4e292e":["054f92bb0a8ff8d94755c13351fbfc928e3e9760"]},"commit2Childs":{"dd745d580729e528151b58aeda87ef82f1b95c9b":["0dda87e5ad7246b25d0da56a16ead95360499d86"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["dd745d580729e528151b58aeda87ef82f1b95c9b"],"0dda87e5ad7246b25d0da56a16ead95360499d86":["054f92bb0a8ff8d94755c13351fbfc928e3e9760"],"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"054f92bb0a8ff8d94755c13351fbfc928e3e9760":["360d15dc189fb48153cb62234f7d20819e4e292e"],"360d15dc189fb48153cb62234f7d20819e4e292e":["a9ac13b5f0ce5ef1b2ce168367d993a79594b23a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}