{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","commits":[{"id":"687e86054415a85f912c6eaa38f995038e5c1cd8","date":1336447427,"type":1,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/analysis/BaseTokenStreamFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","sourceNew":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(luceneMatchVersion,\n          files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = IOUtils.CHARSET_UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","sourceOld":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = StrUtils.splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(luceneMatchVersion, \n          files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = IOUtils.CHARSET_UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57da959ec15bb701bd1d1bf3c613b69009ff4bfd","date":1364833800,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","sourceNew":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(luceneMatchVersion,\n          files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = IOUtils.CHARSET_UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","sourceOld":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(luceneMatchVersion,\n          files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = IOUtils.CHARSET_UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7d89d7e4e5101347833eea558851bf4209218619","date":1396265641,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","sourceNew":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(luceneMatchVersion,\n          files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = StandardCharsets.UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","sourceOld":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(luceneMatchVersion,\n          files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = IOUtils.CHARSET_UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","sourceNew":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(luceneMatchVersion,\n          files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = StandardCharsets.UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","sourceOld":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(luceneMatchVersion,\n          files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = IOUtils.CHARSET_UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff4227bb146f97aabae888091c19e48c88dbb0db","date":1406758576,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","sourceNew":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = StandardCharsets.UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","sourceOld":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(luceneMatchVersion,\n          files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = StandardCharsets.UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cdab62f058ea765dd33deb05b4f19b7d626c801","date":1406803479,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","sourceNew":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(luceneMatchVersion,\n          files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = StandardCharsets.UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","sourceOld":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = StandardCharsets.UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"379db3ad24c4f0214f30a122265a6d6be003a99d","date":1407537768,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","sourceNew":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = StandardCharsets.UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","sourceOld":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(luceneMatchVersion,\n          files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = StandardCharsets.UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"623b5245fbd9d5af9f458826ba9ed3d6212db24d","date":1421078865,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","sourceNew":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = StandardCharsets.UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","sourceOld":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    assureMatchVersion();\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = StandardCharsets.UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","bugFix":["a6042fc86aab3ca254c90a18f082f9569bdd89c5"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"313c36388b6cae6118f75a1860ad0ba0af7e1344","date":1601279368,"type":5,"author":"Tomoko Uchida","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/analysis/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory#getSnowballWordSet(ResourceLoader,String,boolean).mjava","sourceNew":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = StandardCharsets.UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","sourceOld":"  /** same as {@link #getWordSet(ResourceLoader, String, boolean)},\n   * except the input is in snowball format. */\n  protected final CharArraySet getSnowballWordSet(ResourceLoader loader,\n      String wordFiles, boolean ignoreCase) throws IOException {\n    List<String> files = splitFileNames(wordFiles);\n    CharArraySet words = null;\n    if (files.size() > 0) {\n      // default stopwords list has 35 or so words, but maybe don't make it that\n      // big to start\n      words = new CharArraySet(files.size() * 10, ignoreCase);\n      for (String file : files) {\n        InputStream stream = null;\n        Reader reader = null;\n        try {\n          stream = loader.openResource(file.trim());\n          CharsetDecoder decoder = StandardCharsets.UTF_8.newDecoder()\n              .onMalformedInput(CodingErrorAction.REPORT)\n              .onUnmappableCharacter(CodingErrorAction.REPORT);\n          reader = new InputStreamReader(stream, decoder);\n          WordlistLoader.getSnowballWordSet(reader, words);\n        } finally {\n          IOUtils.closeWhileHandlingException(reader, stream);\n        }\n      }\n    }\n    return words;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5eb2511ababf862ea11e10761c70ee560cd84510":["57da959ec15bb701bd1d1bf3c613b69009ff4bfd","7d89d7e4e5101347833eea558851bf4209218619"],"ff4227bb146f97aabae888091c19e48c88dbb0db":["7d89d7e4e5101347833eea558851bf4209218619"],"313c36388b6cae6118f75a1860ad0ba0af7e1344":["623b5245fbd9d5af9f458826ba9ed3d6212db24d"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"687e86054415a85f912c6eaa38f995038e5c1cd8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"623b5245fbd9d5af9f458826ba9ed3d6212db24d":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"57da959ec15bb701bd1d1bf3c613b69009ff4bfd":["687e86054415a85f912c6eaa38f995038e5c1cd8"],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["ff4227bb146f97aabae888091c19e48c88dbb0db"],"7d89d7e4e5101347833eea558851bf4209218619":["57da959ec15bb701bd1d1bf3c613b69009ff4bfd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["313c36388b6cae6118f75a1860ad0ba0af7e1344"]},"commit2Childs":{"5eb2511ababf862ea11e10761c70ee560cd84510":[],"ff4227bb146f97aabae888091c19e48c88dbb0db":["5cdab62f058ea765dd33deb05b4f19b7d626c801"],"313c36388b6cae6118f75a1860ad0ba0af7e1344":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["623b5245fbd9d5af9f458826ba9ed3d6212db24d"],"687e86054415a85f912c6eaa38f995038e5c1cd8":["57da959ec15bb701bd1d1bf3c613b69009ff4bfd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["687e86054415a85f912c6eaa38f995038e5c1cd8"],"623b5245fbd9d5af9f458826ba9ed3d6212db24d":["313c36388b6cae6118f75a1860ad0ba0af7e1344"],"57da959ec15bb701bd1d1bf3c613b69009ff4bfd":["5eb2511ababf862ea11e10761c70ee560cd84510","7d89d7e4e5101347833eea558851bf4209218619"],"7d89d7e4e5101347833eea558851bf4209218619":["5eb2511ababf862ea11e10761c70ee560cd84510","ff4227bb146f97aabae888091c19e48c88dbb0db"],"5cdab62f058ea765dd33deb05b4f19b7d626c801":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}