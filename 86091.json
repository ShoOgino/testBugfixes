{"path":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","commits":[{"id":"11c5f879e49375db0f48ca533856f226c2db57a5","date":1390688316,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentExpressionDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = (InputIterator) dictionary.getWordsIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    Set<SortField> sortFields = new HashSet<SortField>(); \n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_1, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_2, SortField.Type.LONG));\n    sortFields.add(new SortField(WEIGHT_FIELD_NAME_3, SortField.Type.LONG));\n    Dictionary dictionary = new DocumentExpressionDictionary(ir, FIELD_NAME, \"((w1 + w2) - w3)\", sortFields, PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = (InputIterator) dictionary.getWordsIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2) - w3);\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a645276cbaf5dc96a42fd473b9019bde352996c8","date":1391806699,"type":3,"author":"Areek Zillur","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = (InputIterator) dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = (InputIterator) dictionary.getWordsIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a371aa649cc243e82cb8677ca960a1e0232ecedf","date":1393605574,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = (InputIterator) dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.shutdown();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.shutdown();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.shutdown();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.shutdown();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a56958d7f71a28824f20031ffbb2e13502a0274e","date":1425573902,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ee590759ca28a3f2599ba7608ea0a50be4f540f6","date":1432142966,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      Field payloadField = doc.getField(PAYLOAD_FIELD_NAME);\n      if (payloadField == null) assertTrue(inputIterator.payload().length == 0);\n      else assertEquals(inputIterator.payload(), payloadField.binaryValue());\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      assertTrue(inputIterator.payload().equals(doc.getField(PAYLOAD_FIELD_NAME).binaryValue()));\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","bugFix":["24730daba4a74cb3bd673ccacc4ddaee5963af02"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);\n      if (payloadField == null) assertTrue(inputIterator.payload().length == 0);\n      else assertEquals(inputIterator.payload(), payloadField.binaryValue());\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      Field payloadField = doc.getField(PAYLOAD_FIELD_NAME);\n      if (payloadField == null) assertTrue(inputIterator.payload().length == 0);\n      else assertEquals(inputIterator.payload(), payloadField.binaryValue());\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7abbd4266bb36de7f2181eb6d9f3df3ea45ff382","date":1483789945,"type":6,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testLongValuesSourceBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testLongValuesSourceBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    LongValuesSource sumValueSource = sum(WEIGHT_FIELD_NAME_1, WEIGHT_FIELD_NAME_2, WEIGHT_FIELD_NAME_3);\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, sumValueSource, PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);\n      if (payloadField == null) assertTrue(inputIterator.payload().length == 0);\n      else assertEquals(inputIterator.payload(), payloadField.binaryValue());\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);\n      if (payloadField == null) assertTrue(inputIterator.payload().length == 0);\n      else assertEquals(inputIterator.payload(), payloadField.binaryValue());\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7abbd4266bb36de7f2181eb6d9f3df3ea45ff382","date":1483789945,"type":5,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testValueSourceBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testValueSourceBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);\n      if (payloadField == null) assertTrue(inputIterator.payload().length == 0);\n      else assertEquals(inputIterator.payload(), payloadField.binaryValue());\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);\n      if (payloadField == null) assertTrue(inputIterator.payload().length == 0);\n      else assertEquals(inputIterator.payload(), payloadField.binaryValue());\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7abbd4266bb36de7f2181eb6d9f3df3ea45ff382","date":1483789945,"type":6,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testWithLongValuesSource().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testWithLongValuesSource() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, LongValuesSource.constant(10), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), 10);\n      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);\n      if (payloadField == null) assertTrue(inputIterator.payload().length == 0);\n      else assertEquals(inputIterator.payload(), payloadField.binaryValue());\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);\n      if (payloadField == null) assertTrue(inputIterator.payload().length == 0);\n      else assertEquals(inputIterator.payload(), payloadField.binaryValue());\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","date":1484239864,"type":6,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testLongValuesSourceBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testLongValuesSourceBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    LongValuesSource sumValueSource = sum(WEIGHT_FIELD_NAME_1, WEIGHT_FIELD_NAME_2, WEIGHT_FIELD_NAME_3);\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, sumValueSource, PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);\n      if (payloadField == null) assertTrue(inputIterator.payload().length == 0);\n      else assertEquals(inputIterator.payload(), payloadField.binaryValue());\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);\n      if (payloadField == null) assertTrue(inputIterator.payload().length == 0);\n      else assertEquals(inputIterator.payload(), payloadField.binaryValue());\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","date":1484239864,"type":5,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testValueSourceBasic().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testValueSourceBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    LongValuesSource s = sum(WEIGHT_FIELD_NAME_1, WEIGHT_FIELD_NAME_2, WEIGHT_FIELD_NAME_3);\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, s, PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);\n      if (payloadField == null) assertTrue(inputIterator.payload().length == 0);\n      else assertEquals(inputIterator.payload(), payloadField.binaryValue());\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);\n      if (payloadField == null) assertTrue(inputIterator.payload().length == 0);\n      else assertEquals(inputIterator.payload(), payloadField.binaryValue());\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","date":1484239864,"type":6,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testWithLongValuesSource().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/DocumentValueSourceDictionaryTest#testBasic().mjava","sourceNew":"  @Test\n  public void testWithLongValuesSource() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, LongValuesSource.constant(10), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), 10);\n      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);\n      if (payloadField == null) assertTrue(inputIterator.payload().length == 0);\n      else assertEquals(inputIterator.payload(), payloadField.binaryValue());\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","sourceOld":"  @Test\n  public void testBasic() throws IOException {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random());\n    IndexWriterConfig iwc = newIndexWriterConfig(analyzer);\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, iwc);\n    Map<String, Document> docs = generateIndexDocuments(atLeast(100));\n    for(Document doc: docs.values()) {\n      writer.addDocument(doc);\n    }\n    writer.commit();\n    writer.close();\n\n    IndexReader ir = DirectoryReader.open(dir);\n    ValueSource[] toAdd = new ValueSource[] {new LongFieldSource(WEIGHT_FIELD_NAME_1), new LongFieldSource(WEIGHT_FIELD_NAME_2), new LongFieldSource(WEIGHT_FIELD_NAME_3)};\n    Dictionary dictionary = new DocumentValueSourceDictionary(ir, FIELD_NAME, new SumFloatFunction(toAdd), PAYLOAD_FIELD_NAME);\n    InputIterator inputIterator = dictionary.getEntryIterator();\n    BytesRef f;\n    while((f = inputIterator.next())!=null) {\n      Document doc = docs.remove(f.utf8ToString());\n      long w1 = doc.getField(WEIGHT_FIELD_NAME_1).numericValue().longValue();\n      long w2 = doc.getField(WEIGHT_FIELD_NAME_2).numericValue().longValue();\n      long w3 = doc.getField(WEIGHT_FIELD_NAME_3).numericValue().longValue();\n      assertTrue(f.equals(new BytesRef(doc.get(FIELD_NAME))));\n      assertEquals(inputIterator.weight(), (w1 + w2 + w3));\n      IndexableField payloadField = doc.getField(PAYLOAD_FIELD_NAME);\n      if (payloadField == null) assertTrue(inputIterator.payload().length == 0);\n      else assertEquals(inputIterator.payload(), payloadField.binaryValue());\n    }\n    assertTrue(docs.isEmpty());\n    IOUtils.close(ir, analyzer, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","7abbd4266bb36de7f2181eb6d9f3df3ea45ff382"],"a371aa649cc243e82cb8677ca960a1e0232ecedf":["a645276cbaf5dc96a42fd473b9019bde352996c8"],"a645276cbaf5dc96a42fd473b9019bde352996c8":["11c5f879e49375db0f48ca533856f226c2db57a5"],"11c5f879e49375db0f48ca533856f226c2db57a5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["d0ef034a4f10871667ae75181537775ddcf8ade4","a56958d7f71a28824f20031ffbb2e13502a0274e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ee590759ca28a3f2599ba7608ea0a50be4f540f6":["a56958d7f71a28824f20031ffbb2e13502a0274e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["a371aa649cc243e82cb8677ca960a1e0232ecedf"],"7abbd4266bb36de7f2181eb6d9f3df3ea45ff382":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7abbd4266bb36de7f2181eb6d9f3df3ea45ff382"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["ee590759ca28a3f2599ba7608ea0a50be4f540f6"]},"commit2Childs":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":[],"a371aa649cc243e82cb8677ca960a1e0232ecedf":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"a645276cbaf5dc96a42fd473b9019bde352996c8":["a371aa649cc243e82cb8677ca960a1e0232ecedf"],"11c5f879e49375db0f48ca533856f226c2db57a5":["a645276cbaf5dc96a42fd473b9019bde352996c8"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["11c5f879e49375db0f48ca533856f226c2db57a5"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","a56958d7f71a28824f20031ffbb2e13502a0274e"],"ee590759ca28a3f2599ba7608ea0a50be4f540f6":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"7abbd4266bb36de7f2181eb6d9f3df3ea45ff382":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","ee590759ca28a3f2599ba7608ea0a50be4f540f6"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","7abbd4266bb36de7f2181eb6d9f3df3ea45ff382"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}