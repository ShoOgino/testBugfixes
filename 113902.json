{"path":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","commits":[{"id":"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","date":1292695408,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentMerger,SegmentReader).mjava","sourceNew":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n    \n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    // remove pending deletes of the segments \n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentMerger merger, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n    \n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    // remove pending deletes of the segments \n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentMerger,int,SegmentReader).mjava","sourceNew":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n    \n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    // remove pending deletes of the segments \n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentMerger merger, int mergedDocCount, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n    docWriter.remapDeletes(segmentInfos, merger.getDocMaps(), merger.getDelCounts(), merge, mergedDocCount);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    merge.info.setHasProx(merger.hasProx());\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"/dev/null","sourceNew":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    // remove pending deletes of the segments\n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3161e3ffcf20c09a22504a589d4d9bd273e11e33","date":1295142360,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    // remove pending deletes of the segments\n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    // remove pending deletes of the segments\n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c19f985e36a65cc969e8e564fe337a0d41512075","date":1296330536,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    ensureValidMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    assert !segmentInfos.contains(merge.info);\n\n    final Set mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n    assert newSegIdx == curSegCount - merge.segments.size() + 1;\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    \n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n    \n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    // remove pending deletes of the segments \n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    ensureValidMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    assert !segmentInfos.contains(merge.info);\n\n    final Set mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n    assert newSegIdx == curSegCount - merge.segments.size() + 1;\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    \n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n    \n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    // remove pending deletes of the segments \n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3","date":1297940445,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final Set mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted && (!allDeleted || keepFullyDeletedSegments)) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n\n    // Either we found place to insert segment, or, we did\n    // not, but only because all segments we merged became\n    // deleted while we are merging, in which case it should\n    // be the case that the new segment is also all deleted:\n    if (!inserted) {\n      assert allDeleted;\n      if (keepFullyDeletedSegments) {\n        segmentInfos.add(0, merge.info);\n      } else {\n        readerPool.drop(merge.info);\n      }\n    }\n\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    \n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    ensureValidMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    assert !segmentInfos.contains(merge.info);\n\n    final Set mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n    assert newSegIdx == curSegCount - merge.segments.size() + 1;\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    \n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f1bdbf92da222965b46c0a942c3857ba56e5c638","date":1298297608,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final Set mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted && (!allDeleted || keepFullyDeletedSegments)) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n\n    // Either we found place to insert segment, or, we did\n    // not, but only because all segments we merged became\n    // deleted while we are merging, in which case it should\n    // be the case that the new segment is also all deleted:\n    if (!inserted) {\n      assert allDeleted;\n      if (keepFullyDeletedSegments) {\n        segmentInfos.add(0, merge.info);\n      } else {\n        readerPool.drop(merge.info);\n      }\n    }\n\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    \n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    ensureValidMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    assert !segmentInfos.contains(merge.info);\n\n    final Set mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n    assert newSegIdx == curSegCount - merge.segments.size() + 1;\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    \n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final Set mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted && (!allDeleted || keepFullyDeletedSegments)) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n\n    // Either we found place to insert segment, or, we did\n    // not, but only because all segments we merged became\n    // deleted while we are merging, in which case it should\n    // be the case that the new segment is also all deleted:\n    if (!inserted) {\n      assert allDeleted;\n      if (keepFullyDeletedSegments) {\n        segmentInfos.add(0, merge.info);\n      } else {\n        readerPool.drop(merge.info);\n      }\n    }\n\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    return true;\n  }\n\n","sourceOld":"  /* FIXME if we want to support non-contiguous segment merges */\n  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    final int start = ensureContiguousMerge(merge);\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n    setMergeDocStoreIsCompoundFile(merge);\n\n    segmentInfos.subList(start, start + merge.segments.size()).clear();\n    assert !segmentInfos.contains(merge.info);\n    segmentInfos.add(start, merge.info);\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    // remove pending deletes of the segments\n    // that were merged, moving them onto the segment just\n    // before the merged segment\n    // Lock order: IW -> BD\n    bufferedDeletes.commitMerge(merge);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0ef0193974807e4bddf5432a6b0287fe4d6c9df","date":1301476645,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final Set<SegmentInfo> mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted && (!allDeleted || keepFullyDeletedSegments)) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n\n    // Either we found place to insert segment, or, we did\n    // not, but only because all segments we merged became\n    // deleted while we are merging, in which case it should\n    // be the case that the new segment is also all deleted:\n    if (!inserted) {\n      assert allDeleted;\n      if (keepFullyDeletedSegments) {\n        segmentInfos.add(0, merge.info);\n      } else {\n        readerPool.drop(merge.info);\n      }\n    }\n\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final Set mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted && (!allDeleted || keepFullyDeletedSegments)) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n\n    // Either we found place to insert segment, or, we did\n    // not, but only because all segments we merged became\n    // deleted while we are merging, in which case it should\n    // be the case that the new segment is also all deleted:\n    if (!inserted) {\n      assert allDeleted;\n      if (keepFullyDeletedSegments) {\n        segmentInfos.add(0, merge.info);\n      } else {\n        readerPool.drop(merge.info);\n      }\n    }\n\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b3e06be49006ecac364d39d12b9c9f74882f9b9f","date":1304289513,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final Set<SegmentInfo> mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted && (!allDeleted || keepFullyDeletedSegments)) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n\n    // Either we found place to insert segment, or, we did\n    // not, but only because all segments we merged became\n    // deleted while we are merging, in which case it should\n    // be the case that the new segment is also all deleted:\n    if (!inserted) {\n      assert allDeleted;\n      if (keepFullyDeletedSegments) {\n        segmentInfos.add(0, merge.info);\n      } else {\n        readerPool.drop(merge.info);\n      }\n    }\n\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final Set mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted && (!allDeleted || keepFullyDeletedSegments)) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n\n    // Either we found place to insert segment, or, we did\n    // not, but only because all segments we merged became\n    // deleted while we are merging, in which case it should\n    // be the case that the new segment is also all deleted:\n    if (!inserted) {\n      assert allDeleted;\n      if (keepFullyDeletedSegments) {\n        segmentInfos.add(0, merge.info);\n      } else {\n        readerPool.drop(merge.info);\n      }\n    }\n\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    \n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final Set<SegmentInfo> mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted && (!allDeleted || keepFullyDeletedSegments)) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n\n    // Either we found place to insert segment, or, we did\n    // not, but only because all segments we merged became\n    // deleted while we are merging, in which case it should\n    // be the case that the new segment is also all deleted:\n    if (!inserted) {\n      assert allDeleted;\n      if (keepFullyDeletedSegments) {\n        segmentInfos.add(0, merge.info);\n      } else {\n        readerPool.drop(merge.info);\n      }\n    }\n\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final Set mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted && (!allDeleted || keepFullyDeletedSegments)) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n\n    // Either we found place to insert segment, or, we did\n    // not, but only because all segments we merged became\n    // deleted while we are merging, in which case it should\n    // be the case that the new segment is also all deleted:\n    if (!inserted) {\n      assert allDeleted;\n      if (keepFullyDeletedSegments) {\n        segmentInfos.add(0, merge.info);\n      } else {\n        readerPool.drop(merge.info);\n      }\n    }\n\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    \n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"786a4d25ca958a1f315a9d6a74f0441fdafcd522","date":1305734256,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final Set<SegmentInfo> mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted && (!allDeleted || keepFullyDeletedSegments)) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n\n    // Either we found place to insert segment, or, we did\n    // not, but only because all segments we merged became\n    // deleted while we are merging, in which case it should\n    // be the case that the new segment is also all deleted:\n    if (!inserted) {\n      assert allDeleted;\n      if (keepFullyDeletedSegments) {\n        segmentInfos.add(0, merge.info);\n      } else {\n        readerPool.drop(merge.info);\n      }\n    }\n\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":["ae695f21c50b03702b5d0fa2543d5af844bb7cd3","ae695f21c50b03702b5d0fa2543d5af844bb7cd3"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c3a8a449466c1ff7ce2274fe73dab487256964b4","date":1305735867,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final Set<SegmentInfo> mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted && (!allDeleted || keepFullyDeletedSegments)) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n\n    // Either we found place to insert segment, or, we did\n    // not, but only because all segments we merged became\n    // deleted while we are merging, in which case it should\n    // be the case that the new segment is also all deleted:\n    if (!inserted) {\n      assert allDeleted;\n      if (keepFullyDeletedSegments) {\n        segmentInfos.add(0, merge.info);\n      } else {\n        readerPool.drop(merge.info);\n      }\n    }\n\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n      \n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final Set mergedAway = new HashSet<SegmentInfo>(merge.segments);\n    int segIdx = 0;\n    int newSegIdx = 0;\n    boolean inserted = false;\n    final int curSegCount = segmentInfos.size();\n    while(segIdx < curSegCount) {\n      final SegmentInfo info = segmentInfos.info(segIdx++);\n      if (mergedAway.contains(info)) {\n        if (!inserted && (!allDeleted || keepFullyDeletedSegments)) {\n          segmentInfos.set(segIdx-1, merge.info);\n          inserted = true;\n          newSegIdx++;\n        }\n      } else {\n        segmentInfos.set(newSegIdx++, info);\n      }\n    }\n\n    // Either we found place to insert segment, or, we did\n    // not, but only because all segments we merged became\n    // deleted while we are merging, in which case it should\n    // be the case that the new segment is also all deleted:\n    if (!inserted) {\n      assert allDeleted;\n      if (keepFullyDeletedSegments) {\n        segmentInfos.add(0, merge.info);\n      } else {\n        readerPool.drop(merge.info);\n      }\n    }\n\n    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();\n\n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n    \n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n    \n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09b6beb7329eb1b75a38c94b1c5ab4e840743c59","date":1308413204,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.put(merge.info, Boolean.FALSE);\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886","date":1308439813,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.put(merge.info, Boolean.FALSE);\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.add(merge.info);\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9f8b6801dbaf49c247119734f6e4516cce94e49a","date":1308478532,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      if (!segmentsToOptimize.containsKey(merge.info)) {\n        segmentsToOptimize.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.put(merge.info, Boolean.FALSE);\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f902dca0fec763317e17fa91ff6543fc8120c609","date":1308553979,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      if (!segmentsToOptimize.containsKey(merge.info)) {\n        segmentsToOptimize.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      segmentsToOptimize.put(merge.info, Boolean.FALSE);\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"06584e6e98d592b34e1329b384182f368d2025e8","date":1320850353,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      infoStream.message(\"IW\", \"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        infoStream.message(\"IW\", \"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      infoStream.message(\"IW\", \"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      if (!segmentsToOptimize.containsKey(merge.info)) {\n        segmentsToOptimize.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      message(\"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        message(\"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      message(\"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      message(\"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      if (!segmentsToOptimize.containsKey(merge.info)) {\n        segmentsToOptimize.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      infoStream.message(\"IW\", \"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        infoStream.message(\"IW\", \"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      infoStream.message(\"IW\", \"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.maxNumSegments != -1) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      infoStream.message(\"IW\", \"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        infoStream.message(\"IW\", \"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      infoStream.message(\"IW\", \"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.optimize) {\n      // cascade the optimize:\n      if (!segmentsToOptimize.containsKey(merge.info)) {\n        segmentsToOptimize.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"58c6bbc222f074c844e736e6fb23647e3db9cfe3","date":1322743940,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\"))\n      infoStream.message(\"IW\", \"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\"))\n        infoStream.message(\"IW\", \"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (allDeleted && infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.maxNumSegments != -1) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream != null)\n      infoStream.message(\"IW\", \"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream != null)\n        infoStream.message(\"IW\", \"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (infoStream != null && allDeleted) {\n      infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream != null) {\n      infoStream.message(\"IW\", \"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.maxNumSegments != -1) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c5df35ab57c223ea11aec64b53bf611904f3dced","date":1323640545,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      }\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (allDeleted) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.maxNumSegments != -1) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\"))\n      infoStream.message(\"IW\", \"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\"))\n        infoStream.message(\"IW\", \"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (allDeleted && infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.maxNumSegments != -1) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","date":1323720782,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      }\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (allDeleted) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.maxNumSegments != -1) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\"))\n      infoStream.message(\"IW\", \"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\"))\n        infoStream.message(\"IW\", \"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (allDeleted && infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.maxNumSegments != -1) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ce667c6d3400b22523701c549c0d35e26da8b46","date":1324405053,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#commitMerge(MergePolicy.OneMerge,SegmentReader).mjava","sourceNew":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + segString(merge.segments) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skip: it was aborted\");\n      }\n      return false;\n    }\n\n    final ReadersAndLiveDocs mergedDeletes = commitMergedDeletes(merge);\n\n    assert mergedDeletes == null || mergedDeletes.pendingDeleteCount != 0;\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = merge.segments.size() == 0 ||\n      merge.info.docCount == 0 ||\n      (mergedDeletes != null &&\n       mergedDeletes.pendingDeleteCount == merge.info.docCount);\n\n    if (infoStream.isEnabled(\"IW\")) {\n      if (allDeleted) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n\n    // If we merged no segments then we better be dropping\n    // the new segment:\n    assert merge.segments.size() > 0 || dropSegment;\n\n    assert merge.info.docCount != 0 || keepFullyDeletedSegments || dropSegment;\n\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    } else {\n      if (mergedDeletes != null && !poolReaders) {\n        mergedDeletes.writeLiveDocs(directory);\n        readerPool.drop(merge.info);\n      }\n    }\n    \n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    if (merge.maxNumSegments != -1) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {\n\n    assert testPoint(\"startCommitMerge\");\n\n    if (hitOOM) {\n      throw new IllegalStateException(\"this writer hit an OutOfMemoryError; cannot complete merge\");\n    }\n\n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"commitMerge: \" + merge.segString(directory) + \" index=\" + segString());\n    }\n\n    assert merge.registerDone;\n\n    // If merge was explicitly aborted, or, if rollback() or\n    // rollbackTransaction() had been called since our merge\n    // started (which results in an unqualified\n    // deleter.refresh() call that will remove any index\n    // file that current segments does not reference), we\n    // abort this merge\n    if (merge.isAborted()) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"commitMerge: skipping merge \" + merge.segString(directory) + \": it was aborted\");\n      }\n      return false;\n    }\n\n    commitMergedDeletes(merge, mergedReader);\n\n    // If the doc store we are using has been closed and\n    // is in now compound format (but wasn't when we\n    // started), then we will switch to the compound\n    // format as well:\n\n    assert !segmentInfos.contains(merge.info);\n\n    final boolean allDeleted = mergedReader.numDocs() == 0;\n\n    if (allDeleted) {\n      if (infoStream.isEnabled(\"IW\")) {\n        infoStream.message(\"IW\", \"merged segment \" + merge.info + \" is 100% deleted\" +  (keepFullyDeletedSegments ? \"\" : \"; skipping insert\"));\n      }\n    }\n\n    final boolean dropSegment = allDeleted && !keepFullyDeletedSegments;\n    segmentInfos.applyMergeChanges(merge, dropSegment);\n    \n    if (dropSegment) {\n      readerPool.drop(merge.info);\n    }\n    \n    if (infoStream.isEnabled(\"IW\")) {\n      infoStream.message(\"IW\", \"after commit: \" + segString());\n    }\n\n    closeMergeReaders(merge, false);\n\n    // Must note the change to segmentInfos so any commits\n    // in-flight don't lose it:\n    checkpoint();\n\n    // If the merged segments had pending changes, clear\n    // them so that they don't bother writing them to\n    // disk, updating SegmentInfo, etc.:\n    readerPool.clear(merge.segments);\n\n    if (merge.maxNumSegments != -1) {\n      // cascade the forceMerge:\n      if (!segmentsToMerge.containsKey(merge.info)) {\n        segmentsToMerge.put(merge.info, Boolean.FALSE);\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":["ae695f21c50b03702b5d0fa2543d5af844bb7cd3","ae695f21c50b03702b5d0fa2543d5af844bb7cd3"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"c5df35ab57c223ea11aec64b53bf611904f3dced":["58c6bbc222f074c844e736e6fb23647e3db9cfe3"],"58c6bbc222f074c844e736e6fb23647e3db9cfe3":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["29ef99d61cda9641b6250bf9567329a6e65f901d","e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["58c6bbc222f074c844e736e6fb23647e3db9cfe3","c5df35ab57c223ea11aec64b53bf611904f3dced"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["06584e6e98d592b34e1329b384182f368d2025e8"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"c19f985e36a65cc969e8e564fe337a0d41512075":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3":["c19f985e36a65cc969e8e564fe337a0d41512075"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["bde51b089eb7f86171eb3406e38a274743f9b7ac","e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3"],"d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886":["a3776dccca01c11e7046323cfad46a3b4a471233","09b6beb7329eb1b75a38c94b1c5ab4e840743c59"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","c19f985e36a65cc969e8e564fe337a0d41512075"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9ce667c6d3400b22523701c549c0d35e26da8b46":["c5df35ab57c223ea11aec64b53bf611904f3dced"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["3161e3ffcf20c09a22504a589d4d9bd273e11e33","e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3"],"09b6beb7329eb1b75a38c94b1c5ab4e840743c59":["786a4d25ca958a1f315a9d6a74f0441fdafcd522"],"f902dca0fec763317e17fa91ff6543fc8120c609":["d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886","9f8b6801dbaf49c247119734f6e4516cce94e49a"],"06584e6e98d592b34e1329b384182f368d2025e8":["9f8b6801dbaf49c247119734f6e4516cce94e49a"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["f1bdbf92da222965b46c0a942c3857ba56e5c638","b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3","c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"9f8b6801dbaf49c247119734f6e4516cce94e49a":["09b6beb7329eb1b75a38c94b1c5ab4e840743c59"],"786a4d25ca958a1f315a9d6a74f0441fdafcd522":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"3161e3ffcf20c09a22504a589d4d9bd273e11e33":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":["135621f3a0670a9394eb563224a3b76cc4dddc0f","786a4d25ca958a1f315a9d6a74f0441fdafcd522"],"a3776dccca01c11e7046323cfad46a3b4a471233":["e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3","786a4d25ca958a1f315a9d6a74f0441fdafcd522"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9ce667c6d3400b22523701c549c0d35e26da8b46"]},"commit2Childs":{"c5df35ab57c223ea11aec64b53bf611904f3dced":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","9ce667c6d3400b22523701c549c0d35e26da8b46"],"58c6bbc222f074c844e736e6fb23647e3db9cfe3":["c5df35ab57c223ea11aec64b53bf611904f3dced","93ccd971aca7fb61b7f1b946e44714cfc80bfc7c"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":[],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["58c6bbc222f074c844e736e6fb23647e3db9cfe3"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["3161e3ffcf20c09a22504a589d4d9bd273e11e33"],"c19f985e36a65cc969e8e564fe337a0d41512075":["e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3","29ef99d61cda9641b6250bf9567329a6e65f901d"],"e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3":["f1bdbf92da222965b46c0a942c3857ba56e5c638","c0ef0193974807e4bddf5432a6b0287fe4d6c9df","bde51b089eb7f86171eb3406e38a274743f9b7ac","b3e06be49006ecac364d39d12b9c9f74882f9b9f","a3776dccca01c11e7046323cfad46a3b4a471233"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["b3e06be49006ecac364d39d12b9c9f74882f9b9f"],"d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886":["f902dca0fec763317e17fa91ff6543fc8120c609"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["f1bdbf92da222965b46c0a942c3857ba56e5c638"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"9ce667c6d3400b22523701c549c0d35e26da8b46":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","c19f985e36a65cc969e8e564fe337a0d41512075","ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"09b6beb7329eb1b75a38c94b1c5ab4e840743c59":["d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886","9f8b6801dbaf49c247119734f6e4516cce94e49a"],"f902dca0fec763317e17fa91ff6543fc8120c609":[],"06584e6e98d592b34e1329b384182f368d2025e8":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["c3a8a449466c1ff7ce2274fe73dab487256964b4"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"b3e06be49006ecac364d39d12b9c9f74882f9b9f":["135621f3a0670a9394eb563224a3b76cc4dddc0f","786a4d25ca958a1f315a9d6a74f0441fdafcd522"],"9f8b6801dbaf49c247119734f6e4516cce94e49a":["f902dca0fec763317e17fa91ff6543fc8120c609","06584e6e98d592b34e1329b384182f368d2025e8"],"786a4d25ca958a1f315a9d6a74f0441fdafcd522":["09b6beb7329eb1b75a38c94b1c5ab4e840743c59","c3a8a449466c1ff7ce2274fe73dab487256964b4","a3776dccca01c11e7046323cfad46a3b4a471233"],"3161e3ffcf20c09a22504a589d4d9bd273e11e33":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"c3a8a449466c1ff7ce2274fe73dab487256964b4":[],"a3776dccca01c11e7046323cfad46a3b4a471233":["d1ded5d4f5b5e3e5f32bff69cd6fe5e64322a886"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","f902dca0fec763317e17fa91ff6543fc8120c609","c3a8a449466c1ff7ce2274fe73dab487256964b4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}