{"path":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(FieldInfos,SegmentInfo,SegmentReader,NumberFormat).mjava","commits":[{"id":"814339e4b1ce2063ccbc6cacc6443a6446c7718b","date":1331991774,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(FieldInfos,SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(FieldInfos fieldInfos, SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n\n    final Bits onlyDocIsDeleted = new FixedBitSet(1);\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        // Intentionally pull/visit (but don't count in\n        // stats) deleted documents to make sure they too\n        // are not corrupt:\n        Fields tfv = reader.getTermVectors(j);\n\n        // TODO: can we make a IS(FIR) that searches just\n        // this term vector... to pass for searcher?\n\n        if (tfv != null) {\n          // First run with no deletions:\n          checkFields(tfv, null, 1, fieldInfos, null);\n\n          // Again, with the one doc deleted:\n          checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, null);\n\n          // Only agg stats if the doc is live:\n          final boolean doStats = liveDocs == null || liveDocs.get(j);\n          if (doStats) {\n            status.docCount++;\n          }\n\n          FieldsEnum fieldsEnum = tfv.iterator();\n          String field = null;\n          while((field = fieldsEnum.next()) != null) {\n            if (doStats) {\n              status.totVectors++;\n            }\n\n            // Make sure FieldInfo thinks this field is vector'd:\n            final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n            if (!fieldInfo.storeTermVector) {\n              throw new RuntimeException(\"docID=\" + j + \" has term vectors for field=\" + field + \" but FieldInfo has storeTermVector=false\");\n            }\n\n            if (crossCheckTermVectors) {\n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              Terms postingsTerms = postingsFields.terms(field);\n              if (postingsTerms == null) {\n                throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n              }\n              postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                \n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (!postingsTermsEnum.seekExact(term, true)) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                if (postingsPostings == null) {\n                  // Term vectors were indexed w/ offsets but postings were not\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                  if (postingsPostings == null) {\n                    postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                    if (postingsDocs == null) {\n                      postingsHasFreq = false;\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                      if (postingsDocs == null) {\n                        throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n                } else {\n                  postingsHasFreq = true;\n                }\n\n                if (postingsPostings != null) {\n                  postingsDocs2 = postingsPostings;\n                } else {\n                  postingsDocs2 = postingsDocs;\n                }\n                  \n                final int advanceDoc = postingsDocs2.advance(j);\n                if (advanceDoc != j) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (postingsHasFreq && postingsDocs2.freq() != tf) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                  }\n                \n                  if (hasPositions || hasOffsets) {\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                          if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                          }\n                          if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                          }\n                          lastStartOffset = startOffset;\n                        */\n\n                        if (postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n    \n    // TODO: in theory we could test that term vectors have\n    // same terms/pos/offsets as the postings, but it'd be\n    // very slow...\n\n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      // TODO: maybe we can factor out testTermIndex and reuse here?\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        if (liveDocs == null || liveDocs.get(j)) {\n          status.docCount++;\n          Fields tfv = reader.getTermVectors(j);\n          if (tfv != null) {\n            int tfvComputedFieldCount = 0;\n            long tfvComputedTermCount = 0;\n\n            FieldsEnum fieldsEnum = tfv.iterator();\n            String field = null;\n            String lastField = null;\n            while((field = fieldsEnum.next()) != null) {\n              status.totVectors++;\n              tfvComputedFieldCount++;\n\n              if (lastField == null) {\n                lastField = field;\n              } else if (lastField.compareTo(field) > 0) {\n                throw new RuntimeException(\"vector fields are out of order: lastField=\" + lastField + \" field=\" + field + \" doc=\" + j);\n              }\n              \n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              if (crossCheckTermVectors) {\n                Terms postingsTerms = postingsFields.terms(field);\n                if (postingsTerms == null) {\n                  throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              } else {\n                postingsTermsEnum = null;\n              }\n              \n              long tfvComputedTermCountForField = 0;\n              long tfvComputedSumTotalTermFreq = 0;\n              \n              BytesRef lastTerm = null;\n              Comparator<BytesRef> termComp = terms.getComparator();\n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                tfvComputedTermCountForField++;\n                \n                // make sure terms arrive in order according to\n                // the comp\n                if (lastTerm == null) {\n                  lastTerm = BytesRef.deepCopyOf(term);\n                } else {\n                  if (termComp.compare(lastTerm, term) >= 0) {\n                    throw new RuntimeException(\"vector terms out of order for doc \" + j + \": lastTerm=\" + lastTerm + \" term=\" + term);\n                  }\n                  lastTerm.copyBytes(term);\n                }\n                \n                if (termsEnum.docFreq() != 1) {\n                  throw new RuntimeException(\"vector docFreq for doc \" + j + \", field \" + field + \", term\" + term + \" != 1\");\n                }\n                \n                long totalTermFreq = termsEnum.totalTermFreq();\n                \n                if (totalTermFreq != -1 && totalTermFreq <= 0) {\n                  throw new RuntimeException(\"totalTermFreq: \" + totalTermFreq + \" is out of bounds\");\n                }\n\n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1 below\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (crossCheckTermVectors) {\n                  if (!postingsTermsEnum.seekExact(term, true)) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                  }\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                  if (postingsPostings == null) {\n                    // Term vectors were indexed w/ offsets but postings were not\n                    postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                    if (postingsPostings == null) {\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                      if (postingsDocs == null) {\n                        postingsHasFreq = false;\n                        postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                        if (postingsDocs == null) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                        }\n                      } else {\n                        postingsHasFreq = true;\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n\n                  if (postingsPostings != null) {\n                    postingsDocs2 = postingsPostings;\n                  } else {\n                    postingsDocs2 = postingsDocs;\n                  }\n                  \n                  final int advanceDoc = postingsDocs2.advance(j);\n                  if (advanceDoc != j) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                  }\n                } else {\n                  postingsDocs2 = null;\n                  postingsHasFreq = false;\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (tf <= 0) {\n                    throw new RuntimeException(\"vector freq \" + tf + \" is out of bounds\");\n                  }\n                  if (totalTermFreq != -1 && totalTermFreq != tf) {\n                    throw new RuntimeException(\"vector totalTermFreq \" + totalTermFreq + \" != tf \" + tf);\n                  }\n                  if (crossCheckTermVectors && postingsHasFreq) {\n                    if (postingsDocs2.freq() != tf) {\n                      throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                    }\n                  }\n                  tfvComputedSumTotalTermFreq += tf;\n                \n                  if (hasPositions || hasOffsets) {\n                    int lastPosition = -1;\n                    //int lastStartOffset = -1;\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (hasPositions) {\n                        if (pos != -1 && pos < 0) {\n                          throw new RuntimeException(\"vector position \" + pos + \" is out of bounds\");\n                        }\n                        if (pos < lastPosition) {\n                          throw new RuntimeException(\"vector position \" + pos + \" < lastPos \" + lastPosition);\n                        }\n                    \n                        lastPosition = pos;\n                      }\n\n                      if (crossCheckTermVectors && postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                        if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                        }\n                        if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                        }\n                        lastStartOffset = startOffset;\n                        */\n\n                        if (crossCheckTermVectors && postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n                  \n                if (docs2.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" references multiple documents!\");\n                }\n              }\n              \n              long uniqueTermCount = terms.getUniqueTermCount();\n              if (uniqueTermCount != -1 && uniqueTermCount != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector term count for doc \" + j + \", field \" + field + \" = \" + uniqueTermCount + \" != recomputed term count=\" + tfvComputedTermCountForField);\n              }\n              \n              int docCount = terms.getDocCount();\n              if (docCount != -1 && docCount != 1) {\n                throw new RuntimeException(\"vector doc count for doc \" + j + \", field \" + field + \" = \" + docCount + \" != 1\");\n              }\n              \n              long sumDocFreq = terms.getSumDocFreq();\n              if (sumDocFreq != -1 && sumDocFreq != tfvComputedTermCountForField) {\n                throw new RuntimeException(\"vector postings count for doc \" + j + \", field \" + field + \" = \" + sumDocFreq + \" != recomputed postings count=\" + tfvComputedTermCountForField);\n              }\n              \n              long sumTotalTermFreq = terms.getSumTotalTermFreq();\n              if (sumTotalTermFreq != -1 && sumTotalTermFreq != tfvComputedSumTotalTermFreq) {\n                throw new RuntimeException(\"vector sumTotalTermFreq for doc \" + j + \", field \" + field + \" = \" + sumTotalTermFreq + \" != recomputed sumTotalTermFreq=\" + tfvComputedSumTotalTermFreq);\n              }\n              \n              tfvComputedTermCount += tfvComputedTermCountForField;\n            }\n            \n            int tfvUniqueFieldCount = tfv.getUniqueFieldCount();\n            if (tfvUniqueFieldCount != -1 && tfvUniqueFieldCount != tfvComputedFieldCount) {\n              throw new RuntimeException(\"vector field count for doc \" + j + \"=\" + tfvUniqueFieldCount + \" != recomputed uniqueFieldCount=\" + tfvComputedFieldCount);\n            }\n            \n            long tfvUniqueTermCount = tfv.getUniqueTermCount();\n            if (tfvUniqueTermCount != -1 && tfvUniqueTermCount != tfvComputedTermCount) {\n              throw new RuntimeException(\"vector term count for doc \" + j + \"=\" + tfvUniqueTermCount + \" != recomputed uniqueTermCount=\" + tfvComputedTermCount);\n            }\n          }\n        }\n      }\n      \n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d08eba3d52b63561ebf936481ce73e6b6a14aa03","date":1333879759,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(FieldInfos,SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(FieldInfos,SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(FieldInfos fieldInfos, SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n\n    final Bits onlyDocIsDeleted = new FixedBitSet(1);\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final InvertedFields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        // Intentionally pull/visit (but don't count in\n        // stats) deleted documents to make sure they too\n        // are not corrupt:\n        InvertedFields tfv = reader.getTermVectors(j);\n\n        // TODO: can we make a IS(FIR) that searches just\n        // this term vector... to pass for searcher?\n\n        if (tfv != null) {\n          // First run with no deletions:\n          checkFields(tfv, null, 1, fieldInfos, null);\n\n          // Again, with the one doc deleted:\n          checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, null);\n\n          // Only agg stats if the doc is live:\n          final boolean doStats = liveDocs == null || liveDocs.get(j);\n          if (doStats) {\n            status.docCount++;\n          }\n\n          FieldsEnum fieldsEnum = tfv.iterator();\n          String field = null;\n          while((field = fieldsEnum.next()) != null) {\n            if (doStats) {\n              status.totVectors++;\n            }\n\n            // Make sure FieldInfo thinks this field is vector'd:\n            final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n            if (!fieldInfo.storeTermVector) {\n              throw new RuntimeException(\"docID=\" + j + \" has term vectors for field=\" + field + \" but FieldInfo has storeTermVector=false\");\n            }\n\n            if (crossCheckTermVectors) {\n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              Terms postingsTerms = postingsFields.terms(field);\n              if (postingsTerms == null) {\n                throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n              }\n              postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                \n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (!postingsTermsEnum.seekExact(term, true)) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                if (postingsPostings == null) {\n                  // Term vectors were indexed w/ offsets but postings were not\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                  if (postingsPostings == null) {\n                    postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                    if (postingsDocs == null) {\n                      postingsHasFreq = false;\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                      if (postingsDocs == null) {\n                        throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n                } else {\n                  postingsHasFreq = true;\n                }\n\n                if (postingsPostings != null) {\n                  postingsDocs2 = postingsPostings;\n                } else {\n                  postingsDocs2 = postingsDocs;\n                }\n                  \n                final int advanceDoc = postingsDocs2.advance(j);\n                if (advanceDoc != j) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (postingsHasFreq && postingsDocs2.freq() != tf) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                  }\n                \n                  if (hasPositions || hasOffsets) {\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                          if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                          }\n                          if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                          }\n                          lastStartOffset = startOffset;\n                        */\n\n                        if (postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(FieldInfos fieldInfos, SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n\n    final Bits onlyDocIsDeleted = new FixedBitSet(1);\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        // Intentionally pull/visit (but don't count in\n        // stats) deleted documents to make sure they too\n        // are not corrupt:\n        Fields tfv = reader.getTermVectors(j);\n\n        // TODO: can we make a IS(FIR) that searches just\n        // this term vector... to pass for searcher?\n\n        if (tfv != null) {\n          // First run with no deletions:\n          checkFields(tfv, null, 1, fieldInfos, null);\n\n          // Again, with the one doc deleted:\n          checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, null);\n\n          // Only agg stats if the doc is live:\n          final boolean doStats = liveDocs == null || liveDocs.get(j);\n          if (doStats) {\n            status.docCount++;\n          }\n\n          FieldsEnum fieldsEnum = tfv.iterator();\n          String field = null;\n          while((field = fieldsEnum.next()) != null) {\n            if (doStats) {\n              status.totVectors++;\n            }\n\n            // Make sure FieldInfo thinks this field is vector'd:\n            final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n            if (!fieldInfo.storeTermVector) {\n              throw new RuntimeException(\"docID=\" + j + \" has term vectors for field=\" + field + \" but FieldInfo has storeTermVector=false\");\n            }\n\n            if (crossCheckTermVectors) {\n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              Terms postingsTerms = postingsFields.terms(field);\n              if (postingsTerms == null) {\n                throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n              }\n              postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                \n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (!postingsTermsEnum.seekExact(term, true)) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                if (postingsPostings == null) {\n                  // Term vectors were indexed w/ offsets but postings were not\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                  if (postingsPostings == null) {\n                    postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                    if (postingsDocs == null) {\n                      postingsHasFreq = false;\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                      if (postingsDocs == null) {\n                        throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n                } else {\n                  postingsHasFreq = true;\n                }\n\n                if (postingsPostings != null) {\n                  postingsDocs2 = postingsPostings;\n                } else {\n                  postingsDocs2 = postingsDocs;\n                }\n                  \n                final int advanceDoc = postingsDocs2.advance(j);\n                if (advanceDoc != j) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (postingsHasFreq && postingsDocs2.freq() != tf) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                  }\n                \n                  if (hasPositions || hasOffsets) {\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                          if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                          }\n                          if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                          }\n                          lastStartOffset = startOffset;\n                        */\n\n                        if (postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","date":1333892281,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(FieldInfos,SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(FieldInfos,SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(FieldInfos fieldInfos, SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n\n    final Bits onlyDocIsDeleted = new FixedBitSet(1);\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        // Intentionally pull/visit (but don't count in\n        // stats) deleted documents to make sure they too\n        // are not corrupt:\n        Fields tfv = reader.getTermVectors(j);\n\n        // TODO: can we make a IS(FIR) that searches just\n        // this term vector... to pass for searcher?\n\n        if (tfv != null) {\n          // First run with no deletions:\n          checkFields(tfv, null, 1, fieldInfos, null);\n\n          // Again, with the one doc deleted:\n          checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, null);\n\n          // Only agg stats if the doc is live:\n          final boolean doStats = liveDocs == null || liveDocs.get(j);\n          if (doStats) {\n            status.docCount++;\n          }\n\n          FieldsEnum fieldsEnum = tfv.iterator();\n          String field = null;\n          while((field = fieldsEnum.next()) != null) {\n            if (doStats) {\n              status.totVectors++;\n            }\n\n            // Make sure FieldInfo thinks this field is vector'd:\n            final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n            if (!fieldInfo.storeTermVector) {\n              throw new RuntimeException(\"docID=\" + j + \" has term vectors for field=\" + field + \" but FieldInfo has storeTermVector=false\");\n            }\n\n            if (crossCheckTermVectors) {\n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              Terms postingsTerms = postingsFields.terms(field);\n              if (postingsTerms == null) {\n                throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n              }\n              postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                \n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (!postingsTermsEnum.seekExact(term, true)) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                if (postingsPostings == null) {\n                  // Term vectors were indexed w/ offsets but postings were not\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                  if (postingsPostings == null) {\n                    postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                    if (postingsDocs == null) {\n                      postingsHasFreq = false;\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                      if (postingsDocs == null) {\n                        throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n                } else {\n                  postingsHasFreq = true;\n                }\n\n                if (postingsPostings != null) {\n                  postingsDocs2 = postingsPostings;\n                } else {\n                  postingsDocs2 = postingsDocs;\n                }\n                  \n                final int advanceDoc = postingsDocs2.advance(j);\n                if (advanceDoc != j) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (postingsHasFreq && postingsDocs2.freq() != tf) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                  }\n                \n                  if (hasPositions || hasOffsets) {\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                          if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                          }\n                          if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                          }\n                          lastStartOffset = startOffset;\n                        */\n\n                        if (postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(FieldInfos fieldInfos, SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n\n    final Bits onlyDocIsDeleted = new FixedBitSet(1);\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final InvertedFields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        // Intentionally pull/visit (but don't count in\n        // stats) deleted documents to make sure they too\n        // are not corrupt:\n        InvertedFields tfv = reader.getTermVectors(j);\n\n        // TODO: can we make a IS(FIR) that searches just\n        // this term vector... to pass for searcher?\n\n        if (tfv != null) {\n          // First run with no deletions:\n          checkFields(tfv, null, 1, fieldInfos, null);\n\n          // Again, with the one doc deleted:\n          checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, null);\n\n          // Only agg stats if the doc is live:\n          final boolean doStats = liveDocs == null || liveDocs.get(j);\n          if (doStats) {\n            status.docCount++;\n          }\n\n          FieldsEnum fieldsEnum = tfv.iterator();\n          String field = null;\n          while((field = fieldsEnum.next()) != null) {\n            if (doStats) {\n              status.totVectors++;\n            }\n\n            // Make sure FieldInfo thinks this field is vector'd:\n            final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n            if (!fieldInfo.storeTermVector) {\n              throw new RuntimeException(\"docID=\" + j + \" has term vectors for field=\" + field + \" but FieldInfo has storeTermVector=false\");\n            }\n\n            if (crossCheckTermVectors) {\n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              Terms postingsTerms = postingsFields.terms(field);\n              if (postingsTerms == null) {\n                throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n              }\n              postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                \n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (!postingsTermsEnum.seekExact(term, true)) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                if (postingsPostings == null) {\n                  // Term vectors were indexed w/ offsets but postings were not\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                  if (postingsPostings == null) {\n                    postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                    if (postingsDocs == null) {\n                      postingsHasFreq = false;\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                      if (postingsDocs == null) {\n                        throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n                } else {\n                  postingsHasFreq = true;\n                }\n\n                if (postingsPostings != null) {\n                  postingsDocs2 = postingsPostings;\n                } else {\n                  postingsDocs2 = postingsDocs;\n                }\n                  \n                final int advanceDoc = postingsDocs2.advance(j);\n                if (advanceDoc != j) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (postingsHasFreq && postingsDocs2.freq() != tf) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                  }\n                \n                  if (hasPositions || hasOffsets) {\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                          if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                          }\n                          if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                          }\n                          lastStartOffset = startOffset;\n                        */\n\n                        if (postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"76923f6a33f2c4bec7f584e3f251261afe7ea276","date":1337149711,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(FieldInfos,SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(FieldInfos,SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(FieldInfos fieldInfos, SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n\n    final Bits onlyDocIsDeleted = new FixedBitSet(1);\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        // Intentionally pull/visit (but don't count in\n        // stats) deleted documents to make sure they too\n        // are not corrupt:\n        Fields tfv = reader.getTermVectors(j);\n\n        // TODO: can we make a IS(FIR) that searches just\n        // this term vector... to pass for searcher?\n\n        if (tfv != null) {\n          // First run with no deletions:\n          checkFields(tfv, null, 1, fieldInfos, null);\n\n          // Again, with the one doc deleted:\n          checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, null);\n\n          // Only agg stats if the doc is live:\n          final boolean doStats = liveDocs == null || liveDocs.get(j);\n          if (doStats) {\n            status.docCount++;\n          }\n\n          FieldsEnum fieldsEnum = tfv.iterator();\n          String field = null;\n          while((field = fieldsEnum.next()) != null) {\n            if (doStats) {\n              status.totVectors++;\n            }\n\n            // Make sure FieldInfo thinks this field is vector'd:\n            final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n            if (!fieldInfo.hasVectors()) {\n              throw new RuntimeException(\"docID=\" + j + \" has term vectors for field=\" + field + \" but FieldInfo has storeTermVector=false\");\n            }\n\n            if (crossCheckTermVectors) {\n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              Terms postingsTerms = postingsFields.terms(field);\n              if (postingsTerms == null) {\n                throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n              }\n              postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                \n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (!postingsTermsEnum.seekExact(term, true)) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                if (postingsPostings == null) {\n                  // Term vectors were indexed w/ offsets but postings were not\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                  if (postingsPostings == null) {\n                    postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                    if (postingsDocs == null) {\n                      postingsHasFreq = false;\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                      if (postingsDocs == null) {\n                        throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n                } else {\n                  postingsHasFreq = true;\n                }\n\n                if (postingsPostings != null) {\n                  postingsDocs2 = postingsPostings;\n                } else {\n                  postingsDocs2 = postingsDocs;\n                }\n                  \n                final int advanceDoc = postingsDocs2.advance(j);\n                if (advanceDoc != j) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (postingsHasFreq && postingsDocs2.freq() != tf) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                  }\n                \n                  if (hasPositions || hasOffsets) {\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                          if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                          }\n                          if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                          }\n                          lastStartOffset = startOffset;\n                        */\n\n                        if (postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(FieldInfos fieldInfos, SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n\n    final Bits onlyDocIsDeleted = new FixedBitSet(1);\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        // Intentionally pull/visit (but don't count in\n        // stats) deleted documents to make sure they too\n        // are not corrupt:\n        Fields tfv = reader.getTermVectors(j);\n\n        // TODO: can we make a IS(FIR) that searches just\n        // this term vector... to pass for searcher?\n\n        if (tfv != null) {\n          // First run with no deletions:\n          checkFields(tfv, null, 1, fieldInfos, null);\n\n          // Again, with the one doc deleted:\n          checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, null);\n\n          // Only agg stats if the doc is live:\n          final boolean doStats = liveDocs == null || liveDocs.get(j);\n          if (doStats) {\n            status.docCount++;\n          }\n\n          FieldsEnum fieldsEnum = tfv.iterator();\n          String field = null;\n          while((field = fieldsEnum.next()) != null) {\n            if (doStats) {\n              status.totVectors++;\n            }\n\n            // Make sure FieldInfo thinks this field is vector'd:\n            final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n            if (!fieldInfo.storeTermVector) {\n              throw new RuntimeException(\"docID=\" + j + \" has term vectors for field=\" + field + \" but FieldInfo has storeTermVector=false\");\n            }\n\n            if (crossCheckTermVectors) {\n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              Terms postingsTerms = postingsFields.terms(field);\n              if (postingsTerms == null) {\n                throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n              }\n              postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                \n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (!postingsTermsEnum.seekExact(term, true)) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                if (postingsPostings == null) {\n                  // Term vectors were indexed w/ offsets but postings were not\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                  if (postingsPostings == null) {\n                    postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                    if (postingsDocs == null) {\n                      postingsHasFreq = false;\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                      if (postingsDocs == null) {\n                        throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n                } else {\n                  postingsHasFreq = true;\n                }\n\n                if (postingsPostings != null) {\n                  postingsDocs2 = postingsPostings;\n                } else {\n                  postingsDocs2 = postingsDocs;\n                }\n                  \n                final int advanceDoc = postingsDocs2.advance(j);\n                if (advanceDoc != j) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (postingsHasFreq && postingsDocs2.freq() != tf) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                  }\n                \n                  if (hasPositions || hasOffsets) {\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                          if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                          }\n                          if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                          }\n                          lastStartOffset = startOffset;\n                        */\n\n                        if (postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4a8b14bc4241c302311422d5c6f7627f8febb86e","date":1337291675,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(FieldInfos,SegmentInfo,SegmentReader,NumberFormat).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(FieldInfos,SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(FieldInfos fieldInfos, SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n\n    final Bits onlyDocIsDeleted = new FixedBitSet(1);\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        // Intentionally pull/visit (but don't count in\n        // stats) deleted documents to make sure they too\n        // are not corrupt:\n        Fields tfv = reader.getTermVectors(j);\n\n        // TODO: can we make a IS(FIR) that searches just\n        // this term vector... to pass for searcher?\n\n        if (tfv != null) {\n          // First run with no deletions:\n          checkFields(tfv, null, 1, fieldInfos, null, false);\n\n          // Again, with the one doc deleted:\n          checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, null, false);\n\n          // Only agg stats if the doc is live:\n          final boolean doStats = liveDocs == null || liveDocs.get(j);\n          if (doStats) {\n            status.docCount++;\n          }\n\n          FieldsEnum fieldsEnum = tfv.iterator();\n          String field = null;\n          while((field = fieldsEnum.next()) != null) {\n            if (doStats) {\n              status.totVectors++;\n            }\n\n            // Make sure FieldInfo thinks this field is vector'd:\n            final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n            if (!fieldInfo.hasVectors()) {\n              throw new RuntimeException(\"docID=\" + j + \" has term vectors for field=\" + field + \" but FieldInfo has storeTermVector=false\");\n            }\n\n            if (crossCheckTermVectors) {\n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              Terms postingsTerms = postingsFields.terms(field);\n              if (postingsTerms == null) {\n                throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n              }\n              postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                \n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (!postingsTermsEnum.seekExact(term, true)) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                if (postingsPostings == null) {\n                  // Term vectors were indexed w/ offsets but postings were not\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                  if (postingsPostings == null) {\n                    postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                    if (postingsDocs == null) {\n                      postingsHasFreq = false;\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                      if (postingsDocs == null) {\n                        throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n                } else {\n                  postingsHasFreq = true;\n                }\n\n                if (postingsPostings != null) {\n                  postingsDocs2 = postingsPostings;\n                } else {\n                  postingsDocs2 = postingsDocs;\n                }\n                  \n                final int advanceDoc = postingsDocs2.advance(j);\n                if (advanceDoc != j) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (postingsHasFreq && postingsDocs2.freq() != tf) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                  }\n                \n                  if (hasPositions || hasOffsets) {\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                          if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                          }\n                          if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                          }\n                          lastStartOffset = startOffset;\n                        */\n\n                        if (postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(FieldInfos fieldInfos, SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n\n    final Bits onlyDocIsDeleted = new FixedBitSet(1);\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        // Intentionally pull/visit (but don't count in\n        // stats) deleted documents to make sure they too\n        // are not corrupt:\n        Fields tfv = reader.getTermVectors(j);\n\n        // TODO: can we make a IS(FIR) that searches just\n        // this term vector... to pass for searcher?\n\n        if (tfv != null) {\n          // First run with no deletions:\n          checkFields(tfv, null, 1, fieldInfos, null);\n\n          // Again, with the one doc deleted:\n          checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, null);\n\n          // Only agg stats if the doc is live:\n          final boolean doStats = liveDocs == null || liveDocs.get(j);\n          if (doStats) {\n            status.docCount++;\n          }\n\n          FieldsEnum fieldsEnum = tfv.iterator();\n          String field = null;\n          while((field = fieldsEnum.next()) != null) {\n            if (doStats) {\n              status.totVectors++;\n            }\n\n            // Make sure FieldInfo thinks this field is vector'd:\n            final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n            if (!fieldInfo.hasVectors()) {\n              throw new RuntimeException(\"docID=\" + j + \" has term vectors for field=\" + field + \" but FieldInfo has storeTermVector=false\");\n            }\n\n            if (crossCheckTermVectors) {\n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              Terms postingsTerms = postingsFields.terms(field);\n              if (postingsTerms == null) {\n                throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n              }\n              postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                \n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (!postingsTermsEnum.seekExact(term, true)) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                if (postingsPostings == null) {\n                  // Term vectors were indexed w/ offsets but postings were not\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                  if (postingsPostings == null) {\n                    postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                    if (postingsDocs == null) {\n                      postingsHasFreq = false;\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                      if (postingsDocs == null) {\n                        throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n                } else {\n                  postingsHasFreq = true;\n                }\n\n                if (postingsPostings != null) {\n                  postingsDocs2 = postingsPostings;\n                } else {\n                  postingsDocs2 = postingsDocs;\n                }\n                  \n                final int advanceDoc = postingsDocs2.advance(j);\n                if (advanceDoc != j) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (postingsHasFreq && postingsDocs2.freq() != tf) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                  }\n                \n                  if (hasPositions || hasOffsets) {\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                          if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                          }\n                          if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                          }\n                          lastStartOffset = startOffset;\n                        */\n\n                        if (postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(FieldInfos,SegmentInfoPerCommit,SegmentReader,NumberFormat).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(FieldInfos,SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(FieldInfos fieldInfos, SegmentInfoPerCommit info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n\n    final Bits onlyDocIsDeleted = new FixedBitSet(1);\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.info.docCount; ++j) {\n        // Intentionally pull/visit (but don't count in\n        // stats) deleted documents to make sure they too\n        // are not corrupt:\n        Fields tfv = reader.getTermVectors(j);\n\n        // TODO: can we make a IS(FIR) that searches just\n        // this term vector... to pass for searcher?\n\n        if (tfv != null) {\n          // First run with no deletions:\n          checkFields(tfv, null, 1, fieldInfos, null, false);\n\n          // Again, with the one doc deleted:\n          checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, null, false);\n\n          // Only agg stats if the doc is live:\n          final boolean doStats = liveDocs == null || liveDocs.get(j);\n          if (doStats) {\n            status.docCount++;\n          }\n\n          FieldsEnum fieldsEnum = tfv.iterator();\n          String field = null;\n          while((field = fieldsEnum.next()) != null) {\n            if (doStats) {\n              status.totVectors++;\n            }\n\n            // Make sure FieldInfo thinks this field is vector'd:\n            final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n            if (!fieldInfo.hasVectors()) {\n              throw new RuntimeException(\"docID=\" + j + \" has term vectors for field=\" + field + \" but FieldInfo has storeTermVector=false\");\n            }\n\n            if (crossCheckTermVectors) {\n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              Terms postingsTerms = postingsFields.terms(field);\n              if (postingsTerms == null) {\n                throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n              }\n              postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                \n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (!postingsTermsEnum.seekExact(term, true)) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                if (postingsPostings == null) {\n                  // Term vectors were indexed w/ offsets but postings were not\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                  if (postingsPostings == null) {\n                    postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                    if (postingsDocs == null) {\n                      postingsHasFreq = false;\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                      if (postingsDocs == null) {\n                        throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n                } else {\n                  postingsHasFreq = true;\n                }\n\n                if (postingsPostings != null) {\n                  postingsDocs2 = postingsPostings;\n                } else {\n                  postingsDocs2 = postingsDocs;\n                }\n                  \n                final int advanceDoc = postingsDocs2.advance(j);\n                if (advanceDoc != j) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (postingsHasFreq && postingsDocs2.freq() != tf) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                  }\n                \n                  if (hasPositions || hasOffsets) {\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                          if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                          }\n                          if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                          }\n                          lastStartOffset = startOffset;\n                        */\n\n                        if (postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(FieldInfos fieldInfos, SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n\n    final Bits onlyDocIsDeleted = new FixedBitSet(1);\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        // Intentionally pull/visit (but don't count in\n        // stats) deleted documents to make sure they too\n        // are not corrupt:\n        Fields tfv = reader.getTermVectors(j);\n\n        // TODO: can we make a IS(FIR) that searches just\n        // this term vector... to pass for searcher?\n\n        if (tfv != null) {\n          // First run with no deletions:\n          checkFields(tfv, null, 1, fieldInfos, null, false);\n\n          // Again, with the one doc deleted:\n          checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, null, false);\n\n          // Only agg stats if the doc is live:\n          final boolean doStats = liveDocs == null || liveDocs.get(j);\n          if (doStats) {\n            status.docCount++;\n          }\n\n          FieldsEnum fieldsEnum = tfv.iterator();\n          String field = null;\n          while((field = fieldsEnum.next()) != null) {\n            if (doStats) {\n              status.totVectors++;\n            }\n\n            // Make sure FieldInfo thinks this field is vector'd:\n            final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n            if (!fieldInfo.hasVectors()) {\n              throw new RuntimeException(\"docID=\" + j + \" has term vectors for field=\" + field + \" but FieldInfo has storeTermVector=false\");\n            }\n\n            if (crossCheckTermVectors) {\n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              Terms postingsTerms = postingsFields.terms(field);\n              if (postingsTerms == null) {\n                throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n              }\n              postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                \n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (!postingsTermsEnum.seekExact(term, true)) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                if (postingsPostings == null) {\n                  // Term vectors were indexed w/ offsets but postings were not\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                  if (postingsPostings == null) {\n                    postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                    if (postingsDocs == null) {\n                      postingsHasFreq = false;\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                      if (postingsDocs == null) {\n                        throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n                } else {\n                  postingsHasFreq = true;\n                }\n\n                if (postingsPostings != null) {\n                  postingsDocs2 = postingsPostings;\n                } else {\n                  postingsDocs2 = postingsDocs;\n                }\n                  \n                final int advanceDoc = postingsDocs2.advance(j);\n                if (advanceDoc != j) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (postingsHasFreq && postingsDocs2.freq() != tf) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                  }\n                \n                  if (hasPositions || hasOffsets) {\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                          if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                          }\n                          if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                          }\n                          lastStartOffset = startOffset;\n                        */\n\n                        if (postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(FieldInfos,SegmentInfoPerCommit,SegmentReader,NumberFormat).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/CheckIndex#testTermVectors(FieldInfos,SegmentInfo,SegmentReader,NumberFormat).mjava","sourceNew":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(FieldInfos fieldInfos, SegmentInfoPerCommit info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n\n    final Bits onlyDocIsDeleted = new FixedBitSet(1);\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.info.getDocCount(); ++j) {\n        // Intentionally pull/visit (but don't count in\n        // stats) deleted documents to make sure they too\n        // are not corrupt:\n        Fields tfv = reader.getTermVectors(j);\n\n        // TODO: can we make a IS(FIR) that searches just\n        // this term vector... to pass for searcher?\n\n        if (tfv != null) {\n          // First run with no deletions:\n          checkFields(tfv, null, 1, fieldInfos, null, false);\n\n          // Again, with the one doc deleted:\n          checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, null, false);\n\n          // Only agg stats if the doc is live:\n          final boolean doStats = liveDocs == null || liveDocs.get(j);\n          if (doStats) {\n            status.docCount++;\n          }\n\n          FieldsEnum fieldsEnum = tfv.iterator();\n          String field = null;\n          while((field = fieldsEnum.next()) != null) {\n            if (doStats) {\n              status.totVectors++;\n            }\n\n            // Make sure FieldInfo thinks this field is vector'd:\n            final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n            if (!fieldInfo.hasVectors()) {\n              throw new RuntimeException(\"docID=\" + j + \" has term vectors for field=\" + field + \" but FieldInfo has storeTermVector=false\");\n            }\n\n            if (crossCheckTermVectors) {\n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              Terms postingsTerms = postingsFields.terms(field);\n              if (postingsTerms == null) {\n                throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n              }\n              postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                \n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (!postingsTermsEnum.seekExact(term, true)) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                if (postingsPostings == null) {\n                  // Term vectors were indexed w/ offsets but postings were not\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                  if (postingsPostings == null) {\n                    postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                    if (postingsDocs == null) {\n                      postingsHasFreq = false;\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                      if (postingsDocs == null) {\n                        throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n                } else {\n                  postingsHasFreq = true;\n                }\n\n                if (postingsPostings != null) {\n                  postingsDocs2 = postingsPostings;\n                } else {\n                  postingsDocs2 = postingsDocs;\n                }\n                  \n                final int advanceDoc = postingsDocs2.advance(j);\n                if (advanceDoc != j) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (postingsHasFreq && postingsDocs2.freq() != tf) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                  }\n                \n                  if (hasPositions || hasOffsets) {\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                          if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                          }\n                          if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                          }\n                          lastStartOffset = startOffset;\n                        */\n\n                        if (postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","sourceOld":"  /**\n   * Test term vectors for a segment.\n   */\n  private Status.TermVectorStatus testTermVectors(FieldInfos fieldInfos, SegmentInfo info, SegmentReader reader, NumberFormat format) {\n    final Status.TermVectorStatus status = new Status.TermVectorStatus();\n\n    final Bits onlyDocIsDeleted = new FixedBitSet(1);\n    \n    try {\n      if (infoStream != null) {\n        infoStream.print(\"    test: term vectors........\");\n      }\n\n      DocsEnum docs = null;\n      DocsAndPositionsEnum postings = null;\n\n      // Only used if crossCheckTermVectors is true:\n      DocsEnum postingsDocs = null;\n      DocsAndPositionsEnum postingsPostings = null;\n\n      final Bits liveDocs = reader.getLiveDocs();\n\n      final Fields postingsFields;\n      // TODO: testTermsIndex\n      if (crossCheckTermVectors) {\n        postingsFields = reader.fields();\n      } else {\n        postingsFields = null;\n      }\n\n      TermsEnum termsEnum = null;\n      TermsEnum postingsTermsEnum = null;\n\n      for (int j = 0; j < info.docCount; ++j) {\n        // Intentionally pull/visit (but don't count in\n        // stats) deleted documents to make sure they too\n        // are not corrupt:\n        Fields tfv = reader.getTermVectors(j);\n\n        // TODO: can we make a IS(FIR) that searches just\n        // this term vector... to pass for searcher?\n\n        if (tfv != null) {\n          // First run with no deletions:\n          checkFields(tfv, null, 1, fieldInfos, null);\n\n          // Again, with the one doc deleted:\n          checkFields(tfv, onlyDocIsDeleted, 1, fieldInfos, null);\n\n          // Only agg stats if the doc is live:\n          final boolean doStats = liveDocs == null || liveDocs.get(j);\n          if (doStats) {\n            status.docCount++;\n          }\n\n          FieldsEnum fieldsEnum = tfv.iterator();\n          String field = null;\n          while((field = fieldsEnum.next()) != null) {\n            if (doStats) {\n              status.totVectors++;\n            }\n\n            // Make sure FieldInfo thinks this field is vector'd:\n            final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n            if (!fieldInfo.storeTermVector) {\n              throw new RuntimeException(\"docID=\" + j + \" has term vectors for field=\" + field + \" but FieldInfo has storeTermVector=false\");\n            }\n\n            if (crossCheckTermVectors) {\n              Terms terms = tfv.terms(field);\n              termsEnum = terms.iterator(termsEnum);\n\n              Terms postingsTerms = postingsFields.terms(field);\n              if (postingsTerms == null) {\n                throw new RuntimeException(\"vector field=\" + field + \" does not exist in postings; doc=\" + j);\n              }\n              postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);\n              \n              BytesRef term = null;\n              while ((term = termsEnum.next()) != null) {\n                \n                final boolean hasPositions;\n                final boolean hasOffsets;\n                final boolean hasFreqs;\n\n                // TODO: really we need a reflection/query\n                // API so we can just ask what was indexed\n                // instead of \"probing\"...\n\n                // Try offsets:\n                postings = termsEnum.docsAndPositions(null, postings, true);\n                if (postings == null) {\n                  hasOffsets = false;\n                  // Try only positions:\n                  postings = termsEnum.docsAndPositions(null, postings, false);\n                  if (postings == null) {\n                    hasPositions = false;\n                    // Try docIDs & freqs:\n                    docs = termsEnum.docs(null, docs, true);\n                    if (docs == null) {\n                      // OK, only docIDs:\n                      hasFreqs = false;\n                      docs = termsEnum.docs(null, docs, false);\n                    } else {\n                      hasFreqs = true;\n                    }\n                  } else {\n                    hasPositions = true;\n                    hasFreqs = true;\n                  }\n                } else {\n                  hasOffsets = true;\n                  // NOTE: may be a lie... but we accept -1\n                  hasPositions = true;\n                  hasFreqs = true;\n                }\n\n                final DocsEnum docs2;\n                if (hasPositions || hasOffsets) {\n                  assert postings != null;\n                  docs2 = postings;\n                } else {\n                  assert docs != null;\n                  docs2 = docs;\n                }\n\n                final DocsEnum postingsDocs2;\n                final boolean postingsHasFreq;\n                if (!postingsTermsEnum.seekExact(term, true)) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                }\n                postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);\n                if (postingsPostings == null) {\n                  // Term vectors were indexed w/ offsets but postings were not\n                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);\n                  if (postingsPostings == null) {\n                    postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);\n                    if (postingsDocs == null) {\n                      postingsHasFreq = false;\n                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);\n                      if (postingsDocs == null) {\n                        throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" does not exist in postings; doc=\" + j);\n                      }\n                    } else {\n                      postingsHasFreq = true;\n                    }\n                  } else {\n                    postingsHasFreq = true;\n                  }\n                } else {\n                  postingsHasFreq = true;\n                }\n\n                if (postingsPostings != null) {\n                  postingsDocs2 = postingsPostings;\n                } else {\n                  postingsDocs2 = postingsDocs;\n                }\n                  \n                final int advanceDoc = postingsDocs2.advance(j);\n                if (advanceDoc != j) {\n                  throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \": doc=\" + j + \" was not found in postings (got: \" + advanceDoc + \")\");\n                }\n\n                final int doc = docs2.nextDoc();\n                  \n                if (doc != 0) {\n                  throw new RuntimeException(\"vector for doc \" + j + \" didn't return docID=0: got docID=\" + doc);\n                }\n\n                if (hasFreqs) {\n                  final int tf = docs2.freq();\n                  if (postingsHasFreq && postingsDocs2.freq() != tf) {\n                    throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": freq=\" + tf + \" differs from postings freq=\" + postingsDocs2.freq());\n                  }\n                \n                  if (hasPositions || hasOffsets) {\n                    for (int i = 0; i < tf; i++) {\n                      int pos = postings.nextPosition();\n                      if (postingsPostings != null) {\n                        int postingsPos = postingsPostings.nextPosition();\n                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {\n                          throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": pos=\" + pos + \" differs from postings pos=\" + postingsPos);\n                        }\n                      }\n\n                      if (hasOffsets) {\n                        // Call the methods to at least make\n                        // sure they don't throw exc:\n                        final int startOffset = postings.startOffset();\n                        final int endOffset = postings.endOffset();\n                        // TODO: these are too anal...?\n                        /*\n                          if (endOffset < startOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is > endOffset=\" + endOffset);\n                          }\n                          if (startOffset < lastStartOffset) {\n                          throw new RuntimeException(\"vector startOffset=\" + startOffset + \" is < prior startOffset=\" + lastStartOffset);\n                          }\n                          lastStartOffset = startOffset;\n                        */\n\n                        if (postingsPostings != null) {\n                          final int postingsStartOffset = postingsPostings.startOffset();\n\n                          final int postingsEndOffset = postingsPostings.endOffset();\n                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": startOffset=\" + startOffset + \" differs from postings startOffset=\" + postingsStartOffset);\n                          }\n                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {\n                            throw new RuntimeException(\"vector term=\" + term + \" field=\" + field + \" doc=\" + j + \": endOffset=\" + endOffset + \" differs from postings endOffset=\" + postingsEndOffset);\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n      msg(\"OK [\" + status.totVectors + \" total vector count; avg \" + \n          format.format((((float) status.totVectors) / status.docCount)) + \" term/freq vector fields per doc]\");\n    } catch (Throwable e) {\n      msg(\"ERROR [\" + String.valueOf(e.getMessage()) + \"]\");\n      status.error = e;\n      if (infoStream != null) {\n        e.printStackTrace(infoStream);\n      }\n    }\n    \n    return status;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"4a8b14bc4241c302311422d5c6f7627f8febb86e":["76923f6a33f2c4bec7f584e3f251261afe7ea276"],"76923f6a33f2c4bec7f584e3f251261afe7ea276":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"814339e4b1ce2063ccbc6cacc6443a6446c7718b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","9d153abcf92dc5329d98571a8c3035df9bd80648"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9d153abcf92dc5329d98571a8c3035df9bd80648":["4a8b14bc4241c302311422d5c6f7627f8febb86e"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["814339e4b1ce2063ccbc6cacc6443a6446c7718b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"]},"commit2Childs":{"4a8b14bc4241c302311422d5c6f7627f8febb86e":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"76923f6a33f2c4bec7f584e3f251261afe7ea276":["4a8b14bc4241c302311422d5c6f7627f8febb86e"],"814339e4b1ce2063ccbc6cacc6443a6446c7718b":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["814339e4b1ce2063ccbc6cacc6443a6446c7718b"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["76923f6a33f2c4bec7f584e3f251261afe7ea276","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}