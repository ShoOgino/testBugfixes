{"path":"solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","commits":[{"id":"b54504c5305a6cc48f59c627c9c8dd727e2a8f0b","date":1491468518,"type":0,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void moveReplicaTest() throws Exception {\n    cluster.waitForAllNodes(5000);\n    String coll = \"movereplicatest_coll\";\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, \"conf\", 2, 2);\n    create.setMaxShardsPerNode(2);\n    cloudClient.request(create);\n\n    for (int i = 0; i < 10; i++) {\n      cloudClient.add(coll, sdoc(\"id\",String.valueOf(i)));\n      cloudClient.commit(coll);\n    }\n\n    List<Slice> slices = new ArrayList<>(cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlices());\n    Collections.shuffle(slices, random());\n    Slice slice = null;\n    Replica replica = null;\n    for (Slice s : slices) {\n      slice = s;\n      for (Replica r : s.getReplicas()) {\n        if (s.getLeader() != r) {\n          replica = r;\n        }\n      }\n    }\n    String dataDir = getDataDir(replica);\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    ArrayList<String> l = new ArrayList<>(liveNodes);\n    Collections.shuffle(l, random());\n    String targetNode = null;\n    for (String node : liveNodes) {\n      if (!replica.getNodeName().equals(node)) {\n        targetNode = node;\n        break;\n      }\n    }\n    assertNotNull(targetNode);\n\n    CollectionAdminRequest.MoveReplica moveReplica = new CollectionAdminRequest.MoveReplica(coll, replica.getName(), targetNode);\n    moveReplica.process(cloudClient);\n\n    checkNumOfCores(cloudClient, replica.getNodeName(), 0);\n    checkNumOfCores(cloudClient, targetNode, 2);\n\n    waitForState(\"Wait for recovery finish failed\",coll, clusterShape(2,2));\n    slice = cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlice(slice.getName());\n    boolean found = false;\n    for (Replica newReplica : slice.getReplicas()) {\n      if (getDataDir(newReplica).equals(dataDir)) {\n        found = true;\n      }\n    }\n    assertTrue(found);\n\n\n    // data dir is reused so replication will be skipped\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrMetricManager manager = jetty.getCoreContainer().getMetricManager();\n      List<String> registryNames = manager.registryNames().stream()\n          .filter(s -> s.startsWith(\"solr.core.\")).collect(Collectors.toList());\n      for (String registry : registryNames) {\n        Map<String, Metric> metrics = manager.registry(registry).getMetrics();\n        Counter counter = (Counter) metrics.get(\"REPLICATION./replication.requests\");\n        if (counter != null) {\n          assertEquals(0, counter.getCount());\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54ca69905c5d9d1529286f06ab1d12c68f6c13cb","date":1492683554,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void moveReplicaTest() throws Exception {\n    cluster.waitForAllNodes(5000);\n    String coll = \"movereplicatest_coll\";\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, \"conf\", 2, 2);\n    create.setMaxShardsPerNode(2);\n    cloudClient.request(create);\n\n    for (int i = 0; i < 10; i++) {\n      cloudClient.add(coll, sdoc(\"id\",String.valueOf(i)));\n      cloudClient.commit(coll);\n    }\n\n    List<Slice> slices = new ArrayList<>(cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlices());\n    Collections.shuffle(slices, random());\n    Slice slice = null;\n    Replica replica = null;\n    for (Slice s : slices) {\n      slice = s;\n      for (Replica r : s.getReplicas()) {\n        if (s.getLeader() != r) {\n          replica = r;\n        }\n      }\n    }\n    String dataDir = getDataDir(replica);\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    ArrayList<String> l = new ArrayList<>(liveNodes);\n    Collections.shuffle(l, random());\n    String targetNode = null;\n    for (String node : liveNodes) {\n      if (!replica.getNodeName().equals(node)) {\n        targetNode = node;\n        break;\n      }\n    }\n    assertNotNull(targetNode);\n\n    CollectionAdminRequest.MoveReplica moveReplica = new CollectionAdminRequest.MoveReplica(coll, replica.getName(), targetNode);\n    moveReplica.process(cloudClient);\n\n    checkNumOfCores(cloudClient, replica.getNodeName(), 0);\n    checkNumOfCores(cloudClient, targetNode, 2);\n\n    waitForState(\"Wait for recovery finish failed\",coll, clusterShape(2,2));\n    slice = cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlice(slice.getName());\n    boolean found = false;\n    for (Replica newReplica : slice.getReplicas()) {\n      if (getDataDir(newReplica).equals(dataDir)) {\n        found = true;\n      }\n    }\n    assertTrue(found);\n\n\n    // data dir is reused so replication will be skipped\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrMetricManager manager = jetty.getCoreContainer().getMetricManager();\n      List<String> registryNames = manager.registryNames().stream()\n          .filter(s -> s.startsWith(\"solr.core.\")).collect(Collectors.toList());\n      for (String registry : registryNames) {\n        Map<String, Metric> metrics = manager.registry(registry).getMetrics();\n        Counter counter = (Counter) metrics.get(\"REPLICATION./replication.requests\");\n        if (counter != null) {\n          assertEquals(0, counter.getCount());\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6146c07c0dee1ae1e42926167acd127fed5ef59d","date":1516129420,"type":5,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","sourceNew":"  @Test\n  public void moveReplicaTest() throws Exception {\n    cluster.waitForAllNodes(5000);\n    String coll = \"movereplicatest_coll\";\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, \"conf\", 2, 2);\n    create.setMaxShardsPerNode(2);\n    cloudClient.request(create);\n\n    for (int i = 0; i < 10; i++) {\n      cloudClient.add(coll, sdoc(\"id\",String.valueOf(i)));\n      cloudClient.commit(coll);\n    }\n\n    List<Slice> slices = new ArrayList<>(cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlices());\n    Collections.shuffle(slices, random());\n    Slice slice = null;\n    Replica replica = null;\n    for (Slice s : slices) {\n      slice = s;\n      for (Replica r : s.getReplicas()) {\n        if (s.getLeader() != r) {\n          replica = r;\n        }\n      }\n    }\n    String dataDir = getDataDir(replica);\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    ArrayList<String> l = new ArrayList<>(liveNodes);\n    Collections.shuffle(l, random());\n    String targetNode = null;\n    for (String node : liveNodes) {\n      if (!replica.getNodeName().equals(node)) {\n        targetNode = node;\n        break;\n      }\n    }\n    assertNotNull(targetNode);\n\n    CollectionAdminRequest.MoveReplica moveReplica = new CollectionAdminRequest.MoveReplica(coll, replica.getName(), targetNode);\n    moveReplica.process(cloudClient);\n\n    checkNumOfCores(cloudClient, replica.getNodeName(), 0);\n    checkNumOfCores(cloudClient, targetNode, 2);\n\n    waitForState(\"Wait for recovery finish failed\",coll, clusterShape(2,2));\n    slice = cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlice(slice.getName());\n    boolean found = false;\n    for (Replica newReplica : slice.getReplicas()) {\n      if (getDataDir(newReplica).equals(dataDir)) {\n        found = true;\n      }\n    }\n    assertTrue(found);\n\n\n    // data dir is reused so replication will be skipped\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrMetricManager manager = jetty.getCoreContainer().getMetricManager();\n      List<String> registryNames = manager.registryNames().stream()\n          .filter(s -> s.startsWith(\"solr.core.\")).collect(Collectors.toList());\n      for (String registry : registryNames) {\n        Map<String, Metric> metrics = manager.registry(registry).getMetrics();\n        Counter counter = (Counter) metrics.get(\"REPLICATION./replication.requests\");\n        if (counter != null) {\n          assertEquals(0, counter.getCount());\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void moveReplicaTest() throws Exception {\n    cluster.waitForAllNodes(5000);\n    String coll = \"movereplicatest_coll\";\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, \"conf\", 2, 2);\n    create.setMaxShardsPerNode(2);\n    cloudClient.request(create);\n\n    for (int i = 0; i < 10; i++) {\n      cloudClient.add(coll, sdoc(\"id\",String.valueOf(i)));\n      cloudClient.commit(coll);\n    }\n\n    List<Slice> slices = new ArrayList<>(cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlices());\n    Collections.shuffle(slices, random());\n    Slice slice = null;\n    Replica replica = null;\n    for (Slice s : slices) {\n      slice = s;\n      for (Replica r : s.getReplicas()) {\n        if (s.getLeader() != r) {\n          replica = r;\n        }\n      }\n    }\n    String dataDir = getDataDir(replica);\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    ArrayList<String> l = new ArrayList<>(liveNodes);\n    Collections.shuffle(l, random());\n    String targetNode = null;\n    for (String node : liveNodes) {\n      if (!replica.getNodeName().equals(node)) {\n        targetNode = node;\n        break;\n      }\n    }\n    assertNotNull(targetNode);\n\n    CollectionAdminRequest.MoveReplica moveReplica = new CollectionAdminRequest.MoveReplica(coll, replica.getName(), targetNode);\n    moveReplica.process(cloudClient);\n\n    checkNumOfCores(cloudClient, replica.getNodeName(), 0);\n    checkNumOfCores(cloudClient, targetNode, 2);\n\n    waitForState(\"Wait for recovery finish failed\",coll, clusterShape(2,2));\n    slice = cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlice(slice.getName());\n    boolean found = false;\n    for (Replica newReplica : slice.getReplicas()) {\n      if (getDataDir(newReplica).equals(dataDir)) {\n        found = true;\n      }\n    }\n    assertTrue(found);\n\n\n    // data dir is reused so replication will be skipped\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrMetricManager manager = jetty.getCoreContainer().getMetricManager();\n      List<String> registryNames = manager.registryNames().stream()\n          .filter(s -> s.startsWith(\"solr.core.\")).collect(Collectors.toList());\n      for (String registry : registryNames) {\n        Map<String, Metric> metrics = manager.registry(registry).getMetrics();\n        Counter counter = (Counter) metrics.get(\"REPLICATION./replication.requests\");\n        if (counter != null) {\n          assertEquals(0, counter.getCount());\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsCollectionsAPIDistributedZkTest#moveReplicaTest().mjava","sourceNew":"  @Test\n  public void moveReplicaTest() throws Exception {\n    cluster.waitForAllNodes(5000);\n    String coll = \"movereplicatest_coll\";\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, \"conf\", 2, 2);\n    create.setMaxShardsPerNode(2);\n    cloudClient.request(create);\n\n    for (int i = 0; i < 10; i++) {\n      cloudClient.add(coll, sdoc(\"id\",String.valueOf(i)));\n      cloudClient.commit(coll);\n    }\n\n    List<Slice> slices = new ArrayList<>(cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlices());\n    Collections.shuffle(slices, random());\n    Slice slice = null;\n    Replica replica = null;\n    for (Slice s : slices) {\n      slice = s;\n      for (Replica r : s.getReplicas()) {\n        if (s.getLeader() != r) {\n          replica = r;\n        }\n      }\n    }\n    String dataDir = getDataDir(replica);\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    ArrayList<String> l = new ArrayList<>(liveNodes);\n    Collections.shuffle(l, random());\n    String targetNode = null;\n    for (String node : liveNodes) {\n      if (!replica.getNodeName().equals(node)) {\n        targetNode = node;\n        break;\n      }\n    }\n    assertNotNull(targetNode);\n\n    CollectionAdminRequest.MoveReplica moveReplica = new CollectionAdminRequest.MoveReplica(coll, replica.getName(), targetNode);\n    moveReplica.process(cloudClient);\n\n    checkNumOfCores(cloudClient, replica.getNodeName(), 0);\n    checkNumOfCores(cloudClient, targetNode, 2);\n\n    waitForState(\"Wait for recovery finish failed\",coll, clusterShape(2,2));\n    slice = cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlice(slice.getName());\n    boolean found = false;\n    for (Replica newReplica : slice.getReplicas()) {\n      if (getDataDir(newReplica).equals(dataDir)) {\n        found = true;\n      }\n    }\n    assertTrue(found);\n\n\n    // data dir is reused so replication will be skipped\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrMetricManager manager = jetty.getCoreContainer().getMetricManager();\n      List<String> registryNames = manager.registryNames().stream()\n          .filter(s -> s.startsWith(\"solr.core.\")).collect(Collectors.toList());\n      for (String registry : registryNames) {\n        Map<String, Metric> metrics = manager.registry(registry).getMetrics();\n        Counter counter = (Counter) metrics.get(\"REPLICATION./replication.requests\");\n        if (counter != null) {\n          assertEquals(0, counter.getCount());\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void moveReplicaTest() throws Exception {\n    cluster.waitForAllNodes(5000);\n    String coll = \"movereplicatest_coll\";\n\n    CloudSolrClient cloudClient = cluster.getSolrClient();\n\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, \"conf\", 2, 2);\n    create.setMaxShardsPerNode(2);\n    cloudClient.request(create);\n\n    for (int i = 0; i < 10; i++) {\n      cloudClient.add(coll, sdoc(\"id\",String.valueOf(i)));\n      cloudClient.commit(coll);\n    }\n\n    List<Slice> slices = new ArrayList<>(cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlices());\n    Collections.shuffle(slices, random());\n    Slice slice = null;\n    Replica replica = null;\n    for (Slice s : slices) {\n      slice = s;\n      for (Replica r : s.getReplicas()) {\n        if (s.getLeader() != r) {\n          replica = r;\n        }\n      }\n    }\n    String dataDir = getDataDir(replica);\n\n    Set<String> liveNodes = cloudClient.getZkStateReader().getClusterState().getLiveNodes();\n    ArrayList<String> l = new ArrayList<>(liveNodes);\n    Collections.shuffle(l, random());\n    String targetNode = null;\n    for (String node : liveNodes) {\n      if (!replica.getNodeName().equals(node)) {\n        targetNode = node;\n        break;\n      }\n    }\n    assertNotNull(targetNode);\n\n    CollectionAdminRequest.MoveReplica moveReplica = new CollectionAdminRequest.MoveReplica(coll, replica.getName(), targetNode);\n    moveReplica.process(cloudClient);\n\n    checkNumOfCores(cloudClient, replica.getNodeName(), 0);\n    checkNumOfCores(cloudClient, targetNode, 2);\n\n    waitForState(\"Wait for recovery finish failed\",coll, clusterShape(2,2));\n    slice = cloudClient.getZkStateReader().getClusterState().getCollection(coll).getSlice(slice.getName());\n    boolean found = false;\n    for (Replica newReplica : slice.getReplicas()) {\n      if (getDataDir(newReplica).equals(dataDir)) {\n        found = true;\n      }\n    }\n    assertTrue(found);\n\n\n    // data dir is reused so replication will be skipped\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrMetricManager manager = jetty.getCoreContainer().getMetricManager();\n      List<String> registryNames = manager.registryNames().stream()\n          .filter(s -> s.startsWith(\"solr.core.\")).collect(Collectors.toList());\n      for (String registry : registryNames) {\n        Map<String, Metric> metrics = manager.registry(registry).getMetrics();\n        Counter counter = (Counter) metrics.get(\"REPLICATION./replication.requests\");\n        if (counter != null) {\n          assertEquals(0, counter.getCount());\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b54504c5305a6cc48f59c627c9c8dd727e2a8f0b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b94236357aaa22b76c10629851fe4e376e0cea82":["b54504c5305a6cc48f59c627c9c8dd727e2a8f0b","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["b54504c5305a6cc48f59c627c9c8dd727e2a8f0b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b94236357aaa22b76c10629851fe4e376e0cea82"]},"commit2Childs":{"b54504c5305a6cc48f59c627c9c8dd727e2a8f0b":["b94236357aaa22b76c10629851fe4e376e0cea82","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":[],"b94236357aaa22b76c10629851fe4e376e0cea82":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b54504c5305a6cc48f59c627c9c8dd727e2a8f0b","54ca69905c5d9d1529286f06ab1d12c68f6c13cb"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["b94236357aaa22b76c10629851fe4e376e0cea82"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}