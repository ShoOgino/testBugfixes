{"path":"src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","commits":[{"id":"de1e2f4b8cadefed1ffe9f88204679d9e1914d7a","date":1032146359,"type":0,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","pathOld":"/dev/null","sourceNew":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new FileReader(\"src/test/org/apache/lucene/analysis/ru/test1251.txt\");\n\n        sample1251 = new FileReader(\"src/test/org/apache/lucene/analysis/ru/res1251.htm\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        for (;;)\n        {\n            Token token = in.next();\n\n            if (token == null)\n            {\n                break;\n            }\n\n            Token sampleToken = sample.next();\n            assertEquals(\n                \"1251\",\n                token.termText(),\n                sampleToken == null\n                ? null\n                : sampleToken.termText());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"52ef8144ad6d073733a9c0fdd22b133ddb9c346b","date":1064891355,"type":3,"author":"Erik Hatcher","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","pathOld":"src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","sourceNew":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(\"src/test/org/apache/lucene/analysis/ru/test1251.txt\"), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(\"src/test/org/apache/lucene/analysis/ru/res1251.htm\"), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        for (;;)\n        {\n            Token token = in.next();\n\n            if (token == null)\n            {\n                break;\n            }\n\n            Token sampleToken = sample.next();\n            assertEquals(\n                \"1251\",\n                token.termText(),\n                sampleToken == null\n                ? null\n                : sampleToken.termText());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","sourceOld":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new FileReader(\"src/test/org/apache/lucene/analysis/ru/test1251.txt\");\n\n        sample1251 = new FileReader(\"src/test/org/apache/lucene/analysis/ru/res1251.htm\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        for (;;)\n        {\n            Token token = in.next();\n\n            if (token == null)\n            {\n                break;\n            }\n\n            Token sampleToken = sample.next();\n            assertEquals(\n                \"1251\",\n                token.termText(),\n                sampleToken == null\n                ? null\n                : sampleToken.termText());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a2102aa7674682bb4defcbaba1d1dabf61230846","date":1066673277,"type":3,"author":"Erik Hatcher","isMerge":false,"pathNew":"src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","pathOld":"src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","sourceNew":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        for (;;)\n        {\n            Token token = in.next();\n\n            if (token == null)\n            {\n                break;\n            }\n\n            Token sampleToken = sample.next();\n            assertEquals(\n                \"1251\",\n                token.termText(),\n                sampleToken == null\n                ? null\n                : sampleToken.termText());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","sourceOld":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(\"src/test/org/apache/lucene/analysis/ru/test1251.txt\"), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(\"src/test/org/apache/lucene/analysis/ru/res1251.htm\"), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        for (;;)\n        {\n            Token token = in.next();\n\n            if (token == null)\n            {\n                break;\n            }\n\n            Token sampleToken = sample.next();\n            assertEquals(\n                \"1251\",\n                token.termText(),\n                sampleToken == null\n                ? null\n                : sampleToken.termText());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ba8b5470cf673e04acfd3b9de8ef167c7a00582","date":1092688356,"type":4,"author":"Daniel Naber","isMerge":false,"pathNew":"/dev/null","pathOld":"src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#test1251().mjava","sourceNew":null,"sourceOld":"    public void test1251() throws IOException\n    {\n        // 1251\n        inWords1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/test1251.txt\")), \"iso-8859-1\");\n\n        sample1251 = new InputStreamReader(new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/res1251.htm\")), \"iso-8859-1\");\n\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.CP1251);\n        TokenStream in = ra.tokenStream(\"\", inWords1251);\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sample1251,\n                RussianCharsets.CP1251);\n\n        for (;;)\n        {\n            Token token = in.next();\n\n            if (token == null)\n            {\n                break;\n            }\n\n            Token sampleToken = sample.next();\n            assertEquals(\n                \"1251\",\n                token.termText(),\n                sampleToken == null\n                ? null\n                : sampleToken.termText());\n\n        }\n\n        inWords1251.close();\n        sample1251.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"de1e2f4b8cadefed1ffe9f88204679d9e1914d7a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9ba8b5470cf673e04acfd3b9de8ef167c7a00582":["a2102aa7674682bb4defcbaba1d1dabf61230846"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a2102aa7674682bb4defcbaba1d1dabf61230846":["52ef8144ad6d073733a9c0fdd22b133ddb9c346b"],"52ef8144ad6d073733a9c0fdd22b133ddb9c346b":["de1e2f4b8cadefed1ffe9f88204679d9e1914d7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9ba8b5470cf673e04acfd3b9de8ef167c7a00582"]},"commit2Childs":{"de1e2f4b8cadefed1ffe9f88204679d9e1914d7a":["52ef8144ad6d073733a9c0fdd22b133ddb9c346b"],"9ba8b5470cf673e04acfd3b9de8ef167c7a00582":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["de1e2f4b8cadefed1ffe9f88204679d9e1914d7a"],"a2102aa7674682bb4defcbaba1d1dabf61230846":["9ba8b5470cf673e04acfd3b9de8ef167c7a00582"],"52ef8144ad6d073733a9c0fdd22b133ddb9c346b":["a2102aa7674682bb4defcbaba1d1dabf61230846"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}