{"path":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getLeafContext().mjava","commits":[{"id":"081b68cb9e8f4b5405b40bfb223fd7c587171aa1","date":1360072766,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getLeafContext().mjava","pathOld":"/dev/null","sourceNew":"  protected AtomicReaderContext getLeafContext() throws IOException {\n    if (reader == null) {\n      if(wrapToCaching && !(tokenStream instanceof CachingTokenFilter)) {\n        assert !cachedTokenStream;\n        tokenStream = new CachingTokenFilter(new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n        cachedTokenStream = true;\n      }\n      final MemoryIndex indexer = new MemoryIndex(true);\n      indexer.addField(DelegatingAtomicReader.FIELD_NAME, tokenStream);\n      tokenStream.reset();\n      final IndexSearcher searcher = indexer.createSearcher();\n      // MEM index has only atomic ctx\n      reader = new DelegatingAtomicReader(((AtomicReaderContext)searcher.getTopReaderContext()).reader());\n    }\n    return reader.getContext();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["76e8057ae19512a2185e111004c56dc858689ab0"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3e4d4ec39bf5396230748ca859ff05ab024b6fc5","date":1360112310,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getLeafContext().mjava","pathOld":"/dev/null","sourceNew":"  protected AtomicReaderContext getLeafContext() throws IOException {\n    if (reader == null) {\n      if(wrapToCaching && !(tokenStream instanceof CachingTokenFilter)) {\n        assert !cachedTokenStream;\n        tokenStream = new CachingTokenFilter(new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n        cachedTokenStream = true;\n      }\n      final MemoryIndex indexer = new MemoryIndex(true);\n      indexer.addField(DelegatingAtomicReader.FIELD_NAME, tokenStream);\n      tokenStream.reset();\n      final IndexSearcher searcher = indexer.createSearcher();\n      // MEM index has only atomic ctx\n      reader = new DelegatingAtomicReader(((AtomicReaderContext)searcher.getTopReaderContext()).reader());\n    }\n    return reader.getContext();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"76e8057ae19512a2185e111004c56dc858689ab0","date":1365504657,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getLeafContext().mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getLeafContext().mjava","sourceNew":"  protected AtomicReaderContext getLeafContext() throws IOException {\n    if (internalReader == null) {\n      if(wrapToCaching && !(tokenStream instanceof CachingTokenFilter)) {\n        assert !cachedTokenStream;\n        tokenStream = new CachingTokenFilter(new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n        cachedTokenStream = true;\n      }\n      final MemoryIndex indexer = new MemoryIndex(true);\n      indexer.addField(DelegatingAtomicReader.FIELD_NAME, tokenStream);\n      tokenStream.reset();\n      final IndexSearcher searcher = indexer.createSearcher();\n      // MEM index has only atomic ctx\n      internalReader = new DelegatingAtomicReader(((AtomicReaderContext)searcher.getTopReaderContext()).reader());\n    }\n    return internalReader.getContext();\n  }\n\n","sourceOld":"  protected AtomicReaderContext getLeafContext() throws IOException {\n    if (reader == null) {\n      if(wrapToCaching && !(tokenStream instanceof CachingTokenFilter)) {\n        assert !cachedTokenStream;\n        tokenStream = new CachingTokenFilter(new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n        cachedTokenStream = true;\n      }\n      final MemoryIndex indexer = new MemoryIndex(true);\n      indexer.addField(DelegatingAtomicReader.FIELD_NAME, tokenStream);\n      tokenStream.reset();\n      final IndexSearcher searcher = indexer.createSearcher();\n      // MEM index has only atomic ctx\n      reader = new DelegatingAtomicReader(((AtomicReaderContext)searcher.getTopReaderContext()).reader());\n    }\n    return reader.getContext();\n  }\n\n","bugFix":["081b68cb9e8f4b5405b40bfb223fd7c587171aa1"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getLeafContext().mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getLeafContext().mjava","sourceNew":"  protected LeafReaderContext getLeafContext() throws IOException {\n    if (internalReader == null) {\n      if(wrapToCaching && !(tokenStream instanceof CachingTokenFilter)) {\n        assert !cachedTokenStream;\n        tokenStream = new CachingTokenFilter(new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n        cachedTokenStream = true;\n      }\n      final MemoryIndex indexer = new MemoryIndex(true);\n      indexer.addField(DelegatingLeafReader.FIELD_NAME, tokenStream);\n      tokenStream.reset();\n      final IndexSearcher searcher = indexer.createSearcher();\n      // MEM index has only atomic ctx\n      internalReader = new DelegatingLeafReader(((LeafReaderContext)searcher.getTopReaderContext()).reader());\n    }\n    return internalReader.getContext();\n  }\n\n","sourceOld":"  protected AtomicReaderContext getLeafContext() throws IOException {\n    if (internalReader == null) {\n      if(wrapToCaching && !(tokenStream instanceof CachingTokenFilter)) {\n        assert !cachedTokenStream;\n        tokenStream = new CachingTokenFilter(new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n        cachedTokenStream = true;\n      }\n      final MemoryIndex indexer = new MemoryIndex(true);\n      indexer.addField(DelegatingAtomicReader.FIELD_NAME, tokenStream);\n      tokenStream.reset();\n      final IndexSearcher searcher = indexer.createSearcher();\n      // MEM index has only atomic ctx\n      internalReader = new DelegatingAtomicReader(((AtomicReaderContext)searcher.getTopReaderContext()).reader());\n    }\n    return internalReader.getContext();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aeebe27bce18b879b80f68494c52cda1021b5705","date":1417792137,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getLeafContext().mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getLeafContext().mjava","sourceNew":"  protected LeafReaderContext getLeafContext() throws IOException {\n    if (internalReader == null) {\n      boolean cacheIt = wrapToCaching && !(tokenStream instanceof CachingTokenFilter);\n\n      // If it's from term vectors, simply wrap the underlying Terms in a reader\n      if (tokenStream instanceof TokenStreamFromTermVector) {\n        cacheIt = false;\n        Terms termVectorTerms = ((TokenStreamFromTermVector) tokenStream).getTermVectorTerms();\n        if (termVectorTerms.hasPositions() && termVectorTerms.hasOffsets()) {\n          internalReader = new TermVectorLeafReader(DelegatingLeafReader.FIELD_NAME, termVectorTerms);\n        }\n      }\n\n      // Use MemoryIndex (index/invert this tokenStream now)\n      if (internalReader == null) {\n        final MemoryIndex indexer = new MemoryIndex(true);\n        if (cacheIt) {\n          assert !cachedTokenStream;\n          tokenStream = new CachingTokenFilter(new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n          cachedTokenStream = true;\n          indexer.addField(DelegatingLeafReader.FIELD_NAME, tokenStream);\n        } else {\n          indexer.addField(DelegatingLeafReader.FIELD_NAME,\n              new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n        }\n        tokenStream.reset();//reset to beginning when we return\n        final IndexSearcher searcher = indexer.createSearcher();\n        // MEM index has only atomic ctx\n        internalReader = ((LeafReaderContext) searcher.getTopReaderContext()).reader();\n      }\n\n      //Now wrap it so we always use a common field.\n      this.internalReader = new DelegatingLeafReader(internalReader);\n    }\n\n    return internalReader.getContext();\n  }\n\n","sourceOld":"  protected LeafReaderContext getLeafContext() throws IOException {\n    if (internalReader == null) {\n      if(wrapToCaching && !(tokenStream instanceof CachingTokenFilter)) {\n        assert !cachedTokenStream;\n        tokenStream = new CachingTokenFilter(new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n        cachedTokenStream = true;\n      }\n      final MemoryIndex indexer = new MemoryIndex(true);\n      indexer.addField(DelegatingLeafReader.FIELD_NAME, tokenStream);\n      tokenStream.reset();\n      final IndexSearcher searcher = indexer.createSearcher();\n      // MEM index has only atomic ctx\n      internalReader = new DelegatingLeafReader(((LeafReaderContext)searcher.getTopReaderContext()).reader());\n    }\n    return internalReader.getContext();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55244759f906151d96839f8451dee793acb06e75","date":1418999882,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getLeafContext().mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getLeafContext().mjava","sourceNew":"  protected LeafReaderContext getLeafContext() throws IOException {\n    if (internalReader == null) {\n      boolean cacheIt = wrapToCaching && !(tokenStream instanceof CachingTokenFilter);\n\n      // If it's from term vectors, simply wrap the underlying Terms in a reader\n      if (tokenStream instanceof TokenStreamFromTermVector) {\n        cacheIt = false;\n        Terms termVectorTerms = ((TokenStreamFromTermVector) tokenStream).getTermVectorTerms();\n        if (termVectorTerms.hasPositions() && termVectorTerms.hasOffsets()) {\n          internalReader = new TermVectorLeafReader(DelegatingLeafReader.FIELD_NAME, termVectorTerms);\n        }\n      }\n\n      // Use MemoryIndex (index/invert this tokenStream now)\n      if (internalReader == null) {\n        final MemoryIndex indexer = new MemoryIndex(true);\n        if (cacheIt) {\n          assert !cachedTokenStream;\n          tokenStream = new CachingTokenFilter(new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n          cachedTokenStream = true;\n          indexer.addField(DelegatingLeafReader.FIELD_NAME, tokenStream);\n        } else {\n          indexer.addField(DelegatingLeafReader.FIELD_NAME,\n              new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n        }\n        final IndexSearcher searcher = indexer.createSearcher();\n        // MEM index has only atomic ctx\n        internalReader = ((LeafReaderContext) searcher.getTopReaderContext()).reader();\n      }\n\n      //Now wrap it so we always use a common field.\n      this.internalReader = new DelegatingLeafReader(internalReader);\n    }\n\n    return internalReader.getContext();\n  }\n\n","sourceOld":"  protected LeafReaderContext getLeafContext() throws IOException {\n    if (internalReader == null) {\n      boolean cacheIt = wrapToCaching && !(tokenStream instanceof CachingTokenFilter);\n\n      // If it's from term vectors, simply wrap the underlying Terms in a reader\n      if (tokenStream instanceof TokenStreamFromTermVector) {\n        cacheIt = false;\n        Terms termVectorTerms = ((TokenStreamFromTermVector) tokenStream).getTermVectorTerms();\n        if (termVectorTerms.hasPositions() && termVectorTerms.hasOffsets()) {\n          internalReader = new TermVectorLeafReader(DelegatingLeafReader.FIELD_NAME, termVectorTerms);\n        }\n      }\n\n      // Use MemoryIndex (index/invert this tokenStream now)\n      if (internalReader == null) {\n        final MemoryIndex indexer = new MemoryIndex(true);\n        if (cacheIt) {\n          assert !cachedTokenStream;\n          tokenStream = new CachingTokenFilter(new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n          cachedTokenStream = true;\n          indexer.addField(DelegatingLeafReader.FIELD_NAME, tokenStream);\n        } else {\n          indexer.addField(DelegatingLeafReader.FIELD_NAME,\n              new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n        }\n        tokenStream.reset();//reset to beginning when we return\n        final IndexSearcher searcher = indexer.createSearcher();\n        // MEM index has only atomic ctx\n        internalReader = ((LeafReaderContext) searcher.getTopReaderContext()).reader();\n      }\n\n      //Now wrap it so we always use a common field.\n      this.internalReader = new DelegatingLeafReader(internalReader);\n    }\n\n    return internalReader.getContext();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e88ae259732b6a9caf4c8f3a2e5a19c7b54ddbcb","date":1420550360,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getLeafContext().mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#getLeafContext().mjava","sourceNew":"  protected LeafReaderContext getLeafContext() throws IOException {\n    if (internalReader == null) {\n      boolean cacheIt = wrapToCaching && !(tokenStream instanceof CachingTokenFilter);\n\n      // If it's from term vectors, simply wrap the underlying Terms in a reader\n      if (tokenStream instanceof TokenStreamFromTermVector) {\n        cacheIt = false;\n        Terms termVectorTerms = ((TokenStreamFromTermVector) tokenStream).getTermVectorTerms();\n        if (termVectorTerms.hasPositions() && termVectorTerms.hasOffsets()) {\n          internalReader = new TermVectorLeafReader(DelegatingLeafReader.FIELD_NAME, termVectorTerms);\n        }\n      }\n\n      // Use MemoryIndex (index/invert this tokenStream now)\n      if (internalReader == null) {\n        final MemoryIndex indexer = new MemoryIndex(true, usePayloads);//offsets and payloads\n        if (cacheIt) {\n          assert !cachedTokenStream;\n          tokenStream = new CachingTokenFilter(new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n          cachedTokenStream = true;\n          indexer.addField(DelegatingLeafReader.FIELD_NAME, tokenStream);\n        } else {\n          indexer.addField(DelegatingLeafReader.FIELD_NAME,\n              new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n        }\n        final IndexSearcher searcher = indexer.createSearcher();\n        // MEM index has only atomic ctx\n        internalReader = ((LeafReaderContext) searcher.getTopReaderContext()).reader();\n      }\n\n      //Now wrap it so we always use a common field.\n      this.internalReader = new DelegatingLeafReader(internalReader);\n    }\n\n    return internalReader.getContext();\n  }\n\n","sourceOld":"  protected LeafReaderContext getLeafContext() throws IOException {\n    if (internalReader == null) {\n      boolean cacheIt = wrapToCaching && !(tokenStream instanceof CachingTokenFilter);\n\n      // If it's from term vectors, simply wrap the underlying Terms in a reader\n      if (tokenStream instanceof TokenStreamFromTermVector) {\n        cacheIt = false;\n        Terms termVectorTerms = ((TokenStreamFromTermVector) tokenStream).getTermVectorTerms();\n        if (termVectorTerms.hasPositions() && termVectorTerms.hasOffsets()) {\n          internalReader = new TermVectorLeafReader(DelegatingLeafReader.FIELD_NAME, termVectorTerms);\n        }\n      }\n\n      // Use MemoryIndex (index/invert this tokenStream now)\n      if (internalReader == null) {\n        final MemoryIndex indexer = new MemoryIndex(true);\n        if (cacheIt) {\n          assert !cachedTokenStream;\n          tokenStream = new CachingTokenFilter(new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n          cachedTokenStream = true;\n          indexer.addField(DelegatingLeafReader.FIELD_NAME, tokenStream);\n        } else {\n          indexer.addField(DelegatingLeafReader.FIELD_NAME,\n              new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));\n        }\n        final IndexSearcher searcher = indexer.createSearcher();\n        // MEM index has only atomic ctx\n        internalReader = ((LeafReaderContext) searcher.getTopReaderContext()).reader();\n      }\n\n      //Now wrap it so we always use a common field.\n      this.internalReader = new DelegatingLeafReader(internalReader);\n    }\n\n    return internalReader.getContext();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"081b68cb9e8f4b5405b40bfb223fd7c587171aa1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3e4d4ec39bf5396230748ca859ff05ab024b6fc5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","081b68cb9e8f4b5405b40bfb223fd7c587171aa1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e88ae259732b6a9caf4c8f3a2e5a19c7b54ddbcb":["55244759f906151d96839f8451dee793acb06e75"],"55244759f906151d96839f8451dee793acb06e75":["aeebe27bce18b879b80f68494c52cda1021b5705"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["76e8057ae19512a2185e111004c56dc858689ab0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e88ae259732b6a9caf4c8f3a2e5a19c7b54ddbcb"],"aeebe27bce18b879b80f68494c52cda1021b5705":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"76e8057ae19512a2185e111004c56dc858689ab0":["081b68cb9e8f4b5405b40bfb223fd7c587171aa1"]},"commit2Childs":{"081b68cb9e8f4b5405b40bfb223fd7c587171aa1":["3e4d4ec39bf5396230748ca859ff05ab024b6fc5","76e8057ae19512a2185e111004c56dc858689ab0"],"3e4d4ec39bf5396230748ca859ff05ab024b6fc5":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["081b68cb9e8f4b5405b40bfb223fd7c587171aa1","3e4d4ec39bf5396230748ca859ff05ab024b6fc5"],"e88ae259732b6a9caf4c8f3a2e5a19c7b54ddbcb":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"55244759f906151d96839f8451dee793acb06e75":["e88ae259732b6a9caf4c8f3a2e5a19c7b54ddbcb"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["aeebe27bce18b879b80f68494c52cda1021b5705"],"aeebe27bce18b879b80f68494c52cda1021b5705":["55244759f906151d96839f8451dee793acb06e75"],"76e8057ae19512a2185e111004c56dc858689ab0":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3e4d4ec39bf5396230748ca859ff05ab024b6fc5","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}