{"path":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(TermPositionVector).mjava","commits":[{"id":"fafd002a407d38098f1f0edf4365f971102ae0ef","date":1262804916,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(TermPositionVector).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Constructor.\n   * \n   * @param termPositionVector TermPositionVector that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final TermPositionVector termPositionVector) {\n    termAttribute = addAttribute(TermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final String[] terms = termPositionVector.getTerms();\n    for (int i = 0; i < terms.length; i++) {\n      final TermVectorOffsetInfo[] offsets = termPositionVector.getOffsets(i);\n      final int[] termPositions = termPositionVector.getTermPositions(i);\n      for (int j = 0; j < termPositions.length; j++) {\n        Token token;\n        if (offsets != null) {\n          token = new Token(terms[i].toCharArray(), 0, terms[i].length(),\n              offsets[j].getStartOffset(), offsets[j].getEndOffset());\n        } else {\n          token = new Token();\n          token.setTermBuffer(terms[i]);\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(termPositions[j]);\n        this.positionedTokens.add(token);\n      }\n    }\n    final Comparator<Token> tokenComparator = new Comparator<Token>() {\n      public int compare(final Token o1, final Token o2) {\n        if (o1.getPositionIncrement() < o2.getPositionIncrement()) {\n          return -1;\n        }\n        if (o1.getPositionIncrement() > o2.getPositionIncrement()) {\n          return 1;\n        }\n        return 0;\n      }\n    };\n    Collections.sort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(TermPositionVector).mjava","pathOld":"contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenStreamFromTermPositionVector#TokenStreamFromTermPositionVector(TermPositionVector).mjava","sourceNew":"  /**\n   * Constructor.\n   * \n   * @param termPositionVector TermPositionVector that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final TermPositionVector termPositionVector) {\n    termAttribute = addAttribute(TermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final String[] terms = termPositionVector.getTerms();\n    for (int i = 0; i < terms.length; i++) {\n      final TermVectorOffsetInfo[] offsets = termPositionVector.getOffsets(i);\n      final int[] termPositions = termPositionVector.getTermPositions(i);\n      for (int j = 0; j < termPositions.length; j++) {\n        Token token;\n        if (offsets != null) {\n          token = new Token(terms[i].toCharArray(), 0, terms[i].length(),\n              offsets[j].getStartOffset(), offsets[j].getEndOffset());\n        } else {\n          token = new Token();\n          token.setTermBuffer(terms[i]);\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(termPositions[j]);\n        this.positionedTokens.add(token);\n      }\n    }\n    final Comparator<Token> tokenComparator = new Comparator<Token>() {\n      public int compare(final Token o1, final Token o2) {\n        if (o1.getPositionIncrement() < o2.getPositionIncrement()) {\n          return -1;\n        }\n        if (o1.getPositionIncrement() > o2.getPositionIncrement()) {\n          return 1;\n        }\n        return 0;\n      }\n    };\n    Collections.sort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","sourceOld":"  /**\n   * Constructor.\n   * \n   * @param termPositionVector TermPositionVector that contains the data for\n   *        creating the TokenStream. Must have positions and offsets.\n   */\n  public TokenStreamFromTermPositionVector(\n      final TermPositionVector termPositionVector) {\n    termAttribute = addAttribute(TermAttribute.class);\n    positionIncrementAttribute = addAttribute(PositionIncrementAttribute.class);\n    offsetAttribute = addAttribute(OffsetAttribute.class);\n    final String[] terms = termPositionVector.getTerms();\n    for (int i = 0; i < terms.length; i++) {\n      final TermVectorOffsetInfo[] offsets = termPositionVector.getOffsets(i);\n      final int[] termPositions = termPositionVector.getTermPositions(i);\n      for (int j = 0; j < termPositions.length; j++) {\n        Token token;\n        if (offsets != null) {\n          token = new Token(terms[i].toCharArray(), 0, terms[i].length(),\n              offsets[j].getStartOffset(), offsets[j].getEndOffset());\n        } else {\n          token = new Token();\n          token.setTermBuffer(terms[i]);\n        }\n        // Yes - this is the position, not the increment! This is for\n        // sorting. This value\n        // will be corrected before use.\n        token.setPositionIncrement(termPositions[j]);\n        this.positionedTokens.add(token);\n      }\n    }\n    final Comparator<Token> tokenComparator = new Comparator<Token>() {\n      public int compare(final Token o1, final Token o2) {\n        if (o1.getPositionIncrement() < o2.getPositionIncrement()) {\n          return -1;\n        }\n        if (o1.getPositionIncrement() > o2.getPositionIncrement()) {\n          return 1;\n        }\n        return 0;\n      }\n    };\n    Collections.sort(this.positionedTokens, tokenComparator);\n    int lastPosition = -1;\n    for (final Token token : this.positionedTokens) {\n      int thisPosition = token.getPositionIncrement();\n      token.setPositionIncrement(thisPosition - lastPosition);\n      lastPosition = thisPosition;\n    }\n    this.tokensAtCurrentPosition = this.positionedTokens.iterator();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fafd002a407d38098f1f0edf4365f971102ae0ef":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["fafd002a407d38098f1f0edf4365f971102ae0ef"]},"commit2Childs":{"fafd002a407d38098f1f0edf4365f971102ae0ef":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fafd002a407d38098f1f0edf4365f971102ae0ef"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}