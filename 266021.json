{"path":"lucene/src/java/org/apache/lucene/index/ParallelReader#add(AtomicIndexReader,boolean).mjava","commits":[{"id":"2725b2d479964ea5aaea0ba4ae2634716f3ec26c","date":1327188170,"type":1,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/ParallelReader#add(AtomicIndexReader,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/ParallelReader#add(IndexReader,boolean).mjava","sourceNew":" /** Add an AtomicIndexReader whose stored fields will not be returned.  This can\n  * accelerate search when stored fields are only needed from a subset of\n  * the IndexReaders.\n  *\n  * @throws IllegalArgumentException if not all indexes contain the same number\n  *     of documents\n  * @throws IllegalArgumentException if not all indexes have the same value\n  *     of {@link AtomicIndexReader#maxDoc()}\n  * @throws IOException if there is a low-level IO error\n  */\n  public void add(AtomicIndexReader reader, boolean ignoreStoredFields)\n    throws IOException {\n\n    ensureOpen();\n    if (readers.size() == 0) {\n      this.maxDoc = reader.maxDoc();\n      this.numDocs = reader.numDocs();\n      this.hasDeletions = reader.hasDeletions();\n    }\n\n    if (reader.maxDoc() != maxDoc)                // check compatibility\n      throw new IllegalArgumentException\n        (\"All readers must have same maxDoc: \"+maxDoc+\"!=\"+reader.maxDoc());\n    if (reader.numDocs() != numDocs)\n      throw new IllegalArgumentException\n        (\"All readers must have same numDocs: \"+numDocs+\"!=\"+reader.numDocs());\n\n    final FieldInfos readerFieldInfos = ReaderUtil.getMergedFieldInfos(reader);\n    for(FieldInfo fieldInfo : readerFieldInfos) {   // update fieldToReader map\n      // NOTE: first reader having a given field \"wins\":\n      if (fieldToReader.get(fieldInfo.name) == null) {\n        fieldInfos.add(fieldInfo);\n        fieldToReader.put(fieldInfo.name, reader);\n        this.fields.addField(fieldInfo.name, reader.terms(fieldInfo.name));\n      }\n    }\n\n    if (!ignoreStoredFields)\n      storedFieldReaders.add(reader);             // add to storedFieldReaders\n    readers.add(reader);\n    \n    if (incRefReaders) {\n      reader.incRef();\n    }\n    decrefOnClose.add(Boolean.valueOf(incRefReaders));\n    synchronized(normsCache) {\n      normsCache.clear(); // TODO: don't need to clear this for all fields really?\n    }\n  }\n\n","sourceOld":" /** Add an IndexReader whose stored fields will not be returned.  This can\n  * accelerate search when stored fields are only needed from a subset of\n  * the IndexReaders.\n  *\n  * @throws IllegalArgumentException if not all indexes contain the same number\n  *     of documents\n  * @throws IllegalArgumentException if not all indexes have the same value\n  *     of {@link IndexReader#maxDoc()}\n  * @throws IOException if there is a low-level IO error\n  */\n  public void add(IndexReader reader, boolean ignoreStoredFields)\n    throws IOException {\n\n    ensureOpen();\n    if (readers.size() == 0) {\n      this.maxDoc = reader.maxDoc();\n      this.numDocs = reader.numDocs();\n      this.hasDeletions = reader.hasDeletions();\n    }\n\n    if (reader.maxDoc() != maxDoc)                // check compatibility\n      throw new IllegalArgumentException\n        (\"All readers must have same maxDoc: \"+maxDoc+\"!=\"+reader.maxDoc());\n    if (reader.numDocs() != numDocs)\n      throw new IllegalArgumentException\n        (\"All readers must have same numDocs: \"+numDocs+\"!=\"+reader.numDocs());\n\n    final FieldInfos readerFieldInfos = ReaderUtil.getMergedFieldInfos(reader);\n    for(FieldInfo fieldInfo : readerFieldInfos) {   // update fieldToReader map\n      // NOTE: first reader having a given field \"wins\":\n      if (fieldToReader.get(fieldInfo.name) == null) {\n        fieldInfos.add(fieldInfo);\n        fieldToReader.put(fieldInfo.name, reader);\n        this.fields.addField(fieldInfo.name, MultiFields.getFields(reader).terms(fieldInfo.name));\n      }\n    }\n\n    if (!ignoreStoredFields)\n      storedFieldReaders.add(reader);             // add to storedFieldReaders\n    readers.add(reader);\n    \n    if (incRefReaders) {\n      reader.incRef();\n    }\n    decrefOnClose.add(Boolean.valueOf(incRefReaders));\n    synchronized(normsCache) {\n      normsCache.clear(); // TODO: don't need to clear this for all fields really?\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85dda37116c8d94fccd74dfe59f4d7fe4503e74c","date":1327234819,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/ParallelReader#add(AtomicIndexReader,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/ParallelReader#add(AtomicIndexReader,boolean).mjava","sourceNew":" /** Add an AtomicIndexReader whose stored fields will not be returned.  This can\n  * accelerate search when stored fields are only needed from a subset of\n  * the IndexReaders.\n  *\n  * @throws IllegalArgumentException if not all indexes contain the same number\n  *     of documents\n  * @throws IllegalArgumentException if not all indexes have the same value\n  *     of {@link AtomicIndexReader#maxDoc()}\n  * @throws IOException if there is a low-level IO error\n  */\n  public void add(AtomicIndexReader reader, boolean ignoreStoredFields)\n    throws IOException {\n\n    ensureOpen();\n    if (readers.size() == 0) {\n      this.maxDoc = reader.maxDoc();\n      this.numDocs = reader.numDocs();\n      this.hasDeletions = reader.hasDeletions();\n    }\n\n    if (reader.maxDoc() != maxDoc)                // check compatibility\n      throw new IllegalArgumentException\n        (\"All readers must have same maxDoc: \"+maxDoc+\"!=\"+reader.maxDoc());\n    if (reader.numDocs() != numDocs)\n      throw new IllegalArgumentException\n        (\"All readers must have same numDocs: \"+numDocs+\"!=\"+reader.numDocs());\n\n    final FieldInfos readerFieldInfos = MultiFields.getMergedFieldInfos(reader);\n    for(FieldInfo fieldInfo : readerFieldInfos) {   // update fieldToReader map\n      // NOTE: first reader having a given field \"wins\":\n      if (fieldToReader.get(fieldInfo.name) == null) {\n        fieldInfos.add(fieldInfo);\n        fieldToReader.put(fieldInfo.name, reader);\n        this.fields.addField(fieldInfo.name, reader.terms(fieldInfo.name));\n      }\n    }\n\n    if (!ignoreStoredFields)\n      storedFieldReaders.add(reader);             // add to storedFieldReaders\n    readers.add(reader);\n    \n    if (incRefReaders) {\n      reader.incRef();\n    }\n    decrefOnClose.add(Boolean.valueOf(incRefReaders));\n    synchronized(normsCache) {\n      normsCache.clear(); // TODO: don't need to clear this for all fields really?\n    }\n  }\n\n","sourceOld":" /** Add an AtomicIndexReader whose stored fields will not be returned.  This can\n  * accelerate search when stored fields are only needed from a subset of\n  * the IndexReaders.\n  *\n  * @throws IllegalArgumentException if not all indexes contain the same number\n  *     of documents\n  * @throws IllegalArgumentException if not all indexes have the same value\n  *     of {@link AtomicIndexReader#maxDoc()}\n  * @throws IOException if there is a low-level IO error\n  */\n  public void add(AtomicIndexReader reader, boolean ignoreStoredFields)\n    throws IOException {\n\n    ensureOpen();\n    if (readers.size() == 0) {\n      this.maxDoc = reader.maxDoc();\n      this.numDocs = reader.numDocs();\n      this.hasDeletions = reader.hasDeletions();\n    }\n\n    if (reader.maxDoc() != maxDoc)                // check compatibility\n      throw new IllegalArgumentException\n        (\"All readers must have same maxDoc: \"+maxDoc+\"!=\"+reader.maxDoc());\n    if (reader.numDocs() != numDocs)\n      throw new IllegalArgumentException\n        (\"All readers must have same numDocs: \"+numDocs+\"!=\"+reader.numDocs());\n\n    final FieldInfos readerFieldInfos = ReaderUtil.getMergedFieldInfos(reader);\n    for(FieldInfo fieldInfo : readerFieldInfos) {   // update fieldToReader map\n      // NOTE: first reader having a given field \"wins\":\n      if (fieldToReader.get(fieldInfo.name) == null) {\n        fieldInfos.add(fieldInfo);\n        fieldToReader.put(fieldInfo.name, reader);\n        this.fields.addField(fieldInfo.name, reader.terms(fieldInfo.name));\n      }\n    }\n\n    if (!ignoreStoredFields)\n      storedFieldReaders.add(reader);             // add to storedFieldReaders\n    readers.add(reader);\n    \n    if (incRefReaders) {\n      reader.incRef();\n    }\n    decrefOnClose.add(Boolean.valueOf(incRefReaders));\n    synchronized(normsCache) {\n      normsCache.clear(); // TODO: don't need to clear this for all fields really?\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"da6d5ac19a80d65b1e864251f155d30960353b7e","date":1327881054,"type":5,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/ParallelReader#add(AtomicReader,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/ParallelReader#add(AtomicIndexReader,boolean).mjava","sourceNew":" /** Add an AtomicIndexReader whose stored fields will not be returned.  This can\n  * accelerate search when stored fields are only needed from a subset of\n  * the IndexReaders.\n  *\n  * @throws IllegalArgumentException if not all indexes contain the same number\n  *     of documents\n  * @throws IllegalArgumentException if not all indexes have the same value\n  *     of {@link AtomicReader#maxDoc()}\n  * @throws IOException if there is a low-level IO error\n  */\n  public void add(AtomicReader reader, boolean ignoreStoredFields)\n    throws IOException {\n\n    ensureOpen();\n    if (readers.size() == 0) {\n      this.maxDoc = reader.maxDoc();\n      this.numDocs = reader.numDocs();\n      this.hasDeletions = reader.hasDeletions();\n    }\n\n    if (reader.maxDoc() != maxDoc)                // check compatibility\n      throw new IllegalArgumentException\n        (\"All readers must have same maxDoc: \"+maxDoc+\"!=\"+reader.maxDoc());\n    if (reader.numDocs() != numDocs)\n      throw new IllegalArgumentException\n        (\"All readers must have same numDocs: \"+numDocs+\"!=\"+reader.numDocs());\n\n    final FieldInfos readerFieldInfos = MultiFields.getMergedFieldInfos(reader);\n    for(FieldInfo fieldInfo : readerFieldInfos) {   // update fieldToReader map\n      // NOTE: first reader having a given field \"wins\":\n      if (fieldToReader.get(fieldInfo.name) == null) {\n        fieldInfos.add(fieldInfo);\n        fieldToReader.put(fieldInfo.name, reader);\n        this.fields.addField(fieldInfo.name, reader.terms(fieldInfo.name));\n      }\n    }\n\n    if (!ignoreStoredFields)\n      storedFieldReaders.add(reader);             // add to storedFieldReaders\n    readers.add(reader);\n    \n    if (incRefReaders) {\n      reader.incRef();\n    }\n    decrefOnClose.add(Boolean.valueOf(incRefReaders));\n    synchronized(normsCache) {\n      normsCache.clear(); // TODO: don't need to clear this for all fields really?\n    }\n  }\n\n","sourceOld":" /** Add an AtomicIndexReader whose stored fields will not be returned.  This can\n  * accelerate search when stored fields are only needed from a subset of\n  * the IndexReaders.\n  *\n  * @throws IllegalArgumentException if not all indexes contain the same number\n  *     of documents\n  * @throws IllegalArgumentException if not all indexes have the same value\n  *     of {@link AtomicIndexReader#maxDoc()}\n  * @throws IOException if there is a low-level IO error\n  */\n  public void add(AtomicIndexReader reader, boolean ignoreStoredFields)\n    throws IOException {\n\n    ensureOpen();\n    if (readers.size() == 0) {\n      this.maxDoc = reader.maxDoc();\n      this.numDocs = reader.numDocs();\n      this.hasDeletions = reader.hasDeletions();\n    }\n\n    if (reader.maxDoc() != maxDoc)                // check compatibility\n      throw new IllegalArgumentException\n        (\"All readers must have same maxDoc: \"+maxDoc+\"!=\"+reader.maxDoc());\n    if (reader.numDocs() != numDocs)\n      throw new IllegalArgumentException\n        (\"All readers must have same numDocs: \"+numDocs+\"!=\"+reader.numDocs());\n\n    final FieldInfos readerFieldInfos = MultiFields.getMergedFieldInfos(reader);\n    for(FieldInfo fieldInfo : readerFieldInfos) {   // update fieldToReader map\n      // NOTE: first reader having a given field \"wins\":\n      if (fieldToReader.get(fieldInfo.name) == null) {\n        fieldInfos.add(fieldInfo);\n        fieldToReader.put(fieldInfo.name, reader);\n        this.fields.addField(fieldInfo.name, reader.terms(fieldInfo.name));\n      }\n    }\n\n    if (!ignoreStoredFields)\n      storedFieldReaders.add(reader);             // add to storedFieldReaders\n    readers.add(reader);\n    \n    if (incRefReaders) {\n      reader.incRef();\n    }\n    decrefOnClose.add(Boolean.valueOf(incRefReaders));\n    synchronized(normsCache) {\n      normsCache.clear(); // TODO: don't need to clear this for all fields really?\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"85dda37116c8d94fccd74dfe59f4d7fe4503e74c":["2725b2d479964ea5aaea0ba4ae2634716f3ec26c"],"da6d5ac19a80d65b1e864251f155d30960353b7e":["85dda37116c8d94fccd74dfe59f4d7fe4503e74c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2725b2d479964ea5aaea0ba4ae2634716f3ec26c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"85dda37116c8d94fccd74dfe59f4d7fe4503e74c":["da6d5ac19a80d65b1e864251f155d30960353b7e"],"da6d5ac19a80d65b1e864251f155d30960353b7e":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817","2725b2d479964ea5aaea0ba4ae2634716f3ec26c"],"2725b2d479964ea5aaea0ba4ae2634716f3ec26c":["85dda37116c8d94fccd74dfe59f4d7fe4503e74c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["da6d5ac19a80d65b1e864251f155d30960353b7e","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}