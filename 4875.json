{"path":"src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","commits":[{"id":"352bfe1fae83b92d1562f01c057bfbe6f5af3ddb","date":1185160645,"type":0,"author":"Grant Ingersoll","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","pathOld":"/dev/null","sourceNew":"  public void get(int docNum, String field, TermVectorMapper mapper) throws IOException {\n    if (tvx != null) {\n      int fieldNumber = fieldInfos.fieldNumber(field);\n      //We need to account for the FORMAT_SIZE at when seeking in the tvx\n      //We don't need to do this in other seeks because we already have the\n      // file pointer\n      //that was written in another file\n      tvx.seek(((docNum + docStoreOffset) * 8L) + TermVectorsWriter.FORMAT_SIZE);\n      //System.out.println(\"TVX Pointer: \" + tvx.getFilePointer());\n      long position = tvx.readLong();\n\n      tvd.seek(position);\n      int fieldCount = tvd.readVInt();\n      //System.out.println(\"Num Fields: \" + fieldCount);\n      // There are only a few fields per document. We opt for a full scan\n      // rather then requiring that they be ordered. We need to read through\n      // all of the fields anyway to get to the tvf pointers.\n      int number = 0;\n      int found = -1;\n      for (int i = 0; i < fieldCount; i++) {\n        if(tvdFormat == TermVectorsWriter.FORMAT_VERSION)\n          number = tvd.readVInt();\n        else\n          number += tvd.readVInt();\n\n        if (number == fieldNumber)\n          found = i;\n      }\n\n      // This field, although valid in the segment, was not found in this\n      // document\n      if (found != -1) {\n        // Compute position in the tvf file\n        position = 0;\n        for (int i = 0; i <= found; i++)\n          position += tvd.readVLong();\n\n        readTermVector(field, position, mapper);\n      } else {\n        //System.out.println(\"Fieldable not found\");\n      }\n    } else {\n      //System.out.println(\"No tvx file\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["11764865fb318bf86302eab36bdf9cd00c50c110"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"11764865fb318bf86302eab36bdf9cd00c50c110","date":1190109214,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","pathOld":"src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","sourceNew":"  public void get(int docNum, String field, TermVectorMapper mapper) throws IOException {\n    if (tvx != null) {\n      int fieldNumber = fieldInfos.fieldNumber(field);\n      //We need to account for the FORMAT_SIZE at when seeking in the tvx\n      //We don't need to do this in other seeks because we already have the\n      // file pointer\n      //that was written in another file\n      tvx.seek(((docNum + docStoreOffset) * 8L) + FORMAT_SIZE);\n      //System.out.println(\"TVX Pointer: \" + tvx.getFilePointer());\n      long position = tvx.readLong();\n\n      tvd.seek(position);\n      int fieldCount = tvd.readVInt();\n      //System.out.println(\"Num Fields: \" + fieldCount);\n      // There are only a few fields per document. We opt for a full scan\n      // rather then requiring that they be ordered. We need to read through\n      // all of the fields anyway to get to the tvf pointers.\n      int number = 0;\n      int found = -1;\n      for (int i = 0; i < fieldCount; i++) {\n        if(tvdFormat == FORMAT_VERSION)\n          number = tvd.readVInt();\n        else\n          number += tvd.readVInt();\n\n        if (number == fieldNumber)\n          found = i;\n      }\n\n      // This field, although valid in the segment, was not found in this\n      // document\n      if (found != -1) {\n        // Compute position in the tvf file\n        position = 0;\n        for (int i = 0; i <= found; i++)\n          position += tvd.readVLong();\n\n        readTermVector(field, position, mapper);\n      } else {\n        //System.out.println(\"Fieldable not found\");\n      }\n    } else {\n      //System.out.println(\"No tvx file\");\n    }\n  }\n\n","sourceOld":"  public void get(int docNum, String field, TermVectorMapper mapper) throws IOException {\n    if (tvx != null) {\n      int fieldNumber = fieldInfos.fieldNumber(field);\n      //We need to account for the FORMAT_SIZE at when seeking in the tvx\n      //We don't need to do this in other seeks because we already have the\n      // file pointer\n      //that was written in another file\n      tvx.seek(((docNum + docStoreOffset) * 8L) + TermVectorsWriter.FORMAT_SIZE);\n      //System.out.println(\"TVX Pointer: \" + tvx.getFilePointer());\n      long position = tvx.readLong();\n\n      tvd.seek(position);\n      int fieldCount = tvd.readVInt();\n      //System.out.println(\"Num Fields: \" + fieldCount);\n      // There are only a few fields per document. We opt for a full scan\n      // rather then requiring that they be ordered. We need to read through\n      // all of the fields anyway to get to the tvf pointers.\n      int number = 0;\n      int found = -1;\n      for (int i = 0; i < fieldCount; i++) {\n        if(tvdFormat == TermVectorsWriter.FORMAT_VERSION)\n          number = tvd.readVInt();\n        else\n          number += tvd.readVInt();\n\n        if (number == fieldNumber)\n          found = i;\n      }\n\n      // This field, although valid in the segment, was not found in this\n      // document\n      if (found != -1) {\n        // Compute position in the tvf file\n        position = 0;\n        for (int i = 0; i <= found; i++)\n          position += tvd.readVLong();\n\n        readTermVector(field, position, mapper);\n      } else {\n        //System.out.println(\"Fieldable not found\");\n      }\n    } else {\n      //System.out.println(\"No tvx file\");\n    }\n  }\n\n","bugFix":["352bfe1fae83b92d1562f01c057bfbe6f5af3ddb"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f39283f826b260042f4a0469516fd1882ae41578","date":1194097306,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","pathOld":"src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","sourceNew":"  public void get(int docNum, String field, TermVectorMapper mapper) throws IOException {\n    if (tvx != null) {\n      int fieldNumber = fieldInfos.fieldNumber(field);\n      //We need to account for the FORMAT_SIZE at when seeking in the tvx\n      //We don't need to do this in other seeks because we already have the\n      // file pointer\n      //that was written in another file\n      tvx.seek(((docNum + docStoreOffset) * 8L) + FORMAT_SIZE);\n      //System.out.println(\"TVX Pointer: \" + tvx.getFilePointer());\n      long position = tvx.readLong();\n\n      tvd.seek(position);\n      int fieldCount = tvd.readVInt();\n      //System.out.println(\"Num Fields: \" + fieldCount);\n      // There are only a few fields per document. We opt for a full scan\n      // rather then requiring that they be ordered. We need to read through\n      // all of the fields anyway to get to the tvf pointers.\n      int number = 0;\n      int found = -1;\n      for (int i = 0; i < fieldCount; i++) {\n        if(tvdFormat == FORMAT_VERSION)\n          number = tvd.readVInt();\n        else\n          number += tvd.readVInt();\n\n        if (number == fieldNumber)\n          found = i;\n      }\n\n      // This field, although valid in the segment, was not found in this\n      // document\n      if (found != -1) {\n        // Compute position in the tvf file\n        position = 0;\n        for (int i = 0; i <= found; i++)\n          position += tvd.readVLong();\n\n        mapper.setDocumentNumber(docNum);\n        readTermVector(field, position, mapper);\n      } else {\n        //System.out.println(\"Fieldable not found\");\n      }\n    } else {\n      //System.out.println(\"No tvx file\");\n    }\n  }\n\n","sourceOld":"  public void get(int docNum, String field, TermVectorMapper mapper) throws IOException {\n    if (tvx != null) {\n      int fieldNumber = fieldInfos.fieldNumber(field);\n      //We need to account for the FORMAT_SIZE at when seeking in the tvx\n      //We don't need to do this in other seeks because we already have the\n      // file pointer\n      //that was written in another file\n      tvx.seek(((docNum + docStoreOffset) * 8L) + FORMAT_SIZE);\n      //System.out.println(\"TVX Pointer: \" + tvx.getFilePointer());\n      long position = tvx.readLong();\n\n      tvd.seek(position);\n      int fieldCount = tvd.readVInt();\n      //System.out.println(\"Num Fields: \" + fieldCount);\n      // There are only a few fields per document. We opt for a full scan\n      // rather then requiring that they be ordered. We need to read through\n      // all of the fields anyway to get to the tvf pointers.\n      int number = 0;\n      int found = -1;\n      for (int i = 0; i < fieldCount; i++) {\n        if(tvdFormat == FORMAT_VERSION)\n          number = tvd.readVInt();\n        else\n          number += tvd.readVInt();\n\n        if (number == fieldNumber)\n          found = i;\n      }\n\n      // This field, although valid in the segment, was not found in this\n      // document\n      if (found != -1) {\n        // Compute position in the tvf file\n        position = 0;\n        for (int i = 0; i <= found; i++)\n          position += tvd.readVLong();\n\n        readTermVector(field, position, mapper);\n      } else {\n        //System.out.println(\"Fieldable not found\");\n      }\n    } else {\n      //System.out.println(\"No tvx file\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b3d08461c77d39c25ea6ff0cd05b32f948fa2a33","date":1201260752,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","pathOld":"src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","sourceNew":"  public void get(int docNum, String field, TermVectorMapper mapper) throws IOException {\n    if (tvx != null) {\n      int fieldNumber = fieldInfos.fieldNumber(field);\n      //We need to account for the FORMAT_SIZE at when seeking in the tvx\n      //We don't need to do this in other seeks because we already have the\n      // file pointer\n      //that was written in another file\n      seekTvx(docNum);\n      //System.out.println(\"TVX Pointer: \" + tvx.getFilePointer());\n      long tvdPosition = tvx.readLong();\n\n      tvd.seek(tvdPosition);\n      int fieldCount = tvd.readVInt();\n      //System.out.println(\"Num Fields: \" + fieldCount);\n      // There are only a few fields per document. We opt for a full scan\n      // rather then requiring that they be ordered. We need to read through\n      // all of the fields anyway to get to the tvf pointers.\n      int number = 0;\n      int found = -1;\n      for (int i = 0; i < fieldCount; i++) {\n        if (format >= FORMAT_VERSION)\n          number = tvd.readVInt();\n        else\n          number += tvd.readVInt();\n\n        if (number == fieldNumber)\n          found = i;\n      }\n\n      // This field, although valid in the segment, was not found in this\n      // document\n      if (found != -1) {\n        // Compute position in the tvf file\n        long position;\n        if (format >= FORMAT_VERSION2)\n          position = tvx.readLong();\n        else\n          position = tvd.readVLong();\n        for (int i = 1; i <= found; i++)\n          position += tvd.readVLong();\n\n        mapper.setDocumentNumber(docNum);\n        readTermVector(field, position, mapper);\n      } else {\n        //System.out.println(\"Fieldable not found\");\n      }\n    } else {\n      //System.out.println(\"No tvx file\");\n    }\n  }\n\n","sourceOld":"  public void get(int docNum, String field, TermVectorMapper mapper) throws IOException {\n    if (tvx != null) {\n      int fieldNumber = fieldInfos.fieldNumber(field);\n      //We need to account for the FORMAT_SIZE at when seeking in the tvx\n      //We don't need to do this in other seeks because we already have the\n      // file pointer\n      //that was written in another file\n      tvx.seek(((docNum + docStoreOffset) * 8L) + FORMAT_SIZE);\n      //System.out.println(\"TVX Pointer: \" + tvx.getFilePointer());\n      long position = tvx.readLong();\n\n      tvd.seek(position);\n      int fieldCount = tvd.readVInt();\n      //System.out.println(\"Num Fields: \" + fieldCount);\n      // There are only a few fields per document. We opt for a full scan\n      // rather then requiring that they be ordered. We need to read through\n      // all of the fields anyway to get to the tvf pointers.\n      int number = 0;\n      int found = -1;\n      for (int i = 0; i < fieldCount; i++) {\n        if(tvdFormat == FORMAT_VERSION)\n          number = tvd.readVInt();\n        else\n          number += tvd.readVInt();\n\n        if (number == fieldNumber)\n          found = i;\n      }\n\n      // This field, although valid in the segment, was not found in this\n      // document\n      if (found != -1) {\n        // Compute position in the tvf file\n        position = 0;\n        for (int i = 0; i <= found; i++)\n          position += tvd.readVLong();\n\n        mapper.setDocumentNumber(docNum);\n        readTermVector(field, position, mapper);\n      } else {\n        //System.out.println(\"Fieldable not found\");\n      }\n    } else {\n      //System.out.println(\"No tvx file\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","pathOld":"src/java/org/apache/lucene/index/TermVectorsReader#get(int,String,TermVectorMapper).mjava","sourceNew":"  public void get(int docNum, String field, TermVectorMapper mapper) throws IOException {\n    if (tvx != null) {\n      int fieldNumber = fieldInfos.fieldNumber(field);\n      //We need to account for the FORMAT_SIZE at when seeking in the tvx\n      //We don't need to do this in other seeks because we already have the\n      // file pointer\n      //that was written in another file\n      seekTvx(docNum);\n      //System.out.println(\"TVX Pointer: \" + tvx.getFilePointer());\n      long tvdPosition = tvx.readLong();\n\n      tvd.seek(tvdPosition);\n      int fieldCount = tvd.readVInt();\n      //System.out.println(\"Num Fields: \" + fieldCount);\n      // There are only a few fields per document. We opt for a full scan\n      // rather then requiring that they be ordered. We need to read through\n      // all of the fields anyway to get to the tvf pointers.\n      int number = 0;\n      int found = -1;\n      for (int i = 0; i < fieldCount; i++) {\n        if (format >= FORMAT_VERSION)\n          number = tvd.readVInt();\n        else\n          number += tvd.readVInt();\n\n        if (number == fieldNumber)\n          found = i;\n      }\n\n      // This field, although valid in the segment, was not found in this\n      // document\n      if (found != -1) {\n        // Compute position in the tvf file\n        long position;\n        if (format >= FORMAT_VERSION2)\n          position = tvx.readLong();\n        else\n          position = tvd.readVLong();\n        for (int i = 1; i <= found; i++)\n          position += tvd.readVLong();\n\n        mapper.setDocumentNumber(docNum);\n        readTermVector(field, position, mapper);\n      } else {\n        //System.out.println(\"Fieldable not found\");\n      }\n    } else {\n      //System.out.println(\"No tvx file\");\n    }\n  }\n\n","sourceOld":"  public void get(int docNum, String field, TermVectorMapper mapper) throws IOException {\n    if (tvx != null) {\n      int fieldNumber = fieldInfos.fieldNumber(field);\n      //We need to account for the FORMAT_SIZE at when seeking in the tvx\n      //We don't need to do this in other seeks because we already have the\n      // file pointer\n      //that was written in another file\n      seekTvx(docNum);\n      //System.out.println(\"TVX Pointer: \" + tvx.getFilePointer());\n      long tvdPosition = tvx.readLong();\n\n      tvd.seek(tvdPosition);\n      int fieldCount = tvd.readVInt();\n      //System.out.println(\"Num Fields: \" + fieldCount);\n      // There are only a few fields per document. We opt for a full scan\n      // rather then requiring that they be ordered. We need to read through\n      // all of the fields anyway to get to the tvf pointers.\n      int number = 0;\n      int found = -1;\n      for (int i = 0; i < fieldCount; i++) {\n        if (format >= FORMAT_VERSION)\n          number = tvd.readVInt();\n        else\n          number += tvd.readVInt();\n\n        if (number == fieldNumber)\n          found = i;\n      }\n\n      // This field, although valid in the segment, was not found in this\n      // document\n      if (found != -1) {\n        // Compute position in the tvf file\n        long position;\n        if (format >= FORMAT_VERSION2)\n          position = tvx.readLong();\n        else\n          position = tvd.readVLong();\n        for (int i = 1; i <= found; i++)\n          position += tvd.readVLong();\n\n        mapper.setDocumentNumber(docNum);\n        readTermVector(field, position, mapper);\n      } else {\n        //System.out.println(\"Fieldable not found\");\n      }\n    } else {\n      //System.out.println(\"No tvx file\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b3d08461c77d39c25ea6ff0cd05b32f948fa2a33":["f39283f826b260042f4a0469516fd1882ae41578"],"352bfe1fae83b92d1562f01c057bfbe6f5af3ddb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"11764865fb318bf86302eab36bdf9cd00c50c110":["352bfe1fae83b92d1562f01c057bfbe6f5af3ddb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f39283f826b260042f4a0469516fd1882ae41578":["11764865fb318bf86302eab36bdf9cd00c50c110"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["b3d08461c77d39c25ea6ff0cd05b32f948fa2a33"]},"commit2Childs":{"b3d08461c77d39c25ea6ff0cd05b32f948fa2a33":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"352bfe1fae83b92d1562f01c057bfbe6f5af3ddb":["11764865fb318bf86302eab36bdf9cd00c50c110"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["352bfe1fae83b92d1562f01c057bfbe6f5af3ddb"],"11764865fb318bf86302eab36bdf9cd00c50c110":["f39283f826b260042f4a0469516fd1882ae41578"],"f39283f826b260042f4a0469516fd1882ae41578":["b3d08461c77d39c25ea6ff0cd05b32f948fa2a33"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}