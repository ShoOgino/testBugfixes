{"path":"modules/facet/src/test/org/apache/lucene/facet/taxonomy/lucene/TestAddTaxonomies#dotest(int,int,int,boolean).mjava","commits":[{"id":"89f15687f60bd49cd3d9de427e85c17fd9397d61","date":1309381327,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/taxonomy/lucene/TestAddTaxonomies#dotest(int,int,int,boolean).mjava","pathOld":"/dev/null","sourceNew":"  private void dotest(int ntaxonomies, int ncats, int range, boolean disk) throws Exception {\n    Directory dirs[] = new Directory[ntaxonomies];\n    Directory copydirs[] = new Directory[ntaxonomies];\n\n    for (int i=0; i<ntaxonomies; i++) {\n      dirs[i] = new RAMDirectory();\n      copydirs[i] = new RAMDirectory();\n      LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[i]);\n      LuceneTaxonomyWriter copytw = new LuceneTaxonomyWriter(copydirs[i]);\n      for (int j=0; j<ncats; j++) {\n        String cat = Integer.toString(random.nextInt(range));\n        tw.addCategory(new CategoryPath(\"a\",cat));\n        copytw.addCategory(new CategoryPath(\"a\",cat));\n      }\n      // System.err.println(\"Taxonomy \"+i+\": \"+tw.getSize());\n      tw.close();\n      copytw.close();\n    }\n\n    LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[0]);\n    Directory otherdirs[] = new Directory[ntaxonomies-1];\n    System.arraycopy(dirs, 1, otherdirs, 0, ntaxonomies-1);\n\n    OrdinalMap[] maps = new OrdinalMap[ntaxonomies-1];\n    if (ntaxonomies>1) {\n      for (int i=0; i<ntaxonomies-1; i++) {\n        if (disk) {\n          maps[i] = new DiskOrdinalMap(new File(System.getProperty(\"java.io.tmpdir\"),\n              \"tmpmap\"+i));\n        } else {\n          maps[i] = new MemoryOrdinalMap();\n        }\n      }\n    }\n\n    tw.addTaxonomies(otherdirs, maps);\n    // System.err.println(\"Merged axonomy: \"+tw.getSize());\n    tw.close();\n\n    // Check that all original categories in the main taxonomy remain in\n    // unchanged, and the rest of the taxonomies are completely unchanged.\n    for (int i=0; i<ntaxonomies; i++) {\n      TaxonomyReader tr = new LuceneTaxonomyReader(dirs[i]);\n      TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[i]);\n      if (i==0) {\n        assertTrue(tr.getSize() >= copytr.getSize());\n      } else {\n        assertEquals(copytr.getSize(), tr.getSize());\n      }\n      for (int j=0; j<copytr.getSize(); j++) {\n        String expected = copytr.getPath(j).toString();\n        String got = tr.getPath(j).toString();\n        assertTrue(\"Comparing category \"+j+\" of taxonomy \"+i+\": expected \"+expected+\", got \"+got,\n            expected.equals(got));\n      }\n      tr.close();\n      copytr.close();\n    }\n\n    // Check that all the new categories in the main taxonomy are in\n    // lexicographic order. This isn't a requirement of our API, but happens\n    // this way in our current implementation.\n    TaxonomyReader tr = new LuceneTaxonomyReader(dirs[0]);\n    TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[0]);\n    if (tr.getSize() > copytr.getSize()) {\n      String prev = tr.getPath(copytr.getSize()).toString();\n      for (int j=copytr.getSize()+1; j<tr.getSize(); j++) {\n        String n = tr.getPath(j).toString();\n        assertTrue(prev.compareTo(n)<0);\n        prev=n;\n      }\n    }\n    int oldsize = copytr.getSize(); // remember for later\n    tr.close();\n    copytr.close();\n\n    // Check that all the categories from other taxonomies exist in the new\n    // taxonomy.\n    TaxonomyReader main = new LuceneTaxonomyReader(dirs[0]);\n    for (int i=1; i<ntaxonomies; i++) {\n      TaxonomyReader other = new LuceneTaxonomyReader(dirs[i]);\n      for (int j=0; j<other.getSize(); j++) {\n        int otherord = main.getOrdinal(other.getPath(j));\n        assertTrue(otherord != TaxonomyReader.INVALID_ORDINAL);\n      }\n      tr.close();\n    }\n\n    // Check that all the new categories in the merged taxonomy exist in\n    // one of the added taxonomies.\n    TaxonomyReader[] others = new TaxonomyReader[ntaxonomies-1]; \n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1] = new LuceneTaxonomyReader(dirs[i]);\n    }\n    for (int j=oldsize; j<main.getSize(); j++) {\n      boolean found=false;\n      CategoryPath path = main.getPath(j);\n      for (int i=1; i<ntaxonomies; i++) {\n        if (others[i-1].getOrdinal(path) != TaxonomyReader.INVALID_ORDINAL) {\n          found=true;\n          break;\n        }\n      }\n      if (!found) {\n        fail(\"Found category \"+j+\" (\"+path+\") in merged taxonomy not in any of the separate ones\");\n      }\n    }\n\n    // Check that all the maps are correct\n    for (int i=0; i<ntaxonomies-1; i++) {\n      int[] map = maps[i].getMap();\n      for (int j=0; j<map.length; j++) {\n        assertEquals(map[j], main.getOrdinal(others[i].getPath(j)));\n      }\n    }\n\n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1].close();\n    }\n\n    main.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a4df66e06e0c3b520d7d5941e1c043076f06f17","date":1309454196,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/taxonomy/lucene/TestAddTaxonomies#dotest(int,int,int,boolean).mjava","pathOld":"modules/facet/src/test/org/apache/lucene/facet/taxonomy/lucene/TestAddTaxonomies#dotest(int,int,int,boolean).mjava","sourceNew":"  private void dotest(int ntaxonomies, int ncats, int range, boolean disk) throws Exception {\n    Directory dirs[] = new Directory[ntaxonomies];\n    Directory copydirs[] = new Directory[ntaxonomies];\n\n    for (int i=0; i<ntaxonomies; i++) {\n      dirs[i] = newDirectory();\n      copydirs[i] = newDirectory();\n      LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[i]);\n      LuceneTaxonomyWriter copytw = new LuceneTaxonomyWriter(copydirs[i]);\n      for (int j=0; j<ncats; j++) {\n        String cat = Integer.toString(random.nextInt(range));\n        tw.addCategory(new CategoryPath(\"a\",cat));\n        copytw.addCategory(new CategoryPath(\"a\",cat));\n      }\n      // System.err.println(\"Taxonomy \"+i+\": \"+tw.getSize());\n      tw.close();\n      copytw.close();\n    }\n\n    LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[0]);\n    Directory otherdirs[] = new Directory[ntaxonomies-1];\n    System.arraycopy(dirs, 1, otherdirs, 0, ntaxonomies-1);\n\n    OrdinalMap[] maps = new OrdinalMap[ntaxonomies-1];\n    if (ntaxonomies>1) {\n      for (int i=0; i<ntaxonomies-1; i++) {\n        if (disk) {\n          // TODO: use a LTC tempfile\n          maps[i] = new DiskOrdinalMap(new File(System.getProperty(\"java.io.tmpdir\"),\n              \"tmpmap\"+i));\n        } else {\n          maps[i] = new MemoryOrdinalMap();\n        }\n      }\n    }\n\n    tw.addTaxonomies(otherdirs, maps);\n    // System.err.println(\"Merged axonomy: \"+tw.getSize());\n    tw.close();\n\n    // Check that all original categories in the main taxonomy remain in\n    // unchanged, and the rest of the taxonomies are completely unchanged.\n    for (int i=0; i<ntaxonomies; i++) {\n      TaxonomyReader tr = new LuceneTaxonomyReader(dirs[i]);\n      TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[i]);\n      if (i==0) {\n        assertTrue(tr.getSize() >= copytr.getSize());\n      } else {\n        assertEquals(copytr.getSize(), tr.getSize());\n      }\n      for (int j=0; j<copytr.getSize(); j++) {\n        String expected = copytr.getPath(j).toString();\n        String got = tr.getPath(j).toString();\n        assertTrue(\"Comparing category \"+j+\" of taxonomy \"+i+\": expected \"+expected+\", got \"+got,\n            expected.equals(got));\n      }\n      tr.close();\n      copytr.close();\n    }\n\n    // Check that all the new categories in the main taxonomy are in\n    // lexicographic order. This isn't a requirement of our API, but happens\n    // this way in our current implementation.\n    TaxonomyReader tr = new LuceneTaxonomyReader(dirs[0]);\n    TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[0]);\n    if (tr.getSize() > copytr.getSize()) {\n      String prev = tr.getPath(copytr.getSize()).toString();\n      for (int j=copytr.getSize()+1; j<tr.getSize(); j++) {\n        String n = tr.getPath(j).toString();\n        assertTrue(prev.compareTo(n)<0);\n        prev=n;\n      }\n    }\n    int oldsize = copytr.getSize(); // remember for later\n    tr.close();\n    copytr.close();\n\n    // Check that all the categories from other taxonomies exist in the new\n    // taxonomy.\n    TaxonomyReader main = new LuceneTaxonomyReader(dirs[0]);\n    for (int i=1; i<ntaxonomies; i++) {\n      TaxonomyReader other = new LuceneTaxonomyReader(dirs[i]);\n      for (int j=0; j<other.getSize(); j++) {\n        int otherord = main.getOrdinal(other.getPath(j));\n        assertTrue(otherord != TaxonomyReader.INVALID_ORDINAL);\n      }\n      other.close();\n    }\n\n    // Check that all the new categories in the merged taxonomy exist in\n    // one of the added taxonomies.\n    TaxonomyReader[] others = new TaxonomyReader[ntaxonomies-1]; \n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1] = new LuceneTaxonomyReader(dirs[i]);\n    }\n    for (int j=oldsize; j<main.getSize(); j++) {\n      boolean found=false;\n      CategoryPath path = main.getPath(j);\n      for (int i=1; i<ntaxonomies; i++) {\n        if (others[i-1].getOrdinal(path) != TaxonomyReader.INVALID_ORDINAL) {\n          found=true;\n          break;\n        }\n      }\n      if (!found) {\n        fail(\"Found category \"+j+\" (\"+path+\") in merged taxonomy not in any of the separate ones\");\n      }\n    }\n\n    // Check that all the maps are correct\n    for (int i=0; i<ntaxonomies-1; i++) {\n      int[] map = maps[i].getMap();\n      for (int j=0; j<map.length; j++) {\n        assertEquals(map[j], main.getOrdinal(others[i].getPath(j)));\n      }\n    }\n\n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1].close();\n    }\n\n    main.close();\n    IOUtils.closeSafely(false, dirs);\n    IOUtils.closeSafely(false, copydirs);\n  }\n\n","sourceOld":"  private void dotest(int ntaxonomies, int ncats, int range, boolean disk) throws Exception {\n    Directory dirs[] = new Directory[ntaxonomies];\n    Directory copydirs[] = new Directory[ntaxonomies];\n\n    for (int i=0; i<ntaxonomies; i++) {\n      dirs[i] = new RAMDirectory();\n      copydirs[i] = new RAMDirectory();\n      LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[i]);\n      LuceneTaxonomyWriter copytw = new LuceneTaxonomyWriter(copydirs[i]);\n      for (int j=0; j<ncats; j++) {\n        String cat = Integer.toString(random.nextInt(range));\n        tw.addCategory(new CategoryPath(\"a\",cat));\n        copytw.addCategory(new CategoryPath(\"a\",cat));\n      }\n      // System.err.println(\"Taxonomy \"+i+\": \"+tw.getSize());\n      tw.close();\n      copytw.close();\n    }\n\n    LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[0]);\n    Directory otherdirs[] = new Directory[ntaxonomies-1];\n    System.arraycopy(dirs, 1, otherdirs, 0, ntaxonomies-1);\n\n    OrdinalMap[] maps = new OrdinalMap[ntaxonomies-1];\n    if (ntaxonomies>1) {\n      for (int i=0; i<ntaxonomies-1; i++) {\n        if (disk) {\n          maps[i] = new DiskOrdinalMap(new File(System.getProperty(\"java.io.tmpdir\"),\n              \"tmpmap\"+i));\n        } else {\n          maps[i] = new MemoryOrdinalMap();\n        }\n      }\n    }\n\n    tw.addTaxonomies(otherdirs, maps);\n    // System.err.println(\"Merged axonomy: \"+tw.getSize());\n    tw.close();\n\n    // Check that all original categories in the main taxonomy remain in\n    // unchanged, and the rest of the taxonomies are completely unchanged.\n    for (int i=0; i<ntaxonomies; i++) {\n      TaxonomyReader tr = new LuceneTaxonomyReader(dirs[i]);\n      TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[i]);\n      if (i==0) {\n        assertTrue(tr.getSize() >= copytr.getSize());\n      } else {\n        assertEquals(copytr.getSize(), tr.getSize());\n      }\n      for (int j=0; j<copytr.getSize(); j++) {\n        String expected = copytr.getPath(j).toString();\n        String got = tr.getPath(j).toString();\n        assertTrue(\"Comparing category \"+j+\" of taxonomy \"+i+\": expected \"+expected+\", got \"+got,\n            expected.equals(got));\n      }\n      tr.close();\n      copytr.close();\n    }\n\n    // Check that all the new categories in the main taxonomy are in\n    // lexicographic order. This isn't a requirement of our API, but happens\n    // this way in our current implementation.\n    TaxonomyReader tr = new LuceneTaxonomyReader(dirs[0]);\n    TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[0]);\n    if (tr.getSize() > copytr.getSize()) {\n      String prev = tr.getPath(copytr.getSize()).toString();\n      for (int j=copytr.getSize()+1; j<tr.getSize(); j++) {\n        String n = tr.getPath(j).toString();\n        assertTrue(prev.compareTo(n)<0);\n        prev=n;\n      }\n    }\n    int oldsize = copytr.getSize(); // remember for later\n    tr.close();\n    copytr.close();\n\n    // Check that all the categories from other taxonomies exist in the new\n    // taxonomy.\n    TaxonomyReader main = new LuceneTaxonomyReader(dirs[0]);\n    for (int i=1; i<ntaxonomies; i++) {\n      TaxonomyReader other = new LuceneTaxonomyReader(dirs[i]);\n      for (int j=0; j<other.getSize(); j++) {\n        int otherord = main.getOrdinal(other.getPath(j));\n        assertTrue(otherord != TaxonomyReader.INVALID_ORDINAL);\n      }\n      tr.close();\n    }\n\n    // Check that all the new categories in the merged taxonomy exist in\n    // one of the added taxonomies.\n    TaxonomyReader[] others = new TaxonomyReader[ntaxonomies-1]; \n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1] = new LuceneTaxonomyReader(dirs[i]);\n    }\n    for (int j=oldsize; j<main.getSize(); j++) {\n      boolean found=false;\n      CategoryPath path = main.getPath(j);\n      for (int i=1; i<ntaxonomies; i++) {\n        if (others[i-1].getOrdinal(path) != TaxonomyReader.INVALID_ORDINAL) {\n          found=true;\n          break;\n        }\n      }\n      if (!found) {\n        fail(\"Found category \"+j+\" (\"+path+\") in merged taxonomy not in any of the separate ones\");\n      }\n    }\n\n    // Check that all the maps are correct\n    for (int i=0; i<ntaxonomies-1; i++) {\n      int[] map = maps[i].getMap();\n      for (int j=0; j<map.length; j++) {\n        assertEquals(map[j], main.getOrdinal(others[i].getPath(j)));\n      }\n    }\n\n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1].close();\n    }\n\n    main.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/taxonomy/lucene/TestAddTaxonomies#dotest(int,int,int,boolean).mjava","pathOld":"/dev/null","sourceNew":"  private void dotest(int ntaxonomies, int ncats, int range, boolean disk) throws Exception {\n    Directory dirs[] = new Directory[ntaxonomies];\n    Directory copydirs[] = new Directory[ntaxonomies];\n\n    for (int i=0; i<ntaxonomies; i++) {\n      dirs[i] = newDirectory();\n      copydirs[i] = newDirectory();\n      LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[i]);\n      LuceneTaxonomyWriter copytw = new LuceneTaxonomyWriter(copydirs[i]);\n      for (int j=0; j<ncats; j++) {\n        String cat = Integer.toString(random.nextInt(range));\n        tw.addCategory(new CategoryPath(\"a\",cat));\n        copytw.addCategory(new CategoryPath(\"a\",cat));\n      }\n      // System.err.println(\"Taxonomy \"+i+\": \"+tw.getSize());\n      tw.close();\n      copytw.close();\n    }\n\n    LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[0]);\n    Directory otherdirs[] = new Directory[ntaxonomies-1];\n    System.arraycopy(dirs, 1, otherdirs, 0, ntaxonomies-1);\n\n    OrdinalMap[] maps = new OrdinalMap[ntaxonomies-1];\n    if (ntaxonomies>1) {\n      for (int i=0; i<ntaxonomies-1; i++) {\n        if (disk) {\n          // TODO: use a LTC tempfile\n          maps[i] = new DiskOrdinalMap(new File(System.getProperty(\"java.io.tmpdir\"),\n              \"tmpmap\"+i));\n        } else {\n          maps[i] = new MemoryOrdinalMap();\n        }\n      }\n    }\n\n    tw.addTaxonomies(otherdirs, maps);\n    // System.err.println(\"Merged axonomy: \"+tw.getSize());\n    tw.close();\n\n    // Check that all original categories in the main taxonomy remain in\n    // unchanged, and the rest of the taxonomies are completely unchanged.\n    for (int i=0; i<ntaxonomies; i++) {\n      TaxonomyReader tr = new LuceneTaxonomyReader(dirs[i]);\n      TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[i]);\n      if (i==0) {\n        assertTrue(tr.getSize() >= copytr.getSize());\n      } else {\n        assertEquals(copytr.getSize(), tr.getSize());\n      }\n      for (int j=0; j<copytr.getSize(); j++) {\n        String expected = copytr.getPath(j).toString();\n        String got = tr.getPath(j).toString();\n        assertTrue(\"Comparing category \"+j+\" of taxonomy \"+i+\": expected \"+expected+\", got \"+got,\n            expected.equals(got));\n      }\n      tr.close();\n      copytr.close();\n    }\n\n    // Check that all the new categories in the main taxonomy are in\n    // lexicographic order. This isn't a requirement of our API, but happens\n    // this way in our current implementation.\n    TaxonomyReader tr = new LuceneTaxonomyReader(dirs[0]);\n    TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[0]);\n    if (tr.getSize() > copytr.getSize()) {\n      String prev = tr.getPath(copytr.getSize()).toString();\n      for (int j=copytr.getSize()+1; j<tr.getSize(); j++) {\n        String n = tr.getPath(j).toString();\n        assertTrue(prev.compareTo(n)<0);\n        prev=n;\n      }\n    }\n    int oldsize = copytr.getSize(); // remember for later\n    tr.close();\n    copytr.close();\n\n    // Check that all the categories from other taxonomies exist in the new\n    // taxonomy.\n    TaxonomyReader main = new LuceneTaxonomyReader(dirs[0]);\n    for (int i=1; i<ntaxonomies; i++) {\n      TaxonomyReader other = new LuceneTaxonomyReader(dirs[i]);\n      for (int j=0; j<other.getSize(); j++) {\n        int otherord = main.getOrdinal(other.getPath(j));\n        assertTrue(otherord != TaxonomyReader.INVALID_ORDINAL);\n      }\n      other.close();\n    }\n\n    // Check that all the new categories in the merged taxonomy exist in\n    // one of the added taxonomies.\n    TaxonomyReader[] others = new TaxonomyReader[ntaxonomies-1]; \n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1] = new LuceneTaxonomyReader(dirs[i]);\n    }\n    for (int j=oldsize; j<main.getSize(); j++) {\n      boolean found=false;\n      CategoryPath path = main.getPath(j);\n      for (int i=1; i<ntaxonomies; i++) {\n        if (others[i-1].getOrdinal(path) != TaxonomyReader.INVALID_ORDINAL) {\n          found=true;\n          break;\n        }\n      }\n      if (!found) {\n        fail(\"Found category \"+j+\" (\"+path+\") in merged taxonomy not in any of the separate ones\");\n      }\n    }\n\n    // Check that all the maps are correct\n    for (int i=0; i<ntaxonomies-1; i++) {\n      int[] map = maps[i].getMap();\n      for (int j=0; j<map.length; j++) {\n        assertEquals(map[j], main.getOrdinal(others[i].getPath(j)));\n      }\n    }\n\n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1].close();\n    }\n\n    main.close();\n    IOUtils.closeSafely(false, dirs);\n    IOUtils.closeSafely(false, copydirs);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/taxonomy/lucene/TestAddTaxonomies#dotest(int,int,int,boolean).mjava","pathOld":"/dev/null","sourceNew":"  private void dotest(int ntaxonomies, int ncats, int range, boolean disk) throws Exception {\n    Directory dirs[] = new Directory[ntaxonomies];\n    Directory copydirs[] = new Directory[ntaxonomies];\n\n    for (int i=0; i<ntaxonomies; i++) {\n      dirs[i] = newDirectory();\n      copydirs[i] = newDirectory();\n      LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[i]);\n      LuceneTaxonomyWriter copytw = new LuceneTaxonomyWriter(copydirs[i]);\n      for (int j=0; j<ncats; j++) {\n        String cat = Integer.toString(random.nextInt(range));\n        tw.addCategory(new CategoryPath(\"a\",cat));\n        copytw.addCategory(new CategoryPath(\"a\",cat));\n      }\n      // System.err.println(\"Taxonomy \"+i+\": \"+tw.getSize());\n      tw.close();\n      copytw.close();\n    }\n\n    LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[0]);\n    Directory otherdirs[] = new Directory[ntaxonomies-1];\n    System.arraycopy(dirs, 1, otherdirs, 0, ntaxonomies-1);\n\n    OrdinalMap[] maps = new OrdinalMap[ntaxonomies-1];\n    if (ntaxonomies>1) {\n      for (int i=0; i<ntaxonomies-1; i++) {\n        if (disk) {\n          // TODO: use a LTC tempfile\n          maps[i] = new DiskOrdinalMap(new File(System.getProperty(\"java.io.tmpdir\"),\n              \"tmpmap\"+i));\n        } else {\n          maps[i] = new MemoryOrdinalMap();\n        }\n      }\n    }\n\n    tw.addTaxonomies(otherdirs, maps);\n    // System.err.println(\"Merged axonomy: \"+tw.getSize());\n    tw.close();\n\n    // Check that all original categories in the main taxonomy remain in\n    // unchanged, and the rest of the taxonomies are completely unchanged.\n    for (int i=0; i<ntaxonomies; i++) {\n      TaxonomyReader tr = new LuceneTaxonomyReader(dirs[i]);\n      TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[i]);\n      if (i==0) {\n        assertTrue(tr.getSize() >= copytr.getSize());\n      } else {\n        assertEquals(copytr.getSize(), tr.getSize());\n      }\n      for (int j=0; j<copytr.getSize(); j++) {\n        String expected = copytr.getPath(j).toString();\n        String got = tr.getPath(j).toString();\n        assertTrue(\"Comparing category \"+j+\" of taxonomy \"+i+\": expected \"+expected+\", got \"+got,\n            expected.equals(got));\n      }\n      tr.close();\n      copytr.close();\n    }\n\n    // Check that all the new categories in the main taxonomy are in\n    // lexicographic order. This isn't a requirement of our API, but happens\n    // this way in our current implementation.\n    TaxonomyReader tr = new LuceneTaxonomyReader(dirs[0]);\n    TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[0]);\n    if (tr.getSize() > copytr.getSize()) {\n      String prev = tr.getPath(copytr.getSize()).toString();\n      for (int j=copytr.getSize()+1; j<tr.getSize(); j++) {\n        String n = tr.getPath(j).toString();\n        assertTrue(prev.compareTo(n)<0);\n        prev=n;\n      }\n    }\n    int oldsize = copytr.getSize(); // remember for later\n    tr.close();\n    copytr.close();\n\n    // Check that all the categories from other taxonomies exist in the new\n    // taxonomy.\n    TaxonomyReader main = new LuceneTaxonomyReader(dirs[0]);\n    for (int i=1; i<ntaxonomies; i++) {\n      TaxonomyReader other = new LuceneTaxonomyReader(dirs[i]);\n      for (int j=0; j<other.getSize(); j++) {\n        int otherord = main.getOrdinal(other.getPath(j));\n        assertTrue(otherord != TaxonomyReader.INVALID_ORDINAL);\n      }\n      other.close();\n    }\n\n    // Check that all the new categories in the merged taxonomy exist in\n    // one of the added taxonomies.\n    TaxonomyReader[] others = new TaxonomyReader[ntaxonomies-1]; \n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1] = new LuceneTaxonomyReader(dirs[i]);\n    }\n    for (int j=oldsize; j<main.getSize(); j++) {\n      boolean found=false;\n      CategoryPath path = main.getPath(j);\n      for (int i=1; i<ntaxonomies; i++) {\n        if (others[i-1].getOrdinal(path) != TaxonomyReader.INVALID_ORDINAL) {\n          found=true;\n          break;\n        }\n      }\n      if (!found) {\n        fail(\"Found category \"+j+\" (\"+path+\") in merged taxonomy not in any of the separate ones\");\n      }\n    }\n\n    // Check that all the maps are correct\n    for (int i=0; i<ntaxonomies-1; i++) {\n      int[] map = maps[i].getMap();\n      for (int j=0; j<map.length; j++) {\n        assertEquals(map[j], main.getOrdinal(others[i].getPath(j)));\n      }\n    }\n\n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1].close();\n    }\n\n    main.close();\n    IOUtils.closeSafely(false, dirs);\n    IOUtils.closeSafely(false, copydirs);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"24230fe54121f9be9d85f2c2067536296785e421","date":1314462346,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/taxonomy/lucene/TestAddTaxonomies#dotest(int,int,int,boolean).mjava","pathOld":"modules/facet/src/test/org/apache/lucene/facet/taxonomy/lucene/TestAddTaxonomies#dotest(int,int,int,boolean).mjava","sourceNew":"  private void dotest(int ntaxonomies, int ncats, int range, boolean disk) throws Exception {\n    Directory dirs[] = new Directory[ntaxonomies];\n    Directory copydirs[] = new Directory[ntaxonomies];\n\n    for (int i=0; i<ntaxonomies; i++) {\n      dirs[i] = newDirectory();\n      copydirs[i] = newDirectory();\n      LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[i]);\n      LuceneTaxonomyWriter copytw = new LuceneTaxonomyWriter(copydirs[i]);\n      for (int j=0; j<ncats; j++) {\n        String cat = Integer.toString(random.nextInt(range));\n        tw.addCategory(new CategoryPath(\"a\",cat));\n        copytw.addCategory(new CategoryPath(\"a\",cat));\n      }\n      // System.err.println(\"Taxonomy \"+i+\": \"+tw.getSize());\n      tw.close();\n      copytw.close();\n    }\n\n    LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[0]);\n    Directory otherdirs[] = new Directory[ntaxonomies-1];\n    System.arraycopy(dirs, 1, otherdirs, 0, ntaxonomies-1);\n\n    OrdinalMap[] maps = new OrdinalMap[ntaxonomies-1];\n    if (ntaxonomies>1) {\n      for (int i=0; i<ntaxonomies-1; i++) {\n        if (disk) {\n          // TODO: use a LTC tempfile\n          maps[i] = new DiskOrdinalMap(new File(System.getProperty(\"java.io.tmpdir\"),\n              \"tmpmap\"+i));\n        } else {\n          maps[i] = new MemoryOrdinalMap();\n        }\n      }\n    }\n\n    tw.addTaxonomies(otherdirs, maps);\n    // System.err.println(\"Merged axonomy: \"+tw.getSize());\n    tw.close();\n\n    // Check that all original categories in the main taxonomy remain in\n    // unchanged, and the rest of the taxonomies are completely unchanged.\n    for (int i=0; i<ntaxonomies; i++) {\n      TaxonomyReader tr = new LuceneTaxonomyReader(dirs[i]);\n      TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[i]);\n      if (i==0) {\n        assertTrue(tr.getSize() >= copytr.getSize());\n      } else {\n        assertEquals(copytr.getSize(), tr.getSize());\n      }\n      for (int j=0; j<copytr.getSize(); j++) {\n        String expected = copytr.getPath(j).toString();\n        String got = tr.getPath(j).toString();\n        assertTrue(\"Comparing category \"+j+\" of taxonomy \"+i+\": expected \"+expected+\", got \"+got,\n            expected.equals(got));\n      }\n      tr.close();\n      copytr.close();\n    }\n\n    // Check that all the new categories in the main taxonomy are in\n    // lexicographic order. This isn't a requirement of our API, but happens\n    // this way in our current implementation.\n    TaxonomyReader tr = new LuceneTaxonomyReader(dirs[0]);\n    TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[0]);\n    if (tr.getSize() > copytr.getSize()) {\n      String prev = tr.getPath(copytr.getSize()).toString();\n      for (int j=copytr.getSize()+1; j<tr.getSize(); j++) {\n        String n = tr.getPath(j).toString();\n        assertTrue(prev.compareTo(n)<0);\n        prev=n;\n      }\n    }\n    int oldsize = copytr.getSize(); // remember for later\n    tr.close();\n    copytr.close();\n\n    // Check that all the categories from other taxonomies exist in the new\n    // taxonomy.\n    TaxonomyReader main = new LuceneTaxonomyReader(dirs[0]);\n    for (int i=1; i<ntaxonomies; i++) {\n      TaxonomyReader other = new LuceneTaxonomyReader(dirs[i]);\n      for (int j=0; j<other.getSize(); j++) {\n        int otherord = main.getOrdinal(other.getPath(j));\n        assertTrue(otherord != TaxonomyReader.INVALID_ORDINAL);\n      }\n      other.close();\n    }\n\n    // Check that all the new categories in the merged taxonomy exist in\n    // one of the added taxonomies.\n    TaxonomyReader[] others = new TaxonomyReader[ntaxonomies-1]; \n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1] = new LuceneTaxonomyReader(dirs[i]);\n    }\n    for (int j=oldsize; j<main.getSize(); j++) {\n      boolean found=false;\n      CategoryPath path = main.getPath(j);\n      for (int i=1; i<ntaxonomies; i++) {\n        if (others[i-1].getOrdinal(path) != TaxonomyReader.INVALID_ORDINAL) {\n          found=true;\n          break;\n        }\n      }\n      if (!found) {\n        fail(\"Found category \"+j+\" (\"+path+\") in merged taxonomy not in any of the separate ones\");\n      }\n    }\n\n    // Check that all the maps are correct\n    for (int i=0; i<ntaxonomies-1; i++) {\n      int[] map = maps[i].getMap();\n      for (int j=0; j<map.length; j++) {\n        assertEquals(map[j], main.getOrdinal(others[i].getPath(j)));\n      }\n    }\n\n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1].close();\n    }\n\n    main.close();\n    IOUtils.close(dirs);\n    IOUtils.close(copydirs);\n  }\n\n","sourceOld":"  private void dotest(int ntaxonomies, int ncats, int range, boolean disk) throws Exception {\n    Directory dirs[] = new Directory[ntaxonomies];\n    Directory copydirs[] = new Directory[ntaxonomies];\n\n    for (int i=0; i<ntaxonomies; i++) {\n      dirs[i] = newDirectory();\n      copydirs[i] = newDirectory();\n      LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[i]);\n      LuceneTaxonomyWriter copytw = new LuceneTaxonomyWriter(copydirs[i]);\n      for (int j=0; j<ncats; j++) {\n        String cat = Integer.toString(random.nextInt(range));\n        tw.addCategory(new CategoryPath(\"a\",cat));\n        copytw.addCategory(new CategoryPath(\"a\",cat));\n      }\n      // System.err.println(\"Taxonomy \"+i+\": \"+tw.getSize());\n      tw.close();\n      copytw.close();\n    }\n\n    LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[0]);\n    Directory otherdirs[] = new Directory[ntaxonomies-1];\n    System.arraycopy(dirs, 1, otherdirs, 0, ntaxonomies-1);\n\n    OrdinalMap[] maps = new OrdinalMap[ntaxonomies-1];\n    if (ntaxonomies>1) {\n      for (int i=0; i<ntaxonomies-1; i++) {\n        if (disk) {\n          // TODO: use a LTC tempfile\n          maps[i] = new DiskOrdinalMap(new File(System.getProperty(\"java.io.tmpdir\"),\n              \"tmpmap\"+i));\n        } else {\n          maps[i] = new MemoryOrdinalMap();\n        }\n      }\n    }\n\n    tw.addTaxonomies(otherdirs, maps);\n    // System.err.println(\"Merged axonomy: \"+tw.getSize());\n    tw.close();\n\n    // Check that all original categories in the main taxonomy remain in\n    // unchanged, and the rest of the taxonomies are completely unchanged.\n    for (int i=0; i<ntaxonomies; i++) {\n      TaxonomyReader tr = new LuceneTaxonomyReader(dirs[i]);\n      TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[i]);\n      if (i==0) {\n        assertTrue(tr.getSize() >= copytr.getSize());\n      } else {\n        assertEquals(copytr.getSize(), tr.getSize());\n      }\n      for (int j=0; j<copytr.getSize(); j++) {\n        String expected = copytr.getPath(j).toString();\n        String got = tr.getPath(j).toString();\n        assertTrue(\"Comparing category \"+j+\" of taxonomy \"+i+\": expected \"+expected+\", got \"+got,\n            expected.equals(got));\n      }\n      tr.close();\n      copytr.close();\n    }\n\n    // Check that all the new categories in the main taxonomy are in\n    // lexicographic order. This isn't a requirement of our API, but happens\n    // this way in our current implementation.\n    TaxonomyReader tr = new LuceneTaxonomyReader(dirs[0]);\n    TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[0]);\n    if (tr.getSize() > copytr.getSize()) {\n      String prev = tr.getPath(copytr.getSize()).toString();\n      for (int j=copytr.getSize()+1; j<tr.getSize(); j++) {\n        String n = tr.getPath(j).toString();\n        assertTrue(prev.compareTo(n)<0);\n        prev=n;\n      }\n    }\n    int oldsize = copytr.getSize(); // remember for later\n    tr.close();\n    copytr.close();\n\n    // Check that all the categories from other taxonomies exist in the new\n    // taxonomy.\n    TaxonomyReader main = new LuceneTaxonomyReader(dirs[0]);\n    for (int i=1; i<ntaxonomies; i++) {\n      TaxonomyReader other = new LuceneTaxonomyReader(dirs[i]);\n      for (int j=0; j<other.getSize(); j++) {\n        int otherord = main.getOrdinal(other.getPath(j));\n        assertTrue(otherord != TaxonomyReader.INVALID_ORDINAL);\n      }\n      other.close();\n    }\n\n    // Check that all the new categories in the merged taxonomy exist in\n    // one of the added taxonomies.\n    TaxonomyReader[] others = new TaxonomyReader[ntaxonomies-1]; \n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1] = new LuceneTaxonomyReader(dirs[i]);\n    }\n    for (int j=oldsize; j<main.getSize(); j++) {\n      boolean found=false;\n      CategoryPath path = main.getPath(j);\n      for (int i=1; i<ntaxonomies; i++) {\n        if (others[i-1].getOrdinal(path) != TaxonomyReader.INVALID_ORDINAL) {\n          found=true;\n          break;\n        }\n      }\n      if (!found) {\n        fail(\"Found category \"+j+\" (\"+path+\") in merged taxonomy not in any of the separate ones\");\n      }\n    }\n\n    // Check that all the maps are correct\n    for (int i=0; i<ntaxonomies-1; i++) {\n      int[] map = maps[i].getMap();\n      for (int j=0; j<map.length; j++) {\n        assertEquals(map[j], main.getOrdinal(others[i].getPath(j)));\n      }\n    }\n\n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1].close();\n    }\n\n    main.close();\n    IOUtils.closeSafely(false, dirs);\n    IOUtils.closeSafely(false, copydirs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ea469eab8fd0f3032f4fcde1c644a721e8309d3b","date":1320301582,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"modules/facet/src/test/org/apache/lucene/facet/taxonomy/directory/TestAddTaxonomies#dotest(int,int,int,boolean).mjava","pathOld":"modules/facet/src/test/org/apache/lucene/facet/taxonomy/lucene/TestAddTaxonomies#dotest(int,int,int,boolean).mjava","sourceNew":"  private void dotest(int ntaxonomies, int ncats, int range, boolean disk) throws Exception {\n    Directory dirs[] = new Directory[ntaxonomies];\n    Directory copydirs[] = new Directory[ntaxonomies];\n\n    for (int i=0; i<ntaxonomies; i++) {\n      dirs[i] = newDirectory();\n      copydirs[i] = newDirectory();\n      DirectoryTaxonomyWriter tw = new DirectoryTaxonomyWriter(dirs[i]);\n      DirectoryTaxonomyWriter copytw = new DirectoryTaxonomyWriter(copydirs[i]);\n      for (int j=0; j<ncats; j++) {\n        String cat = Integer.toString(random.nextInt(range));\n        tw.addCategory(new CategoryPath(\"a\",cat));\n        copytw.addCategory(new CategoryPath(\"a\",cat));\n      }\n      // System.err.println(\"Taxonomy \"+i+\": \"+tw.getSize());\n      tw.close();\n      copytw.close();\n    }\n\n    DirectoryTaxonomyWriter tw = new DirectoryTaxonomyWriter(dirs[0]);\n    Directory otherdirs[] = new Directory[ntaxonomies-1];\n    System.arraycopy(dirs, 1, otherdirs, 0, ntaxonomies-1);\n\n    OrdinalMap[] maps = new OrdinalMap[ntaxonomies-1];\n    if (ntaxonomies>1) {\n      for (int i=0; i<ntaxonomies-1; i++) {\n        if (disk) {\n          // TODO: use a LTC tempfile\n          maps[i] = new DiskOrdinalMap(new File(System.getProperty(\"java.io.tmpdir\"),\n              \"tmpmap\"+i));\n        } else {\n          maps[i] = new MemoryOrdinalMap();\n        }\n      }\n    }\n\n    tw.addTaxonomies(otherdirs, maps);\n    // System.err.println(\"Merged axonomy: \"+tw.getSize());\n    tw.close();\n\n    // Check that all original categories in the main taxonomy remain in\n    // unchanged, and the rest of the taxonomies are completely unchanged.\n    for (int i=0; i<ntaxonomies; i++) {\n      TaxonomyReader tr = new DirectoryTaxonomyReader(dirs[i]);\n      TaxonomyReader copytr = new DirectoryTaxonomyReader(copydirs[i]);\n      if (i==0) {\n        assertTrue(tr.getSize() >= copytr.getSize());\n      } else {\n        assertEquals(copytr.getSize(), tr.getSize());\n      }\n      for (int j=0; j<copytr.getSize(); j++) {\n        String expected = copytr.getPath(j).toString();\n        String got = tr.getPath(j).toString();\n        assertTrue(\"Comparing category \"+j+\" of taxonomy \"+i+\": expected \"+expected+\", got \"+got,\n            expected.equals(got));\n      }\n      tr.close();\n      copytr.close();\n    }\n\n    // Check that all the new categories in the main taxonomy are in\n    // lexicographic order. This isn't a requirement of our API, but happens\n    // this way in our current implementation.\n    TaxonomyReader tr = new DirectoryTaxonomyReader(dirs[0]);\n    TaxonomyReader copytr = new DirectoryTaxonomyReader(copydirs[0]);\n    if (tr.getSize() > copytr.getSize()) {\n      String prev = tr.getPath(copytr.getSize()).toString();\n      for (int j=copytr.getSize()+1; j<tr.getSize(); j++) {\n        String n = tr.getPath(j).toString();\n        assertTrue(prev.compareTo(n)<0);\n        prev=n;\n      }\n    }\n    int oldsize = copytr.getSize(); // remember for later\n    tr.close();\n    copytr.close();\n\n    // Check that all the categories from other taxonomies exist in the new\n    // taxonomy.\n    TaxonomyReader main = new DirectoryTaxonomyReader(dirs[0]);\n    for (int i=1; i<ntaxonomies; i++) {\n      TaxonomyReader other = new DirectoryTaxonomyReader(dirs[i]);\n      for (int j=0; j<other.getSize(); j++) {\n        int otherord = main.getOrdinal(other.getPath(j));\n        assertTrue(otherord != TaxonomyReader.INVALID_ORDINAL);\n      }\n      other.close();\n    }\n\n    // Check that all the new categories in the merged taxonomy exist in\n    // one of the added taxonomies.\n    TaxonomyReader[] others = new TaxonomyReader[ntaxonomies-1]; \n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1] = new DirectoryTaxonomyReader(dirs[i]);\n    }\n    for (int j=oldsize; j<main.getSize(); j++) {\n      boolean found=false;\n      CategoryPath path = main.getPath(j);\n      for (int i=1; i<ntaxonomies; i++) {\n        if (others[i-1].getOrdinal(path) != TaxonomyReader.INVALID_ORDINAL) {\n          found=true;\n          break;\n        }\n      }\n      if (!found) {\n        fail(\"Found category \"+j+\" (\"+path+\") in merged taxonomy not in any of the separate ones\");\n      }\n    }\n\n    // Check that all the maps are correct\n    for (int i=0; i<ntaxonomies-1; i++) {\n      int[] map = maps[i].getMap();\n      for (int j=0; j<map.length; j++) {\n        assertEquals(map[j], main.getOrdinal(others[i].getPath(j)));\n      }\n    }\n\n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1].close();\n    }\n\n    main.close();\n    IOUtils.close(dirs);\n    IOUtils.close(copydirs);\n  }\n\n","sourceOld":"  private void dotest(int ntaxonomies, int ncats, int range, boolean disk) throws Exception {\n    Directory dirs[] = new Directory[ntaxonomies];\n    Directory copydirs[] = new Directory[ntaxonomies];\n\n    for (int i=0; i<ntaxonomies; i++) {\n      dirs[i] = newDirectory();\n      copydirs[i] = newDirectory();\n      LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[i]);\n      LuceneTaxonomyWriter copytw = new LuceneTaxonomyWriter(copydirs[i]);\n      for (int j=0; j<ncats; j++) {\n        String cat = Integer.toString(random.nextInt(range));\n        tw.addCategory(new CategoryPath(\"a\",cat));\n        copytw.addCategory(new CategoryPath(\"a\",cat));\n      }\n      // System.err.println(\"Taxonomy \"+i+\": \"+tw.getSize());\n      tw.close();\n      copytw.close();\n    }\n\n    LuceneTaxonomyWriter tw = new LuceneTaxonomyWriter(dirs[0]);\n    Directory otherdirs[] = new Directory[ntaxonomies-1];\n    System.arraycopy(dirs, 1, otherdirs, 0, ntaxonomies-1);\n\n    OrdinalMap[] maps = new OrdinalMap[ntaxonomies-1];\n    if (ntaxonomies>1) {\n      for (int i=0; i<ntaxonomies-1; i++) {\n        if (disk) {\n          // TODO: use a LTC tempfile\n          maps[i] = new DiskOrdinalMap(new File(System.getProperty(\"java.io.tmpdir\"),\n              \"tmpmap\"+i));\n        } else {\n          maps[i] = new MemoryOrdinalMap();\n        }\n      }\n    }\n\n    tw.addTaxonomies(otherdirs, maps);\n    // System.err.println(\"Merged axonomy: \"+tw.getSize());\n    tw.close();\n\n    // Check that all original categories in the main taxonomy remain in\n    // unchanged, and the rest of the taxonomies are completely unchanged.\n    for (int i=0; i<ntaxonomies; i++) {\n      TaxonomyReader tr = new LuceneTaxonomyReader(dirs[i]);\n      TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[i]);\n      if (i==0) {\n        assertTrue(tr.getSize() >= copytr.getSize());\n      } else {\n        assertEquals(copytr.getSize(), tr.getSize());\n      }\n      for (int j=0; j<copytr.getSize(); j++) {\n        String expected = copytr.getPath(j).toString();\n        String got = tr.getPath(j).toString();\n        assertTrue(\"Comparing category \"+j+\" of taxonomy \"+i+\": expected \"+expected+\", got \"+got,\n            expected.equals(got));\n      }\n      tr.close();\n      copytr.close();\n    }\n\n    // Check that all the new categories in the main taxonomy are in\n    // lexicographic order. This isn't a requirement of our API, but happens\n    // this way in our current implementation.\n    TaxonomyReader tr = new LuceneTaxonomyReader(dirs[0]);\n    TaxonomyReader copytr = new LuceneTaxonomyReader(copydirs[0]);\n    if (tr.getSize() > copytr.getSize()) {\n      String prev = tr.getPath(copytr.getSize()).toString();\n      for (int j=copytr.getSize()+1; j<tr.getSize(); j++) {\n        String n = tr.getPath(j).toString();\n        assertTrue(prev.compareTo(n)<0);\n        prev=n;\n      }\n    }\n    int oldsize = copytr.getSize(); // remember for later\n    tr.close();\n    copytr.close();\n\n    // Check that all the categories from other taxonomies exist in the new\n    // taxonomy.\n    TaxonomyReader main = new LuceneTaxonomyReader(dirs[0]);\n    for (int i=1; i<ntaxonomies; i++) {\n      TaxonomyReader other = new LuceneTaxonomyReader(dirs[i]);\n      for (int j=0; j<other.getSize(); j++) {\n        int otherord = main.getOrdinal(other.getPath(j));\n        assertTrue(otherord != TaxonomyReader.INVALID_ORDINAL);\n      }\n      other.close();\n    }\n\n    // Check that all the new categories in the merged taxonomy exist in\n    // one of the added taxonomies.\n    TaxonomyReader[] others = new TaxonomyReader[ntaxonomies-1]; \n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1] = new LuceneTaxonomyReader(dirs[i]);\n    }\n    for (int j=oldsize; j<main.getSize(); j++) {\n      boolean found=false;\n      CategoryPath path = main.getPath(j);\n      for (int i=1; i<ntaxonomies; i++) {\n        if (others[i-1].getOrdinal(path) != TaxonomyReader.INVALID_ORDINAL) {\n          found=true;\n          break;\n        }\n      }\n      if (!found) {\n        fail(\"Found category \"+j+\" (\"+path+\") in merged taxonomy not in any of the separate ones\");\n      }\n    }\n\n    // Check that all the maps are correct\n    for (int i=0; i<ntaxonomies-1; i++) {\n      int[] map = maps[i].getMap();\n      for (int j=0; j<map.length; j++) {\n        assertEquals(map[j], main.getOrdinal(others[i].getPath(j)));\n      }\n    }\n\n    for (int i=1; i<ntaxonomies; i++) {\n      others[i-1].close();\n    }\n\n    main.close();\n    IOUtils.close(dirs);\n    IOUtils.close(copydirs);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"24230fe54121f9be9d85f2c2067536296785e421":["7a4df66e06e0c3b520d7d5941e1c043076f06f17"],"ea469eab8fd0f3032f4fcde1c644a721e8309d3b":["24230fe54121f9be9d85f2c2067536296785e421"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7a4df66e06e0c3b520d7d5941e1c043076f06f17":["89f15687f60bd49cd3d9de427e85c17fd9397d61"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","7a4df66e06e0c3b520d7d5941e1c043076f06f17"],"89f15687f60bd49cd3d9de427e85c17fd9397d61":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","7a4df66e06e0c3b520d7d5941e1c043076f06f17"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ea469eab8fd0f3032f4fcde1c644a721e8309d3b"]},"commit2Childs":{"24230fe54121f9be9d85f2c2067536296785e421":["ea469eab8fd0f3032f4fcde1c644a721e8309d3b"],"ea469eab8fd0f3032f4fcde1c644a721e8309d3b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d083e83f225b11e5fdd900e83d26ddb385b6955c","89f15687f60bd49cd3d9de427e85c17fd9397d61","817d8435e9135b756f08ce6710ab0baac51bdf88"],"7a4df66e06e0c3b520d7d5941e1c043076f06f17":["24230fe54121f9be9d85f2c2067536296785e421","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"89f15687f60bd49cd3d9de427e85c17fd9397d61":["7a4df66e06e0c3b520d7d5941e1c043076f06f17"],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}