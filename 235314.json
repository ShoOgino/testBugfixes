{"path":"solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.BootstrapCallable#call().mjava","commits":[{"id":"06e38ae84477e7a7eacea808dc3de9950fce5ccf","date":1470634560,"type":0,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.BootstrapCallable#call().mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public Boolean call() throws Exception {\n      boolean success = false;\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      // we start buffering updates as a safeguard however we do not expect\n      // to receive any updates from the source during bootstrap\n      ulog.bufferUpdates();\n      try {\n        commitOnLeader(masterUrl);\n        // use rep handler directly, so we can do this sync rather than async\n        SolrRequestHandler handler = core.getRequestHandler(ReplicationHandler.PATH);\n        ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n\n        if (replicationHandler == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"Skipping recovery, no \" + ReplicationHandler.PATH + \" handler found\");\n        }\n\n        ModifiableSolrParams solrParams = new ModifiableSolrParams();\n        solrParams.set(ReplicationHandler.MASTER_URL, masterUrl);\n        // we do not want the raw tlog files from the source\n        solrParams.set(ReplicationHandler.TLOG_FILES, false);\n\n        success = replicationHandler.doFetch(solrParams, false);\n\n        // this is required because this callable can race with HttpSolrCall#destroy\n        // which clears the request info.\n        // Applying buffered updates fails without the following line because LogReplayer\n        // also tries to set request info and fails with AssertionError\n        SolrRequestInfo.clearRequestInfo();\n\n        Future<UpdateLog.RecoveryInfo> future = ulog.applyBufferedUpdates();\n        if (future == null) {\n          // no replay needed\n          log.info(\"No replay needed.\");\n        } else {\n          log.info(\"Replaying buffered documents.\");\n          // wait for replay\n          UpdateLog.RecoveryInfo report = future.get();\n          if (report.failed) {\n            SolrException.log(log, \"Replay failed\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Replay failed\");\n          }\n        }\n        return success;\n      } finally {\n        if (closed || !success) {\n          // we cannot apply the buffer in this case because it will introduce newer versions in the\n          // update log and then the source cluster will get those versions via collectioncheckpoint\n          // causing the versions in between to be completely missed\n          boolean dropped = ulog.dropBufferedUpdates();\n          assert dropped;\n        }\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.BootstrapCallable#call().mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public Boolean call() throws Exception {\n      boolean success = false;\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      // we start buffering updates as a safeguard however we do not expect\n      // to receive any updates from the source during bootstrap\n      ulog.bufferUpdates();\n      try {\n        commitOnLeader(masterUrl);\n        // use rep handler directly, so we can do this sync rather than async\n        SolrRequestHandler handler = core.getRequestHandler(ReplicationHandler.PATH);\n        ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n\n        if (replicationHandler == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"Skipping recovery, no \" + ReplicationHandler.PATH + \" handler found\");\n        }\n\n        ModifiableSolrParams solrParams = new ModifiableSolrParams();\n        solrParams.set(ReplicationHandler.MASTER_URL, masterUrl);\n        // we do not want the raw tlog files from the source\n        solrParams.set(ReplicationHandler.TLOG_FILES, false);\n\n        success = replicationHandler.doFetch(solrParams, false);\n\n        // this is required because this callable can race with HttpSolrCall#destroy\n        // which clears the request info.\n        // Applying buffered updates fails without the following line because LogReplayer\n        // also tries to set request info and fails with AssertionError\n        SolrRequestInfo.clearRequestInfo();\n\n        Future<UpdateLog.RecoveryInfo> future = ulog.applyBufferedUpdates();\n        if (future == null) {\n          // no replay needed\n          log.info(\"No replay needed.\");\n        } else {\n          log.info(\"Replaying buffered documents.\");\n          // wait for replay\n          UpdateLog.RecoveryInfo report = future.get();\n          if (report.failed) {\n            SolrException.log(log, \"Replay failed\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Replay failed\");\n          }\n        }\n        return success;\n      } finally {\n        if (closed || !success) {\n          // we cannot apply the buffer in this case because it will introduce newer versions in the\n          // update log and then the source cluster will get those versions via collectioncheckpoint\n          // causing the versions in between to be completely missed\n          boolean dropped = ulog.dropBufferedUpdates();\n          assert dropped;\n        }\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.BootstrapCallable#call().mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public Boolean call() throws Exception {\n      boolean success = false;\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      // we start buffering updates as a safeguard however we do not expect\n      // to receive any updates from the source during bootstrap\n      ulog.bufferUpdates();\n      try {\n        commitOnLeader(masterUrl);\n        // use rep handler directly, so we can do this sync rather than async\n        SolrRequestHandler handler = core.getRequestHandler(ReplicationHandler.PATH);\n        ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n\n        if (replicationHandler == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"Skipping recovery, no \" + ReplicationHandler.PATH + \" handler found\");\n        }\n\n        ModifiableSolrParams solrParams = new ModifiableSolrParams();\n        solrParams.set(ReplicationHandler.MASTER_URL, masterUrl);\n        // we do not want the raw tlog files from the source\n        solrParams.set(ReplicationHandler.TLOG_FILES, false);\n\n        success = replicationHandler.doFetch(solrParams, false);\n\n        // this is required because this callable can race with HttpSolrCall#destroy\n        // which clears the request info.\n        // Applying buffered updates fails without the following line because LogReplayer\n        // also tries to set request info and fails with AssertionError\n        SolrRequestInfo.clearRequestInfo();\n\n        Future<UpdateLog.RecoveryInfo> future = ulog.applyBufferedUpdates();\n        if (future == null) {\n          // no replay needed\n          log.info(\"No replay needed.\");\n        } else {\n          log.info(\"Replaying buffered documents.\");\n          // wait for replay\n          UpdateLog.RecoveryInfo report = future.get();\n          if (report.failed) {\n            SolrException.log(log, \"Replay failed\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Replay failed\");\n          }\n        }\n        return success;\n      } finally {\n        if (closed || !success) {\n          // we cannot apply the buffer in this case because it will introduce newer versions in the\n          // update log and then the source cluster will get those versions via collectioncheckpoint\n          // causing the versions in between to be completely missed\n          boolean dropped = ulog.dropBufferedUpdates();\n          assert dropped;\n        }\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c641347aa34a81b8c172fd46691e3cba6357a6f","date":1490409984,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.BootstrapCallable#call().mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.BootstrapCallable#call().mjava","sourceNew":"    @Override\n    public Boolean call() throws Exception {\n      boolean success = false;\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      // we start buffering updates as a safeguard however we do not expect\n      // to receive any updates from the source during bootstrap\n      ulog.bufferUpdates();\n      try {\n        commitOnLeader(masterUrl);\n        // use rep handler directly, so we can do this sync rather than async\n        SolrRequestHandler handler = core.getRequestHandler(ReplicationHandler.PATH);\n        ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n\n        if (replicationHandler == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"Skipping recovery, no \" + ReplicationHandler.PATH + \" handler found\");\n        }\n\n        ModifiableSolrParams solrParams = new ModifiableSolrParams();\n        solrParams.set(ReplicationHandler.MASTER_URL, masterUrl);\n        // we do not want the raw tlog files from the source\n        solrParams.set(ReplicationHandler.TLOG_FILES, false);\n\n        success = replicationHandler.doFetch(solrParams, false).getSuccessful();\n\n        // this is required because this callable can race with HttpSolrCall#destroy\n        // which clears the request info.\n        // Applying buffered updates fails without the following line because LogReplayer\n        // also tries to set request info and fails with AssertionError\n        SolrRequestInfo.clearRequestInfo();\n\n        Future<UpdateLog.RecoveryInfo> future = ulog.applyBufferedUpdates();\n        if (future == null) {\n          // no replay needed\n          log.info(\"No replay needed.\");\n        } else {\n          log.info(\"Replaying buffered documents.\");\n          // wait for replay\n          UpdateLog.RecoveryInfo report = future.get();\n          if (report.failed) {\n            SolrException.log(log, \"Replay failed\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Replay failed\");\n          }\n        }\n        return success;\n      } finally {\n        if (closed || !success) {\n          // we cannot apply the buffer in this case because it will introduce newer versions in the\n          // update log and then the source cluster will get those versions via collectioncheckpoint\n          // causing the versions in between to be completely missed\n          boolean dropped = ulog.dropBufferedUpdates();\n          assert dropped;\n        }\n      }\n    }\n\n","sourceOld":"    @Override\n    public Boolean call() throws Exception {\n      boolean success = false;\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      // we start buffering updates as a safeguard however we do not expect\n      // to receive any updates from the source during bootstrap\n      ulog.bufferUpdates();\n      try {\n        commitOnLeader(masterUrl);\n        // use rep handler directly, so we can do this sync rather than async\n        SolrRequestHandler handler = core.getRequestHandler(ReplicationHandler.PATH);\n        ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n\n        if (replicationHandler == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"Skipping recovery, no \" + ReplicationHandler.PATH + \" handler found\");\n        }\n\n        ModifiableSolrParams solrParams = new ModifiableSolrParams();\n        solrParams.set(ReplicationHandler.MASTER_URL, masterUrl);\n        // we do not want the raw tlog files from the source\n        solrParams.set(ReplicationHandler.TLOG_FILES, false);\n\n        success = replicationHandler.doFetch(solrParams, false);\n\n        // this is required because this callable can race with HttpSolrCall#destroy\n        // which clears the request info.\n        // Applying buffered updates fails without the following line because LogReplayer\n        // also tries to set request info and fails with AssertionError\n        SolrRequestInfo.clearRequestInfo();\n\n        Future<UpdateLog.RecoveryInfo> future = ulog.applyBufferedUpdates();\n        if (future == null) {\n          // no replay needed\n          log.info(\"No replay needed.\");\n        } else {\n          log.info(\"Replaying buffered documents.\");\n          // wait for replay\n          UpdateLog.RecoveryInfo report = future.get();\n          if (report.failed) {\n            SolrException.log(log, \"Replay failed\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Replay failed\");\n          }\n        }\n        return success;\n      } finally {\n        if (closed || !success) {\n          // we cannot apply the buffer in this case because it will introduce newer versions in the\n          // update log and then the source cluster will get those versions via collectioncheckpoint\n          // causing the versions in between to be completely missed\n          boolean dropped = ulog.dropBufferedUpdates();\n          assert dropped;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d5f6959c652bdf332fe98fc9180b54095a4053ae","date":1490594650,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.BootstrapCallable#call().mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.BootstrapCallable#call().mjava","sourceNew":"    @Override\n    public Boolean call() throws Exception {\n      boolean success = false;\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      // we start buffering updates as a safeguard however we do not expect\n      // to receive any updates from the source during bootstrap\n      ulog.bufferUpdates();\n      try {\n        commitOnLeader(masterUrl);\n        // use rep handler directly, so we can do this sync rather than async\n        SolrRequestHandler handler = core.getRequestHandler(ReplicationHandler.PATH);\n        ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n\n        if (replicationHandler == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"Skipping recovery, no \" + ReplicationHandler.PATH + \" handler found\");\n        }\n\n        ModifiableSolrParams solrParams = new ModifiableSolrParams();\n        solrParams.set(ReplicationHandler.MASTER_URL, masterUrl);\n        // we do not want the raw tlog files from the source\n        solrParams.set(ReplicationHandler.TLOG_FILES, false);\n\n        success = replicationHandler.doFetch(solrParams, false).getSuccessful();\n\n        // this is required because this callable can race with HttpSolrCall#destroy\n        // which clears the request info.\n        // Applying buffered updates fails without the following line because LogReplayer\n        // also tries to set request info and fails with AssertionError\n        SolrRequestInfo.clearRequestInfo();\n\n        Future<UpdateLog.RecoveryInfo> future = ulog.applyBufferedUpdates();\n        if (future == null) {\n          // no replay needed\n          log.info(\"No replay needed.\");\n        } else {\n          log.info(\"Replaying buffered documents.\");\n          // wait for replay\n          UpdateLog.RecoveryInfo report = future.get();\n          if (report.failed) {\n            SolrException.log(log, \"Replay failed\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Replay failed\");\n          }\n        }\n        return success;\n      } finally {\n        if (closed || !success) {\n          // we cannot apply the buffer in this case because it will introduce newer versions in the\n          // update log and then the source cluster will get those versions via collectioncheckpoint\n          // causing the versions in between to be completely missed\n          boolean dropped = ulog.dropBufferedUpdates();\n          assert dropped;\n        }\n      }\n    }\n\n","sourceOld":"    @Override\n    public Boolean call() throws Exception {\n      boolean success = false;\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      // we start buffering updates as a safeguard however we do not expect\n      // to receive any updates from the source during bootstrap\n      ulog.bufferUpdates();\n      try {\n        commitOnLeader(masterUrl);\n        // use rep handler directly, so we can do this sync rather than async\n        SolrRequestHandler handler = core.getRequestHandler(ReplicationHandler.PATH);\n        ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n\n        if (replicationHandler == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"Skipping recovery, no \" + ReplicationHandler.PATH + \" handler found\");\n        }\n\n        ModifiableSolrParams solrParams = new ModifiableSolrParams();\n        solrParams.set(ReplicationHandler.MASTER_URL, masterUrl);\n        // we do not want the raw tlog files from the source\n        solrParams.set(ReplicationHandler.TLOG_FILES, false);\n\n        success = replicationHandler.doFetch(solrParams, false);\n\n        // this is required because this callable can race with HttpSolrCall#destroy\n        // which clears the request info.\n        // Applying buffered updates fails without the following line because LogReplayer\n        // also tries to set request info and fails with AssertionError\n        SolrRequestInfo.clearRequestInfo();\n\n        Future<UpdateLog.RecoveryInfo> future = ulog.applyBufferedUpdates();\n        if (future == null) {\n          // no replay needed\n          log.info(\"No replay needed.\");\n        } else {\n          log.info(\"Replaying buffered documents.\");\n          // wait for replay\n          UpdateLog.RecoveryInfo report = future.get();\n          if (report.failed) {\n            SolrException.log(log, \"Replay failed\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Replay failed\");\n          }\n        }\n        return success;\n      } finally {\n        if (closed || !success) {\n          // we cannot apply the buffer in this case because it will introduce newer versions in the\n          // update log and then the source cluster will get those versions via collectioncheckpoint\n          // causing the versions in between to be completely missed\n          boolean dropped = ulog.dropBufferedUpdates();\n          assert dropped;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"160430584bb0ed88bd4cb089d89d53a0db81f90e","date":1565319532,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.BootstrapCallable#call().mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.BootstrapCallable#call().mjava","sourceNew":"    @Override\n    public Boolean call() throws Exception {\n      boolean success = false;\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      // we start buffering updates as a safeguard however we do not expect\n      // to receive any updates from the source during bootstrap\n      ulog.bufferUpdates();\n      try {\n        commitOnLeader(masterUrl);\n        // use rep handler directly, so we can do this sync rather than async\n        SolrRequestHandler handler = core.getRequestHandler(ReplicationHandler.PATH);\n        ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n\n        if (replicationHandler == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"Skipping recovery, no \" + ReplicationHandler.PATH + \" handler found\");\n        }\n\n        ModifiableSolrParams solrParams = new ModifiableSolrParams();\n        solrParams.set(ReplicationHandler.MASTER_URL, masterUrl);\n        // we do not want the raw tlog files from the source\n        solrParams.set(ReplicationHandler.TLOG_FILES, false);\n\n        success = replicationHandler.doFetch(solrParams, false).getSuccessful();\n\n        // this is required because this callable can race with HttpSolrCall#destroy\n        // which clears the request info.\n        // Applying buffered updates fails without the following line because LogReplayer\n        // also tries to set request info and fails with AssertionError\n        SolrRequestInfo.clearRequestInfo();\n\n        Future<UpdateLog.RecoveryInfo> future = ulog.applyBufferedUpdates();\n        if (future == null) {\n          // no replay needed\n          log.info(\"No replay needed.\");\n        } else {\n          log.info(\"Replaying buffered documents.\");\n          // wait for replay\n          UpdateLog.RecoveryInfo report = future.get();\n          if (report.failed) {\n            SolrException.log(log, \"Replay failed\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Replay failed\");\n          }\n        }\n        if (success)  {\n          ZkController zkController = core.getCoreContainer().getZkController();\n          String collectionName = core.getCoreDescriptor().getCollectionName();\n          ClusterState clusterState = zkController.getZkStateReader().getClusterState();\n          DocCollection collection = clusterState.getCollection(collectionName);\n          Slice slice = collection.getSlice(core.getCoreDescriptor().getCloudDescriptor().getShardId());\n          ZkShardTerms terms = zkController.getShardTerms(collectionName, slice.getName());\n          String coreNodeName = core.getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n          Set<String> allExceptLeader = slice.getReplicas().stream().filter(replica -> !replica.getName().equals(coreNodeName)).map(Replica::getName).collect(Collectors.toSet());\n          terms.ensureTermsIsHigher(coreNodeName, allExceptLeader);\n        }\n        return success;\n      } finally {\n        if (closed || !success) {\n          // we cannot apply the buffer in this case because it will introduce newer versions in the\n          // update log and then the source cluster will get those versions via collectioncheckpoint\n          // causing the versions in between to be completely missed\n          boolean dropped = ulog.dropBufferedUpdates();\n          assert dropped;\n        }\n      }\n    }\n\n","sourceOld":"    @Override\n    public Boolean call() throws Exception {\n      boolean success = false;\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      // we start buffering updates as a safeguard however we do not expect\n      // to receive any updates from the source during bootstrap\n      ulog.bufferUpdates();\n      try {\n        commitOnLeader(masterUrl);\n        // use rep handler directly, so we can do this sync rather than async\n        SolrRequestHandler handler = core.getRequestHandler(ReplicationHandler.PATH);\n        ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n\n        if (replicationHandler == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"Skipping recovery, no \" + ReplicationHandler.PATH + \" handler found\");\n        }\n\n        ModifiableSolrParams solrParams = new ModifiableSolrParams();\n        solrParams.set(ReplicationHandler.MASTER_URL, masterUrl);\n        // we do not want the raw tlog files from the source\n        solrParams.set(ReplicationHandler.TLOG_FILES, false);\n\n        success = replicationHandler.doFetch(solrParams, false).getSuccessful();\n\n        // this is required because this callable can race with HttpSolrCall#destroy\n        // which clears the request info.\n        // Applying buffered updates fails without the following line because LogReplayer\n        // also tries to set request info and fails with AssertionError\n        SolrRequestInfo.clearRequestInfo();\n\n        Future<UpdateLog.RecoveryInfo> future = ulog.applyBufferedUpdates();\n        if (future == null) {\n          // no replay needed\n          log.info(\"No replay needed.\");\n        } else {\n          log.info(\"Replaying buffered documents.\");\n          // wait for replay\n          UpdateLog.RecoveryInfo report = future.get();\n          if (report.failed) {\n            SolrException.log(log, \"Replay failed\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Replay failed\");\n          }\n        }\n        return success;\n      } finally {\n        if (closed || !success) {\n          // we cannot apply the buffer in this case because it will introduce newer versions in the\n          // update log and then the source cluster will get those versions via collectioncheckpoint\n          // causing the versions in between to be completely missed\n          boolean dropped = ulog.dropBufferedUpdates();\n          assert dropped;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a32e902eb5b2408fefa7ca7a8579e22f4ba6f2b4","date":1592286410,"type":3,"author":"Nazerke Seidan","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.BootstrapCallable#call().mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.BootstrapCallable#call().mjava","sourceNew":"    @Override\n    public Boolean call() throws Exception {\n      boolean success = false;\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      // we start buffering updates as a safeguard however we do not expect\n      // to receive any updates from the source during bootstrap\n      ulog.bufferUpdates();\n      try {\n        commitOnLeader(masterUrl);\n        // use rep handler directly, so we can do this sync rather than async\n        SolrRequestHandler handler = core.getRequestHandler(ReplicationHandler.PATH);\n        ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n\n        if (replicationHandler == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"Skipping recovery, no \" + ReplicationHandler.PATH + \" handler found\");\n        }\n\n        ModifiableSolrParams solrParams = new ModifiableSolrParams();\n        solrParams.set(ReplicationHandler.MASTER_URL, masterUrl);\n        // we do not want the raw tlog files from the source\n        solrParams.set(ReplicationHandler.TLOG_FILES, false);\n\n        success = replicationHandler.doFetch(solrParams, false).getSuccessful();\n\n        Future<UpdateLog.RecoveryInfo> future = ulog.applyBufferedUpdates();\n        if (future == null) {\n          // no replay needed\n          log.info(\"No replay needed.\");\n        } else {\n          log.info(\"Replaying buffered documents.\");\n          // wait for replay\n          UpdateLog.RecoveryInfo report = future.get();\n          if (report.failed) {\n            SolrException.log(log, \"Replay failed\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Replay failed\");\n          }\n        }\n        if (success)  {\n          ZkController zkController = core.getCoreContainer().getZkController();\n          String collectionName = core.getCoreDescriptor().getCollectionName();\n          ClusterState clusterState = zkController.getZkStateReader().getClusterState();\n          DocCollection collection = clusterState.getCollection(collectionName);\n          Slice slice = collection.getSlice(core.getCoreDescriptor().getCloudDescriptor().getShardId());\n          ZkShardTerms terms = zkController.getShardTerms(collectionName, slice.getName());\n          String coreNodeName = core.getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n          Set<String> allExceptLeader = slice.getReplicas().stream().filter(replica -> !replica.getName().equals(coreNodeName)).map(Replica::getName).collect(Collectors.toSet());\n          terms.ensureTermsIsHigher(coreNodeName, allExceptLeader);\n        }\n        return success;\n      } finally {\n        if (closed || !success) {\n          // we cannot apply the buffer in this case because it will introduce newer versions in the\n          // update log and then the source cluster will get those versions via collectioncheckpoint\n          // causing the versions in between to be completely missed\n          boolean dropped = ulog.dropBufferedUpdates();\n          assert dropped;\n        }\n      }\n    }\n\n","sourceOld":"    @Override\n    public Boolean call() throws Exception {\n      boolean success = false;\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      // we start buffering updates as a safeguard however we do not expect\n      // to receive any updates from the source during bootstrap\n      ulog.bufferUpdates();\n      try {\n        commitOnLeader(masterUrl);\n        // use rep handler directly, so we can do this sync rather than async\n        SolrRequestHandler handler = core.getRequestHandler(ReplicationHandler.PATH);\n        ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n\n        if (replicationHandler == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"Skipping recovery, no \" + ReplicationHandler.PATH + \" handler found\");\n        }\n\n        ModifiableSolrParams solrParams = new ModifiableSolrParams();\n        solrParams.set(ReplicationHandler.MASTER_URL, masterUrl);\n        // we do not want the raw tlog files from the source\n        solrParams.set(ReplicationHandler.TLOG_FILES, false);\n\n        success = replicationHandler.doFetch(solrParams, false).getSuccessful();\n\n        // this is required because this callable can race with HttpSolrCall#destroy\n        // which clears the request info.\n        // Applying buffered updates fails without the following line because LogReplayer\n        // also tries to set request info and fails with AssertionError\n        SolrRequestInfo.clearRequestInfo();\n\n        Future<UpdateLog.RecoveryInfo> future = ulog.applyBufferedUpdates();\n        if (future == null) {\n          // no replay needed\n          log.info(\"No replay needed.\");\n        } else {\n          log.info(\"Replaying buffered documents.\");\n          // wait for replay\n          UpdateLog.RecoveryInfo report = future.get();\n          if (report.failed) {\n            SolrException.log(log, \"Replay failed\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Replay failed\");\n          }\n        }\n        if (success)  {\n          ZkController zkController = core.getCoreContainer().getZkController();\n          String collectionName = core.getCoreDescriptor().getCollectionName();\n          ClusterState clusterState = zkController.getZkStateReader().getClusterState();\n          DocCollection collection = clusterState.getCollection(collectionName);\n          Slice slice = collection.getSlice(core.getCoreDescriptor().getCloudDescriptor().getShardId());\n          ZkShardTerms terms = zkController.getShardTerms(collectionName, slice.getName());\n          String coreNodeName = core.getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n          Set<String> allExceptLeader = slice.getReplicas().stream().filter(replica -> !replica.getName().equals(coreNodeName)).map(Replica::getName).collect(Collectors.toSet());\n          terms.ensureTermsIsHigher(coreNodeName, allExceptLeader);\n        }\n        return success;\n      } finally {\n        if (closed || !success) {\n          // we cannot apply the buffer in this case because it will introduce newer versions in the\n          // update log and then the source cluster will get those versions via collectioncheckpoint\n          // causing the versions in between to be completely missed\n          boolean dropped = ulog.dropBufferedUpdates();\n          assert dropped;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e","date":1596664368,"type":3,"author":"Marcus","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.BootstrapCallable#call().mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.BootstrapCallable#call().mjava","sourceNew":"    @Override\n    public Boolean call() throws Exception {\n      boolean success = false;\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      // we start buffering updates as a safeguard however we do not expect\n      // to receive any updates from the source during bootstrap\n      ulog.bufferUpdates();\n      try {\n        commitOnLeader(leaderUrl);\n        // use rep handler directly, so we can do this sync rather than async\n        SolrRequestHandler handler = core.getRequestHandler(ReplicationHandler.PATH);\n        ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n\n        if (replicationHandler == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"Skipping recovery, no \" + ReplicationHandler.PATH + \" handler found\");\n        }\n\n        ModifiableSolrParams solrParams = new ModifiableSolrParams();\n        solrParams.set(ReplicationHandler.LEADER_URL, leaderUrl);\n        // we do not want the raw tlog files from the source\n        solrParams.set(ReplicationHandler.TLOG_FILES, false);\n\n        success = replicationHandler.doFetch(solrParams, false).getSuccessful();\n\n        Future<UpdateLog.RecoveryInfo> future = ulog.applyBufferedUpdates();\n        if (future == null) {\n          // no replay needed\n          log.info(\"No replay needed.\");\n        } else {\n          log.info(\"Replaying buffered documents.\");\n          // wait for replay\n          UpdateLog.RecoveryInfo report = future.get();\n          if (report.failed) {\n            SolrException.log(log, \"Replay failed\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Replay failed\");\n          }\n        }\n        if (success)  {\n          ZkController zkController = core.getCoreContainer().getZkController();\n          String collectionName = core.getCoreDescriptor().getCollectionName();\n          ClusterState clusterState = zkController.getZkStateReader().getClusterState();\n          DocCollection collection = clusterState.getCollection(collectionName);\n          Slice slice = collection.getSlice(core.getCoreDescriptor().getCloudDescriptor().getShardId());\n          ZkShardTerms terms = zkController.getShardTerms(collectionName, slice.getName());\n          String coreNodeName = core.getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n          Set<String> allExceptLeader = slice.getReplicas().stream().filter(replica -> !replica.getName().equals(coreNodeName)).map(Replica::getName).collect(Collectors.toSet());\n          terms.ensureTermsIsHigher(coreNodeName, allExceptLeader);\n        }\n        return success;\n      } finally {\n        if (closed || !success) {\n          // we cannot apply the buffer in this case because it will introduce newer versions in the\n          // update log and then the source cluster will get those versions via collectioncheckpoint\n          // causing the versions in between to be completely missed\n          boolean dropped = ulog.dropBufferedUpdates();\n          assert dropped;\n        }\n      }\n    }\n\n","sourceOld":"    @Override\n    public Boolean call() throws Exception {\n      boolean success = false;\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      // we start buffering updates as a safeguard however we do not expect\n      // to receive any updates from the source during bootstrap\n      ulog.bufferUpdates();\n      try {\n        commitOnLeader(masterUrl);\n        // use rep handler directly, so we can do this sync rather than async\n        SolrRequestHandler handler = core.getRequestHandler(ReplicationHandler.PATH);\n        ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n\n        if (replicationHandler == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"Skipping recovery, no \" + ReplicationHandler.PATH + \" handler found\");\n        }\n\n        ModifiableSolrParams solrParams = new ModifiableSolrParams();\n        solrParams.set(ReplicationHandler.MASTER_URL, masterUrl);\n        // we do not want the raw tlog files from the source\n        solrParams.set(ReplicationHandler.TLOG_FILES, false);\n\n        success = replicationHandler.doFetch(solrParams, false).getSuccessful();\n\n        Future<UpdateLog.RecoveryInfo> future = ulog.applyBufferedUpdates();\n        if (future == null) {\n          // no replay needed\n          log.info(\"No replay needed.\");\n        } else {\n          log.info(\"Replaying buffered documents.\");\n          // wait for replay\n          UpdateLog.RecoveryInfo report = future.get();\n          if (report.failed) {\n            SolrException.log(log, \"Replay failed\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Replay failed\");\n          }\n        }\n        if (success)  {\n          ZkController zkController = core.getCoreContainer().getZkController();\n          String collectionName = core.getCoreDescriptor().getCollectionName();\n          ClusterState clusterState = zkController.getZkStateReader().getClusterState();\n          DocCollection collection = clusterState.getCollection(collectionName);\n          Slice slice = collection.getSlice(core.getCoreDescriptor().getCloudDescriptor().getShardId());\n          ZkShardTerms terms = zkController.getShardTerms(collectionName, slice.getName());\n          String coreNodeName = core.getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n          Set<String> allExceptLeader = slice.getReplicas().stream().filter(replica -> !replica.getName().equals(coreNodeName)).map(Replica::getName).collect(Collectors.toSet());\n          terms.ensureTermsIsHigher(coreNodeName, allExceptLeader);\n        }\n        return success;\n      } finally {\n        if (closed || !success) {\n          // we cannot apply the buffer in this case because it will introduce newer versions in the\n          // update log and then the source cluster will get those versions via collectioncheckpoint\n          // causing the versions in between to be completely missed\n          boolean dropped = ulog.dropBufferedUpdates();\n          assert dropped;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1","date":1598647393,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/handler/CdcrRequestHandler.BootstrapCallable#call().mjava","sourceNew":null,"sourceOld":"    @Override\n    public Boolean call() throws Exception {\n      boolean success = false;\n      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();\n      // we start buffering updates as a safeguard however we do not expect\n      // to receive any updates from the source during bootstrap\n      ulog.bufferUpdates();\n      try {\n        commitOnLeader(leaderUrl);\n        // use rep handler directly, so we can do this sync rather than async\n        SolrRequestHandler handler = core.getRequestHandler(ReplicationHandler.PATH);\n        ReplicationHandler replicationHandler = (ReplicationHandler) handler;\n\n        if (replicationHandler == null) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"Skipping recovery, no \" + ReplicationHandler.PATH + \" handler found\");\n        }\n\n        ModifiableSolrParams solrParams = new ModifiableSolrParams();\n        solrParams.set(ReplicationHandler.LEADER_URL, leaderUrl);\n        // we do not want the raw tlog files from the source\n        solrParams.set(ReplicationHandler.TLOG_FILES, false);\n\n        success = replicationHandler.doFetch(solrParams, false).getSuccessful();\n\n        Future<UpdateLog.RecoveryInfo> future = ulog.applyBufferedUpdates();\n        if (future == null) {\n          // no replay needed\n          log.info(\"No replay needed.\");\n        } else {\n          log.info(\"Replaying buffered documents.\");\n          // wait for replay\n          UpdateLog.RecoveryInfo report = future.get();\n          if (report.failed) {\n            SolrException.log(log, \"Replay failed\");\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Replay failed\");\n          }\n        }\n        if (success)  {\n          ZkController zkController = core.getCoreContainer().getZkController();\n          String collectionName = core.getCoreDescriptor().getCollectionName();\n          ClusterState clusterState = zkController.getZkStateReader().getClusterState();\n          DocCollection collection = clusterState.getCollection(collectionName);\n          Slice slice = collection.getSlice(core.getCoreDescriptor().getCloudDescriptor().getShardId());\n          ZkShardTerms terms = zkController.getShardTerms(collectionName, slice.getName());\n          String coreNodeName = core.getCoreDescriptor().getCloudDescriptor().getCoreNodeName();\n          Set<String> allExceptLeader = slice.getReplicas().stream().filter(replica -> !replica.getName().equals(coreNodeName)).map(Replica::getName).collect(Collectors.toSet());\n          terms.ensureTermsIsHigher(coreNodeName, allExceptLeader);\n        }\n        return success;\n      } finally {\n        if (closed || !success) {\n          // we cannot apply the buffer in this case because it will introduce newer versions in the\n          // update log and then the source cluster will get those versions via collectioncheckpoint\n          // causing the versions in between to be completely missed\n          boolean dropped = ulog.dropBufferedUpdates();\n          assert dropped;\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"160430584bb0ed88bd4cb089d89d53a0db81f90e":["7c641347aa34a81b8c172fd46691e3cba6357a6f"],"7c641347aa34a81b8c172fd46691e3cba6357a6f":["06e38ae84477e7a7eacea808dc3de9950fce5ccf"],"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e":["a32e902eb5b2408fefa7ca7a8579e22f4ba6f2b4"],"d5f6959c652bdf332fe98fc9180b54095a4053ae":["06e38ae84477e7a7eacea808dc3de9950fce5ccf"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"06e38ae84477e7a7eacea808dc3de9950fce5ccf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1":["65a5d87a40f9143cd55be76eb1dde1b32a8dae5e"],"a32e902eb5b2408fefa7ca7a8579e22f4ba6f2b4":["160430584bb0ed88bd4cb089d89d53a0db81f90e"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","06e38ae84477e7a7eacea808dc3de9950fce5ccf"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","06e38ae84477e7a7eacea808dc3de9950fce5ccf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1"]},"commit2Childs":{"160430584bb0ed88bd4cb089d89d53a0db81f90e":["a32e902eb5b2408fefa7ca7a8579e22f4ba6f2b4"],"7c641347aa34a81b8c172fd46691e3cba6357a6f":["160430584bb0ed88bd4cb089d89d53a0db81f90e"],"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e":["23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1"],"d5f6959c652bdf332fe98fc9180b54095a4053ae":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["06e38ae84477e7a7eacea808dc3de9950fce5ccf","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"06e38ae84477e7a7eacea808dc3de9950fce5ccf":["7c641347aa34a81b8c172fd46691e3cba6357a6f","d5f6959c652bdf332fe98fc9180b54095a4053ae","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"a32e902eb5b2408fefa7ca7a8579e22f4ba6f2b4":["65a5d87a40f9143cd55be76eb1dde1b32a8dae5e"],"23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d5f6959c652bdf332fe98fc9180b54095a4053ae","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}