{"path":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericField.DataType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (numericTokenStream == null) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        numericTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n        // initialize value in TokenStream\n        final Number val = (Number) fieldsData;\n        switch (numericType) {\n        case INT:\n          numericTokenStream.setIntValue(val.intValue());\n          break;\n        case LONG:\n          numericTokenStream.setLongValue(val.longValue());\n          break;\n        case FLOAT:\n          numericTokenStream.setFloatValue(val.floatValue());\n          break;\n        case DOUBLE:\n          numericTokenStream.setDoubleValue(val.doubleValue());\n          break;\n        default:\n          assert false : \"Should never get here\";\n        }\n      } else {\n        // OK -- previously cached and we already updated if\n        // setters were called.\n      }\n\n      return numericTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n\n      return new TokenStream() {\n        CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);\n        boolean used;\n\n        @Override\n        public boolean incrementToken() throws IOException {\n          if (used) {\n            return false;\n          }\n          termAttribute.setEmpty().append(stringValue());\n          offsetAttribute.setOffset(0, stringValue().length());\n          used = true;\n          return true;\n        }\n\n        @Override\n        public void reset() throws IOException {\n          used = false;\n        }\n      };\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","sourceOld":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericField.DataType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (numericTokenStream == null) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        numericTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n        // initialize value in TokenStream\n        final Number val = (Number) fieldsData;\n        switch (numericType) {\n        case INT:\n          numericTokenStream.setIntValue(val.intValue());\n          break;\n        case LONG:\n          numericTokenStream.setLongValue(val.longValue());\n          break;\n        case FLOAT:\n          numericTokenStream.setFloatValue(val.floatValue());\n          break;\n        case DOUBLE:\n          numericTokenStream.setDoubleValue(val.doubleValue());\n          break;\n        default:\n          assert false : \"Should never get here\";\n        }\n      } else {\n        // OK -- previously cached and we already updated if\n        // setters were called.\n      }\n\n      return numericTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n\n      return new TokenStream() {\n        CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);\n        boolean used;\n\n        @Override\n        public boolean incrementToken() throws IOException {\n          if (used) {\n            return false;\n          }\n          termAttribute.setEmpty().append(stringValue());\n          offsetAttribute.setOffset(0, stringValue().length());\n          used = true;\n          return true;\n        }\n\n        @Override\n        public void reset() throws IOException {\n          used = false;\n        }\n      };\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a78a90fc9701e511308346ea29f4f5e548bb39fe","date":1329489995,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (numericTokenStream == null) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        numericTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n        // initialize value in TokenStream\n        final Number val = (Number) fieldsData;\n        switch (numericType) {\n        case INT:\n          numericTokenStream.setIntValue(val.intValue());\n          break;\n        case LONG:\n          numericTokenStream.setLongValue(val.longValue());\n          break;\n        case FLOAT:\n          numericTokenStream.setFloatValue(val.floatValue());\n          break;\n        case DOUBLE:\n          numericTokenStream.setDoubleValue(val.doubleValue());\n          break;\n        default:\n          assert false : \"Should never get here\";\n        }\n      } else {\n        // OK -- previously cached and we already updated if\n        // setters were called.\n      }\n\n      return numericTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n\n      return new TokenStream() {\n        CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);\n        boolean used;\n\n        @Override\n        public boolean incrementToken() throws IOException {\n          if (used) {\n            return false;\n          }\n          termAttribute.setEmpty().append(stringValue());\n          offsetAttribute.setOffset(0, stringValue().length());\n          used = true;\n          return true;\n        }\n\n        @Override\n        public void reset() throws IOException {\n          used = false;\n        }\n      };\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","sourceOld":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericField.DataType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (numericTokenStream == null) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        numericTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n        // initialize value in TokenStream\n        final Number val = (Number) fieldsData;\n        switch (numericType) {\n        case INT:\n          numericTokenStream.setIntValue(val.intValue());\n          break;\n        case LONG:\n          numericTokenStream.setLongValue(val.longValue());\n          break;\n        case FLOAT:\n          numericTokenStream.setFloatValue(val.floatValue());\n          break;\n        case DOUBLE:\n          numericTokenStream.setDoubleValue(val.doubleValue());\n          break;\n        default:\n          assert false : \"Should never get here\";\n        }\n      } else {\n        // OK -- previously cached and we already updated if\n        // setters were called.\n      }\n\n      return numericTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n\n      return new TokenStream() {\n        CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);\n        boolean used;\n\n        @Override\n        public boolean incrementToken() throws IOException {\n          if (used) {\n            return false;\n          }\n          termAttribute.setEmpty().append(stringValue());\n          offsetAttribute.setOffset(0, stringValue().length());\n          used = true;\n          return true;\n        }\n\n        @Override\n        public void reset() throws IOException {\n          used = false;\n        }\n      };\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":["fa0f44f887719e97183771e977cfc4bfb485b766"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4d3e8520fd031bab31fd0e4d480e55958bc45efe","date":1340901565,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (numericTokenStream == null) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        numericTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n        // initialize value in TokenStream\n        final Number val = (Number) fieldsData;\n        switch (numericType) {\n        case INT:\n          numericTokenStream.setIntValue(val.intValue());\n          break;\n        case LONG:\n          numericTokenStream.setLongValue(val.longValue());\n          break;\n        case FLOAT:\n          numericTokenStream.setFloatValue(val.floatValue());\n          break;\n        case DOUBLE:\n          numericTokenStream.setDoubleValue(val.doubleValue());\n          break;\n        default:\n          assert false : \"Should never get here\";\n        }\n      } else {\n        // OK -- previously cached and we already updated if\n        // setters were called.\n      }\n\n      return numericTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n\n      return new TokenStream() {\n        CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);\n        boolean used;\n\n        @Override\n        public boolean incrementToken() {\n          if (used) {\n            return false;\n          }\n          termAttribute.setEmpty().append(stringValue());\n          offsetAttribute.setOffset(0, stringValue().length());\n          used = true;\n          return true;\n        }\n\n        @Override\n        public void reset() {\n          used = false;\n        }\n      };\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","sourceOld":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (numericTokenStream == null) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        numericTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n        // initialize value in TokenStream\n        final Number val = (Number) fieldsData;\n        switch (numericType) {\n        case INT:\n          numericTokenStream.setIntValue(val.intValue());\n          break;\n        case LONG:\n          numericTokenStream.setLongValue(val.longValue());\n          break;\n        case FLOAT:\n          numericTokenStream.setFloatValue(val.floatValue());\n          break;\n        case DOUBLE:\n          numericTokenStream.setDoubleValue(val.doubleValue());\n          break;\n        default:\n          assert false : \"Should never get here\";\n        }\n      } else {\n        // OK -- previously cached and we already updated if\n        // setters were called.\n      }\n\n      return numericTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n\n      return new TokenStream() {\n        CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);\n        boolean used;\n\n        @Override\n        public boolean incrementToken() throws IOException {\n          if (used) {\n            return false;\n          }\n          termAttribute.setEmpty().append(stringValue());\n          offsetAttribute.setOffset(0, stringValue().length());\n          used = true;\n          return true;\n        }\n\n        @Override\n        public void reset() throws IOException {\n          used = false;\n        }\n      };\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":["8b3bdb938a073ccc28d7ed813f6e8c4cb58e04c5"],"bugIntro":["2b7d23fd7761cfb5055ce47fc02aee3e155ac202"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (numericTokenStream == null) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        numericTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n        // initialize value in TokenStream\n        final Number val = (Number) fieldsData;\n        switch (numericType) {\n        case INT:\n          numericTokenStream.setIntValue(val.intValue());\n          break;\n        case LONG:\n          numericTokenStream.setLongValue(val.longValue());\n          break;\n        case FLOAT:\n          numericTokenStream.setFloatValue(val.floatValue());\n          break;\n        case DOUBLE:\n          numericTokenStream.setDoubleValue(val.doubleValue());\n          break;\n        default:\n          assert false : \"Should never get here\";\n        }\n      } else {\n        // OK -- previously cached and we already updated if\n        // setters were called.\n      }\n\n      return numericTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n\n      return new TokenStream() {\n        CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);\n        boolean used;\n\n        @Override\n        public boolean incrementToken() {\n          if (used) {\n            return false;\n          }\n          termAttribute.setEmpty().append(stringValue());\n          offsetAttribute.setOffset(0, stringValue().length());\n          used = true;\n          return true;\n        }\n\n        @Override\n        public void reset() {\n          used = false;\n        }\n      };\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","sourceOld":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (numericTokenStream == null) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        numericTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n        // initialize value in TokenStream\n        final Number val = (Number) fieldsData;\n        switch (numericType) {\n        case INT:\n          numericTokenStream.setIntValue(val.intValue());\n          break;\n        case LONG:\n          numericTokenStream.setLongValue(val.longValue());\n          break;\n        case FLOAT:\n          numericTokenStream.setFloatValue(val.floatValue());\n          break;\n        case DOUBLE:\n          numericTokenStream.setDoubleValue(val.doubleValue());\n          break;\n        default:\n          assert false : \"Should never get here\";\n        }\n      } else {\n        // OK -- previously cached and we already updated if\n        // setters were called.\n      }\n\n      return numericTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n\n      return new TokenStream() {\n        CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);\n        boolean used;\n\n        @Override\n        public boolean incrementToken() throws IOException {\n          if (used) {\n            return false;\n          }\n          termAttribute.setEmpty().append(stringValue());\n          offsetAttribute.setOffset(0, stringValue().length());\n          used = true;\n          return true;\n        }\n\n        @Override\n        public void reset() throws IOException {\n          used = false;\n        }\n      };\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2b7d23fd7761cfb5055ce47fc02aee3e155ac202","date":1345553007,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        assert false : \"Should never get here\";\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","sourceOld":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (numericTokenStream == null) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        numericTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n        // initialize value in TokenStream\n        final Number val = (Number) fieldsData;\n        switch (numericType) {\n        case INT:\n          numericTokenStream.setIntValue(val.intValue());\n          break;\n        case LONG:\n          numericTokenStream.setLongValue(val.longValue());\n          break;\n        case FLOAT:\n          numericTokenStream.setFloatValue(val.floatValue());\n          break;\n        case DOUBLE:\n          numericTokenStream.setDoubleValue(val.doubleValue());\n          break;\n        default:\n          assert false : \"Should never get here\";\n        }\n      } else {\n        // OK -- previously cached and we already updated if\n        // setters were called.\n      }\n\n      return numericTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n\n      return new TokenStream() {\n        CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);\n        boolean used;\n\n        @Override\n        public boolean incrementToken() {\n          if (used) {\n            return false;\n          }\n          termAttribute.setEmpty().append(stringValue());\n          offsetAttribute.setOffset(0, stringValue().length());\n          used = true;\n          return true;\n        }\n\n        @Override\n        public void reset() {\n          used = false;\n        }\n      };\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":["fa0f44f887719e97183771e977cfc4bfb485b766","4d3e8520fd031bab31fd0e4d480e55958bc45efe","8b3bdb938a073ccc28d7ed813f6e8c4cb58e04c5"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"190bb9bef51c64832a51cf820b20992d4cf60c51","date":1345670976,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        assert false : \"Should never get here\";\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","sourceOld":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        assert false : \"Should never get here\";\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"bugIntro":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"001b25b42373b22a52f399dbf072f1224632e8e6","date":1345889167,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        assert false : \"Should never get here\";\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","sourceOld":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (numericTokenStream == null) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        numericTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n        // initialize value in TokenStream\n        final Number val = (Number) fieldsData;\n        switch (numericType) {\n        case INT:\n          numericTokenStream.setIntValue(val.intValue());\n          break;\n        case LONG:\n          numericTokenStream.setLongValue(val.longValue());\n          break;\n        case FLOAT:\n          numericTokenStream.setFloatValue(val.floatValue());\n          break;\n        case DOUBLE:\n          numericTokenStream.setDoubleValue(val.doubleValue());\n          break;\n        default:\n          assert false : \"Should never get here\";\n        }\n      } else {\n        // OK -- previously cached and we already updated if\n        // setters were called.\n      }\n\n      return numericTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n\n      return new TokenStream() {\n        CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);\n        OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);\n        boolean used;\n\n        @Override\n        public boolean incrementToken() {\n          if (used) {\n            return false;\n          }\n          termAttribute.setEmpty().append(stringValue());\n          offsetAttribute.setOffset(0, stringValue().length());\n          used = true;\n          return true;\n        }\n\n        @Override\n        public void reset() {\n          used = false;\n        }\n      };\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), new StringReader(stringValue()));\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"99bfa1bcb7cecbfe48118f6e71f7ccc7a9247afc","date":1346106609,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        assert false : \"Should never get here\";\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","sourceOld":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        assert false : \"Should never get here\";\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"05a14b2611ead08655a2b2bdc61632eb31316e57","date":1346366621,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        assert false : \"Should never get here\";\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","sourceOld":"  /**\n   * {@inheritDoc}\n   */\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        assert false : \"Should never get here\";\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a92d88a85748af0cb6a68706f8ac3ba6bd686fa6","date":1346421325,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","sourceOld":"  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        assert false : \"Should never get here\";\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0d1f90e969803cc84174589b5e4a39b7935fecd","date":1346584861,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","sourceOld":"  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        assert false : \"Should never get here\";\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7530de27b87b961b51f01bd1299b7004d46e8823","date":1355236261,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  @Override\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","sourceOld":"  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  @Override\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","sourceOld":"  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c83d6c4335f31cae14f625a222bc842f20073dcd","date":1373306148,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  @Override\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), stringValue());\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","sourceOld":"  @Override\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":["190bb9bef51c64832a51cf820b20992d4cf60c51"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  @Override\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), stringValue());\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","sourceOld":"  @Override\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      if (internalReader == null) {\n        internalReader = new ReusableStringReader();\n      }\n      internalReader.setValue(stringValue());\n      return analyzer.tokenStream(name(), internalReader);\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a1e7272ef767c1304198a2cb2000cf54ea49f808","date":1384786433,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  @Override\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), stringValue());\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; this=\" + this);\n  }\n\n","sourceOld":"  @Override\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), stringValue());\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0b656cbf28fe2a4be7de3f0e561623ca39d06884","date":1388622204,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  @Override\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), stringValue());\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n  }\n\n","sourceOld":"  @Override\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), stringValue());\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; this=\" + this);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc728b07df73b197e6d940d27f9b08b63918f13","date":1388834348,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  @Override\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), stringValue());\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n  }\n\n","sourceOld":"  @Override\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), stringValue());\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"090a3a6b4b32e55f8fe1eab3359dbe628a208a0c","date":1399054058,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer,TokenStream).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/document/Field#tokenStream(Analyzer).mjava","sourceNew":"  @Override\n  public TokenStream tokenStream(Analyzer analyzer, TokenStream reuse) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(reuse instanceof NumericTokenStream && ((NumericTokenStream)reuse).getPrecisionStep() == type.numericPrecisionStep())) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        reuse = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) reuse;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return reuse;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(reuse instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        reuse = new StringTokenStream();\n      }\n      ((StringTokenStream) reuse).setValue(stringValue());\n      return reuse;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), stringValue());\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n  }\n\n","sourceOld":"  @Override\n  public TokenStream tokenStream(Analyzer analyzer) throws IOException {\n    if (!fieldType().indexed()) {\n      return null;\n    }\n\n    final NumericType numericType = fieldType().numericType();\n    if (numericType != null) {\n      if (!(internalTokenStream instanceof NumericTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new NumericTokenStream(type.numericPrecisionStep());\n      }\n      final NumericTokenStream nts = (NumericTokenStream) internalTokenStream;\n      // initialize value in TokenStream\n      final Number val = (Number) fieldsData;\n      switch (numericType) {\n      case INT:\n        nts.setIntValue(val.intValue());\n        break;\n      case LONG:\n        nts.setLongValue(val.longValue());\n        break;\n      case FLOAT:\n        nts.setFloatValue(val.floatValue());\n        break;\n      case DOUBLE:\n        nts.setDoubleValue(val.doubleValue());\n        break;\n      default:\n        throw new AssertionError(\"Should never get here\");\n      }\n      return internalTokenStream;\n    }\n\n    if (!fieldType().tokenized()) {\n      if (stringValue() == null) {\n        throw new IllegalArgumentException(\"Non-Tokenized Fields must have a String value\");\n      }\n      if (!(internalTokenStream instanceof StringTokenStream)) {\n        // lazy init the TokenStream as it is heavy to instantiate\n        // (attributes,...) if not needed (stored field loading)\n        internalTokenStream = new StringTokenStream();\n      }\n      ((StringTokenStream) internalTokenStream).setValue(stringValue());\n      return internalTokenStream;\n    }\n\n    if (tokenStream != null) {\n      return tokenStream;\n    } else if (readerValue() != null) {\n      return analyzer.tokenStream(name(), readerValue());\n    } else if (stringValue() != null) {\n      return analyzer.tokenStream(name(), stringValue());\n    }\n\n    throw new IllegalArgumentException(\"Field must have either TokenStream, String, Reader or Number value; got \" + this);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["a92d88a85748af0cb6a68706f8ac3ba6bd686fa6","7530de27b87b961b51f01bd1299b7004d46e8823"],"001b25b42373b22a52f399dbf072f1224632e8e6":["4d3e8520fd031bab31fd0e4d480e55958bc45efe","190bb9bef51c64832a51cf820b20992d4cf60c51"],"99bfa1bcb7cecbfe48118f6e71f7ccc7a9247afc":["190bb9bef51c64832a51cf820b20992d4cf60c51"],"a1e7272ef767c1304198a2cb2000cf54ea49f808":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["7530de27b87b961b51f01bd1299b7004d46e8823","c83d6c4335f31cae14f625a222bc842f20073dcd"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"190bb9bef51c64832a51cf820b20992d4cf60c51":["2b7d23fd7761cfb5055ce47fc02aee3e155ac202"],"05a14b2611ead08655a2b2bdc61632eb31316e57":["001b25b42373b22a52f399dbf072f1224632e8e6","99bfa1bcb7cecbfe48118f6e71f7ccc7a9247afc"],"a92d88a85748af0cb6a68706f8ac3ba6bd686fa6":["99bfa1bcb7cecbfe48118f6e71f7ccc7a9247afc"],"a78a90fc9701e511308346ea29f4f5e548bb39fe":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0d1f90e969803cc84174589b5e4a39b7935fecd":["05a14b2611ead08655a2b2bdc61632eb31316e57","a92d88a85748af0cb6a68706f8ac3ba6bd686fa6"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["7530de27b87b961b51f01bd1299b7004d46e8823"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["a78a90fc9701e511308346ea29f4f5e548bb39fe","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"090a3a6b4b32e55f8fe1eab3359dbe628a208a0c":["3cc728b07df73b197e6d940d27f9b08b63918f13"],"2b7d23fd7761cfb5055ce47fc02aee3e155ac202":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"3cc728b07df73b197e6d940d27f9b08b63918f13":["c83d6c4335f31cae14f625a222bc842f20073dcd","0b656cbf28fe2a4be7de3f0e561623ca39d06884"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"7530de27b87b961b51f01bd1299b7004d46e8823":["a92d88a85748af0cb6a68706f8ac3ba6bd686fa6"],"0b656cbf28fe2a4be7de3f0e561623ca39d06884":["a1e7272ef767c1304198a2cb2000cf54ea49f808"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["090a3a6b4b32e55f8fe1eab3359dbe628a208a0c"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"001b25b42373b22a52f399dbf072f1224632e8e6":["05a14b2611ead08655a2b2bdc61632eb31316e57"],"99bfa1bcb7cecbfe48118f6e71f7ccc7a9247afc":["05a14b2611ead08655a2b2bdc61632eb31316e57","a92d88a85748af0cb6a68706f8ac3ba6bd686fa6"],"a1e7272ef767c1304198a2cb2000cf54ea49f808":["0b656cbf28fe2a4be7de3f0e561623ca39d06884"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"190bb9bef51c64832a51cf820b20992d4cf60c51":["001b25b42373b22a52f399dbf072f1224632e8e6","99bfa1bcb7cecbfe48118f6e71f7ccc7a9247afc"],"05a14b2611ead08655a2b2bdc61632eb31316e57":["d0d1f90e969803cc84174589b5e4a39b7935fecd"],"a92d88a85748af0cb6a68706f8ac3ba6bd686fa6":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","d0d1f90e969803cc84174589b5e4a39b7935fecd","7530de27b87b961b51f01bd1299b7004d46e8823"],"a78a90fc9701e511308346ea29f4f5e548bb39fe":["fe33227f6805edab2036cbb80645cc4e2d1fa424","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"d0d1f90e969803cc84174589b5e4a39b7935fecd":[],"c83d6c4335f31cae14f625a222bc842f20073dcd":["a1e7272ef767c1304198a2cb2000cf54ea49f808","37a0f60745e53927c4c876cfe5b5a58170f0646c","3cc728b07df73b197e6d940d27f9b08b63918f13"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"2b7d23fd7761cfb5055ce47fc02aee3e155ac202":["190bb9bef51c64832a51cf820b20992d4cf60c51"],"090a3a6b4b32e55f8fe1eab3359dbe628a208a0c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cc728b07df73b197e6d940d27f9b08b63918f13":["090a3a6b4b32e55f8fe1eab3359dbe628a208a0c"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["001b25b42373b22a52f399dbf072f1224632e8e6","fe33227f6805edab2036cbb80645cc4e2d1fa424","2b7d23fd7761cfb5055ce47fc02aee3e155ac202"],"7530de27b87b961b51f01bd1299b7004d46e8823":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","37a0f60745e53927c4c876cfe5b5a58170f0646c","c83d6c4335f31cae14f625a222bc842f20073dcd"],"0b656cbf28fe2a4be7de3f0e561623ca39d06884":["3cc728b07df73b197e6d940d27f9b08b63918f13"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","37a0f60745e53927c4c876cfe5b5a58170f0646c","d0d1f90e969803cc84174589b5e4a39b7935fecd","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}