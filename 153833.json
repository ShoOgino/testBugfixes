{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curGramSize = minGram;\n          curPos = 0;\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n          // if length by start + end offsets doesn't match the term text then assume\n          // this is a synonym and don't adjust the offsets.\n          hasIllegalOffsets = (tokStart + curTermLength) != tokEnd;\n        }\n      }\n      while (curGramSize <= maxGram) {\n        while (curPos+curGramSize <= curTermLength) {     // while there is input\n          clearAttributes();\n          termAtt.copyBuffer(curTermBuffer, curPos, curGramSize);\n          if (hasIllegalOffsets) {\n            offsetAtt.setOffset(tokStart, tokEnd);\n          } else {\n            offsetAtt.setOffset(tokStart + curPos, tokStart + curPos + curGramSize);\n          }\n          curPos++;\n          return true;\n        }\n        curGramSize++;                         // increase n-gram size\n        curPos = 0;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curGramSize = minGram;\n          curPos = 0;\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n          // if length by start + end offsets doesn't match the term text then assume\n          // this is a synonym and don't adjust the offsets.\n          hasIllegalOffsets = (tokStart + curTermLength) != tokEnd;\n        }\n      }\n      while (curGramSize <= maxGram) {\n        while (curPos+curGramSize <= curTermLength) {     // while there is input\n          clearAttributes();\n          termAtt.copyBuffer(curTermBuffer, curPos, curGramSize);\n          if (hasIllegalOffsets) {\n            offsetAtt.setOffset(tokStart, tokEnd);\n          } else {\n            offsetAtt.setOffset(tokStart + curPos, tokStart + curPos + curGramSize);\n          }\n          curPos++;\n          return true;\n        }\n        curGramSize++;                         // increase n-gram size\n        curPos = 0;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4c807c4005aae1acaf5cebc9af40883985fb89a8","date":1366974206,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n          // if length by start + end offsets doesn't match the term text then assume\n          // this is a synonym and don't adjust the offsets.\n          hasIllegalOffsets = (tokStart + curTermLength) != tokEnd;\n        }\n      }\n      if (version.onOrAfter(Version.LUCENE_44)) {\n        if (curGramSize > maxGram || curPos + curGramSize > curTermLength) {\n          ++curPos;\n          curGramSize = minGram;\n        }\n        if (curPos + curGramSize <= curTermLength) {\n          clearAttributes();\n          termAtt.copyBuffer(curTermBuffer, curPos, curGramSize);\n          posIncAtt.setPositionIncrement(curPosInc);\n          curPosInc = 0;\n          posLenAtt.setPositionLength(curPosLen);\n          offsetAtt.setOffset(tokStart, tokEnd);\n          curGramSize++;\n          return true;\n        }\n      } else {\n        while (curGramSize <= maxGram) {\n          while (curPos+curGramSize <= curTermLength) {     // while there is input\n            clearAttributes();\n            termAtt.copyBuffer(curTermBuffer, curPos, curGramSize);\n            if (hasIllegalOffsets) {\n              offsetAtt.setOffset(tokStart, tokEnd);\n            } else {\n              offsetAtt.setOffset(tokStart + curPos, tokStart + curPos + curGramSize);\n            }\n            curPos++;\n            return true;\n          }\n          curGramSize++;                         // increase n-gram size\n          curPos = 0;\n        }\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curGramSize = minGram;\n          curPos = 0;\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n          // if length by start + end offsets doesn't match the term text then assume\n          // this is a synonym and don't adjust the offsets.\n          hasIllegalOffsets = (tokStart + curTermLength) != tokEnd;\n        }\n      }\n      while (curGramSize <= maxGram) {\n        while (curPos+curGramSize <= curTermLength) {     // while there is input\n          clearAttributes();\n          termAtt.copyBuffer(curTermBuffer, curPos, curGramSize);\n          if (hasIllegalOffsets) {\n            offsetAtt.setOffset(tokStart, tokEnd);\n          } else {\n            offsetAtt.setOffset(tokStart + curPos, tokStart + curPos + curGramSize);\n          }\n          curPos++;\n          return true;\n        }\n        curGramSize++;                         // increase n-gram size\n        curPos = 0;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","bugFix":["0c17d12803da6cadc96b3cdf15b0b940eddb28de","9b5756469957918cac40a831acec9cf01c8c2bb3"],"bugIntro":["8a255765a5625ff80fba75863de5a16ea392015e","bbbdd19493fa8ae4bdac9205ae34e7387f08f304"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704","date":1371043069,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = charUtils.codePointCount(termAtt);\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n          // if length by start + end offsets doesn't match the term text then assume\n          // this is a synonym and don't adjust the offsets.\n          hasIllegalOffsets = (tokStart + curTermLength) != tokEnd;\n        }\n      }\n      if (version.onOrAfter(Version.LUCENE_44)) {\n        if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n          ++curPos;\n          curGramSize = minGram;\n        }\n        if ((curPos + curGramSize) <= curCodePointCount) {\n          clearAttributes();\n          final int start = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n          final int end = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n          termAtt.copyBuffer(curTermBuffer, start, end - start);\n          posIncAtt.setPositionIncrement(curPosInc);\n          curPosInc = 0;\n          posLenAtt.setPositionLength(curPosLen);\n          offsetAtt.setOffset(tokStart, tokEnd);\n          curGramSize++;\n          return true;\n        }\n      } else {\n        while (curGramSize <= maxGram) {\n          while (curPos+curGramSize <= curTermLength) {     // while there is input\n            clearAttributes();\n            termAtt.copyBuffer(curTermBuffer, curPos, curGramSize);\n            if (hasIllegalOffsets) {\n              offsetAtt.setOffset(tokStart, tokEnd);\n            } else {\n              offsetAtt.setOffset(tokStart + curPos, tokStart + curPos + curGramSize);\n            }\n            curPos++;\n            return true;\n          }\n          curGramSize++;                         // increase n-gram size\n          curPos = 0;\n        }\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n          // if length by start + end offsets doesn't match the term text then assume\n          // this is a synonym and don't adjust the offsets.\n          hasIllegalOffsets = (tokStart + curTermLength) != tokEnd;\n        }\n      }\n      if (version.onOrAfter(Version.LUCENE_44)) {\n        if (curGramSize > maxGram || curPos + curGramSize > curTermLength) {\n          ++curPos;\n          curGramSize = minGram;\n        }\n        if (curPos + curGramSize <= curTermLength) {\n          clearAttributes();\n          termAtt.copyBuffer(curTermBuffer, curPos, curGramSize);\n          posIncAtt.setPositionIncrement(curPosInc);\n          curPosInc = 0;\n          posLenAtt.setPositionLength(curPosLen);\n          offsetAtt.setOffset(tokStart, tokEnd);\n          curGramSize++;\n          return true;\n        }\n      } else {\n        while (curGramSize <= maxGram) {\n          while (curPos+curGramSize <= curTermLength) {     // while there is input\n            clearAttributes();\n            termAtt.copyBuffer(curTermBuffer, curPos, curGramSize);\n            if (hasIllegalOffsets) {\n              offsetAtt.setOffset(tokStart, tokEnd);\n            } else {\n              offsetAtt.setOffset(tokStart + curPos, tokStart + curPos + curGramSize);\n            }\n            curPos++;\n            return true;\n          }\n          curGramSize++;                         // increase n-gram size\n          curPos = 0;\n        }\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"dd330c9d05eacbd6e952fe0dea852e7ae037eb50","date":1398873035,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = charUtils.codePointCount(termAtt);\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n          // if length by start + end offsets doesn't match the term text then assume\n          // this is a synonym and don't adjust the offsets.\n          hasIllegalOffsets = (tokStart + curTermLength) != tokEnd;\n        }\n      }\n      if (version.onOrAfter(Version.LUCENE_4_4)) {\n        if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n          ++curPos;\n          curGramSize = minGram;\n        }\n        if ((curPos + curGramSize) <= curCodePointCount) {\n          clearAttributes();\n          final int start = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n          final int end = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n          termAtt.copyBuffer(curTermBuffer, start, end - start);\n          posIncAtt.setPositionIncrement(curPosInc);\n          curPosInc = 0;\n          posLenAtt.setPositionLength(curPosLen);\n          offsetAtt.setOffset(tokStart, tokEnd);\n          curGramSize++;\n          return true;\n        }\n      } else {\n        while (curGramSize <= maxGram) {\n          while (curPos+curGramSize <= curTermLength) {     // while there is input\n            clearAttributes();\n            termAtt.copyBuffer(curTermBuffer, curPos, curGramSize);\n            if (hasIllegalOffsets) {\n              offsetAtt.setOffset(tokStart, tokEnd);\n            } else {\n              offsetAtt.setOffset(tokStart + curPos, tokStart + curPos + curGramSize);\n            }\n            curPos++;\n            return true;\n          }\n          curGramSize++;                         // increase n-gram size\n          curPos = 0;\n        }\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = charUtils.codePointCount(termAtt);\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n          // if length by start + end offsets doesn't match the term text then assume\n          // this is a synonym and don't adjust the offsets.\n          hasIllegalOffsets = (tokStart + curTermLength) != tokEnd;\n        }\n      }\n      if (version.onOrAfter(Version.LUCENE_44)) {\n        if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n          ++curPos;\n          curGramSize = minGram;\n        }\n        if ((curPos + curGramSize) <= curCodePointCount) {\n          clearAttributes();\n          final int start = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n          final int end = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n          termAtt.copyBuffer(curTermBuffer, start, end - start);\n          posIncAtt.setPositionIncrement(curPosInc);\n          curPosInc = 0;\n          posLenAtt.setPositionLength(curPosLen);\n          offsetAtt.setOffset(tokStart, tokEnd);\n          curGramSize++;\n          return true;\n        }\n      } else {\n        while (curGramSize <= maxGram) {\n          while (curPos+curGramSize <= curTermLength) {     // while there is input\n            clearAttributes();\n            termAtt.copyBuffer(curTermBuffer, curPos, curGramSize);\n            if (hasIllegalOffsets) {\n              offsetAtt.setOffset(tokStart, tokEnd);\n            } else {\n              offsetAtt.setOffset(tokStart + curPos, tokStart + curPos + curGramSize);\n            }\n            curPos++;\n            return true;\n          }\n          curGramSize++;                         // increase n-gram size\n          curPos = 0;\n        }\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"379db3ad24c4f0214f30a122265a6d6be003a99d","date":1407537768,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = charUtils.codePointCount(termAtt);\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n          // if length by start + end offsets doesn't match the term text then assume\n          // this is a synonym and don't adjust the offsets.\n          hasIllegalOffsets = (tokStart + curTermLength) != tokEnd;\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        clearAttributes();\n        final int start = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        posLenAtt.setPositionLength(curPosLen);\n        offsetAtt.setOffset(tokStart, tokEnd);\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = charUtils.codePointCount(termAtt);\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n          // if length by start + end offsets doesn't match the term text then assume\n          // this is a synonym and don't adjust the offsets.\n          hasIllegalOffsets = (tokStart + curTermLength) != tokEnd;\n        }\n      }\n      if (version.onOrAfter(Version.LUCENE_4_4)) {\n        if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n          ++curPos;\n          curGramSize = minGram;\n        }\n        if ((curPos + curGramSize) <= curCodePointCount) {\n          clearAttributes();\n          final int start = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n          final int end = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n          termAtt.copyBuffer(curTermBuffer, start, end - start);\n          posIncAtt.setPositionIncrement(curPosInc);\n          curPosInc = 0;\n          posLenAtt.setPositionLength(curPosLen);\n          offsetAtt.setOffset(tokStart, tokEnd);\n          curGramSize++;\n          return true;\n        }\n      } else {\n        while (curGramSize <= maxGram) {\n          while (curPos+curGramSize <= curTermLength) {     // while there is input\n            clearAttributes();\n            termAtt.copyBuffer(curTermBuffer, curPos, curGramSize);\n            if (hasIllegalOffsets) {\n              offsetAtt.setOffset(tokStart, tokEnd);\n            } else {\n              offsetAtt.setOffset(tokStart + curPos, tokStart + curPos + curGramSize);\n            }\n            curPos++;\n            return true;\n          }\n          curGramSize++;                         // increase n-gram size\n          curPos = 0;\n        }\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":["8a255765a5625ff80fba75863de5a16ea392015e","bbbdd19493fa8ae4bdac9205ae34e7387f08f304"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc","date":1465824262,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = Character.codePointCount(termAtt, 0, termAtt.length());\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        clearAttributes();\n        final int start = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        posLenAtt.setPositionLength(curPosLen);\n        offsetAtt.setOffset(tokStart, tokEnd);\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = charUtils.codePointCount(termAtt);\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n          // if length by start + end offsets doesn't match the term text then assume\n          // this is a synonym and don't adjust the offsets.\n          hasIllegalOffsets = (tokStart + curTermLength) != tokEnd;\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        clearAttributes();\n        final int start = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        posLenAtt.setPositionLength(curPosLen);\n        offsetAtt.setOffset(tokStart, tokEnd);\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":["8a255765a5625ff80fba75863de5a16ea392015e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79","date":1465913303,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = Character.codePointCount(termAtt, 0, termAtt.length());\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        clearAttributes();\n        final int start = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        posLenAtt.setPositionLength(curPosLen);\n        offsetAtt.setOffset(tokStart, tokEnd);\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = charUtils.codePointCount(termAtt);\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n          // if length by start + end offsets doesn't match the term text then assume\n          // this is a synonym and don't adjust the offsets.\n          hasIllegalOffsets = (tokStart + curTermLength) != tokEnd;\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        clearAttributes();\n        final int start = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        posLenAtt.setPositionLength(curPosLen);\n        offsetAtt.setOffset(tokStart, tokEnd);\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = Character.codePointCount(termAtt, 0, termAtt.length());\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        clearAttributes();\n        final int start = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        posLenAtt.setPositionLength(curPosLen);\n        offsetAtt.setOffset(tokStart, tokEnd);\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = charUtils.codePointCount(termAtt);\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n          // if length by start + end offsets doesn't match the term text then assume\n          // this is a synonym and don't adjust the offsets.\n          hasIllegalOffsets = (tokStart + curTermLength) != tokEnd;\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        clearAttributes();\n        final int start = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = charUtils.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        posLenAtt.setPositionLength(curPosLen);\n        offsetAtt.setOffset(tokStart, tokEnd);\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4188a39e51b877e66d58390c0583e205eb3d1131","date":1484323643,"type":3,"author":"Nathan Gass","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = Character.codePointCount(termAtt, 0, termAtt.length());\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          state = captureState();\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        restoreState(state);\n        final int start = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = Character.codePointCount(termAtt, 0, termAtt.length());\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        clearAttributes();\n        final int start = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        posLenAtt.setPositionLength(curPosLen);\n        offsetAtt.setOffset(tokStart, tokEnd);\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":["8a255765a5625ff80fba75863de5a16ea392015e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bbbdd19493fa8ae4bdac9205ae34e7387f08f304","date":1484561803,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = Character.codePointCount(termAtt, 0, termAtt.length());\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          state = captureState();\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        restoreState(state);\n        final int start = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = Character.codePointCount(termAtt, 0, termAtt.length());\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        clearAttributes();\n        final int start = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        posLenAtt.setPositionLength(curPosLen);\n        offsetAtt.setOffset(tokStart, tokEnd);\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","bugFix":["226f5e862af9059a60fe80d2b27e547bcd95971c","379db3ad24c4f0214f30a122265a6d6be003a99d","4c807c4005aae1acaf5cebc9af40883985fb89a8","0c17d12803da6cadc96b3cdf15b0b940eddb28de"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"507e7decdf00981d09a74632ea30299a4ce6ba72","date":1484600874,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","sourceNew":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = Character.codePointCount(termAtt, 0, termAtt.length());\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          state = captureState();\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        restoreState(state);\n        final int start = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = Character.codePointCount(termAtt, 0, termAtt.length());\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          curPosLen = posLenAtt.getPositionLength();\n          tokStart = offsetAtt.startOffset();\n          tokEnd = offsetAtt.endOffset();\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        clearAttributes();\n        final int start = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        posLenAtt.setPositionLength(curPosLen);\n        offsetAtt.setOffset(tokStart, tokEnd);\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a255765a5625ff80fba75863de5a16ea392015e","date":1528161860,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        }\n        state = captureState();\n        \n        curTermLength = termAtt.length();\n        curTermCodePointCount = Character.codePointCount(termAtt, 0, termAtt.length());\n        curPosIncr += posIncrAtt.getPositionIncrement();\n        curPos = 0;\n        \n        if (preserveOriginal && curTermCodePointCount < minGram) {\n          // Token is shorter than minGram, but we'd still like to keep it.\n          posIncrAtt.setPositionIncrement(curPosIncr);\n          curPosIncr = 0;\n          return true;\n        }\n        \n        curTermBuffer = termAtt.buffer().clone();\n        curGramSize = minGram;\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curTermCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curTermCodePointCount) {\n        restoreState(state);\n        final int start = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncrAtt.setPositionIncrement(curPosIncr);\n        curPosIncr = 0;\n        curGramSize++;\n        return true;\n      }\n      else if (preserveOriginal && curTermCodePointCount > maxGram) {\n        // Token is longer than maxGram, but we'd still like to keep it.\n        restoreState(state);\n        posIncrAtt.setPositionIncrement(0);\n        termAtt.copyBuffer(curTermBuffer, 0, curTermLength);\n        curTermBuffer = null;\n        return true;\n      }\n      \n      // Done with this input token, get next token on next iteration.\n      curTermBuffer = null;  \n    }\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = Character.codePointCount(termAtt, 0, termAtt.length());\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          state = captureState();\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        restoreState(state);\n        final int start = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","bugFix":["379db3ad24c4f0214f30a122265a6d6be003a99d","4c807c4005aae1acaf5cebc9af40883985fb89a8","a7347509fad0711ac30cb15a746e9a3830a38ebd","9b5756469957918cac40a831acec9cf01c8c2bb3","4188a39e51b877e66d58390c0583e205eb3d1131","fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        }\n        state = captureState();\n        \n        curTermLength = termAtt.length();\n        curTermCodePointCount = Character.codePointCount(termAtt, 0, termAtt.length());\n        curPosIncr += posIncrAtt.getPositionIncrement();\n        curPos = 0;\n        \n        if (preserveOriginal && curTermCodePointCount < minGram) {\n          // Token is shorter than minGram, but we'd still like to keep it.\n          posIncrAtt.setPositionIncrement(curPosIncr);\n          curPosIncr = 0;\n          return true;\n        }\n        \n        curTermBuffer = termAtt.buffer().clone();\n        curGramSize = minGram;\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curTermCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curTermCodePointCount) {\n        restoreState(state);\n        final int start = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncrAtt.setPositionIncrement(curPosIncr);\n        curPosIncr = 0;\n        curGramSize++;\n        return true;\n      }\n      else if (preserveOriginal && curTermCodePointCount > maxGram) {\n        // Token is longer than maxGram, but we'd still like to keep it.\n        restoreState(state);\n        posIncrAtt.setPositionIncrement(0);\n        termAtt.copyBuffer(curTermBuffer, 0, curTermLength);\n        curTermBuffer = null;\n        return true;\n      }\n      \n      // Done with this input token, get next token on next iteration.\n      curTermBuffer = null;  \n    }\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = Character.codePointCount(termAtt, 0, termAtt.length());\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          state = captureState();\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        restoreState(state);\n        final int start = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        }\n        state = captureState();\n        \n        curTermLength = termAtt.length();\n        curTermCodePointCount = Character.codePointCount(termAtt, 0, termAtt.length());\n        curPosIncr += posIncrAtt.getPositionIncrement();\n        curPos = 0;\n        \n        if (preserveOriginal && curTermCodePointCount < minGram) {\n          // Token is shorter than minGram, but we'd still like to keep it.\n          posIncrAtt.setPositionIncrement(curPosIncr);\n          curPosIncr = 0;\n          return true;\n        }\n        \n        curTermBuffer = termAtt.buffer().clone();\n        curGramSize = minGram;\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curTermCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curTermCodePointCount) {\n        restoreState(state);\n        final int start = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncrAtt.setPositionIncrement(curPosIncr);\n        curPosIncr = 0;\n        curGramSize++;\n        return true;\n      }\n      else if (preserveOriginal && curTermCodePointCount > maxGram) {\n        // Token is longer than maxGram, but we'd still like to keep it.\n        restoreState(state);\n        posIncrAtt.setPositionIncrement(0);\n        termAtt.copyBuffer(curTermBuffer, 0, curTermLength);\n        curTermBuffer = null;\n        return true;\n      }\n      \n      // Done with this input token, get next token on next iteration.\n      curTermBuffer = null;  \n    }\n  }\n\n","sourceOld":"  /** Returns the next token in the stream, or null at EOS. */\n  @Override\n  public final boolean incrementToken() throws IOException {\n    while (true) {\n      if (curTermBuffer == null) {\n        if (!input.incrementToken()) {\n          return false;\n        } else {\n          curTermBuffer = termAtt.buffer().clone();\n          curTermLength = termAtt.length();\n          curCodePointCount = Character.codePointCount(termAtt, 0, termAtt.length());\n          curGramSize = minGram;\n          curPos = 0;\n          curPosInc = posIncAtt.getPositionIncrement();\n          state = captureState();\n        }\n      }\n\n      if (curGramSize > maxGram || (curPos + curGramSize) > curCodePointCount) {\n        ++curPos;\n        curGramSize = minGram;\n      }\n      if ((curPos + curGramSize) <= curCodePointCount) {\n        restoreState(state);\n        final int start = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, 0, curPos);\n        final int end = Character.offsetByCodePoints(curTermBuffer, 0, curTermLength, start, curGramSize);\n        termAtt.copyBuffer(curTermBuffer, start, end - start);\n        posIncAtt.setPositionIncrement(curPosInc);\n        curPosInc = 0;\n        curGramSize++;\n        return true;\n      }\n      curTermBuffer = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8a255765a5625ff80fba75863de5a16ea392015e":["bbbdd19493fa8ae4bdac9205ae34e7387f08f304"],"fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"4188a39e51b877e66d58390c0583e205eb3d1131":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"4c807c4005aae1acaf5cebc9af40883985fb89a8":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"507e7decdf00981d09a74632ea30299a4ce6ba72":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","bbbdd19493fa8ae4bdac9205ae34e7387f08f304"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["379db3ad24c4f0214f30a122265a6d6be003a99d","57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704":["4c807c4005aae1acaf5cebc9af40883985fb89a8"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["dd330c9d05eacbd6e952fe0dea852e7ae037eb50"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["bbbdd19493fa8ae4bdac9205ae34e7387f08f304","8a255765a5625ff80fba75863de5a16ea392015e"],"dd330c9d05eacbd6e952fe0dea852e7ae037eb50":["bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704"],"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79":["379db3ad24c4f0214f30a122265a6d6be003a99d","fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc"],"f592209545c71895260367152601e9200399776d":["bbbdd19493fa8ae4bdac9205ae34e7387f08f304","8a255765a5625ff80fba75863de5a16ea392015e"],"bbbdd19493fa8ae4bdac9205ae34e7387f08f304":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79","4188a39e51b877e66d58390c0583e205eb3d1131"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8a255765a5625ff80fba75863de5a16ea392015e"]},"commit2Childs":{"8a255765a5625ff80fba75863de5a16ea392015e":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"4188a39e51b877e66d58390c0583e205eb3d1131":["bbbdd19493fa8ae4bdac9205ae34e7387f08f304"],"4c807c4005aae1acaf5cebc9af40883985fb89a8":["bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704"],"507e7decdf00981d09a74632ea30299a4ce6ba72":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["507e7decdf00981d09a74632ea30299a4ce6ba72"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["4c807c4005aae1acaf5cebc9af40883985fb89a8"],"bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704":["dd330c9d05eacbd6e952fe0dea852e7ae037eb50"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"dd330c9d05eacbd6e952fe0dea852e7ae037eb50":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79":["4188a39e51b877e66d58390c0583e205eb3d1131","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","bbbdd19493fa8ae4bdac9205ae34e7387f08f304"],"f592209545c71895260367152601e9200399776d":[],"bbbdd19493fa8ae4bdac9205ae34e7387f08f304":["8a255765a5625ff80fba75863de5a16ea392015e","507e7decdf00981d09a74632ea30299a4ce6ba72","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["507e7decdf00981d09a74632ea30299a4ce6ba72","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}