{"path":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","pathOld":"src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","sourceNew":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      TermDocs termDocs = reader.termDocs(term);\n      if (termDocs != null) {\n        try {\n          if (termDocs.skipTo(doc) && termDocs.doc() == doc) {\n            tf = termDocs.freq();\n          }\n        } finally {\n          termDocs.close();\n        }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      TermDocs termDocs = reader.termDocs(term);\n      if (termDocs != null) {\n        try {\n          if (termDocs.skipTo(doc) && termDocs.doc() == doc) {\n            tf = termDocs.freq();\n          }\n        } finally {\n          termDocs.close();\n        }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"955c32f886db6f6356c9fcdea6b1f1cb4effda24","date":1270581567,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","sourceNew":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      DocsEnum docs = reader.termDocsEnum(MultiFields.getDeletedDocs(reader), term.field(), new BytesRef(term.text()));\n      if (docs != null) {\n          int newDoc = docs.advance(doc);\n          if (newDoc == doc) {\n            tf = docs.freq();\n          }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      TermDocs termDocs = reader.termDocs(term);\n      if (termDocs != null) {\n        try {\n          if (termDocs.skipTo(doc) && termDocs.doc() == doc) {\n            tf = termDocs.freq();\n          }\n        } finally {\n          termDocs.close();\n        }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4f29ba80b723649f5feb7e37afe1a558dd2c1304","date":1278318805,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","sourceNew":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      DocsEnum docs = reader.termDocsEnum(MultiFields.getDeletedDocs(reader), term.field(), term.bytes());\n      if (docs != null) {\n          int newDoc = docs.advance(doc);\n          if (newDoc == doc) {\n            tf = docs.freq();\n          }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      DocsEnum docs = reader.termDocsEnum(MultiFields.getDeletedDocs(reader), term.field(), new BytesRef(term.text()));\n      if (docs != null) {\n          int newDoc = docs.advance(doc);\n          if (newDoc == doc) {\n            tf = docs.freq();\n          }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","sourceNew":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      DocsEnum docs = reader.termDocsEnum(MultiFields.getDeletedDocs(reader), term.field(), term.bytes());\n      if (docs != null) {\n          int newDoc = docs.advance(doc);\n          if (newDoc == doc) {\n            tf = docs.freq();\n          }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      DocsEnum docs = reader.termDocsEnum(MultiFields.getDeletedDocs(reader), term.field(), new BytesRef(term.text()));\n      if (docs != null) {\n          int newDoc = docs.advance(doc);\n          if (newDoc == doc) {\n            tf = docs.freq();\n          }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d302ba328993a5b449c2e0b3b5e15ae53e45879","date":1281609097,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","sourceNew":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      DocsEnum docs = reader.termDocsEnum(reader.getDeletedDocs(), term.field(), term.bytes());\n      if (docs != null) {\n          int newDoc = docs.advance(doc);\n          if (newDoc == doc) {\n            tf = docs.freq();\n          }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      DocsEnum docs = reader.termDocsEnum(MultiFields.getDeletedDocs(reader), term.field(), term.bytes());\n      if (docs != null) {\n          int newDoc = docs.advance(doc);\n          if (newDoc == doc) {\n            tf = docs.freq();\n          }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","sourceNew":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      DocsEnum docs = reader.termDocsEnum(reader.getDeletedDocs(), term.field(), term.bytes());\n      if (docs != null) {\n          int newDoc = docs.advance(doc);\n          if (newDoc == doc) {\n            tf = docs.freq();\n          }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      DocsEnum docs = reader.termDocsEnum(MultiFields.getDeletedDocs(reader), term.field(), term.bytes());\n      if (docs != null) {\n          int newDoc = docs.advance(doc);\n          if (newDoc == doc) {\n            tf = docs.freq();\n          }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2dadf0f3286a34a0fee6e788ffce88624bf2984e","date":1294260428,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(ReaderContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","sourceNew":"    @Override\n    public Explanation explain(ReaderContext context, int doc)\n      throws IOException {\n      final IndexReader reader = context.reader;\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      DocsEnum docs = reader.termDocsEnum(reader.getDeletedDocs(), term.field(), term.bytes());\n      if (docs != null) {\n          int newDoc = docs.advance(doc);\n          if (newDoc == doc) {\n            tf = docs.freq();\n          }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","sourceOld":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      DocsEnum docs = reader.termDocsEnum(reader.getDeletedDocs(), term.field(), term.bytes());\n      if (docs != null) {\n          int newDoc = docs.advance(doc);\n          if (newDoc == doc) {\n            tf = docs.freq();\n          }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","sourceNew":null,"sourceOld":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      DocsEnum docs = reader.termDocsEnum(reader.getDeletedDocs(), term.field(), term.bytes());\n      if (docs != null) {\n          int newDoc = docs.advance(doc);\n          if (newDoc == doc) {\n            tf = docs.freq();\n          }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/search/TermQuery.TermWeight#explain(IndexReader,int).mjava","sourceNew":null,"sourceOld":"    @Override\n    public Explanation explain(IndexReader reader, int doc)\n      throws IOException {\n\n      ComplexExplanation result = new ComplexExplanation();\n      result.setDescription(\"weight(\"+getQuery()+\" in \"+doc+\"), product of:\");\n\n      Explanation expl = new Explanation(idf, idfExp.explain());\n\n      // explain query weight\n      Explanation queryExpl = new Explanation();\n      queryExpl.setDescription(\"queryWeight(\" + getQuery() + \"), product of:\");\n\n      Explanation boostExpl = new Explanation(getBoost(), \"boost\");\n      if (getBoost() != 1.0f)\n        queryExpl.addDetail(boostExpl);\n      queryExpl.addDetail(expl);\n\n      Explanation queryNormExpl = new Explanation(queryNorm,\"queryNorm\");\n      queryExpl.addDetail(queryNormExpl);\n\n      queryExpl.setValue(boostExpl.getValue() *\n                         expl.getValue() *\n                         queryNormExpl.getValue());\n\n      result.addDetail(queryExpl);\n\n      // explain field weight\n      String field = term.field();\n      ComplexExplanation fieldExpl = new ComplexExplanation();\n      fieldExpl.setDescription(\"fieldWeight(\"+term+\" in \"+doc+\n                               \"), product of:\");\n\n      Explanation tfExplanation = new Explanation();\n      int tf = 0;\n      DocsEnum docs = reader.termDocsEnum(reader.getDeletedDocs(), term.field(), term.bytes());\n      if (docs != null) {\n          int newDoc = docs.advance(doc);\n          if (newDoc == doc) {\n            tf = docs.freq();\n          }\n        tfExplanation.setValue(similarity.tf(tf));\n        tfExplanation.setDescription(\"tf(termFreq(\"+term+\")=\"+tf+\")\");\n      } else {\n        tfExplanation.setValue(0.0f);\n        tfExplanation.setDescription(\"no matching term\");\n      }\n      fieldExpl.addDetail(tfExplanation);\n      fieldExpl.addDetail(expl);\n\n      Explanation fieldNormExpl = new Explanation();\n      byte[] fieldNorms = reader.norms(field);\n      float fieldNorm =\n        fieldNorms!=null ? similarity.decodeNormValue(fieldNorms[doc]) : 1.0f;\n      fieldNormExpl.setValue(fieldNorm);\n      fieldNormExpl.setDescription(\"fieldNorm(field=\"+field+\", doc=\"+doc+\")\");\n      fieldExpl.addDetail(fieldNormExpl);\n      \n      fieldExpl.setMatch(Boolean.valueOf(tfExplanation.isMatch()));\n      fieldExpl.setValue(tfExplanation.getValue() *\n                         expl.getValue() *\n                         fieldNormExpl.getValue());\n\n      result.addDetail(fieldExpl);\n      result.setMatch(fieldExpl.getMatch());\n      \n      // combine them\n      result.setValue(queryExpl.getValue() * fieldExpl.getValue());\n\n      if (queryExpl.getValue() == 1.0f)\n        return fieldExpl;\n\n      return result;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4f29ba80b723649f5feb7e37afe1a558dd2c1304":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["0d302ba328993a5b449c2e0b3b5e15ae53e45879","2dadf0f3286a34a0fee6e788ffce88624bf2984e"],"2dadf0f3286a34a0fee6e788ffce88624bf2984e":["0d302ba328993a5b449c2e0b3b5e15ae53e45879"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"0d302ba328993a5b449c2e0b3b5e15ae53e45879":["4f29ba80b723649f5feb7e37afe1a558dd2c1304"],"5f4e87790277826a2aea119328600dfb07761f32":["955c32f886db6f6356c9fcdea6b1f1cb4effda24","4f29ba80b723649f5feb7e37afe1a558dd2c1304"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["5f4e87790277826a2aea119328600dfb07761f32","0d302ba328993a5b449c2e0b3b5e15ae53e45879"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","2dadf0f3286a34a0fee6e788ffce88624bf2984e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2dadf0f3286a34a0fee6e788ffce88624bf2984e"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"4f29ba80b723649f5feb7e37afe1a558dd2c1304":["0d302ba328993a5b449c2e0b3b5e15ae53e45879","5f4e87790277826a2aea119328600dfb07761f32"],"29ef99d61cda9641b6250bf9567329a6e65f901d":[],"2dadf0f3286a34a0fee6e788ffce88624bf2984e":["29ef99d61cda9641b6250bf9567329a6e65f901d","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"955c32f886db6f6356c9fcdea6b1f1cb4effda24":["4f29ba80b723649f5feb7e37afe1a558dd2c1304","5f4e87790277826a2aea119328600dfb07761f32"],"0d302ba328993a5b449c2e0b3b5e15ae53e45879":["29ef99d61cda9641b6250bf9567329a6e65f901d","2dadf0f3286a34a0fee6e788ffce88624bf2984e","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"5f4e87790277826a2aea119328600dfb07761f32":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"868da859b43505d9d2a023bfeae6dd0c795f5295":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["955c32f886db6f6356c9fcdea6b1f1cb4effda24"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["29ef99d61cda9641b6250bf9567329a6e65f901d","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}