{"path":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","commits":[{"id":"e3ce1ef883d26aa73919aa2d53991726e96caa13","date":1445421402,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"/dev/null","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final ByteArrayDataInput reader = new ByteArrayDataInput();\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n        private final ByteArrayDataInput readerB = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          reader.reset(a.bytes, a.offset, a.length);\n          reader.readBytes(scratch1, 0, scratch1.length);\n          final int docIDA = reader.readVInt();\n          final long ordA = reader.readVLong();\n\n          reader.reset(b.bytes, b.offset, b.length);\n          reader.readBytes(scratch2, 0, scratch2.length);\n          final int docIDB = reader.readVInt();\n          final long ordB = reader.readVLong();\n\n          int cmp = BKDUtil.compare(bytesPerDim, scratch1, dim, scratch2, dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break\n          cmp = Integer.compare(docIDA, docIDB);\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          return Long.compare(ordA, ordB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["2b84d416bbd661ae4b2a28d103bdfccb851e00de"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1786be6a11f9cf5e48ce84869d1bb71e9c02f966","date":1448381196,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final ByteArrayDataInput reader = new ByteArrayDataInput();\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n        private final ByteArrayDataInput readerB = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          reader.reset(a.bytes, a.offset, a.length);\n          reader.readBytes(scratch1, 0, scratch1.length);\n          final int docIDA = reader.readVInt();\n          final long ordA = reader.readVLong();\n\n          reader.reset(b.bytes, b.offset, b.length);\n          reader.readBytes(scratch2, 0, scratch2.length);\n          final int docIDB = reader.readVInt();\n          final long ordB = reader.readVLong();\n\n          int cmp = BKDUtil.compare(bytesPerDim, scratch1, dim, scratch2, dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break\n          cmp = Integer.compare(docIDA, docIDB);\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          return Long.compare(ordA, ordB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final ByteArrayDataInput reader = new ByteArrayDataInput();\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n        private final ByteArrayDataInput readerB = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          reader.reset(a.bytes, a.offset, a.length);\n          reader.readBytes(scratch1, 0, scratch1.length);\n          final int docIDA = reader.readVInt();\n          final long ordA = reader.readVLong();\n\n          reader.reset(b.bytes, b.offset, b.length);\n          reader.readBytes(scratch2, 0, scratch2.length);\n          final int docIDB = reader.readVInt();\n          final long ordB = reader.readVLong();\n\n          int cmp = BKDUtil.compare(bytesPerDim, scratch1, dim, scratch2, dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break\n          cmp = Integer.compare(docIDA, docIDB);\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          return Long.compare(ordA, ordB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"770342641f7b505eaa8dccdc666158bff2419109","date":1449868421,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final ByteArrayDataInput reader = new ByteArrayDataInput();\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n        private final ByteArrayDataInput readerB = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          reader.reset(a.bytes, a.offset, a.length);\n          reader.readBytes(scratch1, 0, scratch1.length);\n          final int docIDA = reader.readVInt();\n          final long ordA = reader.readVLong();\n\n          reader.reset(b.bytes, b.offset, b.length);\n          reader.readBytes(scratch2, 0, scratch2.length);\n          final int docIDB = reader.readVInt();\n          final long ordB = reader.readVLong();\n\n          int cmp = NumericUtils.compare(bytesPerDim, scratch1, dim, scratch2, dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break\n          cmp = Integer.compare(docIDA, docIDB);\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          return Long.compare(ordA, ordB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final ByteArrayDataInput reader = new ByteArrayDataInput();\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n        private final ByteArrayDataInput readerB = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          reader.reset(a.bytes, a.offset, a.length);\n          reader.readBytes(scratch1, 0, scratch1.length);\n          final int docIDA = reader.readVInt();\n          final long ordA = reader.readVLong();\n\n          reader.reset(b.bytes, b.offset, b.length);\n          reader.readBytes(scratch2, 0, scratch2.length);\n          final int docIDB = reader.readVInt();\n          final long ordB = reader.readVLong();\n\n          int cmp = BKDUtil.compare(bytesPerDim, scratch1, dim, scratch2, dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break\n          cmp = Integer.compare(docIDA, docIDB);\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          return Long.compare(ordA, ordB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"12bfdc932307442b651432f92845942f9041ace8","date":1456860728,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final ByteArrayDataInput reader = new ByteArrayDataInput();\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n        private final ByteArrayDataInput readerB = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          reader.reset(a.bytes, a.offset, a.length);\n          reader.readBytes(scratch1, 0, scratch1.length);\n          final int docIDA = reader.readVInt();\n          final long ordA = reader.readVLong();\n\n          reader.reset(b.bytes, b.offset, b.length);\n          reader.readBytes(scratch2, 0, scratch2.length);\n          final int docIDB = reader.readVInt();\n          final long ordB = reader.readVLong();\n\n          int cmp = StringHelper.compare(bytesPerDim, scratch1, bytesPerDim*dim, scratch2, bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break\n          cmp = Integer.compare(docIDA, docIDB);\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          return Long.compare(ordA, ordB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final ByteArrayDataInput reader = new ByteArrayDataInput();\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n        private final ByteArrayDataInput readerB = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          reader.reset(a.bytes, a.offset, a.length);\n          reader.readBytes(scratch1, 0, scratch1.length);\n          final int docIDA = reader.readVInt();\n          final long ordA = reader.readVLong();\n\n          reader.reset(b.bytes, b.offset, b.length);\n          reader.readBytes(scratch2, 0, scratch2.length);\n          final int docIDB = reader.readVInt();\n          final long ordB = reader.readVLong();\n\n          int cmp = NumericUtils.compare(bytesPerDim, scratch1, dim, scratch2, dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break\n          cmp = Integer.compare(docIDA, docIDB);\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          return Long.compare(ordA, ordB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"74abfad53a433ccd1fa4997d620a9b016f3bb24e","date":1456866481,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n\n          // First compare the bytes on the dimension we are sorting on:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID and then ord:\n          reader.reset(a.bytes, a.offset + packedBytesLength, a.length);\n          final int docIDA = reader.readVInt();\n          final long ordA = reader.readVLong();\n\n          reader.reset(b.bytes, b.offset + packedBytesLength, b.length);\n          final int docIDB = reader.readVInt();\n          final long ordB = reader.readVLong();\n\n          cmp = Integer.compare(docIDA, docIDB);\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // TODO: is this really necessary?  If OfflineSorter is stable, we can safely return 0 here, and avoid writing ords?\n          return Long.compare(ordA, ordB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final ByteArrayDataInput reader = new ByteArrayDataInput();\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n        private final ByteArrayDataInput readerB = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          reader.reset(a.bytes, a.offset, a.length);\n          reader.readBytes(scratch1, 0, scratch1.length);\n          final int docIDA = reader.readVInt();\n          final long ordA = reader.readVLong();\n\n          reader.reset(b.bytes, b.offset, b.length);\n          reader.readBytes(scratch2, 0, scratch2.length);\n          final int docIDB = reader.readVInt();\n          final long ordB = reader.readVLong();\n\n          int cmp = StringHelper.compare(bytesPerDim, scratch1, bytesPerDim*dim, scratch2, bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break\n          cmp = Integer.compare(docIDA, docIDB);\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          return Long.compare(ordA, ordB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"adc9dc8ef0ce617b940a039fd12f79e8b098cc7f","date":1456936072,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n\n          // First compare the bytes on the dimension we are sorting on:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID:\n          reader.reset(a.bytes, a.offset + packedBytesLength + Long.BYTES, a.length);\n          final int docIDA = reader.readInt();\n\n          reader.reset(b.bytes, b.offset + packedBytesLength + Long.BYTES, b.length);\n          final int docIDB = reader.readInt();\n\n          // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n          // can't matter at search time since we don't write ords into the index:\n          return Integer.compare(docIDA, docIDB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n\n          // First compare the bytes on the dimension we are sorting on:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID and then ord:\n          reader.reset(a.bytes, a.offset + packedBytesLength, a.length);\n          final int docIDA = reader.readVInt();\n          final long ordA = reader.readVLong();\n\n          reader.reset(b.bytes, b.offset + packedBytesLength, b.length);\n          final int docIDB = reader.readVInt();\n          final long ordB = reader.readVLong();\n\n          cmp = Integer.compare(docIDA, docIDB);\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // TODO: is this really necessary?  If OfflineSorter is stable, we can safely return 0 here, and avoid writing ords?\n          return Long.compare(ordA, ordB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount);\n    }\n  }\n\n","bugFix":null,"bugIntro":["2b84d416bbd661ae4b2a28d103bdfccb851e00de"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cf1a614098b46c9c22afebd7b898ae4d1d2fc273","date":1457088850,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n\n          // First compare the bytes on the dimension we are sorting on:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID:\n          reader.reset(a.bytes, a.offset + packedBytesLength + Long.BYTES, a.length);\n          final int docIDA = reader.readInt();\n\n          reader.reset(b.bytes, b.offset + packedBytesLength + Long.BYTES, b.length);\n          final int docIDB = reader.readInt();\n\n          // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n          // can't matter at search time since we don't write ords into the index:\n          return Integer.compare(docIDA, docIDB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final ByteArrayDataInput reader = new ByteArrayDataInput();\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n        private final ByteArrayDataInput readerB = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          reader.reset(a.bytes, a.offset, a.length);\n          reader.readBytes(scratch1, 0, scratch1.length);\n          final int docIDA = reader.readVInt();\n          final long ordA = reader.readVLong();\n\n          reader.reset(b.bytes, b.offset, b.length);\n          reader.readBytes(scratch2, 0, scratch2.length);\n          final int docIDB = reader.readVInt();\n          final long ordB = reader.readVLong();\n\n          int cmp = NumericUtils.compare(bytesPerDim, scratch1, dim, scratch2, dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break\n          cmp = Integer.compare(docIDA, docIDB);\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          return Long.compare(ordA, ordB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca","date":1457777566,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n\n          // First compare the bytes on the dimension we are sorting on:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID:\n          int offset;\n          if (longOrds) {\n            offset = Long.BYTES;\n          } else {\n            offset = Integer.BYTES;\n          }\n          reader.reset(a.bytes, a.offset + packedBytesLength + offset, a.length);\n          final int docIDA = reader.readInt();\n\n          reader.reset(b.bytes, b.offset + packedBytesLength + offset, b.length);\n          final int docIDB = reader.readInt();\n\n          // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n          // can't matter at search time since we don't write ords into the index:\n          return Integer.compare(docIDA, docIDB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n\n          // First compare the bytes on the dimension we are sorting on:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID:\n          reader.reset(a.bytes, a.offset + packedBytesLength + Long.BYTES, a.length);\n          final int docIDA = reader.readInt();\n\n          reader.reset(b.bytes, b.offset + packedBytesLength + Long.BYTES, b.length);\n          final int docIDB = reader.readInt();\n\n          // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n          // can't matter at search time since we don't write ords into the index:\n          return Integer.compare(docIDA, docIDB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2b84d416bbd661ae4b2a28d103bdfccb851e00de","date":1458041762,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n\n          // First compare the bytes on the dimension we are sorting on:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID:\n          int offset;\n          if (longOrds) {\n            offset = Long.BYTES;\n          } else {\n            offset = Integer.BYTES;\n          }\n          reader.reset(a.bytes, a.offset + packedBytesLength + offset, a.length);\n          final int docIDA = reader.readInt();\n\n          reader.reset(b.bytes, b.offset + packedBytesLength + offset, b.length);\n          final int docIDB = reader.readInt();\n\n          // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n          // can't matter at search time since we don't write ords into the index:\n          return Integer.compare(docIDA, docIDB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n\n          // First compare the bytes on the dimension we are sorting on:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID:\n          int offset;\n          if (longOrds) {\n            offset = Long.BYTES;\n          } else {\n            offset = Integer.BYTES;\n          }\n          reader.reset(a.bytes, a.offset + packedBytesLength + offset, a.length);\n          final int docIDA = reader.readInt();\n\n          reader.reset(b.bytes, b.offset + packedBytesLength + offset, b.length);\n          final int docIDB = reader.readInt();\n\n          // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n          // can't matter at search time since we don't write ords into the index:\n          return Integer.compare(docIDA, docIDB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                if (len != bytesPerDoc) {\n                  throw new IllegalArgumentException(\"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc);\n                }\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds);\n    }\n  }\n\n","bugFix":["adc9dc8ef0ce617b940a039fd12f79e8b098cc7f","e3ce1ef883d26aa73919aa2d53991726e96caa13"],"bugIntro":["1e52a98a3809d9d747b7694f15f80b7018403ef5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"950b7a6881d14da782b60444c11295e3ec50d41a","date":1458379095,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n\n          // First compare the bytes on the dimension we are sorting on:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID:\n          int offset;\n          if (longOrds) {\n            offset = Long.BYTES;\n          } else {\n            offset = Integer.BYTES;\n          }\n          reader.reset(a.bytes, a.offset + packedBytesLength + offset, a.length);\n          final int docIDA = reader.readInt();\n\n          reader.reset(b.bytes, b.offset + packedBytesLength + offset, b.length);\n          final int docIDB = reader.readInt();\n\n          // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n          // can't matter at search time since we don't write ords into the index:\n          return Integer.compare(docIDA, docIDB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return false;\n                }\n                ref.grow(bytesPerDoc);\n                in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n\n          // First compare the bytes on the dimension we are sorting on:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID:\n          int offset;\n          if (longOrds) {\n            offset = Long.BYTES;\n          } else {\n            offset = Integer.BYTES;\n          }\n          reader.reset(a.bytes, a.offset + packedBytesLength + offset, a.length);\n          final int docIDA = reader.readInt();\n\n          reader.reset(b.bytes, b.offset + packedBytesLength + offset, b.length);\n          final int docIDB = reader.readInt();\n\n          // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n          // can't matter at search time since we don't write ords into the index:\n          return Integer.compare(docIDA, docIDB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(IndexInput in) throws IOException {\n            return new ByteSequencesReader(in) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                ref.grow(bytesPerDoc);\n                try {\n                  in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                } catch (EOFException eofe) {\n                  return false;\n                }\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"416f9e28900210be57b69bc12e2954fb98ed7ebe","date":1458479803,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n\n          // First compare the bytes on the dimension we are sorting on:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID:\n          int offset;\n          if (singleValuePerDoc) {\n            offset = 0;\n          } else if (longOrds) {\n            offset = Long.BYTES;\n          } else {\n            offset = Integer.BYTES;\n          }\n          reader.reset(a.bytes, a.offset + packedBytesLength + offset, a.length);\n          final int docIDA = reader.readInt();\n\n          reader.reset(b.bytes, b.offset + packedBytesLength + offset, b.length);\n          final int docIDB = reader.readInt();\n\n          // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n          // can't matter at search time since we don't write ords into the index:\n          return Integer.compare(docIDA, docIDB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return false;\n                }\n                ref.grow(bytesPerDoc);\n                in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n\n          // First compare the bytes on the dimension we are sorting on:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID:\n          int offset;\n          if (longOrds) {\n            offset = Long.BYTES;\n          } else {\n            offset = Integer.BYTES;\n          }\n          reader.reset(a.bytes, a.offset + packedBytesLength + offset, a.length);\n          final int docIDA = reader.readInt();\n\n          reader.reset(b.bytes, b.offset + packedBytesLength + offset, b.length);\n          final int docIDB = reader.readInt();\n\n          // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n          // can't matter at search time since we don't write ords into the index:\n          return Integer.compare(docIDA, docIDB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return false;\n                }\n                ref.grow(bytesPerDoc);\n                in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1987c0002f396ce6d6dada94c6773d6ba0e03f50","date":1458660902,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n\n          // First compare the bytes on the dimension we are sorting on:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID:\n          int offset;\n          if (singleValuePerDoc) {\n            offset = 0;\n          } else if (longOrds) {\n            offset = Long.BYTES;\n          } else {\n            offset = Integer.BYTES;\n          }\n          reader.reset(a.bytes, a.offset + packedBytesLength + offset, a.length);\n          final int docIDA = reader.readInt();\n\n          reader.reset(b.bytes, b.offset + packedBytesLength + offset, b.length);\n          final int docIDB = reader.readInt();\n\n          // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n          // can't matter at search time since we don't write ords into the index:\n          return Integer.compare(docIDA, docIDB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return false;\n                }\n                ref.grow(bytesPerDoc);\n                in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, 0, (int) pointCount, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n\n          // First compare the bytes on the dimension we are sorting on:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID:\n          int offset;\n          if (singleValuePerDoc) {\n            offset = 0;\n          } else if (longOrds) {\n            offset = Long.BYTES;\n          } else {\n            offset = Integer.BYTES;\n          }\n          reader.reset(a.bytes, a.offset + packedBytesLength + offset, a.length);\n          final int docIDA = reader.readInt();\n\n          reader.reset(b.bytes, b.offset + packedBytesLength + offset, b.length);\n          final int docIDB = reader.readInt();\n\n          // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n          // can't matter at search time since we don't write ords into the index:\n          return Integer.compare(docIDA, docIDB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return false;\n                }\n                ref.grow(bytesPerDoc);\n                in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bc57257d8a309205ebefdf9ee778da293673f599","date":1458828168,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          // First compare by the requested dimension we are sorting by:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID ... no need to tie break on ord, for the case where the same doc has\n          // the same value in a given dimension indexed more than once: it can't matter at search\n          // time since we don't write ords into the index:\n\n          return StringHelper.compare(Integer.BYTES,\n                                      a.bytes, a.offset + packedBytesLength,\n                                      b.bytes, b.offset + packedBytesLength);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return false;\n                }\n                ref.grow(bytesPerDoc);\n                in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n\n          // First compare the bytes on the dimension we are sorting on:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID:\n          int offset;\n          if (singleValuePerDoc) {\n            offset = 0;\n          } else if (longOrds) {\n            offset = Long.BYTES;\n          } else {\n            offset = Integer.BYTES;\n          }\n          reader.reset(a.bytes, a.offset + packedBytesLength + offset, a.length);\n          final int docIDA = reader.readInt();\n\n          reader.reset(b.bytes, b.offset + packedBytesLength + offset, b.length);\n          final int docIDB = reader.readInt();\n\n          // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it\n          // can't matter at search time since we don't write ords into the index:\n          return Integer.compare(docIDA, docIDB);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return false;\n                }\n                ref.grow(bytesPerDoc);\n                in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7849935cc625c020857f3b29be91b5d4323d19aa","date":1458978426,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          // First compare by the requested dimension we are sorting by:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID ... no need to tie break on ord, for the case where the same doc has\n          // the same value in a given dimension indexed more than once: it can't matter at search\n          // time since we don't write ords into the index:\n\n          return StringHelper.compare(Integer.BYTES,\n                                      a.bytes, a.offset + packedBytesLength,\n                                      b.bytes, b.offset + packedBytesLength);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          // First compare by the requested dimension we are sorting by:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID ... no need to tie break on ord, for the case where the same doc has\n          // the same value in a given dimension indexed more than once: it can't matter at search\n          // time since we don't write ords into the index:\n\n          return StringHelper.compare(Integer.BYTES,\n                                      a.bytes, a.offset + packedBytesLength,\n                                      b.bytes, b.offset + packedBytesLength);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              @Override\n              public boolean read(BytesRefBuilder ref) throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return false;\n                }\n                ref.grow(bytesPerDoc);\n                in.readBytes(ref.bytes(), 0, bytesPerDoc);\n                ref.setLength(bytesPerDoc);\n                return true;\n              }\n            };\n          }\n        };\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f6a5bbbabf9fffa3247e7dc730254570822cf4b3","date":1458987953,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          // First compare by the requested dimension we are sorting by:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID ... no need to tie break on ord, for the case where the same doc has\n          // the same value in a given dimension indexed more than once: it can't matter at search\n          // time since we don't write ords into the index:\n\n          return StringHelper.compare(Integer.BYTES,\n                                      a.bytes, a.offset + packedBytesLength,\n                                      b.bytes, b.offset + packedBytesLength);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          // First compare by the requested dimension we are sorting by:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID ... no need to tie break on ord, for the case where the same doc has\n          // the same value in a given dimension indexed more than once: it can't matter at search\n          // time since we don't write ords into the index:\n\n          return StringHelper.compare(Integer.BYTES,\n                                      a.bytes, a.offset + packedBytesLength,\n                                      b.bytes, b.offset + packedBytesLength);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1e52a98a3809d9d747b7694f15f80b7018403ef5","date":1459072349,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          // First compare by the requested dimension we are sorting by:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID ... no need to tie break on ord, for the case where the same doc has\n          // the same value in a given dimension indexed more than once: it can't matter at search\n          // time since we don't write ords into the index:\n\n          return StringHelper.compare(Integer.BYTES,\n                                      a.bytes, a.offset + packedBytesLength,\n                                      b.bytes, b.offset + packedBytesLength);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          // First compare by the requested dimension we are sorting by:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID ... no need to tie break on ord, for the case where the same doc has\n          // the same value in a given dimension indexed more than once: it can't matter at search\n          // time since we don't write ords into the index:\n\n          return StringHelper.compare(Integer.BYTES,\n                                      a.bytes, a.offset + packedBytesLength,\n                                      b.bytes, b.offset + packedBytesLength);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":["2b84d416bbd661ae4b2a28d103bdfccb851e00de"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ee52259641568741fbc6ecc51284431e2a36475c","date":1459331525,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          // First compare by the requested dimension we are sorting by:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + offset, b.bytes, b.offset + offset);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID ... no need to tie break on ord, for the case where the same doc has\n          // the same value in a given dimension indexed more than once: it can't matter at search\n          // time since we don't write ords into the index:\n\n          return StringHelper.compare(Integer.BYTES,\n                                      a.bytes, a.offset + packedBytesLength,\n                                      b.bytes, b.offset + packedBytesLength);\n        }\n      };\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          // First compare by the requested dimension we are sorting by:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID ... no need to tie break on ord, for the case where the same doc has\n          // the same value in a given dimension indexed more than once: it can't matter at search\n          // time since we don't write ords into the index:\n\n          return StringHelper.compare(Integer.BYTES,\n                                      a.bytes, a.offset + packedBytesLength,\n                                      b.bytes, b.offset + packedBytesLength);\n        }\n      };\n\n      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:\n      IndexOutput[] lastWriter = new IndexOutput[1];\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            lastWriter[0] = out;\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n      sorter.sort(tempInput.getName());\n\n      assert lastWriter[0] != null;\n\n      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e","date":1464596999,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          // First compare by the requested dimension we are sorting by:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + offset, b.bytes, b.offset + offset);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID ... no need to tie break on ord, for the case where the same doc has\n          // the same value in a given dimension indexed more than once: it can't matter at search\n          // time since we don't write ords into the index:\n\n          return StringHelper.compare(Integer.BYTES,\n                                      a.bytes, a.offset + packedBytesLength,\n                                      b.bytes, b.offset + packedBytesLength);\n        }\n      };\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"da8a02bef7458089240404614139b53c9f875ec7","date":1464597207,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          // First compare by the requested dimension we are sorting by:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + offset, b.bytes, b.offset + offset);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID ... no need to tie break on ord, for the case where the same doc has\n          // the same value in a given dimension indexed more than once: it can't matter at search\n          // time since we don't write ords into the index:\n\n          return StringHelper.compare(Integer.BYTES,\n                                      a.bytes, a.offset + packedBytesLength,\n                                      b.bytes, b.offset + packedBytesLength);\n        }\n      };\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5b8ee93140fd0efef7e101786e3ed5160a700b5f","date":1464820111,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          // First compare by the requested dimension we are sorting by:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + offset, b.bytes, b.offset + offset);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID ... no need to tie break on ord, for the case where the same doc has\n          // the same value in a given dimension indexed more than once: it can't matter at search\n          // time since we don't write ords into the index:\n\n          return StringHelper.compare(Integer.BYTES,\n                                      a.bytes, a.offset + packedBytesLength,\n                                      b.bytes, b.offset + packedBytesLength);\n        }\n      };\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a20457919db052812998f60294d17daa883ff972","date":1470227748,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDims;\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDims;\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDims;\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {\n \n        final ByteArrayDataInput reader = new ByteArrayDataInput();\n\n        @Override\n        public int compare(BytesRef a, BytesRef b) {\n          // First compare by the requested dimension we are sorting by:\n          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + offset, b.bytes, b.offset + offset);\n\n          if (cmp != 0) {\n            return cmp;\n          }\n\n          // Tie-break by docID ... no need to tie break on ord, for the case where the same doc has\n          // the same value in a given dimension indexed more than once: it can't matter at search\n          // time since we don't write ords into the index:\n\n          return StringHelper.compare(Integer.BYTES,\n                                      a.bytes, a.offset + packedBytesLength,\n                                      b.bytes, b.offset + packedBytesLength);\n        }\n      };\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"62e7e8f89cb6b0283f3f5d6c0945453b73f09d45","date":1492172132,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDims;\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out, long count) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDims;\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54ca69905c5d9d1529286f06ab1d12c68f6c13cb","date":1492683554,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDims;\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out, long count) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDims;\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7dcb0432bcb41451b41e9aaaabe99f5d208258fe","date":1493203108,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDims;\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc, null, 0) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out, long count) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDims;\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out, long count) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDims;\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc, null, 0) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out, long count) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDims;\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out, long count) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6652c943595e92c187ee904c382863013eae28f","date":1539042663,"type":3,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDataDims;\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDataDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc, null, 0) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out, long count) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDims;\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc, null, 0) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out, long count) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5db3224bb6ba28cb735531b45593da725fa751d1","date":1547448966,"type":3,"author":"iverase","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":"  //return a new point writer sort by the provided dimension from input data\n  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDataDims;\n\n    if (heapPointWriter != null) {\n      assert tempInput == null;\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted = heapPointWriter;\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, Math.toIntExact(this.pointCount), dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n      sorted.close();\n      heapPointWriter = null;\n      return sorted;\n    } else {\n      // Offline sort:\n      assert tempInput != null;\n      OfflinePointWriter sorted = sortOffLine(dim, tempInput.getName(), 0, pointCount);\n      tempDir.deleteFile(tempInput.getName());\n      tempInput = null;\n      return sorted;\n    }\n  }\n\n","sourceOld":"  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDataDims;\n\n    if (heapPointWriter != null) {\n\n      assert tempInput == null;\n\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted;\n\n      if (dim == 0) {\n        // First dim can re-use the current heap writer\n        sorted = heapPointWriter;\n      } else {\n        // Subsequent dims need a private copy\n        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);\n        sorted.copyFrom(heapPointWriter);\n      }\n\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n\n      sorted.close();\n      return sorted;\n    } else {\n\n      // Offline sort:\n      assert tempInput != null;\n\n      final int offset = bytesPerDim * dim;\n\n      Comparator<BytesRef> cmp;\n      if (dim == numDataDims - 1) {\n        // in that case the bytes for the dimension and for the doc id are contiguous,\n        // so we don't need a branch\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            return ref.bytes[ref.offset + offset + i] & 0xff;\n          }\n        };\n      } else {\n        cmp = new BytesRefComparator(bytesPerDim + Integer.BYTES) {\n          @Override\n          protected int byteAt(BytesRef ref, int i) {\n            if (i < bytesPerDim) {\n              return ref.bytes[ref.offset + offset + i] & 0xff;\n            } else {\n              return ref.bytes[ref.offset + packedBytesLength + i - bytesPerDim] & 0xff;\n            }\n          }\n        };\n      }\n\n      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + \"_bkd\" + dim, cmp, offlineSorterBufferMB, offlineSorterMaxTempFiles, bytesPerDoc, null, 0) {\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesWriter getWriter(IndexOutput out, long count) {\n            return new ByteSequencesWriter(out) {\n              @Override\n              public void write(byte[] bytes, int off, int len) throws IOException {\n                assert len == bytesPerDoc: \"len=\" + len + \" bytesPerDoc=\" + bytesPerDoc;\n                out.writeBytes(bytes, off, len);\n              }\n            };\n          }\n\n          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */\n          @Override\n          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {\n            return new ByteSequencesReader(in, name) {\n              final BytesRef scratch = new BytesRef(new byte[bytesPerDoc]);\n              @Override\n              public BytesRef next() throws IOException {\n                if (in.getFilePointer() >= end) {\n                  return null;\n                }\n                in.readBytes(scratch.bytes, 0, bytesPerDoc);\n                return scratch;\n              }\n            };\n          }\n        };\n\n      String name = sorter.sort(tempInput.getName());\n\n      return new OfflinePointWriter(tempDir, name, packedBytesLength, pointCount, longOrds, singleValuePerDoc);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"78bdc7d6906146edb12a1a6c1f765ba680ed5124","date":1549523533,"type":4,"author":"iverase","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#sort(int).mjava","sourceNew":null,"sourceOld":"  //return a new point writer sort by the provided dimension from input data\n  private PointWriter sort(int dim) throws IOException {\n    assert dim >= 0 && dim < numDataDims;\n\n    if (heapPointWriter != null) {\n      assert tempInput == null;\n      // We never spilled the incoming points to disk, so now we sort in heap:\n      HeapPointWriter sorted = heapPointWriter;\n      //long t0 = System.nanoTime();\n      sortHeapPointWriter(sorted, Math.toIntExact(this.pointCount), dim);\n      //long t1 = System.nanoTime();\n      //System.out.println(\"BKD: sort took \" + ((t1-t0)/1000000.0) + \" msec\");\n      sorted.close();\n      heapPointWriter = null;\n      return sorted;\n    } else {\n      // Offline sort:\n      assert tempInput != null;\n      OfflinePointWriter sorted = sortOffLine(dim, tempInput.getName(), 0, pointCount);\n      tempDir.deleteFile(tempInput.getName());\n      tempInput = null;\n      return sorted;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["a20457919db052812998f60294d17daa883ff972"],"5db3224bb6ba28cb735531b45593da725fa751d1":["f6652c943595e92c187ee904c382863013eae28f"],"f6652c943595e92c187ee904c382863013eae28f":["7dcb0432bcb41451b41e9aaaabe99f5d208258fe"],"f6a5bbbabf9fffa3247e7dc730254570822cf4b3":["7849935cc625c020857f3b29be91b5d4323d19aa"],"1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e":["ee52259641568741fbc6ecc51284431e2a36475c"],"78bdc7d6906146edb12a1a6c1f765ba680ed5124":["5db3224bb6ba28cb735531b45593da725fa751d1"],"bc57257d8a309205ebefdf9ee778da293673f599":["1987c0002f396ce6d6dada94c6773d6ba0e03f50"],"2b84d416bbd661ae4b2a28d103bdfccb851e00de":["9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca"],"da8a02bef7458089240404614139b53c9f875ec7":["ee52259641568741fbc6ecc51284431e2a36475c","1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e"],"74abfad53a433ccd1fa4997d620a9b016f3bb24e":["12bfdc932307442b651432f92845942f9041ace8"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","7dcb0432bcb41451b41e9aaaabe99f5d208258fe"],"12bfdc932307442b651432f92845942f9041ace8":["770342641f7b505eaa8dccdc666158bff2419109"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"950b7a6881d14da782b60444c11295e3ec50d41a":["2b84d416bbd661ae4b2a28d103bdfccb851e00de"],"1987c0002f396ce6d6dada94c6773d6ba0e03f50":["416f9e28900210be57b69bc12e2954fb98ed7ebe"],"1786be6a11f9cf5e48ce84869d1bb71e9c02f966":["e3ce1ef883d26aa73919aa2d53991726e96caa13"],"a20457919db052812998f60294d17daa883ff972":["1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e"],"e3ce1ef883d26aa73919aa2d53991726e96caa13":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5b8ee93140fd0efef7e101786e3ed5160a700b5f":["ee52259641568741fbc6ecc51284431e2a36475c","1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e"],"7dcb0432bcb41451b41e9aaaabe99f5d208258fe":["62e7e8f89cb6b0283f3f5d6c0945453b73f09d45"],"adc9dc8ef0ce617b940a039fd12f79e8b098cc7f":["74abfad53a433ccd1fa4997d620a9b016f3bb24e"],"770342641f7b505eaa8dccdc666158bff2419109":["1786be6a11f9cf5e48ce84869d1bb71e9c02f966"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["ee52259641568741fbc6ecc51284431e2a36475c","a20457919db052812998f60294d17daa883ff972"],"9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"7849935cc625c020857f3b29be91b5d4323d19aa":["bc57257d8a309205ebefdf9ee778da293673f599"],"ee52259641568741fbc6ecc51284431e2a36475c":["1e52a98a3809d9d747b7694f15f80b7018403ef5"],"1e52a98a3809d9d747b7694f15f80b7018403ef5":["f6a5bbbabf9fffa3247e7dc730254570822cf4b3"],"416f9e28900210be57b69bc12e2954fb98ed7ebe":["950b7a6881d14da782b60444c11295e3ec50d41a"],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["770342641f7b505eaa8dccdc666158bff2419109","adc9dc8ef0ce617b940a039fd12f79e8b098cc7f"],"62e7e8f89cb6b0283f3f5d6c0945453b73f09d45":["a20457919db052812998f60294d17daa883ff972"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e","a20457919db052812998f60294d17daa883ff972"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["78bdc7d6906146edb12a1a6c1f765ba680ed5124"]},"commit2Childs":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["e9017cf144952056066919f1ebc7897ff9bd71b1"],"5db3224bb6ba28cb735531b45593da725fa751d1":["78bdc7d6906146edb12a1a6c1f765ba680ed5124"],"f6652c943595e92c187ee904c382863013eae28f":["5db3224bb6ba28cb735531b45593da725fa751d1"],"f6a5bbbabf9fffa3247e7dc730254570822cf4b3":["1e52a98a3809d9d747b7694f15f80b7018403ef5"],"1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e":["da8a02bef7458089240404614139b53c9f875ec7","a20457919db052812998f60294d17daa883ff972","5b8ee93140fd0efef7e101786e3ed5160a700b5f","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"78bdc7d6906146edb12a1a6c1f765ba680ed5124":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"bc57257d8a309205ebefdf9ee778da293673f599":["7849935cc625c020857f3b29be91b5d4323d19aa"],"2b84d416bbd661ae4b2a28d103bdfccb851e00de":["950b7a6881d14da782b60444c11295e3ec50d41a"],"da8a02bef7458089240404614139b53c9f875ec7":[],"74abfad53a433ccd1fa4997d620a9b016f3bb24e":["adc9dc8ef0ce617b940a039fd12f79e8b098cc7f"],"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"12bfdc932307442b651432f92845942f9041ace8":["74abfad53a433ccd1fa4997d620a9b016f3bb24e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e3ce1ef883d26aa73919aa2d53991726e96caa13"],"950b7a6881d14da782b60444c11295e3ec50d41a":["416f9e28900210be57b69bc12e2954fb98ed7ebe"],"1987c0002f396ce6d6dada94c6773d6ba0e03f50":["bc57257d8a309205ebefdf9ee778da293673f599"],"1786be6a11f9cf5e48ce84869d1bb71e9c02f966":["770342641f7b505eaa8dccdc666158bff2419109"],"a20457919db052812998f60294d17daa883ff972":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","62e7e8f89cb6b0283f3f5d6c0945453b73f09d45","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"e3ce1ef883d26aa73919aa2d53991726e96caa13":["1786be6a11f9cf5e48ce84869d1bb71e9c02f966"],"5b8ee93140fd0efef7e101786e3ed5160a700b5f":[],"7dcb0432bcb41451b41e9aaaabe99f5d208258fe":["f6652c943595e92c187ee904c382863013eae28f","e9017cf144952056066919f1ebc7897ff9bd71b1"],"adc9dc8ef0ce617b940a039fd12f79e8b098cc7f":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"770342641f7b505eaa8dccdc666158bff2419109":["12bfdc932307442b651432f92845942f9041ace8","cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca":["2b84d416bbd661ae4b2a28d103bdfccb851e00de"],"7849935cc625c020857f3b29be91b5d4323d19aa":["f6a5bbbabf9fffa3247e7dc730254570822cf4b3"],"ee52259641568741fbc6ecc51284431e2a36475c":["1ad3fdaef92a8e8112ab0f5be5fd95362cf9030e","da8a02bef7458089240404614139b53c9f875ec7","5b8ee93140fd0efef7e101786e3ed5160a700b5f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"416f9e28900210be57b69bc12e2954fb98ed7ebe":["1987c0002f396ce6d6dada94c6773d6ba0e03f50"],"1e52a98a3809d9d747b7694f15f80b7018403ef5":["ee52259641568741fbc6ecc51284431e2a36475c"],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["9a5a0f27d9486cd33de88627ed3d2ff8dc5074ca"],"62e7e8f89cb6b0283f3f5d6c0945453b73f09d45":["7dcb0432bcb41451b41e9aaaabe99f5d208258fe"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["da8a02bef7458089240404614139b53c9f875ec7","e9017cf144952056066919f1ebc7897ff9bd71b1","5b8ee93140fd0efef7e101786e3ed5160a700b5f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}