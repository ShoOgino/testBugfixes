{"path":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","commits":[{"id":"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76","date":1471585465,"type":1,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processRestoreAction(ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI backupPath = repository.createURI(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  private void processRestoreAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME); // of backup\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = this.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI backupPath = repository.createURI(location, backupName);\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String,Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      createCollection(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice: restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      addPropertyParams(message, propMap);\n\n      addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice: restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice: restoreCollection.getSlices()) {\n        for(int i=1; i<numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          addPropertyParams(message, propMap);\n\n          addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"403d05f7f8d69b65659157eff1bc1d2717f04c66","date":1471692961,"type":1,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processRestoreAction(ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI backupPath = repository.createURI(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  private void processRestoreAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME); // of backup\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = this.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI backupPath = repository.createURI(location, backupName);\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String,Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      createCollection(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice: restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      addPropertyParams(message, propMap);\n\n      addReplica(clusterState, new ZkNodeProps(propMap), new NamedList());\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice: restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice: restoreCollection.getSlices()) {\n        for(int i=1; i<numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          addPropertyParams(message, propMap);\n\n          addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"af3193c66df8e8324d4bce9f66df967af9e8c602","date":1472772499,"type":3,"author":"Hrishikesh Gadre","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI backupPath = repository.createURI(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":["4c623a7f72be34d6c45bee682028c50327d9e4b7"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"da02fc41cfc83eaee66abb7c926f2c909bda6d26","date":1472818509,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI backupPath = repository.createURI(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bc8f206328a706450934717bec7ccc22ad166fc0","date":1473142172,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI backupPath = repository.createURI(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI backupPath = repository.createURI(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b2ad92550399520cc0148c3ee5ca087706f12da4","date":1478270512,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"199dfa410f1fdbfd3294106b04096cce5ed34b21","date":1478812506,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d18dd44acd824af8b51a5994c9475b32b094fb76","date":1494427167,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    int repFactor = message.getInt(REPLICATION_FACTOR, backupCollectionState.getReplicationFactor());\n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * repFactor) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, replication factor %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, repFactor, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Map<ReplicaAssigner.Position, String> positionVsNodes = ocmh.identifyNodes(clusterState, nodeList,\n        message, sliceNames, repFactor);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = pvn.getKey();\n        if (position.shard == slice.getName()) {\n          node = pvn.getValue();\n          propMap.put(CoreAdminParams.NODE, node);\n          positionVsNodes.remove(position);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n            ReplicaAssigner.Position position = pvn.getKey();\n            if (position.shard == slice.getName()) {\n              node = pvn.getValue();\n              propMap.put(CoreAdminParams.NODE, node);\n              positionVsNodes.remove(position);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":["c5c99ad021f3da085fcb66220598a8f91dc5e453"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b31ebc7a867ddea79d438a8fca876a94e644d11a","date":1494496172,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    int repFactor = message.getInt(REPLICATION_FACTOR, backupCollectionState.getReplicationFactor());\n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * repFactor) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, replication factor %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, repFactor, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Map<ReplicaAssigner.Position, String> positionVsNodes = ocmh.identifyNodes(clusterState, nodeList,\n        message, sliceNames, repFactor);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = pvn.getKey();\n        if (position.shard == slice.getName()) {\n          node = pvn.getValue();\n          propMap.put(CoreAdminParams.NODE, node);\n          positionVsNodes.remove(position);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n            ReplicaAssigner.Position position = pvn.getKey();\n            if (position.shard == slice.getName()) {\n              node = pvn.getValue();\n              propMap.put(CoreAdminParams.NODE, node);\n              positionVsNodes.remove(position);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"61c45e99cf6676da48f19d7511c73712ad39402b","date":1495508331,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Map<ReplicaAssigner.Position, String> positionVsNodes = ocmh.identifyNodes(clusterState, nodeList,\n        message, sliceNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      \n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" + \n            Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = pvn.getKey();\n        if (position.shard == slice.getName()) {\n          node = pvn.getValue();\n          propMap.put(CoreAdminParams.NODE, node);\n          positionVsNodes.remove(position);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    if (totalReplicasPerShard > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n        \n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n          }\n\n          log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n            ReplicaAssigner.Position position = pvn.getKey();\n            if (position.shard == slice.getName()) {\n              node = pvn.getValue();\n              propMap.put(CoreAdminParams.NODE, node);\n              positionVsNodes.remove(position);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    int repFactor = message.getInt(REPLICATION_FACTOR, backupCollectionState.getReplicationFactor());\n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * repFactor) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, replication factor %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, repFactor, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Map<ReplicaAssigner.Position, String> positionVsNodes = ocmh.identifyNodes(clusterState, nodeList,\n        message, sliceNames, repFactor);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = pvn.getKey();\n        if (position.shard == slice.getName()) {\n          node = pvn.getValue();\n          propMap.put(CoreAdminParams.NODE, node);\n          positionVsNodes.remove(position);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n            ReplicaAssigner.Position position = pvn.getKey();\n            if (position.shard == slice.getName()) {\n              node = pvn.getValue();\n              propMap.put(CoreAdminParams.NODE, node);\n              positionVsNodes.remove(position);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"25e4a4cddd699db6cce60282e747c7705897e821","date":1496721158,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Map<ReplicaAssigner.Position, String> positionVsNodes = ocmh.identifyNodes(clusterState, nodeList,\n        restoreCollectionName, message, sliceNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      \n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" + \n            Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = pvn.getKey();\n        if (position.shard == slice.getName()) {\n          node = pvn.getValue();\n          propMap.put(CoreAdminParams.NODE, node);\n          positionVsNodes.remove(position);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    if (totalReplicasPerShard > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n        \n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n          }\n\n          log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n            ReplicaAssigner.Position position = pvn.getKey();\n            if (position.shard == slice.getName()) {\n              node = pvn.getValue();\n              propMap.put(CoreAdminParams.NODE, node);\n              positionVsNodes.remove(position);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Map<ReplicaAssigner.Position, String> positionVsNodes = ocmh.identifyNodes(clusterState, nodeList,\n        message, sliceNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      \n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" + \n            Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = pvn.getKey();\n        if (position.shard == slice.getName()) {\n          node = pvn.getValue();\n          propMap.put(CoreAdminParams.NODE, node);\n          positionVsNodes.remove(position);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    if (totalReplicasPerShard > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n        \n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n          }\n\n          log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n            ReplicaAssigner.Position position = pvn.getKey();\n            if (position.shard == slice.getName()) {\n              node = pvn.getValue();\n              propMap.put(CoreAdminParams.NODE, node);\n              positionVsNodes.remove(position);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"74aea047dff7f7c38a2d766827bd20d356f98c6a","date":1496721416,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Map<ReplicaAssigner.Position, String> positionVsNodes = ocmh.identifyNodes(clusterState, nodeList,\n        restoreCollectionName, message, sliceNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      \n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" + \n            Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = pvn.getKey();\n        if (position.shard == slice.getName()) {\n          node = pvn.getValue();\n          propMap.put(CoreAdminParams.NODE, node);\n          positionVsNodes.remove(position);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    if (totalReplicasPerShard > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n        \n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n          }\n\n          log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n            ReplicaAssigner.Position position = pvn.getKey();\n            if (position.shard == slice.getName()) {\n              node = pvn.getValue();\n              propMap.put(CoreAdminParams.NODE, node);\n              positionVsNodes.remove(position);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Map<ReplicaAssigner.Position, String> positionVsNodes = ocmh.identifyNodes(clusterState, nodeList,\n        message, sliceNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      \n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" + \n            Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = pvn.getKey();\n        if (position.shard == slice.getName()) {\n          node = pvn.getValue();\n          propMap.put(CoreAdminParams.NODE, node);\n          positionVsNodes.remove(position);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    if (totalReplicasPerShard > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n        \n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n          }\n\n          log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n            ReplicaAssigner.Position position = pvn.getKey();\n            if (position.shard == slice.getName()) {\n              node = pvn.getValue();\n              propMap.put(CoreAdminParams.NODE, node);\n              positionVsNodes.remove(position);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Map<ReplicaAssigner.Position, String> positionVsNodes = ocmh.identifyNodes(clusterState, nodeList,\n        restoreCollectionName, message, sliceNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      \n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" + \n            Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = pvn.getKey();\n        if (position.shard == slice.getName()) {\n          node = pvn.getValue();\n          propMap.put(CoreAdminParams.NODE, node);\n          positionVsNodes.remove(position);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    if (totalReplicasPerShard > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n        \n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n          }\n\n          log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n            ReplicaAssigner.Position position = pvn.getKey();\n            if (position.shard == slice.getName()) {\n              node = pvn.getValue();\n              propMap.put(CoreAdminParams.NODE, node);\n              positionVsNodes.remove(position);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Map<ReplicaAssigner.Position, String> positionVsNodes = ocmh.identifyNodes(clusterState, nodeList,\n        restoreCollectionName, message, sliceNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      \n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" + \n            Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = pvn.getKey();\n        if (position.shard == slice.getName()) {\n          node = pvn.getValue();\n          propMap.put(CoreAdminParams.NODE, node);\n          positionVsNodes.remove(position);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    if (totalReplicasPerShard > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n        \n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n          }\n\n          log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n            ReplicaAssigner.Position position = pvn.getKey();\n            if (position.shard == slice.getName()) {\n              node = pvn.getValue();\n              propMap.put(CoreAdminParams.NODE, node);\n              positionVsNodes.remove(position);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Map<ReplicaAssigner.Position, String> positionVsNodes = ocmh.identifyNodes(clusterState, nodeList,\n        message, sliceNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      \n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" + \n            Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = pvn.getKey();\n        if (position.shard == slice.getName()) {\n          node = pvn.getValue();\n          propMap.put(CoreAdminParams.NODE, node);\n          positionVsNodes.remove(position);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    if (totalReplicasPerShard > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n        \n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n          }\n\n          log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n            ReplicaAssigner.Position position = pvn.getKey();\n            if (position.shard == slice.getName()) {\n              node = pvn.getValue();\n              propMap.put(CoreAdminParams.NODE, node);\n              positionVsNodes.remove(position);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"969718c368b28ed1b2335ea2deb275c696cddb4f","date":1498803580,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    List<ReplicaPosition> replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n        ocmh.zkStateReader, clusterState,\n        nodeList, restoreCollectionName,\n        message, sliceNames,\n        numNrtReplicas, numTlogReplicas, numPullReplicas);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      \n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" + \n            Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    if (totalReplicasPerShard > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n        \n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n          }\n\n          log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Map<ReplicaAssigner.Position, String> positionVsNodes = ocmh.identifyNodes(clusterState, nodeList,\n        restoreCollectionName, message, sliceNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      \n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" + \n            Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = pvn.getKey();\n        if (position.shard == slice.getName()) {\n          node = pvn.getValue();\n          propMap.put(CoreAdminParams.NODE, node);\n          positionVsNodes.remove(position);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    if (totalReplicasPerShard > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n        \n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n          }\n\n          log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n            ReplicaAssigner.Position position = pvn.getKey();\n            if (position.shard == slice.getName()) {\n              node = pvn.getValue();\n              propMap.put(CoreAdminParams.NODE, node);\n              positionVsNodes.remove(position);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0d92226151c91fb4bebcca6d18782d1c84aee2cd","date":1498804792,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    List<ReplicaPosition> replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n        ocmh.zkStateReader, clusterState,\n        nodeList, restoreCollectionName,\n        message, sliceNames,\n        numNrtReplicas, numTlogReplicas, numPullReplicas);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      \n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" + \n            Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    if (totalReplicasPerShard > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n        \n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n          }\n\n          log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = OverseerCollectionMessageHandler.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    Map<ReplicaAssigner.Position, String> positionVsNodes = ocmh.identifyNodes(clusterState, nodeList,\n        restoreCollectionName, message, sliceNames, numNrtReplicas, numTlogReplicas, numPullReplicas);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      \n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" + \n            Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n        ReplicaAssigner.Position position = pvn.getKey();\n        if (position.shard == slice.getName()) {\n          node = pvn.getValue();\n          propMap.put(CoreAdminParams.NODE, node);\n          positionVsNodes.remove(position);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    if (totalReplicasPerShard > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n        \n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n          }\n\n          log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (Map.Entry<ReplicaAssigner.Position, String> pvn : positionVsNodes.entrySet()) {\n            ReplicaAssigner.Position position = pvn.getKey();\n            if (position.shard == slice.getName()) {\n              node = pvn.getValue();\n              propMap.put(CoreAdminParams.NODE, node);\n              positionVsNodes.remove(position);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bccf7971a36bd151490117582a0a1a695081ead3","date":1502778995,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    List<ReplicaPosition> replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n        ocmh.zkStateReader, clusterState,\n        nodeList, restoreCollectionName,\n        message, sliceNames,\n        numNrtReplicas, numTlogReplicas, numPullReplicas);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      \n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" + \n            Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    if (totalReplicasPerShard > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n        \n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n          }\n\n          log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":["076d58da25128e8a4c511abf07c5d86c4ebddcbf","076d58da25128e8a4c511abf07c5d86c4ebddcbf","ab6131420a270c49b653c969cc1dbbaf7d1b36e7","ab6131420a270c49b653c969cc1dbbaf7d1b36e7","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c304e97e7c1d472bc70e801b35ee78583916c6cd","date":1507105431,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    List<ReplicaPosition> replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n        ocmh.zkStateReader, clusterState,\n        nodeList, restoreCollectionName,\n        message, sliceNames,\n        numNrtReplicas, numTlogReplicas, numPullReplicas);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      \n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" + \n            Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    if (totalReplicasPerShard > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n        \n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n          }\n\n          log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"560c18d71dad43d675158783c3840f8c80d6d39c","date":1507105532,"type":3,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    List<ReplicaPosition> replicaPositions = Assign.identifyNodes(() -> ocmh.overseer.getZkController().getCoreContainer(),\n        ocmh.zkStateReader, clusterState,\n        nodeList, restoreCollectionName,\n        message, sliceNames,\n        numNrtReplicas, numTlogReplicas, numPullReplicas);\n\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      \n      if (numNrtReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n      } else if (numTlogReplicas >= 1) {\n        propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" + \n            Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n      }\n\n      // Get the first node matching the shard to restore in\n      String node;\n      for (ReplicaPosition replicaPosition : replicaPositions) {\n        if (Objects.equals(replicaPosition.shard, slice.getName())) {\n          node = replicaPosition.node;\n          propMap.put(CoreAdminParams.NODE, node);\n          replicaPositions.remove(replicaPosition);\n          break;\n        }\n      }\n\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    if (totalReplicasPerShard > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n      for (Slice slice : restoreCollection.getSlices()) {\n\n        //Add the remaining replicas for each shard, considering it's type\n        int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n        // We already created either a NRT or an TLOG replica as leader\n        if (numNrtReplicas > 0) {\n          createdNrtReplicas++;\n        } else if (createdTlogReplicas > 0) {\n          createdTlogReplicas++;\n        }\n        \n        for (int i = 1; i < totalReplicasPerShard; i++) {\n          Replica.Type typeToCreate;\n          if (createdNrtReplicas < numNrtReplicas) {\n            createdNrtReplicas++;\n            typeToCreate = Replica.Type.NRT;\n          } else if (createdTlogReplicas < numTlogReplicas) {\n            createdTlogReplicas++;\n            typeToCreate = Replica.Type.TLOG;\n          } else {\n            createdPullReplicas++;\n            typeToCreate = Replica.Type.PULL;\n            assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n          }\n\n          log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n          // Get the first node matching the shard to restore in\n          String node;\n          for (ReplicaPosition replicaPosition : replicaPositions) {\n            if (Objects.equals(replicaPosition.shard, slice.getName())) {\n              node = replicaPosition.node;\n              propMap.put(CoreAdminParams.NODE, node);\n              replicaPositions.remove(replicaPosition);\n              break;\n            }\n          }\n\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"529c69423fc9de95d4d764f4c998f095fead50bd","date":1509480852,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","bugFix":null,"bugIntro":["5ad9c35f926b4bf8da0336d1300efc709c8d5a56","5ad9c35f926b4bf8da0336d1300efc709c8d5a56"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"427295870ac138112ed6ab0973a2dbe42e0a1a2d","date":1510742913,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(PolicyHelper.getPolicySessionRef(ocmh.overseer.getSolrCloudManager()));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(ocmh.policySessionRef);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d907c28c7fe6305eaec1756d51365f5149e1e41d","date":1512533044,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      PolicyHelper.clearFlagAndDecref(PolicyHelper.getPolicySessionRef(ocmh.overseer.getSolrCloudManager()));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6146c07c0dee1ae1e42926167acd127fed5ef59d","date":1516129420,"type":5,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, OverseerCollectionMessageHandler.RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(OverseerCollectionMessageHandler.COLL_CONF);\n    String restoreConfigName = message.getStr(OverseerCollectionMessageHandler.COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : OverseerCollectionMessageHandler.COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET, OverseerCollectionMessageHandler.CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(OverseerCollectionMessageHandler.COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(OverseerCollectionMessageHandler.NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(OverseerCollectionMessageHandler.SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":4,"author":"Karl Wright","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":null,"sourceOld":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI location = repository.createURI(message.getStr(CoreAdminParams.BACKUP_LOCATION));\n    URI backupPath = repository.resolve(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    // Get the Solr nodes to restore a collection.\n    final List<String> nodeList = Assign.getLiveOrLiveAndCreateNodeSetList(\n        zkStateReader.getClusterState().getLiveNodes(), message, RANDOM);\n\n    int numShards = backupCollectionState.getActiveSlices().size();\n    \n    int numNrtReplicas = getInt(message, NRT_REPLICAS, backupCollectionState.getNumNrtReplicas(), 0);\n    if (numNrtReplicas == 0) {\n      numNrtReplicas = getInt(message, REPLICATION_FACTOR, backupCollectionState.getReplicationFactor(), 0);\n    }\n    int numTlogReplicas = getInt(message, TLOG_REPLICAS, backupCollectionState.getNumTlogReplicas(), 0);\n    int numPullReplicas = getInt(message, PULL_REPLICAS, backupCollectionState.getNumPullReplicas(), 0);\n    int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;\n    \n    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());\n    int availableNodeCount = nodeList.size();\n    if ((numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST,\n          String.format(Locale.ROOT, \"Solr cloud with available number of nodes:%d is insufficient for\"\n              + \" restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d.\"\n              + \" Consider increasing maxShardsPerNode value OR number of available nodes.\",\n              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));\n    }\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n      if (properties.get(STATE_FORMAT) == null) {\n        propMap.put(STATE_FORMAT, \"2\");\n      }\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n\n    List<String> sliceNames = new ArrayList<>();\n    restoreCollection.getSlices().forEach(x -> sliceNames.add(x.getName()));\n    PolicyHelper.SessionWrapper sessionWrapper = null;\n\n    try {\n      List<ReplicaPosition> replicaPositions = Assign.identifyNodes(\n          ocmh.cloudManager, clusterState,\n          nodeList, restoreCollectionName,\n          message, sliceNames,\n          numNrtReplicas, numTlogReplicas, numPullReplicas);\n      sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n      //Create one replica per shard and copy backed up data to it\n      for (Slice slice : restoreCollection.getSlices()) {\n        log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n        propMap.put(COLLECTION_PROP, restoreCollectionName);\n        propMap.put(SHARD_ID_PROP, slice.getName());\n\n        if (numNrtReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.NRT.name());\n        } else if (numTlogReplicas >= 1) {\n          propMap.put(REPLICA_TYPE, Replica.Type.TLOG.name());\n        } else {\n          throw new SolrException(ErrorCode.BAD_REQUEST, \"Unexpected number of replicas, replicationFactor, \" +\n              Replica.Type.NRT + \" or \" + Replica.Type.TLOG + \" must be greater than 0\");\n        }\n\n        // Get the first node matching the shard to restore in\n        String node;\n        for (ReplicaPosition replicaPosition : replicaPositions) {\n          if (Objects.equals(replicaPosition.shard, slice.getName())) {\n            node = replicaPosition.node;\n            propMap.put(CoreAdminParams.NODE, node);\n            replicaPositions.remove(replicaPosition);\n            break;\n          }\n        }\n\n        // add async param\n        if (asyncId != null) {\n          propMap.put(ASYNC, asyncId);\n        }\n        ocmh.addPropertyParams(message, propMap);\n\n        ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      //Copy data from backed up index to each replica\n      for (Slice slice : restoreCollection.getSlices()) {\n        ModifiableSolrParams params = new ModifiableSolrParams();\n        params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n        params.set(NAME, \"snapshot.\" + slice.getName());\n        params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.toASCIIString());\n        params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n        ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n      }\n      ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n      //Mark all shards in ACTIVE STATE\n      {\n        HashMap<String, Object> propMap = new HashMap<>();\n        propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n        propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n        for (Slice shard : restoreCollection.getSlices()) {\n          propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n        }\n        inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n      }\n\n      //refresh the location copy of collection state\n      restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n      if (totalReplicasPerShard > 1) {\n        log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n        for (Slice slice : restoreCollection.getSlices()) {\n\n          //Add the remaining replicas for each shard, considering it's type\n          int createdNrtReplicas = 0, createdTlogReplicas = 0, createdPullReplicas = 0;\n\n          // We already created either a NRT or an TLOG replica as leader\n          if (numNrtReplicas > 0) {\n            createdNrtReplicas++;\n          } else if (createdTlogReplicas > 0) {\n            createdTlogReplicas++;\n          }\n\n          for (int i = 1; i < totalReplicasPerShard; i++) {\n            Replica.Type typeToCreate;\n            if (createdNrtReplicas < numNrtReplicas) {\n              createdNrtReplicas++;\n              typeToCreate = Replica.Type.NRT;\n            } else if (createdTlogReplicas < numTlogReplicas) {\n              createdTlogReplicas++;\n              typeToCreate = Replica.Type.TLOG;\n            } else {\n              createdPullReplicas++;\n              typeToCreate = Replica.Type.PULL;\n              assert createdPullReplicas <= numPullReplicas: \"Unexpected number of replicas\";\n            }\n\n            log.debug(\"Adding replica for shard={} collection={} of type {} \", slice.getName(), restoreCollection, typeToCreate);\n            HashMap<String, Object> propMap = new HashMap<>();\n            propMap.put(COLLECTION_PROP, restoreCollectionName);\n            propMap.put(SHARD_ID_PROP, slice.getName());\n            propMap.put(REPLICA_TYPE, typeToCreate.name());\n\n            // Get the first node matching the shard to restore in\n            String node;\n            for (ReplicaPosition replicaPosition : replicaPositions) {\n              if (Objects.equals(replicaPosition.shard, slice.getName())) {\n                node = replicaPosition.node;\n                propMap.put(CoreAdminParams.NODE, node);\n                replicaPositions.remove(replicaPosition);\n                break;\n              }\n            }\n\n            // add async param\n            if (asyncId != null) {\n              propMap.put(ASYNC, asyncId);\n            }\n            ocmh.addPropertyParams(message, propMap);\n\n            ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n          }\n        }\n      }\n\n      log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n    } finally {\n      if (sessionWrapper != null) sessionWrapper.release();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"da02fc41cfc83eaee66abb7c926f2c909bda6d26":["403d05f7f8d69b65659157eff1bc1d2717f04c66","af3193c66df8e8324d4bce9f66df967af9e8c602"],"b94236357aaa22b76c10629851fe4e376e0cea82":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"25e4a4cddd699db6cce60282e747c7705897e821":["61c45e99cf6676da48f19d7511c73712ad39402b"],"c304e97e7c1d472bc70e801b35ee78583916c6cd":["969718c368b28ed1b2335ea2deb275c696cddb4f","bccf7971a36bd151490117582a0a1a695081ead3"],"b31ebc7a867ddea79d438a8fca876a94e644d11a":["b2ad92550399520cc0148c3ee5ca087706f12da4","d18dd44acd824af8b51a5994c9475b32b094fb76"],"199dfa410f1fdbfd3294106b04096cce5ed34b21":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","b2ad92550399520cc0148c3ee5ca087706f12da4"],"bc8f206328a706450934717bec7ccc22ad166fc0":["403d05f7f8d69b65659157eff1bc1d2717f04c66","da02fc41cfc83eaee66abb7c926f2c909bda6d26"],"d18dd44acd824af8b51a5994c9475b32b094fb76":["b2ad92550399520cc0148c3ee5ca087706f12da4"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["b2ad92550399520cc0148c3ee5ca087706f12da4","74aea047dff7f7c38a2d766827bd20d356f98c6a"],"529c69423fc9de95d4d764f4c998f095fead50bd":["560c18d71dad43d675158783c3840f8c80d6d39c"],"74aea047dff7f7c38a2d766827bd20d356f98c6a":["61c45e99cf6676da48f19d7511c73712ad39402b","25e4a4cddd699db6cce60282e747c7705897e821"],"969718c368b28ed1b2335ea2deb275c696cddb4f":["28288370235ed02234a64753cdbf0c6ec096304a"],"0d92226151c91fb4bebcca6d18782d1c84aee2cd":["e9017cf144952056066919f1ebc7897ff9bd71b1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["403d05f7f8d69b65659157eff1bc1d2717f04c66","da02fc41cfc83eaee66abb7c926f2c909bda6d26"],"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"af3193c66df8e8324d4bce9f66df967af9e8c602":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["d907c28c7fe6305eaec1756d51365f5149e1e41d"],"560c18d71dad43d675158783c3840f8c80d6d39c":["969718c368b28ed1b2335ea2deb275c696cddb4f","c304e97e7c1d472bc70e801b35ee78583916c6cd"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","66e0b82bd39567aa2bf534e5282d05fb4a4a2c76"],"61c45e99cf6676da48f19d7511c73712ad39402b":["d18dd44acd824af8b51a5994c9475b32b094fb76"],"bccf7971a36bd151490117582a0a1a695081ead3":["0d92226151c91fb4bebcca6d18782d1c84aee2cd"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"28288370235ed02234a64753cdbf0c6ec096304a":["61c45e99cf6676da48f19d7511c73712ad39402b","74aea047dff7f7c38a2d766827bd20d356f98c6a"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"427295870ac138112ed6ab0973a2dbe42e0a1a2d":["529c69423fc9de95d4d764f4c998f095fead50bd"],"b2ad92550399520cc0148c3ee5ca087706f12da4":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b94236357aaa22b76c10629851fe4e376e0cea82"],"d907c28c7fe6305eaec1756d51365f5149e1e41d":["427295870ac138112ed6ab0973a2dbe42e0a1a2d"]},"commit2Childs":{"da02fc41cfc83eaee66abb7c926f2c909bda6d26":["bc8f206328a706450934717bec7ccc22ad166fc0","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"b94236357aaa22b76c10629851fe4e376e0cea82":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"25e4a4cddd699db6cce60282e747c7705897e821":["74aea047dff7f7c38a2d766827bd20d356f98c6a"],"c304e97e7c1d472bc70e801b35ee78583916c6cd":["560c18d71dad43d675158783c3840f8c80d6d39c"],"b31ebc7a867ddea79d438a8fca876a94e644d11a":[],"199dfa410f1fdbfd3294106b04096cce5ed34b21":[],"bc8f206328a706450934717bec7ccc22ad166fc0":[],"d18dd44acd824af8b51a5994c9475b32b094fb76":["b31ebc7a867ddea79d438a8fca876a94e644d11a","61c45e99cf6676da48f19d7511c73712ad39402b"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["0d92226151c91fb4bebcca6d18782d1c84aee2cd"],"529c69423fc9de95d4d764f4c998f095fead50bd":["427295870ac138112ed6ab0973a2dbe42e0a1a2d"],"74aea047dff7f7c38a2d766827bd20d356f98c6a":["e9017cf144952056066919f1ebc7897ff9bd71b1","28288370235ed02234a64753cdbf0c6ec096304a"],"969718c368b28ed1b2335ea2deb275c696cddb4f":["c304e97e7c1d472bc70e801b35ee78583916c6cd","560c18d71dad43d675158783c3840f8c80d6d39c"],"0d92226151c91fb4bebcca6d18782d1c84aee2cd":["bccf7971a36bd151490117582a0a1a695081ead3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["66e0b82bd39567aa2bf534e5282d05fb4a4a2c76","403d05f7f8d69b65659157eff1bc1d2717f04c66","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","b2ad92550399520cc0148c3ee5ca087706f12da4"],"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"af3193c66df8e8324d4bce9f66df967af9e8c602":["da02fc41cfc83eaee66abb7c926f2c909bda6d26"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["b94236357aaa22b76c10629851fe4e376e0cea82","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"560c18d71dad43d675158783c3840f8c80d6d39c":["529c69423fc9de95d4d764f4c998f095fead50bd"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["da02fc41cfc83eaee66abb7c926f2c909bda6d26","bc8f206328a706450934717bec7ccc22ad166fc0","17e5da53e4e5bd659e22add9bba1cfa222e7e30d","af3193c66df8e8324d4bce9f66df967af9e8c602"],"61c45e99cf6676da48f19d7511c73712ad39402b":["25e4a4cddd699db6cce60282e747c7705897e821","74aea047dff7f7c38a2d766827bd20d356f98c6a","28288370235ed02234a64753cdbf0c6ec096304a"],"bccf7971a36bd151490117582a0a1a695081ead3":["c304e97e7c1d472bc70e801b35ee78583916c6cd"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["b94236357aaa22b76c10629851fe4e376e0cea82"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["199dfa410f1fdbfd3294106b04096cce5ed34b21"],"28288370235ed02234a64753cdbf0c6ec096304a":["969718c368b28ed1b2335ea2deb275c696cddb4f"],"427295870ac138112ed6ab0973a2dbe42e0a1a2d":["d907c28c7fe6305eaec1756d51365f5149e1e41d"],"b2ad92550399520cc0148c3ee5ca087706f12da4":["b31ebc7a867ddea79d438a8fca876a94e644d11a","199dfa410f1fdbfd3294106b04096cce5ed34b21","d18dd44acd824af8b51a5994c9475b32b094fb76","e9017cf144952056066919f1ebc7897ff9bd71b1"],"d907c28c7fe6305eaec1756d51365f5149e1e41d":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b31ebc7a867ddea79d438a8fca876a94e644d11a","199dfa410f1fdbfd3294106b04096cce5ed34b21","bc8f206328a706450934717bec7ccc22ad166fc0","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}