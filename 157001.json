{"path":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","commits":[{"id":"9dbf99ca10e1ef2ffbfeb7119d644bf20b267368","date":1379006067,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","pathOld":"/dev/null","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    TermFreqPayload keys[] = new TermFreqPayload[] {\n      new TermFreqPayload(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    File tempDir = _TestUtil.getTempDir(\"AnalyzingInfixSuggesterTest\");\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {\n        @Override\n        protected Directory getDirectory(File path) {\n          return newDirectory();\n        }\n\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text));\n          CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n          OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n          ts.reset();\n          List<LookupHighlightFragment> fragments = new ArrayList<LookupHighlightFragment>();\n          int upto = 0;\n          while (ts.incrementToken()) {\n            String token = termAtt.toString();\n            int startOffset = offsetAtt.startOffset();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < startOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n              upto = startOffset;\n            } else if (upto > startOffset) {\n              continue;\n            }\n\n            if (matchedTokens.contains(token)) {\n              // Token matches.\n              fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n              upto = endOffset;\n            } else if (prefixToken != null && token.startsWith(prefixToken)) {\n              fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n              if (prefixToken.length() < token.length()) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n              }\n              upto = endOffset;\n            }\n          }\n          ts.end();\n          int endOffset = offsetAtt.endOffset();\n          if (upto < endOffset) {\n            fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n          }\n          ts.close();\n\n          return fragments;\n        }\n      };\n    suggester.build(new TermFreqPayloadArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627","4637747f71df783fc2014ef1f1e0418466e3bed6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"782ed6a4b4ba50ec19734fc8db4e570ee193d627","date":1381127065,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    TermFreqPayload keys[] = new TermFreqPayload[] {\n      new TermFreqPayload(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    File tempDir = _TestUtil.getTempDir(\"AnalyzingInfixSuggesterTest\");\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {\n        @Override\n        protected Directory getDirectory(File path) {\n          return newDirectory();\n        }\n\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<LookupHighlightFragment>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new TermFreqPayloadArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    TermFreqPayload keys[] = new TermFreqPayload[] {\n      new TermFreqPayload(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    File tempDir = _TestUtil.getTempDir(\"AnalyzingInfixSuggesterTest\");\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {\n        @Override\n        protected Directory getDirectory(File path) {\n          return newDirectory();\n        }\n\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text));\n          CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n          OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n          ts.reset();\n          List<LookupHighlightFragment> fragments = new ArrayList<LookupHighlightFragment>();\n          int upto = 0;\n          while (ts.incrementToken()) {\n            String token = termAtt.toString();\n            int startOffset = offsetAtt.startOffset();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < startOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n              upto = startOffset;\n            } else if (upto > startOffset) {\n              continue;\n            }\n\n            if (matchedTokens.contains(token)) {\n              // Token matches.\n              fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n              upto = endOffset;\n            } else if (prefixToken != null && token.startsWith(prefixToken)) {\n              fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n              if (prefixToken.length() < token.length()) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n              }\n              upto = endOffset;\n            }\n          }\n          ts.end();\n          int endOffset = offsetAtt.endOffset();\n          if (upto < endOffset) {\n            fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n          }\n          ts.close();\n\n          return fragments;\n        }\n      };\n    suggester.build(new TermFreqPayloadArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","bugFix":["9dbf99ca10e1ef2ffbfeb7119d644bf20b267368"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"41aee74b5f91a096e3fd950f4a336bc763f0e7a7","date":1381772070,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    File tempDir = _TestUtil.getTempDir(\"AnalyzingInfixSuggesterTest\");\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {\n        @Override\n        protected Directory getDirectory(File path) {\n          return newDirectory();\n        }\n\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<LookupHighlightFragment>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    TermFreqPayload keys[] = new TermFreqPayload[] {\n      new TermFreqPayload(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    File tempDir = _TestUtil.getTempDir(\"AnalyzingInfixSuggesterTest\");\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {\n        @Override\n        protected Directory getDirectory(File path) {\n          return newDirectory();\n        }\n\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<LookupHighlightFragment>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new TermFreqPayloadArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    File tempDir = TestUtil.getTempDir(\"AnalyzingInfixSuggesterTest\");\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {\n        @Override\n        protected Directory getDirectory(File path) {\n          return newDirectory();\n        }\n\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<LookupHighlightFragment>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    File tempDir = _TestUtil.getTempDir(\"AnalyzingInfixSuggesterTest\");\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {\n        @Override\n        protected Directory getDirectory(File path) {\n          return newDirectory();\n        }\n\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<LookupHighlightFragment>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(_TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","bugFix":null,"bugIntro":["4637747f71df783fc2014ef1f1e0418466e3bed6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f1e7da8a91a92330e8f04b171b83e655a4a25c31","date":1394125906,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, newDirectory(), a, a, 3) {\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<LookupHighlightFragment>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    File tempDir = TestUtil.getTempDir(\"AnalyzingInfixSuggesterTest\");\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {\n        @Override\n        protected Directory getDirectory(File path) {\n          return newDirectory();\n        }\n\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<LookupHighlightFragment>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4637747f71df783fc2014ef1f1e0418466e3bed6","date":1394196311,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, newDirectory(), a, a, 3) {\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<LookupHighlightFragment>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    File tempDir = TestUtil.getTempDir(\"AnalyzingInfixSuggesterTest\");\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {\n        @Override\n        protected Directory getDirectory(File path) {\n          return newDirectory();\n        }\n\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<LookupHighlightFragment>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","bugFix":["9dbf99ca10e1ef2ffbfeb7119d644bf20b267368","6613659748fe4411a7dcf85266e55db1f95f7315"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"96ea64d994d340044e0d57aeb6a5871539d10ca5","date":1394225445,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, newDirectory(), a, a, 3) {\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<LookupHighlightFragment>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    File tempDir = TestUtil.getTempDir(\"AnalyzingInfixSuggesterTest\");\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, tempDir, a, a, 3) {\n        @Override\n        protected Directory getDirectory(File path) {\n          return newDirectory();\n        }\n\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<LookupHighlightFragment>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, newDirectory(), a, a, 3) {\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, newDirectory(), a, a, 3) {\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<LookupHighlightFragment>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6549d5ea6b7b25525309b981de3ec92b4dff99d1","date":1408666035,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, newDirectory(), a, a, 3, false) {\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, newDirectory(), a, a, 3) {\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"19e497fe4da591a79332da97681b8017d9c61165","date":1409030374,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(newDirectory(), a, a, 3, false) {\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(TEST_VERSION_CURRENT, newDirectory(), a, a, 3, false) {\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a56958d7f71a28824f20031ffbb2e13502a0274e","date":1425573902,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(newDirectory(), a, a, 3, false) {\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n    a.close();\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(newDirectory(), a, a, 3, false) {\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggesterTest#testHighlightAsObject().mjava","sourceNew":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(newDirectory(), a, a, 3, false) {\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n    a.close();\n  }\n\n","sourceOld":"  @SuppressWarnings(\"unchecked\")\n  public void testHighlightAsObject() throws Exception {\n    Input keys[] = new Input[] {\n      new Input(\"a penny saved is a penny earned\", 10, new BytesRef(\"foobaz\")),\n    };\n\n    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    AnalyzingInfixSuggester suggester = new AnalyzingInfixSuggester(newDirectory(), a, a, 3, false) {\n        @Override\n        protected Object highlight(String text, Set<String> matchedTokens, String prefixToken) throws IOException {\n          try (TokenStream ts = queryAnalyzer.tokenStream(\"text\", new StringReader(text))) {\n            CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n            OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n            ts.reset();\n            List<LookupHighlightFragment> fragments = new ArrayList<>();\n            int upto = 0;\n            while (ts.incrementToken()) {\n              String token = termAtt.toString();\n              int startOffset = offsetAtt.startOffset();\n              int endOffset = offsetAtt.endOffset();\n              if (upto < startOffset) {\n                fragments.add(new LookupHighlightFragment(text.substring(upto, startOffset), false));\n                upto = startOffset;\n              } else if (upto > startOffset) {\n                continue;\n              }\n              \n              if (matchedTokens.contains(token)) {\n                // Token matches.\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, endOffset), true));\n                upto = endOffset;\n              } else if (prefixToken != null && token.startsWith(prefixToken)) {\n                fragments.add(new LookupHighlightFragment(text.substring(startOffset, startOffset+prefixToken.length()), true));\n                if (prefixToken.length() < token.length()) {\n                  fragments.add(new LookupHighlightFragment(text.substring(startOffset+prefixToken.length(), startOffset+token.length()), false));\n                }\n                upto = endOffset;\n              }\n            }\n            ts.end();\n            int endOffset = offsetAtt.endOffset();\n            if (upto < endOffset) {\n              fragments.add(new LookupHighlightFragment(text.substring(upto), false));\n            }\n            \n            return fragments;\n          }\n        }\n      };\n    suggester.build(new InputArrayIterator(keys));\n\n    List<LookupResult> results = suggester.lookup(TestUtil.stringToCharSequence(\"ear\", random()), 10, true, true);\n    assertEquals(1, results.size());\n    assertEquals(\"a penny saved is a penny <b>ear</b>ned\", toString((List<LookupHighlightFragment>) results.get(0).highlightKey));\n    assertEquals(10, results.get(0).value);\n    assertEquals(new BytesRef(\"foobaz\"), results.get(0).payload);\n    suggester.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["4637747f71df783fc2014ef1f1e0418466e3bed6"],"96ea64d994d340044e0d57aeb6a5871539d10ca5":["6613659748fe4411a7dcf85266e55db1f95f7315","4637747f71df783fc2014ef1f1e0418466e3bed6"],"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"6613659748fe4411a7dcf85266e55db1f95f7315":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"6549d5ea6b7b25525309b981de3ec92b4dff99d1":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"9dbf99ca10e1ef2ffbfeb7119d644bf20b267368":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["9dbf99ca10e1ef2ffbfeb7119d644bf20b267368"],"f1e7da8a91a92330e8f04b171b83e655a4a25c31":["6613659748fe4411a7dcf85266e55db1f95f7315"],"19e497fe4da591a79332da97681b8017d9c61165":["6549d5ea6b7b25525309b981de3ec92b4dff99d1"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["19e497fe4da591a79332da97681b8017d9c61165","a56958d7f71a28824f20031ffbb2e13502a0274e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a56958d7f71a28824f20031ffbb2e13502a0274e":["19e497fe4da591a79332da97681b8017d9c61165"],"4637747f71df783fc2014ef1f1e0418466e3bed6":["6613659748fe4411a7dcf85266e55db1f95f7315","f1e7da8a91a92330e8f04b171b83e655a4a25c31"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a56958d7f71a28824f20031ffbb2e13502a0274e"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6549d5ea6b7b25525309b981de3ec92b4dff99d1"],"96ea64d994d340044e0d57aeb6a5871539d10ca5":[],"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["6613659748fe4411a7dcf85266e55db1f95f7315"],"6613659748fe4411a7dcf85266e55db1f95f7315":["96ea64d994d340044e0d57aeb6a5871539d10ca5","f1e7da8a91a92330e8f04b171b83e655a4a25c31","4637747f71df783fc2014ef1f1e0418466e3bed6"],"6549d5ea6b7b25525309b981de3ec92b4dff99d1":["19e497fe4da591a79332da97681b8017d9c61165"],"9dbf99ca10e1ef2ffbfeb7119d644bf20b267368":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"f1e7da8a91a92330e8f04b171b83e655a4a25c31":["4637747f71df783fc2014ef1f1e0418466e3bed6"],"19e497fe4da591a79332da97681b8017d9c61165":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","a56958d7f71a28824f20031ffbb2e13502a0274e"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9dbf99ca10e1ef2ffbfeb7119d644bf20b267368"],"4637747f71df783fc2014ef1f1e0418466e3bed6":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","96ea64d994d340044e0d57aeb6a5871539d10ca5"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["96ea64d994d340044e0d57aeb6a5871539d10ca5","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}