{"path":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","commits":[{"id":"a493e6d0c3ad86bd55c0a1360d110142e948f2bd","date":1289406991,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"/dev/null","sourceNew":"  /*\n   * Test is hetrogenous index segements are merge sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider);\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundDocStore(false);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["295775b7fc38425a963bfab5be1f7fe7003d0f7b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"/dev/null","sourceNew":"  /*\n   * Test is hetrogenous index segements are merge sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider);\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundDocStore(false);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"295775b7fc38425a963bfab5be1f7fe7003d0f7b","date":1289666592,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test is hetrogenous index segements are merge sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundDocStore(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test is hetrogenous index segements are merge sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider);\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundDocStore(false);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c498d3f8d75170b121f5eda2c6210ac5beb5d411","date":1289726298,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test is hetrogenous index segements are merge sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundDocStore(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test is hetrogenous index segements are merge sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider);\n    IndexWriter writer = newWriter(dir, iwconf);\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundDocStore(false);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","date":1292695408,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test is hetrogenous index segements are merge sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test is hetrogenous index segements are merge sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundDocStore(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test is hetrogenous index segements are merge sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test is hetrogenous index segements are merge sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundDocStore(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"/dev/null","sourceNew":"  /*\n   * Test is hetrogenous index segements are merge sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"56da903869515527852ee21ea7ef7bfe414cd40d","date":1294224724,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test is hetrogenous index segements are merge sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test is hetrogenous index segements are merge sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test is hetrogenous index segements are merge sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c19f985e36a65cc969e8e564fe337a0d41512075","date":1296330536,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    ((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/perfield/TestPerFieldPostingsFormat#testChangeCodecAndMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestPerFieldCodecSupport#testChangeCodecAndMerge().mjava","sourceNew":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  // TODO: not sure this test is that great, we should probably peek inside PerFieldPostingsFormat or something?!\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(new MockCodec());\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    Lucene40Codec codec = (Lucene40Codec)iwconf.getCodec();\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setOpenMode(OpenMode.APPEND).setCodec(codec);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    iwconf.setCodec(new MockCodec2()); // uses standard for field content\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    codec = (Lucene40Codec)iwconf.getCodec();\n    PostingsFormat origContentCodec = PostingsFormat.forName(\"MockSep\");\n    PostingsFormat newContentCodec = PostingsFormat.forName(\"Lucene40\");\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10);\n\n    dir.close();\n  }\n\n","sourceOld":"  /*\n   * Test that heterogeneous index segments are merged sucessfully\n   */\n  @Test\n  public void testChangeCodecAndMerge() throws IOException {\n    Directory dir = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    if (VERBOSE) {\n      System.out.println(\"TEST: make new index\");\n    }\n    IndexWriterConfig iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT,\n             new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(provider);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    IndexWriter writer = newWriter(dir, iwconf);\n\n    addDocs(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    if (VERBOSE) {\n      System.out.println(\"TEST: addDocs3\");\n    }\n    addDocs3(writer, 10);\n    writer.commit();\n    writer.close();\n\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        provider.lookup(\"MockSep\"));\n\n    iwconf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setOpenMode(OpenMode.APPEND).setCodecProvider(provider);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setUseCompoundFile(false);\n    //((LogMergePolicy) iwconf.getMergePolicy()).setMergeFactor(10);\n    iwconf.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);\n\n    provider = new MockCodecProvider2(); // uses standard for field content\n    iwconf.setCodecProvider(provider);\n    writer = newWriter(dir, iwconf);\n    // swap in new codec for currently written segments\n    if (VERBOSE) {\n      System.out.println(\"TEST: add docs w/ Standard codec for content field\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    Codec origContentCodec = provider.lookup(\"MockSep\");\n    Codec newContentCodec = provider.lookup(\"Standard\");\n    assertHybridCodecPerField(_TestUtil.checkIndex(dir, provider), \"content\",\n        origContentCodec, origContentCodec, newContentCodec);\n    assertEquals(30, writer.maxDoc());\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);   ////\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: add more docs w/ new codec\");\n    }\n    addDocs2(writer, 10);\n    writer.commit();\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n    assertEquals(40, writer.maxDoc());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now optimize\");\n    }\n    writer.optimize();\n    assertEquals(40, writer.maxDoc());\n    writer.close();\n    assertCodecPerFieldOptimized(_TestUtil.checkIndex(dir, provider),\n        \"content\", newContentCodec);\n    assertQuery(new Term(\"content\", \"ccc\"), dir, 10, provider);\n    assertQuery(new Term(\"content\", \"bbb\"), dir, 20, provider);\n    assertQuery(new Term(\"content\", \"aaa\"), dir, 10, provider);\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70ad682703b8585f5d0a637efec044d57ec05efb":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","56da903869515527852ee21ea7ef7bfe414cd40d"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["85a883878c0af761245ab048babc63d099f835f3","295775b7fc38425a963bfab5be1f7fe7003d0f7b"],"a493e6d0c3ad86bd55c0a1360d110142e948f2bd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"85a883878c0af761245ab048babc63d099f835f3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a493e6d0c3ad86bd55c0a1360d110142e948f2bd"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["c498d3f8d75170b121f5eda2c6210ac5beb5d411","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"962d04139994fce5193143ef35615499a9a96d78":["bde51b089eb7f86171eb3406e38a274743f9b7ac","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"c19f985e36a65cc969e8e564fe337a0d41512075":["56da903869515527852ee21ea7ef7bfe414cd40d"],"7b91922b55d15444d554721b352861d028eb8278":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"295775b7fc38425a963bfab5be1f7fe7003d0f7b":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["c19f985e36a65cc969e8e564fe337a0d41512075"],"56da903869515527852ee21ea7ef7bfe414cd40d":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"a3776dccca01c11e7046323cfad46a3b4a471233":["c19f985e36a65cc969e8e564fe337a0d41512075","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["70ad682703b8585f5d0a637efec044d57ec05efb","c19f985e36a65cc969e8e564fe337a0d41512075"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["295775b7fc38425a963bfab5be1f7fe7003d0f7b"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","56da903869515527852ee21ea7ef7bfe414cd40d"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["868da859b43505d9d2a023bfeae6dd0c795f5295","c19f985e36a65cc969e8e564fe337a0d41512075"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7b91922b55d15444d554721b352861d028eb8278"]},"commit2Childs":{"70ad682703b8585f5d0a637efec044d57ec05efb":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"85a883878c0af761245ab048babc63d099f835f3":["c498d3f8d75170b121f5eda2c6210ac5beb5d411"],"a493e6d0c3ad86bd55c0a1360d110142e948f2bd":["85a883878c0af761245ab048babc63d099f835f3","295775b7fc38425a963bfab5be1f7fe7003d0f7b"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["70ad682703b8585f5d0a637efec044d57ec05efb"],"962d04139994fce5193143ef35615499a9a96d78":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"c19f985e36a65cc969e8e564fe337a0d41512075":["f2c5f0cb44df114db4228c8f77861714b5cabaea","a3776dccca01c11e7046323cfad46a3b4a471233","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"7b91922b55d15444d554721b352861d028eb8278":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"295775b7fc38425a963bfab5be1f7fe7003d0f7b":["c498d3f8d75170b121f5eda2c6210ac5beb5d411","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","7b91922b55d15444d554721b352861d028eb8278","a3776dccca01c11e7046323cfad46a3b4a471233"],"56da903869515527852ee21ea7ef7bfe414cd40d":["70ad682703b8585f5d0a637efec044d57ec05efb","c19f985e36a65cc969e8e564fe337a0d41512075","868da859b43505d9d2a023bfeae6dd0c795f5295"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd","85a883878c0af761245ab048babc63d099f835f3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","56da903869515527852ee21ea7ef7bfe414cd40d"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["962d04139994fce5193143ef35615499a9a96d78"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}