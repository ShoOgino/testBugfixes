{"path":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,IndexDocValues).mjava","commits":[{"id":"41e5bbad683f7546e96f08ffe8bc50cf447f2586","date":1307113213,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,IndexDocValues).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,DocValues).mjava","sourceNew":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      IndexDocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    int docBase = 0;\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for (final IndexReader reader : mergeState.readers) {\n      final IndexDocValues r = reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, docBase, reader.maxDoc(), reader\n            .getDeletedDocs()));\n      }\n      docBase += reader.numDocs();\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","sourceOld":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      DocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    int docBase = 0;\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for (final IndexReader reader : mergeState.readers) {\n      final DocValues r = reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, docBase, reader.maxDoc(), reader\n            .getDeletedDocs()));\n      }\n      docBase += reader.numDocs();\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e8d7ba2175f47e280231533f7d3016249cea88b","date":1307711934,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,IndexDocValues).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      IndexDocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    int docBase = 0;\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for (final IndexReader reader : mergeState.readers) {\n      final IndexDocValues r = reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, docBase, reader.maxDoc(), reader\n            .getDeletedDocs()));\n      }\n      docBase += reader.numDocs();\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,IndexDocValues).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      IndexDocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    int docBase = 0;\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for (final IndexReader reader : mergeState.readers) {\n      final IndexDocValues r = reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, docBase, reader.maxDoc(), reader\n            .getDeletedDocs()));\n      }\n      docBase += reader.numDocs();\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","date":1309960478,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,IndexDocValues).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,IndexDocValues).mjava","sourceNew":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      IndexDocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    int docBase = 0;\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for (final IndexReader reader : mergeState.readers) {\n      final IndexDocValues r = reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, docBase, reader.maxDoc(),\n                                    reader.getLiveDocs()));\n      }\n      docBase += reader.numDocs();\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","sourceOld":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      IndexDocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    int docBase = 0;\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for (final IndexReader reader : mergeState.readers) {\n      final IndexDocValues r = reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, docBase, reader.maxDoc(), reader\n            .getDeletedDocs()));\n      }\n      docBase += reader.numDocs();\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,IndexDocValues).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,IndexDocValues).mjava","sourceNew":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      IndexDocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    int docBase = 0;\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for (final IndexReader reader : mergeState.readers) {\n      final IndexDocValues r = reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, docBase, reader.maxDoc(),\n                                    reader.getLiveDocs()));\n      }\n      docBase += reader.numDocs();\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","sourceOld":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      IndexDocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    int docBase = 0;\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for (final IndexReader reader : mergeState.readers) {\n      final IndexDocValues r = reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, docBase, reader.maxDoc(), reader\n            .getDeletedDocs()));\n      }\n      docBase += reader.numDocs();\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,IndexDocValues).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,IndexDocValues).mjava","sourceNew":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      IndexDocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    int docBase = 0;\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for (final IndexReader reader : mergeState.readers) {\n      final IndexDocValues r = reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, docBase, reader.maxDoc(),\n                                    reader.getLiveDocs()));\n      }\n      docBase += reader.numDocs();\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","sourceOld":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      IndexDocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    int docBase = 0;\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for (final IndexReader reader : mergeState.readers) {\n      final IndexDocValues r = reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, docBase, reader.maxDoc(), reader\n            .getDeletedDocs()));\n      }\n      docBase += reader.numDocs();\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0061262413ecc163d6eebba1b5c43ab91a0c2dc5","date":1311195279,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,IndexDocValues).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,IndexDocValues).mjava","sourceNew":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      IndexDocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for(int readerIDX=0;readerIDX<mergeState.readers.size();readerIDX++) {\n      final org.apache.lucene.index.codecs.MergeState.IndexReaderAndLiveDocs reader = mergeState.readers.get(readerIDX);\n      final IndexDocValues r = reader.reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, mergeState.docBase[readerIDX], reader.reader.maxDoc(),\n                                    reader.liveDocs));\n      }\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","sourceOld":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      IndexDocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    int docBase = 0;\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for (final IndexReader reader : mergeState.readers) {\n      final IndexDocValues r = reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, docBase, reader.maxDoc(),\n                                    reader.getLiveDocs()));\n      }\n      docBase += reader.numDocs();\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"32aca6bb0a6aa0a1813e7d035ac0e039f54269f4","date":1318260487,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(MergeState,IndexDocValues[]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/DocValuesConsumer#merge(org.apache.lucene.index.codecs.MergeState,IndexDocValues).mjava","sourceNew":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param docValues docValues array containing one instance per reader (\n   *          {@link MergeState#readers}) or <code>null</code> if the reader has\n   *          no {@link IndexDocValues} instance.\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(MergeState mergeState, IndexDocValues[] docValues) throws IOException {\n    assert mergeState != null;\n    boolean hasMerged = false;\n    for(int readerIDX=0;readerIDX<mergeState.readers.size();readerIDX++) {\n      final org.apache.lucene.index.codecs.MergeState.IndexReaderAndLiveDocs reader = mergeState.readers.get(readerIDX);\n      if (docValues[readerIDX] != null) {\n        hasMerged = true;\n        merge(new Writer.SingleSubMergeState(docValues[readerIDX], mergeState.docBase[readerIDX], reader.reader.maxDoc(),\n                                    reader.liveDocs));\n      }\n    }\n    // only finish if no exception is thrown!\n    if (hasMerged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","sourceOld":"  /**\n   * Merges the given {@link org.apache.lucene.index.codecs.MergeState} into\n   * this {@link DocValuesConsumer}.\n   * \n   * @param mergeState\n   *          the state to merge\n   * @param values\n   *          the docValues to merge in\n   * @throws IOException\n   *           if an {@link IOException} occurs\n   */\n  public void merge(org.apache.lucene.index.codecs.MergeState mergeState,\n      IndexDocValues values) throws IOException {\n    assert mergeState != null;\n    // TODO we need some kind of compatibility notation for values such\n    // that two slightly different segments can be merged eg. fixed vs.\n    // variable byte len or float32 vs. float64\n    boolean merged = false;\n    /*\n     * We ignore the given DocValues here and merge from the subReaders directly\n     * to support bulk copies on the DocValues Writer level. if this gets merged\n     * with MultiDocValues the writer can not optimize for bulk-copyable data\n     */\n    for(int readerIDX=0;readerIDX<mergeState.readers.size();readerIDX++) {\n      final org.apache.lucene.index.codecs.MergeState.IndexReaderAndLiveDocs reader = mergeState.readers.get(readerIDX);\n      final IndexDocValues r = reader.reader.docValues(mergeState.fieldInfo.name);\n      if (r != null) {\n        merged = true;\n        merge(new Writer.MergeState(r, mergeState.docBase[readerIDX], reader.reader.maxDoc(),\n                                    reader.liveDocs));\n      }\n    }\n    if (merged) {\n      finish(mergeState.mergedDocCount);\n    }\n  }\n\n","bugFix":null,"bugIntro":["fa0f44f887719e97183771e977cfc4bfb485b766","fa0f44f887719e97183771e977cfc4bfb485b766"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2e8d7ba2175f47e280231533f7d3016249cea88b"],"2e8d7ba2175f47e280231533f7d3016249cea88b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","41e5bbad683f7546e96f08ffe8bc50cf447f2586"],"0061262413ecc163d6eebba1b5c43ab91a0c2dc5":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["2e8d7ba2175f47e280231533f7d3016249cea88b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"41e5bbad683f7546e96f08ffe8bc50cf447f2586":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"32aca6bb0a6aa0a1813e7d035ac0e039f54269f4":["0061262413ecc163d6eebba1b5c43ab91a0c2dc5"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["2e8d7ba2175f47e280231533f7d3016249cea88b","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["32aca6bb0a6aa0a1813e7d035ac0e039f54269f4"]},"commit2Childs":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"2e8d7ba2175f47e280231533f7d3016249cea88b":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"0061262413ecc163d6eebba1b5c43ab91a0c2dc5":["32aca6bb0a6aa0a1813e7d035ac0e039f54269f4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","2e8d7ba2175f47e280231533f7d3016249cea88b","41e5bbad683f7546e96f08ffe8bc50cf447f2586"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["0061262413ecc163d6eebba1b5c43ab91a0c2dc5","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"41e5bbad683f7546e96f08ffe8bc50cf447f2586":["2e8d7ba2175f47e280231533f7d3016249cea88b"],"32aca6bb0a6aa0a1813e7d035ac0e039f54269f4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}