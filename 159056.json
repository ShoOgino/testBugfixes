{"path":"lucene/test-framework/src/java/org/apache/lucene/search/similarities/BaseSimilarityTestCase#newCorpus(Random,int).mjava","commits":[{"id":"ad1dc49b5314cfdb82a7ea40d2f92f07fe8cee46","date":1508899684,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/similarities/BaseSimilarityTestCase#newCorpus(Random,int).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * returns a random corpus that is at least possible given\n   * the norm value for a single document.\n   */\n  static CollectionStatistics newCorpus(Random random, int norm) {\n    // lower bound of tokens in the collection (you produced this norm somehow)\n    final int lowerBound;\n    if (norm == 0) {\n      // norms are omitted, but there must have been at least one token to produce that norm\n      lowerBound = 1;    \n    } else {\n      // minimum value that would decode to such a norm\n      lowerBound = SmallFloat.byte4ToInt((byte) norm);\n    }\n    final long maxDoc;\n    if (random.nextBoolean()) {\n      // small collection\n      maxDoc = TestUtil.nextLong(random, 1, 100000);\n    } else {\n      // yuge collection\n      maxDoc = TestUtil.nextLong(random, 1, MAXDOC_FORTESTING);\n    }\n    // TODO: make this a mandatory statistic, or test it with -1\n    final long docCount;\n    if (random.nextBoolean()) {\n      // sparse field\n      docCount = TestUtil.nextLong(random, 1, maxDoc);\n    } else {\n      // fully populated\n      docCount = maxDoc;\n    }\n    // random docsize: but can't require docs to have > 2B tokens\n    long upperBound;\n    try {\n      upperBound = Math.min(MAXTOKENS_FORTESTING, Math.multiplyExact(docCount, Integer.MAX_VALUE));\n    } catch (ArithmeticException overflow) {\n      upperBound = MAXTOKENS_FORTESTING;\n    }\n    // TODO: make this a mandatory statistic, or test it with -1\n    final long sumDocFreq;\n    if (random.nextBoolean()) {\n      // shortest possible docs\n      sumDocFreq = docCount;\n    } else {\n      // random docsize\n      sumDocFreq = TestUtil.nextLong(random, docCount, upperBound + 1 - lowerBound);\n    }\n    final long sumTotalTermFreq;\n    switch (random.nextInt(3)) {\n      case 0:\n        // unsupported (e.g. omitTF)\n        sumTotalTermFreq = -1;\n        break;\n      case 1:\n        // no repetition of terms (except to satisfy this norm)\n        sumTotalTermFreq = sumDocFreq - 1 + lowerBound;\n        break;\n      default:\n        // random repetition\n        assert sumDocFreq - 1 + lowerBound <= upperBound;\n        sumTotalTermFreq = TestUtil.nextLong(random, sumDocFreq - 1 + lowerBound, upperBound);\n        break;\n    }\n    return new CollectionStatistics(\"field\", maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"086ffe31d8fba0110227db122974163709ecc1b4","date":1509678141,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/similarities/BaseSimilarityTestCase#newCorpus(Random,int).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/similarities/BaseSimilarityTestCase#newCorpus(Random,int).mjava","sourceNew":"  /**\n   * returns a random corpus that is at least possible given\n   * the norm value for a single document.\n   */\n  static CollectionStatistics newCorpus(Random random, int norm) {\n    // lower bound of tokens in the collection (you produced this norm somehow)\n    final int lowerBound;\n    if (norm == 0) {\n      // norms are omitted, but there must have been at least one token to produce that norm\n      lowerBound = 1;    \n    } else {\n      // minimum value that would decode to such a norm\n      lowerBound = SmallFloat.byte4ToInt((byte) norm);\n    }\n    final long maxDoc;\n    if (random.nextBoolean()) {\n      // small collection\n      maxDoc = TestUtil.nextLong(random, 1, 100000);\n    } else {\n      // yuge collection\n      maxDoc = TestUtil.nextLong(random, 1, MAXDOC_FORTESTING);\n    }\n    final long docCount;\n    if (random.nextBoolean()) {\n      // sparse field\n      docCount = TestUtil.nextLong(random, 1, maxDoc);\n    } else {\n      // fully populated\n      docCount = maxDoc;\n    }\n    // random docsize: but can't require docs to have > 2B tokens\n    long upperBound;\n    try {\n      upperBound = Math.min(MAXTOKENS_FORTESTING, Math.multiplyExact(docCount, Integer.MAX_VALUE));\n    } catch (ArithmeticException overflow) {\n      upperBound = MAXTOKENS_FORTESTING;\n    }\n    final long sumDocFreq;\n    if (random.nextBoolean()) {\n      // shortest possible docs\n      sumDocFreq = docCount;\n    } else {\n      // random docsize\n      sumDocFreq = TestUtil.nextLong(random, docCount, upperBound + 1 - lowerBound);\n    }\n    final long sumTotalTermFreq;\n    switch (random.nextInt(3)) {\n      case 0:\n        // term frequencies were omitted\n        sumTotalTermFreq = sumDocFreq;\n        break;\n      case 1:\n        // no repetition of terms (except to satisfy this norm)\n        sumTotalTermFreq = sumDocFreq - 1 + lowerBound;\n        break;\n      default:\n        // random repetition\n        assert sumDocFreq - 1 + lowerBound <= upperBound;\n        sumTotalTermFreq = TestUtil.nextLong(random, sumDocFreq - 1 + lowerBound, upperBound);\n        break;\n    }\n    return new CollectionStatistics(\"field\", maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n  }\n\n","sourceOld":"  /**\n   * returns a random corpus that is at least possible given\n   * the norm value for a single document.\n   */\n  static CollectionStatistics newCorpus(Random random, int norm) {\n    // lower bound of tokens in the collection (you produced this norm somehow)\n    final int lowerBound;\n    if (norm == 0) {\n      // norms are omitted, but there must have been at least one token to produce that norm\n      lowerBound = 1;    \n    } else {\n      // minimum value that would decode to such a norm\n      lowerBound = SmallFloat.byte4ToInt((byte) norm);\n    }\n    final long maxDoc;\n    if (random.nextBoolean()) {\n      // small collection\n      maxDoc = TestUtil.nextLong(random, 1, 100000);\n    } else {\n      // yuge collection\n      maxDoc = TestUtil.nextLong(random, 1, MAXDOC_FORTESTING);\n    }\n    // TODO: make this a mandatory statistic, or test it with -1\n    final long docCount;\n    if (random.nextBoolean()) {\n      // sparse field\n      docCount = TestUtil.nextLong(random, 1, maxDoc);\n    } else {\n      // fully populated\n      docCount = maxDoc;\n    }\n    // random docsize: but can't require docs to have > 2B tokens\n    long upperBound;\n    try {\n      upperBound = Math.min(MAXTOKENS_FORTESTING, Math.multiplyExact(docCount, Integer.MAX_VALUE));\n    } catch (ArithmeticException overflow) {\n      upperBound = MAXTOKENS_FORTESTING;\n    }\n    // TODO: make this a mandatory statistic, or test it with -1\n    final long sumDocFreq;\n    if (random.nextBoolean()) {\n      // shortest possible docs\n      sumDocFreq = docCount;\n    } else {\n      // random docsize\n      sumDocFreq = TestUtil.nextLong(random, docCount, upperBound + 1 - lowerBound);\n    }\n    final long sumTotalTermFreq;\n    switch (random.nextInt(3)) {\n      case 0:\n        // unsupported (e.g. omitTF)\n        sumTotalTermFreq = -1;\n        break;\n      case 1:\n        // no repetition of terms (except to satisfy this norm)\n        sumTotalTermFreq = sumDocFreq - 1 + lowerBound;\n        break;\n      default:\n        // random repetition\n        assert sumDocFreq - 1 + lowerBound <= upperBound;\n        sumTotalTermFreq = TestUtil.nextLong(random, sumDocFreq - 1 + lowerBound, upperBound);\n        break;\n    }\n    return new CollectionStatistics(\"field\", maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d523b8189b211dd1630166aa77b8c88bb48b3fcc","date":1510144168,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/similarities/BaseSimilarityTestCase#newCorpus(Random,int).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/similarities/BaseSimilarityTestCase#newCorpus(Random,int).mjava","sourceNew":"  /**\n   * returns a random corpus that is at least possible given\n   * the norm value for a single document.\n   */\n  static CollectionStatistics newCorpus(Random random, int norm) {\n    // lower bound of tokens in the collection (you produced this norm somehow)\n    final int lowerBound;\n    if (norm == 0) {\n      // norms are omitted, but there must have been at least one token to produce that norm\n      lowerBound = 1;    \n    } else {\n      // minimum value that would decode to such a norm\n      lowerBound = SmallFloat.byte4ToInt((byte) norm);\n    }\n    final long maxDoc;\n    if (random.nextBoolean()) {\n      // small collection\n      maxDoc = TestUtil.nextLong(random, 1, 100000);\n    } else {\n      // yuge collection\n      maxDoc = TestUtil.nextLong(random, 1, MAXDOC_FORTESTING);\n    }\n    final long docCount;\n    if (random.nextBoolean()) {\n      // sparse field\n      docCount = TestUtil.nextLong(random, 1, maxDoc);\n    } else {\n      // fully populated\n      docCount = maxDoc;\n    }\n    // random docsize: but can't require docs to have > 2B tokens\n    long upperBound;\n    try {\n      upperBound = Math.min(MAXTOKENS_FORTESTING, Math.multiplyExact(docCount, Integer.MAX_VALUE));\n    } catch (ArithmeticException overflow) {\n      upperBound = MAXTOKENS_FORTESTING;\n    }\n    final long sumDocFreq;\n    if (random.nextBoolean()) {\n      // shortest possible docs\n      sumDocFreq = docCount;\n    } else {\n      // random docsize\n      sumDocFreq = TestUtil.nextLong(random, docCount, upperBound + 1 - lowerBound);\n    }\n    final long sumTotalTermFreq;\n    switch (random.nextInt(3)) {\n      case 0:\n        // term frequencies were omitted\n        sumTotalTermFreq = sumDocFreq;\n        break;\n      case 1:\n        // no repetition of terms (except to satisfy this norm)\n        sumTotalTermFreq = sumDocFreq - 1 + lowerBound;\n        break;\n      default:\n        // random repetition\n        assert sumDocFreq - 1 + lowerBound <= upperBound;\n        sumTotalTermFreq = TestUtil.nextLong(random, sumDocFreq - 1 + lowerBound, upperBound);\n        break;\n    }\n    return new CollectionStatistics(\"field\", maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n  }\n\n","sourceOld":"  /**\n   * returns a random corpus that is at least possible given\n   * the norm value for a single document.\n   */\n  static CollectionStatistics newCorpus(Random random, int norm) {\n    // lower bound of tokens in the collection (you produced this norm somehow)\n    final int lowerBound;\n    if (norm == 0) {\n      // norms are omitted, but there must have been at least one token to produce that norm\n      lowerBound = 1;    \n    } else {\n      // minimum value that would decode to such a norm\n      lowerBound = SmallFloat.byte4ToInt((byte) norm);\n    }\n    final long maxDoc;\n    if (random.nextBoolean()) {\n      // small collection\n      maxDoc = TestUtil.nextLong(random, 1, 100000);\n    } else {\n      // yuge collection\n      maxDoc = TestUtil.nextLong(random, 1, MAXDOC_FORTESTING);\n    }\n    // TODO: make this a mandatory statistic, or test it with -1\n    final long docCount;\n    if (random.nextBoolean()) {\n      // sparse field\n      docCount = TestUtil.nextLong(random, 1, maxDoc);\n    } else {\n      // fully populated\n      docCount = maxDoc;\n    }\n    // random docsize: but can't require docs to have > 2B tokens\n    long upperBound;\n    try {\n      upperBound = Math.min(MAXTOKENS_FORTESTING, Math.multiplyExact(docCount, Integer.MAX_VALUE));\n    } catch (ArithmeticException overflow) {\n      upperBound = MAXTOKENS_FORTESTING;\n    }\n    // TODO: make this a mandatory statistic, or test it with -1\n    final long sumDocFreq;\n    if (random.nextBoolean()) {\n      // shortest possible docs\n      sumDocFreq = docCount;\n    } else {\n      // random docsize\n      sumDocFreq = TestUtil.nextLong(random, docCount, upperBound + 1 - lowerBound);\n    }\n    final long sumTotalTermFreq;\n    switch (random.nextInt(3)) {\n      case 0:\n        // unsupported (e.g. omitTF)\n        sumTotalTermFreq = -1;\n        break;\n      case 1:\n        // no repetition of terms (except to satisfy this norm)\n        sumTotalTermFreq = sumDocFreq - 1 + lowerBound;\n        break;\n      default:\n        // random repetition\n        assert sumDocFreq - 1 + lowerBound <= upperBound;\n        sumTotalTermFreq = TestUtil.nextLong(random, sumDocFreq - 1 + lowerBound, upperBound);\n        break;\n    }\n    return new CollectionStatistics(\"field\", maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83d379038462cf6dcf64cc9e9a49053c4bb78011","date":1512580797,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/search/similarities/BaseSimilarityTestCase#newCorpus(Random,int).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/search/similarities/BaseSimilarityTestCase#newCorpus(Random,int).mjava","sourceNew":"  /**\n   * returns a random corpus that is at least possible given\n   * the norm value for a single document.\n   */\n  static CollectionStatistics newCorpus(Random random, int norm) {\n    // lower bound of tokens in the collection (you produced this norm somehow)\n    final int lowerBound;\n    if (norm == 0) {\n      // norms are omitted, but there must have been at least one token to produce that norm\n      lowerBound = 1;    \n    } else {\n      // minimum value that would decode to such a norm\n      lowerBound = SmallFloat.byte4ToInt((byte) norm);\n    }\n    final long maxDoc;\n    switch (random.nextInt(6)) {\n      case 0:\n        // 1 doc collection\n        maxDoc = 1;\n        break;\n      case 1:\n        // 2 doc collection\n        maxDoc = 2;\n        break;\n      case 2:\n        // tiny collection\n        maxDoc = TestUtil.nextLong(random, 3, 16);\n        break;\n      case 3:\n        // small collection\n        maxDoc = TestUtil.nextLong(random, 16, 100000);\n        break;\n      case 4:\n        // big collection\n        maxDoc = TestUtil.nextLong(random, 100000, MAXDOC_FORTESTING);\n        break;\n      default:\n        // yuge collection\n        maxDoc = MAXDOC_FORTESTING;\n        break;\n    }\n    final long docCount;\n    switch (random.nextInt(3)) {\n      case 0:\n        // sparsest field\n        docCount = 1;\n        break;\n      case 1:\n        // sparse field\n        docCount = TestUtil.nextLong(random, 1, maxDoc);\n        break;\n      default:\n        // fully populated\n        docCount = maxDoc;\n        break;\n    }\n    // random docsize: but can't require docs to have > 2B tokens\n    long upperBound;\n    try {\n      upperBound = Math.min(MAXTOKENS_FORTESTING, Math.multiplyExact(docCount, Integer.MAX_VALUE));\n    } catch (ArithmeticException overflow) {\n      upperBound = MAXTOKENS_FORTESTING;\n    }\n    final long sumDocFreq;\n    switch (random.nextInt(3)) {\n      case 0:\n        // shortest possible docs\n        sumDocFreq = docCount;\n        break;\n      case 1:\n        // biggest possible docs\n        sumDocFreq = upperBound + 1 - lowerBound;\n        break;\n      default:\n        // random docsize\n        sumDocFreq = TestUtil.nextLong(random, docCount, upperBound + 1 - lowerBound);\n        break;\n    }\n    final long sumTotalTermFreq;\n    switch (random.nextInt(4)) {\n      case 0:\n        // term frequencies were omitted\n        sumTotalTermFreq = sumDocFreq;\n        break;\n      case 1:\n        // no repetition of terms (except to satisfy this norm)\n        sumTotalTermFreq = sumDocFreq - 1 + lowerBound;\n        break;\n      case 2:\n        // maximum repetition of terms\n        sumTotalTermFreq = upperBound;\n        break;\n      default:\n        // random repetition\n        assert sumDocFreq - 1 + lowerBound <= upperBound;\n        sumTotalTermFreq = TestUtil.nextLong(random, sumDocFreq - 1 + lowerBound, upperBound);\n        break;\n    }\n    return new CollectionStatistics(\"field\", maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n  }\n\n","sourceOld":"  /**\n   * returns a random corpus that is at least possible given\n   * the norm value for a single document.\n   */\n  static CollectionStatistics newCorpus(Random random, int norm) {\n    // lower bound of tokens in the collection (you produced this norm somehow)\n    final int lowerBound;\n    if (norm == 0) {\n      // norms are omitted, but there must have been at least one token to produce that norm\n      lowerBound = 1;    \n    } else {\n      // minimum value that would decode to such a norm\n      lowerBound = SmallFloat.byte4ToInt((byte) norm);\n    }\n    final long maxDoc;\n    if (random.nextBoolean()) {\n      // small collection\n      maxDoc = TestUtil.nextLong(random, 1, 100000);\n    } else {\n      // yuge collection\n      maxDoc = TestUtil.nextLong(random, 1, MAXDOC_FORTESTING);\n    }\n    final long docCount;\n    if (random.nextBoolean()) {\n      // sparse field\n      docCount = TestUtil.nextLong(random, 1, maxDoc);\n    } else {\n      // fully populated\n      docCount = maxDoc;\n    }\n    // random docsize: but can't require docs to have > 2B tokens\n    long upperBound;\n    try {\n      upperBound = Math.min(MAXTOKENS_FORTESTING, Math.multiplyExact(docCount, Integer.MAX_VALUE));\n    } catch (ArithmeticException overflow) {\n      upperBound = MAXTOKENS_FORTESTING;\n    }\n    final long sumDocFreq;\n    if (random.nextBoolean()) {\n      // shortest possible docs\n      sumDocFreq = docCount;\n    } else {\n      // random docsize\n      sumDocFreq = TestUtil.nextLong(random, docCount, upperBound + 1 - lowerBound);\n    }\n    final long sumTotalTermFreq;\n    switch (random.nextInt(3)) {\n      case 0:\n        // term frequencies were omitted\n        sumTotalTermFreq = sumDocFreq;\n        break;\n      case 1:\n        // no repetition of terms (except to satisfy this norm)\n        sumTotalTermFreq = sumDocFreq - 1 + lowerBound;\n        break;\n      default:\n        // random repetition\n        assert sumDocFreq - 1 + lowerBound <= upperBound;\n        sumTotalTermFreq = TestUtil.nextLong(random, sumDocFreq - 1 + lowerBound, upperBound);\n        break;\n    }\n    return new CollectionStatistics(\"field\", maxDoc, docCount, sumTotalTermFreq, sumDocFreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"83d379038462cf6dcf64cc9e9a49053c4bb78011":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"ad1dc49b5314cfdb82a7ea40d2f92f07fe8cee46":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"086ffe31d8fba0110227db122974163709ecc1b4":["ad1dc49b5314cfdb82a7ea40d2f92f07fe8cee46"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["ad1dc49b5314cfdb82a7ea40d2f92f07fe8cee46","086ffe31d8fba0110227db122974163709ecc1b4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["83d379038462cf6dcf64cc9e9a49053c4bb78011"]},"commit2Childs":{"83d379038462cf6dcf64cc9e9a49053c4bb78011":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ad1dc49b5314cfdb82a7ea40d2f92f07fe8cee46":["086ffe31d8fba0110227db122974163709ecc1b4","d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"086ffe31d8fba0110227db122974163709ecc1b4":["d523b8189b211dd1630166aa77b8c88bb48b3fcc"],"d523b8189b211dd1630166aa77b8c88bb48b3fcc":["83d379038462cf6dcf64cc9e9a49053c4bb78011"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ad1dc49b5314cfdb82a7ea40d2f92f07fe8cee46"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}