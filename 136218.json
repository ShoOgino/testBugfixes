{"path":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","commits":[{"id":"f470b537db3da4e8d0c39bc72fae5f9865a9ec3c","date":1275494784,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"/dev/null","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b21422ff1d1d56499dec481f193b402e5e8def5b","date":1281472367,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory(random);\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory(random);\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"132903c28af3aa6f67284b78de91c0f0a99488c2","date":1284282129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a186ae8733084223c22044e935e4ef848a143d1","date":1289694819,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n          didWarm.set(true);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c498d3f8d75170b121f5eda2c6210ac5beb5d411","date":1289726298,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n          didWarm.set(true);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e8cc373c801e54cec75daf9f52792cb4b17f536","date":1291116159,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = new IndexSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n          didWarm.set(true);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = new IndexSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n          didWarm.set(true);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = new IndexSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = new MockRAMDirectory();\n    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())\n                                    .setMaxBufferedDocs(2).setReaderPooling(true));\n    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n        public void warm(IndexReader r) throws IOException {\n          final IndexSearcher s = new IndexSearcher(r);\n          final TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n          assertEquals(20, hits.totalHits);\n        }\n      });\n    \n    Document doc = new Document();\n    doc.add(new Field(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01","date":1296400215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = new IndexSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = new IndexSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790e1fde4caa765b3faaad3fbcd25c6973450336","date":1296689245,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n                s.close();\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = new IndexSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n                s.close();\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = new IndexSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n                s.close();\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = new IndexSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n                s.close();\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n                s.close();\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n                s.close();\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n                s.close();\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n                s.close();\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n                s.close();\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n                s.close();\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n                s.close();\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n                s.close();\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n                s.close();\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", Field.Store.YES, Field.Index.NOT_ANALYZED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0e7c2454a6a8237bfd0e953f5b940838408c9055","date":1323649300,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n                s.close();\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","date":1323720782,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n                s.close();\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55c2bb1bcc0edd142e63b9230976dfc3e500dbe8","date":1327857288,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(AtomicIndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"da6d5ac19a80d65b1e864251f155d30960353b7e","date":1327881054,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(AtomicReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(AtomicIndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(AtomicReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(IndexReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterReader#testSegmentWarmer().mjava","sourceNew":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(AtomicReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","sourceOld":"  public void testSegmentWarmer() throws Exception {\n    Directory dir = newDirectory();\n    final AtomicBoolean didWarm = new AtomicBoolean();\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMaxBufferedDocs(2).\n            setReaderPooling(true).\n            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n              @Override\n              public void warm(AtomicReader r) throws IOException {\n                IndexSearcher s = newSearcher(r);\n                TopDocs hits = s.search(new TermQuery(new Term(\"foo\", \"bar\")), 10);\n                assertEquals(20, hits.totalHits);\n                didWarm.set(true);\n              }\n            }).\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"foo\", \"bar\", StringField.TYPE_UNSTORED));\n    for(int i=0;i<20;i++) {\n      w.addDocument(doc);\n    }\n    w.waitForMerges();\n    w.close();\n    dir.close();\n    assertTrue(didWarm.get());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":["1509f151d7692d84fae414b2b799ac06ba60fcb4","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"55c2bb1bcc0edd142e63b9230976dfc3e500dbe8":["0e7c2454a6a8237bfd0e953f5b940838408c9055"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["f470b537db3da4e8d0c39bc72fae5f9865a9ec3c","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["790e1fde4caa765b3faaad3fbcd25c6973450336"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["3bb13258feba31ab676502787ab2e1779f129b7a","790e1fde4caa765b3faaad3fbcd25c6973450336"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["f470b537db3da4e8d0c39bc72fae5f9865a9ec3c"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","790e1fde4caa765b3faaad3fbcd25c6973450336"],"70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"2a186ae8733084223c22044e935e4ef848a143d1":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["132903c28af3aa6f67284b78de91c0f0a99488c2","2a186ae8733084223c22044e935e4ef848a143d1"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"962d04139994fce5193143ef35615499a9a96d78":["bde51b089eb7f86171eb3406e38a274743f9b7ac","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["0e7c2454a6a8237bfd0e953f5b940838408c9055","da6d5ac19a80d65b1e864251f155d30960353b7e"],"790e1fde4caa765b3faaad3fbcd25c6973450336":["70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01"],"da6d5ac19a80d65b1e864251f155d30960353b7e":["55c2bb1bcc0edd142e63b9230976dfc3e500dbe8"],"a3776dccca01c11e7046323cfad46a3b4a471233":["790e1fde4caa765b3faaad3fbcd25c6973450336","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"f470b537db3da4e8d0c39bc72fae5f9865a9ec3c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3bb13258feba31ab676502787ab2e1779f129b7a":["c498d3f8d75170b121f5eda2c6210ac5beb5d411","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["2a186ae8733084223c22044e935e4ef848a143d1"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"93ccd971aca7fb61b7f1b946e44714cfc80bfc7c":[],"55c2bb1bcc0edd142e63b9230976dfc3e500dbe8":["da6d5ac19a80d65b1e864251f155d30960353b7e"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["2a186ae8733084223c22044e935e4ef848a143d1","c498d3f8d75170b121f5eda2c6210ac5beb5d411"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["1509f151d7692d84fae414b2b799ac06ba60fcb4","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"0e7c2454a6a8237bfd0e953f5b940838408c9055":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","55c2bb1bcc0edd142e63b9230976dfc3e500dbe8","5cab9a86bd67202d20b6adc463008c8e982b070a"],"1f653cfcf159baeaafe5d01682a911e95bba4012":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f470b537db3da4e8d0c39bc72fae5f9865a9ec3c"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","0e7c2454a6a8237bfd0e953f5b940838408c9055"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["962d04139994fce5193143ef35615499a9a96d78"],"70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01":["790e1fde4caa765b3faaad3fbcd25c6973450336"],"2a186ae8733084223c22044e935e4ef848a143d1":["c498d3f8d75170b121f5eda2c6210ac5beb5d411","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"c498d3f8d75170b121f5eda2c6210ac5beb5d411":["3bb13258feba31ab676502787ab2e1779f129b7a"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"962d04139994fce5193143ef35615499a9a96d78":[],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"790e1fde4caa765b3faaad3fbcd25c6973450336":["f2c5f0cb44df114db4228c8f77861714b5cabaea","29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","a3776dccca01c11e7046323cfad46a3b4a471233"],"da6d5ac19a80d65b1e864251f155d30960353b7e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"f470b537db3da4e8d0c39bc72fae5f9865a9ec3c":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b21422ff1d1d56499dec481f193b402e5e8def5b"],"3bb13258feba31ab676502787ab2e1779f129b7a":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","70e12dd4a648dadc5999dde1f0fb3a71a6ae4b01","3bb13258feba31ab676502787ab2e1779f129b7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["93ccd971aca7fb61b7f1b946e44714cfc80bfc7c","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}