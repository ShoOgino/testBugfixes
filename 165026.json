{"path":"lucene/spatial3d/src/test/org/apache/lucene/spatial3d/TestGeo3DPoint#verify(double[],double[],PlanetModel).mjava","commits":[{"id":"c33ed6824db1d3c54aaf0208e68c3df3fd43d93a","date":1583186777,"type":1,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/spatial3d/src/test/org/apache/lucene/spatial3d/TestGeo3DPoint#verify(double[],double[],PlanetModel).mjava","pathOld":"lucene/spatial3d/src/test/org/apache/lucene/spatial3d/TestGeo3DPoint#verify(double[],double[]).mjava","sourceNew":"  private static void verify(double[] lats, double[] lons, final PlanetModel planetModel) throws Exception {\n    IndexWriterConfig iwc = newIndexWriterConfig();\n\n    GeoPoint[] points = new GeoPoint[lats.length];\n    GeoPoint[] unquantizedPoints = new GeoPoint[lats.length];\n    \n    // Pre-quantize all lat/lons:\n    for(int i=0;i<lats.length;i++) {\n      if (Double.isNaN(lats[i]) == false) {\n        //System.out.println(\"lats[\" + i + \"] = \" + lats[i]);\n        unquantizedPoints[i] = new GeoPoint(planetModel, toRadians(lats[i]), toRadians(lons[i]));\n        points[i] = quantize(unquantizedPoints[i], planetModel);\n      }\n    }\n\n    // Else we can get O(N^2) merging:\n    int mbd = iwc.getMaxBufferedDocs();\n    if (mbd != -1 && mbd < points.length/100) {\n      iwc.setMaxBufferedDocs(points.length/100);\n    }\n    iwc.setCodec(getCodec());\n    Directory dir;\n    if (points.length > 100000) {\n      dir = newFSDirectory(createTempDir(\"TestBKDTree\"));\n    } else {\n      dir = getDirectory();\n    }\n    Set<Integer> deleted = new HashSet<>();\n    // RandomIndexWriter is too slow here:\n    IndexWriter w = new IndexWriter(dir, iwc);\n    for(int id=0;id<points.length;id++) {\n      Document doc = new Document();\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"id\", id));\n      GeoPoint point = points[id];\n      if (point != null) {\n        doc.add(new Geo3DPoint(\"point\", planetModel, point.x, point.y, point.z));\n      }\n      w.addDocument(doc);\n      if (id > 0 && random().nextInt(100) == 42) {\n        int idToDelete = random().nextInt(id);\n        w.deleteDocuments(new Term(\"id\", \"\"+idToDelete));\n        deleted.add(idToDelete);\n        if (VERBOSE) {\n          System.err.println(\"  delete id=\" + idToDelete);\n        }\n      }\n    }\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader r = DirectoryReader.open(w);\n    if (VERBOSE) {\n      System.out.println(\"TEST: using reader \" + r);\n    }\n    w.close();\n\n    // We can't wrap with \"exotic\" readers because the geo3d query must see the Geo3DDVFormat:\n    IndexSearcher s = newSearcher(r, false);\n\n    final int iters = atLeast(100);\n\n    for (int iter=0;iter<iters;iter++) {\n\n      /*\n      GeoShape shape = randomShape();\n\n      if (VERBOSE) {\n        System.err.println(\"\\nTEST: iter=\" + iter + \" shape=\"+shape);\n      }\n      */\n      \n      Query query = random3DQuery(\"point\", planetModel); // Geo3DPoint.newShapeQuery(\"point\", shape);\n\n      if (VERBOSE) {\n        System.err.println(\"  using query: \" + query);\n      }\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public ScoreMode scoreMode() {\n            return ScoreMode.COMPLETE_NO_SCORES;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      if (VERBOSE) {\n        System.err.println(\"  hitCount: \" + hits.cardinality());\n      }\n      \n      NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n      for(int docID=0;docID<r.maxDoc();docID++) {\n        assertEquals(docID, docIDToID.nextDoc());\n        int id = (int) docIDToID.longValue();\n        GeoPoint point = points[id];\n        GeoPoint unquantizedPoint = unquantizedPoints[id];\n        if (point != null && unquantizedPoint != null) {\n          GeoShape shape = ((PointInGeo3DShapeQuery)query).getShape();\n          XYZBounds bounds = new XYZBounds();\n          shape.getBounds(bounds);\n          XYZSolid solid = XYZSolidFactory.makeXYZSolid(planetModel, bounds.getMinimumX(), bounds.getMaximumX(), bounds.getMinimumY(), bounds.getMaximumY(), bounds.getMinimumZ(), bounds.getMaximumZ());\n\n          boolean expected = ((deleted.contains(id) == false) && shape.isWithin(point));\n          if (hits.get(docID) != expected) {\n            StringBuilder b = new StringBuilder();\n            if (expected) {\n              b.append(\"FAIL: id=\" + id + \" should have matched but did not\\n\");\n            } else {\n              b.append(\"FAIL: id=\" + id + \" should not have matched but did\\n\");\n            }\n            b.append(\"  shape=\" + shape + \"\\n\");\n            b.append(\"  bounds=\" + bounds + \"\\n\");\n            b.append(\"  world bounds=(\" +\n              \" minX=\" + planetModel.getMinimumXValue() + \" maxX=\" + planetModel.getMaximumXValue() +\n              \" minY=\" + planetModel.getMinimumYValue() + \" maxY=\" + planetModel.getMaximumYValue() +\n              \" minZ=\" + planetModel.getMinimumZValue() + \" maxZ=\" + planetModel.getMaximumZValue() + \"\\n\");\n            b.append(\"  quantized point=\" + point + \" within shape? \"+shape.isWithin(point)+\" within bounds? \"+solid.isWithin(point)+\"\\n\");\n            b.append(\"  unquantized point=\" + unquantizedPoint + \" within shape? \"+shape.isWithin(unquantizedPoint)+\" within bounds? \"+solid.isWithin(unquantizedPoint)+\"\\n\");\n            b.append(\"  docID=\" + docID + \" deleted?=\" + deleted.contains(id) + \"\\n\");\n            b.append(\"  query=\" + query + \"\\n\");\n            b.append(\"  explanation:\\n    \" + explain(\"point\", shape, point, unquantizedPoint, r, docID).replace(\"\\n\", \"\\n  \"));\n            fail(b.toString());\n          }\n        } else {\n          assertFalse(hits.get(docID));\n        }\n      }\n    }\n\n    IOUtils.close(r, dir);\n  }\n\n","sourceOld":"  private static void verify(double[] lats, double[] lons) throws Exception {\n    IndexWriterConfig iwc = newIndexWriterConfig();\n\n    GeoPoint[] points = new GeoPoint[lats.length];\n    GeoPoint[] unquantizedPoints = new GeoPoint[lats.length];\n    \n    // Pre-quantize all lat/lons:\n    for(int i=0;i<lats.length;i++) {\n      if (Double.isNaN(lats[i]) == false) {\n        //System.out.println(\"lats[\" + i + \"] = \" + lats[i]);\n        unquantizedPoints[i] = new GeoPoint(PlanetModel.WGS84, toRadians(lats[i]), toRadians(lons[i]));\n        points[i] = quantize(unquantizedPoints[i]);\n      }\n    }\n\n    // Else we can get O(N^2) merging:\n    int mbd = iwc.getMaxBufferedDocs();\n    if (mbd != -1 && mbd < points.length/100) {\n      iwc.setMaxBufferedDocs(points.length/100);\n    }\n    iwc.setCodec(getCodec());\n    Directory dir;\n    if (points.length > 100000) {\n      dir = newFSDirectory(createTempDir(\"TestBKDTree\"));\n    } else {\n      dir = getDirectory();\n    }\n    Set<Integer> deleted = new HashSet<>();\n    // RandomIndexWriter is too slow here:\n    IndexWriter w = new IndexWriter(dir, iwc);\n    for(int id=0;id<points.length;id++) {\n      Document doc = new Document();\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"id\", id));\n      GeoPoint point = points[id];\n      if (point != null) {\n        doc.add(new Geo3DPoint(\"point\", point.x, point.y, point.z));\n      }\n      w.addDocument(doc);\n      if (id > 0 && random().nextInt(100) == 42) {\n        int idToDelete = random().nextInt(id);\n        w.deleteDocuments(new Term(\"id\", \"\"+idToDelete));\n        deleted.add(idToDelete);\n        if (VERBOSE) {\n          System.err.println(\"  delete id=\" + idToDelete);\n        }\n      }\n    }\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader r = DirectoryReader.open(w);\n    if (VERBOSE) {\n      System.out.println(\"TEST: using reader \" + r);\n    }\n    w.close();\n\n    // We can't wrap with \"exotic\" readers because the geo3d query must see the Geo3DDVFormat:\n    IndexSearcher s = newSearcher(r, false);\n\n    final int iters = atLeast(100);\n\n    for (int iter=0;iter<iters;iter++) {\n\n      /*\n      GeoShape shape = randomShape();\n\n      if (VERBOSE) {\n        System.err.println(\"\\nTEST: iter=\" + iter + \" shape=\"+shape);\n      }\n      */\n      \n      Query query = random3DQuery(\"point\"); // Geo3DPoint.newShapeQuery(\"point\", shape);\n\n      if (VERBOSE) {\n        System.err.println(\"  using query: \" + query);\n      }\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public ScoreMode scoreMode() {\n            return ScoreMode.COMPLETE_NO_SCORES;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      if (VERBOSE) {\n        System.err.println(\"  hitCount: \" + hits.cardinality());\n      }\n      \n      NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n\n      for(int docID=0;docID<r.maxDoc();docID++) {\n        assertEquals(docID, docIDToID.nextDoc());\n        int id = (int) docIDToID.longValue();\n        GeoPoint point = points[id];\n        GeoPoint unquantizedPoint = unquantizedPoints[id];\n        if (point != null && unquantizedPoint != null) {\n          GeoShape shape = ((PointInGeo3DShapeQuery)query).getShape();\n          XYZBounds bounds = new XYZBounds();\n          shape.getBounds(bounds);\n          XYZSolid solid = XYZSolidFactory.makeXYZSolid(PlanetModel.WGS84, bounds.getMinimumX(), bounds.getMaximumX(), bounds.getMinimumY(), bounds.getMaximumY(), bounds.getMinimumZ(), bounds.getMaximumZ());\n\n          boolean expected = ((deleted.contains(id) == false) && shape.isWithin(point));\n          if (hits.get(docID) != expected) {\n            StringBuilder b = new StringBuilder();\n            if (expected) {\n              b.append(\"FAIL: id=\" + id + \" should have matched but did not\\n\");\n            } else {\n              b.append(\"FAIL: id=\" + id + \" should not have matched but did\\n\");\n            }\n            b.append(\"  shape=\" + shape + \"\\n\");\n            b.append(\"  bounds=\" + bounds + \"\\n\");\n            b.append(\"  world bounds=(\" +\n              \" minX=\" + PlanetModel.WGS84.getMinimumXValue() + \" maxX=\" + PlanetModel.WGS84.getMaximumXValue() +\n              \" minY=\" + PlanetModel.WGS84.getMinimumYValue() + \" maxY=\" + PlanetModel.WGS84.getMaximumYValue() +\n              \" minZ=\" + PlanetModel.WGS84.getMinimumZValue() + \" maxZ=\" + PlanetModel.WGS84.getMaximumZValue() + \"\\n\");\n            b.append(\"  quantized point=\" + point + \" within shape? \"+shape.isWithin(point)+\" within bounds? \"+solid.isWithin(point)+\"\\n\");\n            b.append(\"  unquantized point=\" + unquantizedPoint + \" within shape? \"+shape.isWithin(unquantizedPoint)+\" within bounds? \"+solid.isWithin(unquantizedPoint)+\"\\n\");\n            b.append(\"  docID=\" + docID + \" deleted?=\" + deleted.contains(id) + \"\\n\");\n            b.append(\"  query=\" + query + \"\\n\");\n            b.append(\"  explanation:\\n    \" + explain(\"point\", shape, point, unquantizedPoint, r, docID).replace(\"\\n\", \"\\n  \"));\n            fail(b.toString());\n          }\n        } else {\n          assertFalse(hits.get(docID));\n        }\n      }\n    }\n\n    IOUtils.close(r, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c33ed6824db1d3c54aaf0208e68c3df3fd43d93a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c33ed6824db1d3c54aaf0208e68c3df3fd43d93a"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c33ed6824db1d3c54aaf0208e68c3df3fd43d93a"],"c33ed6824db1d3c54aaf0208e68c3df3fd43d93a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}