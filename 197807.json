{"path":"lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor#processField(FieldInfos.Builder,int,String,IndexableFieldType).mjava","commits":[{"id":"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4","date":1341839195,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor#processField(FieldInfos.Builder,int,String,IndexableFieldType).mjava","pathOld":"/dev/null","sourceNew":"  private DocFieldProcessorPerField processField(FieldInfos.Builder fieldInfos,\n      final int thisFieldGen, final String fieldName, IndexableFieldType ft) {\n    // Make sure we have a PerField allocated\n    final int hashPos = fieldName.hashCode() & hashMask;\n    DocFieldProcessorPerField fp = fieldHash[hashPos];\n    while(fp != null && !fp.fieldInfo.name.equals(fieldName)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n\n      // TODO FI: we need to genericize the \"flags\" that a\n      // field holds, and, how these flags are merged; it\n      // needs to be more \"pluggable\" such that if I want\n      // to have a new \"thing\" my Fields can do, I can\n      // easily add it\n      FieldInfo fi = fieldInfos.addOrUpdate(fieldName, ft);\n\n      fp = new DocFieldProcessorPerField(this, fi);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n    } else {\n      fieldInfos.addOrUpdate(fp.fieldInfo.name, ft);\n    }\n\n    if (thisFieldGen != fp.lastGen) {\n\n      // First time we're seeing this field for this doc\n      fp.fieldCount = 0;\n\n      if (fieldCount == fields.length) {\n        final int newSize = fields.length*2;\n        DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];\n        System.arraycopy(fields, 0, newArray, 0, fieldCount);\n        fields = newArray;\n      }\n\n      fields[fieldCount++] = fp;\n      fp.lastGen = thisFieldGen;\n    }\n    return fp;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor#processField(FieldInfos.Builder,int,String,IndexableFieldType).mjava","pathOld":"/dev/null","sourceNew":"  private DocFieldProcessorPerField processField(FieldInfos.Builder fieldInfos,\n      final int thisFieldGen, final String fieldName, IndexableFieldType ft) {\n    // Make sure we have a PerField allocated\n    final int hashPos = fieldName.hashCode() & hashMask;\n    DocFieldProcessorPerField fp = fieldHash[hashPos];\n    while(fp != null && !fp.fieldInfo.name.equals(fieldName)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n\n      // TODO FI: we need to genericize the \"flags\" that a\n      // field holds, and, how these flags are merged; it\n      // needs to be more \"pluggable\" such that if I want\n      // to have a new \"thing\" my Fields can do, I can\n      // easily add it\n      FieldInfo fi = fieldInfos.addOrUpdate(fieldName, ft);\n\n      fp = new DocFieldProcessorPerField(this, fi);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n    } else {\n      fieldInfos.addOrUpdate(fp.fieldInfo.name, ft);\n    }\n\n    if (thisFieldGen != fp.lastGen) {\n\n      // First time we're seeing this field for this doc\n      fp.fieldCount = 0;\n\n      if (fieldCount == fields.length) {\n        final int newSize = fields.length*2;\n        DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];\n        System.arraycopy(fields, 0, newArray, 0, fieldCount);\n        fields = newArray;\n      }\n\n      fields[fieldCount++] = fp;\n      fp.lastGen = thisFieldGen;\n    }\n    return fp;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"127981e5a1e1d1425c5fdc816ceacf753ca70ee4","date":1354205321,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor#processField(FieldInfos.Builder,int,String,IndexableFieldType).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor#processField(FieldInfos.Builder,int,String,IndexableFieldType).mjava","sourceNew":"  private DocFieldProcessorPerField processField(FieldInfos.Builder fieldInfos,\n      final int thisFieldGen, final String fieldName, IndexableFieldType ft) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = fieldName.hashCode() & hashMask;\n    DocFieldProcessorPerField fp = fieldHash[hashPos];\n    while(fp != null && !fp.fieldInfo.name.equals(fieldName)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n\n      // TODO FI: we need to genericize the \"flags\" that a\n      // field holds, and, how these flags are merged; it\n      // needs to be more \"pluggable\" such that if I want\n      // to have a new \"thing\" my Fields can do, I can\n      // easily add it\n      FieldInfo fi = fieldInfos.addOrUpdate(fieldName, ft);\n\n      fp = new DocFieldProcessorPerField(this, fi);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n    } else {\n      // nocommit this is wasteful: it's another hash lookup\n      // by field name; can we just do fp.fieldInfo.update\n      // directly?\n      fieldInfos.addOrUpdate(fp.fieldInfo.name, ft);\n    }\n\n    if (thisFieldGen != fp.lastGen) {\n\n      // First time we're seeing this field for this doc\n      fp.fieldCount = 0;\n\n      if (fieldCount == fields.length) {\n        final int newSize = fields.length*2;\n        DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];\n        System.arraycopy(fields, 0, newArray, 0, fieldCount);\n        fields = newArray;\n      }\n\n      fields[fieldCount++] = fp;\n      fp.lastGen = thisFieldGen;\n    }\n    return fp;\n  }\n\n","sourceOld":"  private DocFieldProcessorPerField processField(FieldInfos.Builder fieldInfos,\n      final int thisFieldGen, final String fieldName, IndexableFieldType ft) {\n    // Make sure we have a PerField allocated\n    final int hashPos = fieldName.hashCode() & hashMask;\n    DocFieldProcessorPerField fp = fieldHash[hashPos];\n    while(fp != null && !fp.fieldInfo.name.equals(fieldName)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n\n      // TODO FI: we need to genericize the \"flags\" that a\n      // field holds, and, how these flags are merged; it\n      // needs to be more \"pluggable\" such that if I want\n      // to have a new \"thing\" my Fields can do, I can\n      // easily add it\n      FieldInfo fi = fieldInfos.addOrUpdate(fieldName, ft);\n\n      fp = new DocFieldProcessorPerField(this, fi);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n    } else {\n      fieldInfos.addOrUpdate(fp.fieldInfo.name, ft);\n    }\n\n    if (thisFieldGen != fp.lastGen) {\n\n      // First time we're seeing this field for this doc\n      fp.fieldCount = 0;\n\n      if (fieldCount == fields.length) {\n        final int newSize = fields.length*2;\n        DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];\n        System.arraycopy(fields, 0, newArray, 0, fieldCount);\n        fields = newArray;\n      }\n\n      fields[fieldCount++] = fp;\n      fp.lastGen = thisFieldGen;\n    }\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9b830d15919532780f9829c079e3be76ad2976e","date":1359605132,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor#processField(FieldInfos.Builder,int,String,IndexableFieldType).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor#processField(FieldInfos.Builder,int,String,IndexableFieldType).mjava","sourceNew":"  private DocFieldProcessorPerField processField(FieldInfos.Builder fieldInfos,\n      final int thisFieldGen, final String fieldName, IndexableFieldType ft) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = fieldName.hashCode() & hashMask;\n    DocFieldProcessorPerField fp = fieldHash[hashPos];\n    while(fp != null && !fp.fieldInfo.name.equals(fieldName)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n\n      // TODO FI: we need to genericize the \"flags\" that a\n      // field holds, and, how these flags are merged; it\n      // needs to be more \"pluggable\" such that if I want\n      // to have a new \"thing\" my Fields can do, I can\n      // easily add it\n      FieldInfo fi = fieldInfos.addOrUpdate(fieldName, ft);\n\n      fp = new DocFieldProcessorPerField(this, fi);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n    } else {\n      // nocommit: dangerous: maybe FI.update()/FI ctor()/FIS.addOrUpdate need only take FT\n      // instead of a thousand parameters? Surely we can make this better... like:\n      // fp.fieldInfo.update(ft);\n      fp.fieldInfo.update(ft.indexed(), false, ft.omitNorms(), false, ft.indexOptions());\n    }\n\n    if (thisFieldGen != fp.lastGen) {\n\n      // First time we're seeing this field for this doc\n      fp.fieldCount = 0;\n\n      if (fieldCount == fields.length) {\n        final int newSize = fields.length*2;\n        DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];\n        System.arraycopy(fields, 0, newArray, 0, fieldCount);\n        fields = newArray;\n      }\n\n      fields[fieldCount++] = fp;\n      fp.lastGen = thisFieldGen;\n    }\n    return fp;\n  }\n\n","sourceOld":"  private DocFieldProcessorPerField processField(FieldInfos.Builder fieldInfos,\n      final int thisFieldGen, final String fieldName, IndexableFieldType ft) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = fieldName.hashCode() & hashMask;\n    DocFieldProcessorPerField fp = fieldHash[hashPos];\n    while(fp != null && !fp.fieldInfo.name.equals(fieldName)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n\n      // TODO FI: we need to genericize the \"flags\" that a\n      // field holds, and, how these flags are merged; it\n      // needs to be more \"pluggable\" such that if I want\n      // to have a new \"thing\" my Fields can do, I can\n      // easily add it\n      FieldInfo fi = fieldInfos.addOrUpdate(fieldName, ft);\n\n      fp = new DocFieldProcessorPerField(this, fi);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n    } else {\n      // nocommit this is wasteful: it's another hash lookup\n      // by field name; can we just do fp.fieldInfo.update\n      // directly?\n      fieldInfos.addOrUpdate(fp.fieldInfo.name, ft);\n    }\n\n    if (thisFieldGen != fp.lastGen) {\n\n      // First time we're seeing this field for this doc\n      fp.fieldCount = 0;\n\n      if (fieldCount == fields.length) {\n        final int newSize = fields.length*2;\n        DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];\n        System.arraycopy(fields, 0, newArray, 0, fieldCount);\n        fields = newArray;\n      }\n\n      fields[fieldCount++] = fp;\n      fp.lastGen = thisFieldGen;\n    }\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"50110fe9088380a4f557899cce4a52f1257c8494","date":1359751675,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor#processField(FieldInfos.Builder,int,String,IndexableFieldType).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor#processField(FieldInfos.Builder,int,String,IndexableFieldType).mjava","sourceNew":"  private DocFieldProcessorPerField processField(FieldInfos.Builder fieldInfos,\n      final int thisFieldGen, final String fieldName, IndexableFieldType ft) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = fieldName.hashCode() & hashMask;\n    DocFieldProcessorPerField fp = fieldHash[hashPos];\n    while(fp != null && !fp.fieldInfo.name.equals(fieldName)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n\n      // TODO FI: we need to genericize the \"flags\" that a\n      // field holds, and, how these flags are merged; it\n      // needs to be more \"pluggable\" such that if I want\n      // to have a new \"thing\" my Fields can do, I can\n      // easily add it\n      FieldInfo fi = fieldInfos.addOrUpdate(fieldName, ft);\n\n      fp = new DocFieldProcessorPerField(this, fi);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n    } else {\n      fp.fieldInfo.update(ft);\n    }\n\n    if (thisFieldGen != fp.lastGen) {\n\n      // First time we're seeing this field for this doc\n      fp.fieldCount = 0;\n\n      if (fieldCount == fields.length) {\n        final int newSize = fields.length*2;\n        DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];\n        System.arraycopy(fields, 0, newArray, 0, fieldCount);\n        fields = newArray;\n      }\n\n      fields[fieldCount++] = fp;\n      fp.lastGen = thisFieldGen;\n    }\n    return fp;\n  }\n\n","sourceOld":"  private DocFieldProcessorPerField processField(FieldInfos.Builder fieldInfos,\n      final int thisFieldGen, final String fieldName, IndexableFieldType ft) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = fieldName.hashCode() & hashMask;\n    DocFieldProcessorPerField fp = fieldHash[hashPos];\n    while(fp != null && !fp.fieldInfo.name.equals(fieldName)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n\n      // TODO FI: we need to genericize the \"flags\" that a\n      // field holds, and, how these flags are merged; it\n      // needs to be more \"pluggable\" such that if I want\n      // to have a new \"thing\" my Fields can do, I can\n      // easily add it\n      FieldInfo fi = fieldInfos.addOrUpdate(fieldName, ft);\n\n      fp = new DocFieldProcessorPerField(this, fi);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n    } else {\n      // nocommit: dangerous: maybe FI.update()/FI ctor()/FIS.addOrUpdate need only take FT\n      // instead of a thousand parameters? Surely we can make this better... like:\n      // fp.fieldInfo.update(ft);\n      fp.fieldInfo.update(ft.indexed(), false, ft.omitNorms(), false, ft.indexOptions());\n    }\n\n    if (thisFieldGen != fp.lastGen) {\n\n      // First time we're seeing this field for this doc\n      fp.fieldCount = 0;\n\n      if (fieldCount == fields.length) {\n        final int newSize = fields.length*2;\n        DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];\n        System.arraycopy(fields, 0, newArray, 0, fieldCount);\n        fields = newArray;\n      }\n\n      fields[fieldCount++] = fp;\n      fp.lastGen = thisFieldGen;\n    }\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor#processField(FieldInfos.Builder,int,String,IndexableFieldType).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor#processField(FieldInfos.Builder,int,String,IndexableFieldType).mjava","sourceNew":"  private DocFieldProcessorPerField processField(FieldInfos.Builder fieldInfos,\n      final int thisFieldGen, final String fieldName, IndexableFieldType ft) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = fieldName.hashCode() & hashMask;\n    DocFieldProcessorPerField fp = fieldHash[hashPos];\n    while(fp != null && !fp.fieldInfo.name.equals(fieldName)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n\n      // TODO FI: we need to genericize the \"flags\" that a\n      // field holds, and, how these flags are merged; it\n      // needs to be more \"pluggable\" such that if I want\n      // to have a new \"thing\" my Fields can do, I can\n      // easily add it\n      FieldInfo fi = fieldInfos.addOrUpdate(fieldName, ft);\n\n      fp = new DocFieldProcessorPerField(this, fi);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n    } else {\n      fp.fieldInfo.update(ft);\n    }\n\n    if (thisFieldGen != fp.lastGen) {\n\n      // First time we're seeing this field for this doc\n      fp.fieldCount = 0;\n\n      if (fieldCount == fields.length) {\n        final int newSize = fields.length*2;\n        DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];\n        System.arraycopy(fields, 0, newArray, 0, fieldCount);\n        fields = newArray;\n      }\n\n      fields[fieldCount++] = fp;\n      fp.lastGen = thisFieldGen;\n    }\n    return fp;\n  }\n\n","sourceOld":"  private DocFieldProcessorPerField processField(FieldInfos.Builder fieldInfos,\n      final int thisFieldGen, final String fieldName, IndexableFieldType ft) {\n    // Make sure we have a PerField allocated\n    final int hashPos = fieldName.hashCode() & hashMask;\n    DocFieldProcessorPerField fp = fieldHash[hashPos];\n    while(fp != null && !fp.fieldInfo.name.equals(fieldName)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n\n      // TODO FI: we need to genericize the \"flags\" that a\n      // field holds, and, how these flags are merged; it\n      // needs to be more \"pluggable\" such that if I want\n      // to have a new \"thing\" my Fields can do, I can\n      // easily add it\n      FieldInfo fi = fieldInfos.addOrUpdate(fieldName, ft);\n\n      fp = new DocFieldProcessorPerField(this, fi);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n    } else {\n      fieldInfos.addOrUpdate(fp.fieldInfo.name, ft);\n    }\n\n    if (thisFieldGen != fp.lastGen) {\n\n      // First time we're seeing this field for this doc\n      fp.fieldCount = 0;\n\n      if (fieldCount == fields.length) {\n        final int newSize = fields.length*2;\n        DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];\n        System.arraycopy(fields, 0, newArray, 0, fieldCount);\n        fields = newArray;\n      }\n\n      fields[fieldCount++] = fp;\n      fp.lastGen = thisFieldGen;\n    }\n    return fp;\n  }\n\n","bugFix":["8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"52c7e49be259508735752fba88085255014a6ecf","date":1398706273,"type":4,"author":"Michael McCandless","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor#processField(FieldInfos.Builder,int,String,IndexableFieldType).mjava","sourceNew":null,"sourceOld":"  private DocFieldProcessorPerField processField(FieldInfos.Builder fieldInfos,\n      final int thisFieldGen, final String fieldName, IndexableFieldType ft) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = fieldName.hashCode() & hashMask;\n    DocFieldProcessorPerField fp = fieldHash[hashPos];\n    while(fp != null && !fp.fieldInfo.name.equals(fieldName)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n\n      // TODO FI: we need to genericize the \"flags\" that a\n      // field holds, and, how these flags are merged; it\n      // needs to be more \"pluggable\" such that if I want\n      // to have a new \"thing\" my Fields can do, I can\n      // easily add it\n      FieldInfo fi = fieldInfos.addOrUpdate(fieldName, ft);\n\n      fp = new DocFieldProcessorPerField(this, fi);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n    } else {\n      fp.fieldInfo.update(ft);\n    }\n\n    if (thisFieldGen != fp.lastGen) {\n\n      // First time we're seeing this field for this doc\n      fp.fieldCount = 0;\n\n      if (fieldCount == fields.length) {\n        final int newSize = fields.length*2;\n        DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];\n        System.arraycopy(fields, 0, newArray, 0, fieldCount);\n        fields = newArray;\n      }\n\n      fields[fieldCount++] = fp;\n      fp.lastGen = thisFieldGen;\n    }\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3394716f52b34ab259ad5247e7595d9f9db6e935","date":1398791921,"type":4,"author":"Michael McCandless","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor#processField(FieldInfos.Builder,int,String,IndexableFieldType).mjava","sourceNew":null,"sourceOld":"  private DocFieldProcessorPerField processField(FieldInfos.Builder fieldInfos,\n      final int thisFieldGen, final String fieldName, IndexableFieldType ft) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = fieldName.hashCode() & hashMask;\n    DocFieldProcessorPerField fp = fieldHash[hashPos];\n    while(fp != null && !fp.fieldInfo.name.equals(fieldName)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n\n      // TODO FI: we need to genericize the \"flags\" that a\n      // field holds, and, how these flags are merged; it\n      // needs to be more \"pluggable\" such that if I want\n      // to have a new \"thing\" my Fields can do, I can\n      // easily add it\n      FieldInfo fi = fieldInfos.addOrUpdate(fieldName, ft);\n\n      fp = new DocFieldProcessorPerField(this, fi);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n    } else {\n      fp.fieldInfo.update(ft);\n    }\n\n    if (thisFieldGen != fp.lastGen) {\n\n      // First time we're seeing this field for this doc\n      fp.fieldCount = 0;\n\n      if (fieldCount == fields.length) {\n        final int newSize = fields.length*2;\n        DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];\n        System.arraycopy(fields, 0, newArray, 0, fieldCount);\n        fields = newArray;\n      }\n\n      fields[fieldCount++] = fp;\n      fp.lastGen = thisFieldGen;\n    }\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","date":1398844771,"type":4,"author":"Dawid Weiss","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocFieldProcessor#processField(FieldInfos.Builder,int,String,IndexableFieldType).mjava","sourceNew":null,"sourceOld":"  private DocFieldProcessorPerField processField(FieldInfos.Builder fieldInfos,\n      final int thisFieldGen, final String fieldName, IndexableFieldType ft) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = fieldName.hashCode() & hashMask;\n    DocFieldProcessorPerField fp = fieldHash[hashPos];\n    while(fp != null && !fp.fieldInfo.name.equals(fieldName)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n\n      // TODO FI: we need to genericize the \"flags\" that a\n      // field holds, and, how these flags are merged; it\n      // needs to be more \"pluggable\" such that if I want\n      // to have a new \"thing\" my Fields can do, I can\n      // easily add it\n      FieldInfo fi = fieldInfos.addOrUpdate(fieldName, ft);\n\n      fp = new DocFieldProcessorPerField(this, fi);\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n    } else {\n      fp.fieldInfo.update(ft);\n    }\n\n    if (thisFieldGen != fp.lastGen) {\n\n      // First time we're seeing this field for this doc\n      fp.fieldCount = 0;\n\n      if (fieldCount == fields.length) {\n        final int newSize = fields.length*2;\n        DocFieldProcessorPerField newArray[] = new DocFieldProcessorPerField[newSize];\n        System.arraycopy(fields, 0, newArray, 0, fieldCount);\n        fields = newArray;\n      }\n\n      fields[fieldCount++] = fp;\n      fp.lastGen = thisFieldGen;\n    }\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3394716f52b34ab259ad5247e7595d9f9db6e935":["d4d69c535930b5cce125cff868d40f6373dc27d4","52c7e49be259508735752fba88085255014a6ecf"],"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1d028314cced5858683a1bb4741423d0f934257b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":["d4d69c535930b5cce125cff868d40f6373dc27d4","3394716f52b34ab259ad5247e7595d9f9db6e935"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["1d028314cced5858683a1bb4741423d0f934257b","50110fe9088380a4f557899cce4a52f1257c8494"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"127981e5a1e1d1425c5fdc816ceacf753ca70ee4":["1d028314cced5858683a1bb4741423d0f934257b"],"e9b830d15919532780f9829c079e3be76ad2976e":["127981e5a1e1d1425c5fdc816ceacf753ca70ee4"],"50110fe9088380a4f557899cce4a52f1257c8494":["e9b830d15919532780f9829c079e3be76ad2976e"],"52c7e49be259508735752fba88085255014a6ecf":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3394716f52b34ab259ad5247e7595d9f9db6e935"]},"commit2Childs":{"3394716f52b34ab259ad5247e7595d9f9db6e935":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4":["1d028314cced5858683a1bb4741423d0f934257b"],"1d028314cced5858683a1bb4741423d0f934257b":["d4d69c535930b5cce125cff868d40f6373dc27d4","127981e5a1e1d1425c5fdc816ceacf753ca70ee4"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":[],"d4d69c535930b5cce125cff868d40f6373dc27d4":["3394716f52b34ab259ad5247e7595d9f9db6e935","c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","52c7e49be259508735752fba88085255014a6ecf"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4","1d028314cced5858683a1bb4741423d0f934257b"],"127981e5a1e1d1425c5fdc816ceacf753ca70ee4":["e9b830d15919532780f9829c079e3be76ad2976e"],"e9b830d15919532780f9829c079e3be76ad2976e":["50110fe9088380a4f557899cce4a52f1257c8494"],"50110fe9088380a4f557899cce4a52f1257c8494":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"52c7e49be259508735752fba88085255014a6ecf":["3394716f52b34ab259ad5247e7595d9f9db6e935"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}