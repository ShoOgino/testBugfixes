{"path":"modules/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergePolicy().mjava","commits":[{"id":"ecc11368dc265bfdad90214f8bf5da99016ab1e2","date":1294144090,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"modules/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergePolicy().mjava","pathOld":"lucene/contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergePolicy().mjava","sourceNew":"  /**\n   * Test that we can set merge policy\".\n   */\n  public void testMergePolicy() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"ram.flush.mb=-1\",\n        \"max.buffered=2\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.policy=\" + MyMergePolicy.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n    assertTrue(\"did not use the specified MergePolicy\", ((MyMergePolicy) benchmark.getRunData().getIndexWriter().getConfig().getMergePolicy()).called);\n    benchmark.getRunData().getIndexWriter().close();\n    \n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that we can set merge policy\".\n   */\n  public void testMergePolicy() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"ram.flush.mb=-1\",\n        \"max.buffered=2\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.policy=\" + MyMergePolicy.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n    assertTrue(\"did not use the specified MergePolicy\", ((MyMergePolicy) benchmark.getRunData().getIndexWriter().getConfig().getMergePolicy()).called);\n    benchmark.getRunData().getIndexWriter().close();\n    \n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergePolicy().mjava","pathOld":"lucene/contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergePolicy().mjava","sourceNew":"  /**\n   * Test that we can set merge policy\".\n   */\n  public void testMergePolicy() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"ram.flush.mb=-1\",\n        \"max.buffered=2\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.policy=\" + MyMergePolicy.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n    assertTrue(\"did not use the specified MergePolicy\", ((MyMergePolicy) benchmark.getRunData().getIndexWriter().getConfig().getMergePolicy()).called);\n    benchmark.getRunData().getIndexWriter().close();\n    \n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that we can set merge policy\".\n   */\n  public void testMergePolicy() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"ram.flush.mb=-1\",\n        \"max.buffered=2\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.policy=\" + MyMergePolicy.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n    assertTrue(\"did not use the specified MergePolicy\", ((MyMergePolicy) benchmark.getRunData().getIndexWriter().getConfig().getMergePolicy()).called);\n    benchmark.getRunData().getIndexWriter().close();\n    \n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":1,"author":"Michael Busch","isMerge":true,"pathNew":"modules/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergePolicy().mjava","pathOld":"lucene/contrib/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergePolicy().mjava","sourceNew":"  /**\n   * Test that we can set merge policy\".\n   */\n  public void testMergePolicy() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"ram.flush.mb=-1\",\n        \"max.buffered=2\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.policy=\" + MyMergePolicy.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n    assertTrue(\"did not use the specified MergePolicy\", ((MyMergePolicy) benchmark.getRunData().getIndexWriter().getConfig().getMergePolicy()).called);\n    benchmark.getRunData().getIndexWriter().close();\n    \n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that we can set merge policy\".\n   */\n  public void testMergePolicy() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"ram.flush.mb=-1\",\n        \"max.buffered=2\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.policy=\" + MyMergePolicy.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n    assertTrue(\"did not use the specified MergePolicy\", ((MyMergePolicy) benchmark.getRunData().getIndexWriter().getConfig().getMergePolicy()).called);\n    benchmark.getRunData().getIndexWriter().close();\n    \n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9f2f1c6050eb49fa5cb22fbdf977c76e65ea3caf","date":1323050351,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergePolicy().mjava","pathOld":"modules/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergePolicy().mjava","sourceNew":"  /**\n   * Test that we can set merge policy\".\n   */\n  public void testMergePolicy() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"ram.flush.mb=-1\",\n        \"max.buffered=2\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.policy=\" + MyMergePolicy.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n    assertTrue(\"did not use the specified MergePolicy\", ((MyMergePolicy) benchmark.getRunData().getIndexWriter().getConfig().getMergePolicy()).called);\n    benchmark.getRunData().getIndexWriter().close();\n    \n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that we can set merge policy\".\n   */\n  public void testMergePolicy() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"ram.flush.mb=-1\",\n        \"max.buffered=2\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.policy=\" + MyMergePolicy.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n    assertTrue(\"did not use the specified MergePolicy\", ((MyMergePolicy) benchmark.getRunData().getIndexWriter().getConfig().getMergePolicy()).called);\n    benchmark.getRunData().getIndexWriter().close();\n    \n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"modules/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergePolicy().mjava","pathOld":"modules/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergePolicy().mjava","sourceNew":"  /**\n   * Test that we can set merge policy\".\n   */\n  public void testMergePolicy() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"ram.flush.mb=-1\",\n        \"max.buffered=2\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.policy=\" + MyMergePolicy.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n    assertTrue(\"did not use the specified MergePolicy\", ((MyMergePolicy) benchmark.getRunData().getIndexWriter().getConfig().getMergePolicy()).called);\n    benchmark.getRunData().getIndexWriter().close();\n    \n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that we can set merge policy\".\n   */\n  public void testMergePolicy() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"ram.flush.mb=-1\",\n        \"max.buffered=2\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.policy=\" + MyMergePolicy.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n    assertTrue(\"did not use the specified MergePolicy\", ((MyMergePolicy) benchmark.getRunData().getIndexWriter().getConfig().getMergePolicy()).called);\n    benchmark.getRunData().getIndexWriter().close();\n    \n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"modules/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergePolicy().mjava","pathOld":"modules/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergePolicy().mjava","sourceNew":"  /**\n   * Test that we can set merge policy\".\n   */\n  public void testMergePolicy() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"ram.flush.mb=-1\",\n        \"max.buffered=2\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.policy=\" + MyMergePolicy.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n    assertTrue(\"did not use the specified MergePolicy\", ((MyMergePolicy) benchmark.getRunData().getIndexWriter().getConfig().getMergePolicy()).called);\n    benchmark.getRunData().getIndexWriter().close();\n    \n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that we can set merge policy\".\n   */\n  public void testMergePolicy() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"ram.flush.mb=-1\",\n        \"max.buffered=2\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.policy=\" + MyMergePolicy.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n    assertTrue(\"did not use the specified MergePolicy\", ((MyMergePolicy) benchmark.getRunData().getIndexWriter().getConfig().getMergePolicy()).called);\n    benchmark.getRunData().getIndexWriter().close();\n    \n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory(), true);\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergePolicy().mjava","pathOld":"modules/benchmark/src/test/org/apache/lucene/benchmark/byTask/TestPerfTasksLogic#testMergePolicy().mjava","sourceNew":"  /**\n   * Test that we can set merge policy\".\n   */\n  public void testMergePolicy() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"ram.flush.mb=-1\",\n        \"max.buffered=2\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.policy=\" + MyMergePolicy.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n    assertTrue(\"did not use the specified MergePolicy\", ((MyMergePolicy) benchmark.getRunData().getIndexWriter().getConfig().getMergePolicy()).called);\n    benchmark.getRunData().getIndexWriter().close();\n    \n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that we can set merge policy\".\n   */\n  public void testMergePolicy() throws Exception {\n    // 1. alg definition (required in every \"logic\" test)\n    String algLines[] = {\n        \"# ----- properties \",\n        \"content.source=org.apache.lucene.benchmark.byTask.feeds.LineDocSource\",\n        \"docs.file=\" + getReuters20LinesFile(),\n        \"content.source.log.step=3\",\n        \"ram.flush.mb=-1\",\n        \"max.buffered=2\",\n        \"doc.term.vector=false\",\n        \"content.source.forever=false\",\n        \"directory=RAMDirectory\",\n        \"merge.policy=\" + MyMergePolicy.class.getName(),\n        \"doc.stored=false\",\n        \"doc.tokenized=false\",\n        \"debug.level=1\",\n        \"# ----- alg \",\n        \"{ \\\"Rounds\\\"\",\n        \"  ResetSystemErase\",\n        \"  CreateIndex\",\n        \"  { \\\"AddDocs\\\"  AddDoc > : * \",\n        \"} : 2\",\n    };\n\n    // 2. execute the algorithm  (required in every \"logic\" test)\n    Benchmark benchmark = execBenchmark(algLines);\n    assertTrue(\"did not use the specified MergePolicy\", ((MyMergePolicy) benchmark.getRunData().getIndexWriter().getConfig().getMergePolicy()).called);\n    benchmark.getRunData().getIndexWriter().close();\n    \n    // 3. test number of docs in the index\n    IndexReader ir = IndexReader.open(benchmark.getRunData().getDirectory());\n    int ndocsExpected = 20; // first 20 reuters docs.\n    assertEquals(\"wrong number of docs in the index!\", ndocsExpected, ir.numDocs());\n    ir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9f2f1c6050eb49fa5cb22fbdf977c76e65ea3caf":["ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"70ad682703b8585f5d0a637efec044d57ec05efb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"ecc11368dc265bfdad90214f8bf5da99016ab1e2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["ecc11368dc265bfdad90214f8bf5da99016ab1e2","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ecc11368dc265bfdad90214f8bf5da99016ab1e2","9f2f1c6050eb49fa5cb22fbdf977c76e65ea3caf"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"9f2f1c6050eb49fa5cb22fbdf977c76e65ea3caf":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"70ad682703b8585f5d0a637efec044d57ec05efb":[],"ecc11368dc265bfdad90214f8bf5da99016ab1e2":["9f2f1c6050eb49fa5cb22fbdf977c76e65ea3caf","70ad682703b8585f5d0a637efec044d57ec05efb","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3615ce4a1f785ae1b779244de52c6a7d99227e60","868da859b43505d9d2a023bfeae6dd0c795f5295"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["70ad682703b8585f5d0a637efec044d57ec05efb","ecc11368dc265bfdad90214f8bf5da99016ab1e2","868da859b43505d9d2a023bfeae6dd0c795f5295"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["b89678825b68eccaf09e6ab71675fc0b0af1e099","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00"],"868da859b43505d9d2a023bfeae6dd0c795f5295":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["70ad682703b8585f5d0a637efec044d57ec05efb","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}